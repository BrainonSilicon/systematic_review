Authors,Author(s) ID,Title,Year,Source title,Volume,Issue,Art. No.,Page start,Page end,Page count,Cited by,DOI,Link,Affiliations,Authors with affiliations,Abstract,Author Keywords,Index Keywords,Document Type,Publication Stage,Open Access,Source,EID
"Fristedt S., Smith F., Grynne A., Browall M.","55084313400;55346672700;57221701745;13102729200;","Digi-Do: a digital information tool to support patients with breast cancer before, during, and after start of radiotherapy treatment: an RCT study protocol",2021,"BMC Medical Informatics and Decision Making","21","1", 76,"","",,,"10.1186/s12911-021-01448-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101771341&doi=10.1186%2fs12911-021-01448-3&partnerID=40&md5=20d63504c6ce82e8a6c6276d22fd80f8","Jönköping Academy For Improvement of Health and Welfare and IMPROVE, School of Health and Welfare, Jönköping University, Jönköping, Sweden; Department of Health Sciences, Faculty of Medicine, Lund University, Lund, Sweden; Regional Cancer Centre West, Gothenburg, Sweden; Department of Technology Management and Economics, Chalmers University of Technology, Gothenburg, Sweden; Department of Nursing and IMPROVE, School of Health and Welfare, Jönköping University, Jönköping, Sweden; Affiliated with the Department of Oncology, Institute of Clinical Sciences, Sahlgrenska Academy, University of Gothenburg, Gothenburg, Sweden","Fristedt, S., Jönköping Academy For Improvement of Health and Welfare and IMPROVE, School of Health and Welfare, Jönköping University, Jönköping, Sweden, Department of Health Sciences, Faculty of Medicine, Lund University, Lund, Sweden; Smith, F., Regional Cancer Centre West, Gothenburg, Sweden, Department of Technology Management and Economics, Chalmers University of Technology, Gothenburg, Sweden; Grynne, A., Department of Nursing and IMPROVE, School of Health and Welfare, Jönköping University, Jönköping, Sweden; Browall, M., Department of Nursing and IMPROVE, School of Health and Welfare, Jönköping University, Jönköping, Sweden, Affiliated with the Department of Oncology, Institute of Clinical Sciences, Sahlgrenska Academy, University of Gothenburg, Gothenburg, Sweden","Background: Radiation Therapy (RT) is a common treatment after breast cancer surgery and a complex process using high energy X-rays to eradicate cancer cells, important in reducing the risk of local recurrence. The high-tech environment and unfamiliar nature of RT can affect the patient’s experience of the treatment. Misconceptions or lack of knowledge about RT processes can increase levels of anxiety and enhance feelings of being unprepared at the beginning of treatment. Moreover, the waiting time is often quite long. The primary aim of this study will be to evaluate whether a digital information tool with VR-technology and preparatory information can decrease distress as well as enhance the self-efficacy and health literacy of patients affected by breast cancer before, during, and after RT. A secondary aim will be to explore whether the digital information tool increase patient flow while maintaining or increasing the quality of care. Method: The study is a prospective and longitudinal RCT study with an Action Research participatory design approach including mixed-methods data collection, i.e., standardised instruments, qualitative interviews (face-to-face and telephone) with a phenomenological hermeneutical approach, diaries, observations, and time measurements, and scheduled to take place from autumn 2020 to spring 2022. The intervention group (n = 80), will receive standard care and information (oral and written) and the digital information tool; and the control group (n = 80), will receive standard care and information (oral and written). Study recruitment and randomisation will be completed at two centres in the west of Sweden. Discussion: Research in this area is scarce and, to our knowledge, only few previous studies examine VR as a tool for increasing preparedness for patients with breast cancer about to undergo RT that also includes follow-ups six months after completed treatment. The participatory approach and design will safeguard the possibilities to capture the patient perspective throughout the development process, and the RCT design supports high research quality. Digitalisation brings new possibilities to provide safe, person-centred information that also displays a realistic picture of RT treatment and its contexts. The planned study will generate generalisable knowledge of relevance in similar health care contexts. Trial registration: ClinicalTrials.gov Identifier: NCT04394325. Registered May 19, 2020. Prospectively registered. © 2021, The Author(s).","Evaluation; Health literacy; Participatory design; Self-efficacy; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85101771341
"Monteiro P., Melo M., Valente A., Vasconcelos-Raposo J., Bessa M.","57201131572;7102354924;7102410111;36070012200;14031038800;","Delivering Critical Stimuli for Decision Making in VR Training: Evaluation Study of a Firefighter Training Scenario",2021,"IEEE Transactions on Human-Machine Systems","51","2", 9247430,"65","74",,,"10.1109/THMS.2020.3030746","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103091552&doi=10.1109%2fTHMS.2020.3030746&partnerID=40&md5=2ab0568260ec97afacd284c5f8dae21d","Inesc Tec, Porto, 4200-465, Portugal; Universidade de Trás-os-Montes e Alto Douro, Vila Real, 5000-801, Portugal","Monteiro, P., Inesc Tec, Porto, 4200-465, Portugal; Melo, M., Inesc Tec, Porto, 4200-465, Portugal; Valente, A., Inesc Tec, Porto, 4200-465, Portugal, Universidade de Trás-os-Montes e Alto Douro, Vila Real, 5000-801, Portugal; Vasconcelos-Raposo, J., Inesc Tec, Porto, 4200-465, Portugal, Universidade de Trás-os-Montes e Alto Douro, Vila Real, 5000-801, Portugal; Bessa, M., Inesc Tec, Porto, 4200-465, Portugal, Universidade de Trás-os-Montes e Alto Douro, Vila Real, 5000-801, Portugal","The goal for a virtual reality (VR) training system is to enable trainees to acquire all the knowledge they need to perform effectively in a real environment. Such a system should provide an experience so authentic that no further real-world training is necessary, meaning that it is sufficient to train in VR. We evaluate the impact of a haptic thermal stimulus, which is of paramount importance to decision making, on trainees performance and knowledge acquisition. A thermal device was created to deliver the stimulus. As a proof of concept, a procedure from firefighter training is selected, in which sensing the temperature of a door with one's hand is essential. The sample consisted of 48 subjects divided among three experimental scenarios: one in which a virtual thermometer is used (visual stimulus), another in which the temperature is felt with the hand (thermal stimulus) and a third in which both methods are used (visual + thermal stimuli). For the performance evaluation, we measured the total time taken, the numbers of correctly executed procedures and identified neutral planes, the deviation from the target height, and the responses to a knowledge transfer questionnaire. Presence, cybersickness, and usability are measured to evaluate the impact of the haptic thermal stimulus. Considering the thermal stimulus condition as the baseline, we conclude that the significantly different results in the performance among the conditions indicate that the better performance in the visual-only condition is not representative of the real-life performance. Consequently, VR training applications need to deliver the correct stimuli for decision making. © 2013 IEEE.","Firefighters; haptic cues; multisensory displays; thermal; training; virtual reality (VR)","Fire extinguishers; Knowledge acquisition; Knowledge management; Virtual reality; Evaluation study; Knowledge transfer; Proof of concept; Real environments; Real-life performance; Training applications; Training scenario; Training Systems; Decision making",Article,"Final","",Scopus,2-s2.0-85103091552
"Baceviciute S., Terkildsen T., Makransky G.","55441702500;57205338475;50361371800;","Remediating learning from non-immersive to immersive media: Using EEG to investigate the effects of environmental embeddedness on reading in Virtual Reality",2021,"Computers and Education","164",, 104122,"","",,,"10.1016/j.compedu.2020.104122","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100105880&doi=10.1016%2fj.compedu.2020.104122&partnerID=40&md5=0e064f3f47964fe4caef507e98daa3ff","University of Copenhagen, Department of Psychology, Denmark","Baceviciute, S., University of Copenhagen, Department of Psychology, Denmark; Terkildsen, T., University of Copenhagen, Department of Psychology, Denmark; Makransky, G., University of Copenhagen, Department of Psychology, Denmark","Virtual Reality (VR) has the potential to enrich education but little is known about how unique affordances of immersive technology might influence leaning and cognition. This study investigates one particular affordance of VR, namely environmental embeddedness, which enables learners to be situated in simulated or imagined settings that contextualize their learning. A sample of 51 university students were administered written learning material in a between-subjects design study, wherein one group read text about sarcoma cancer on a physical pamphlet in the real world, and the other group read identical text on a virtual pamphlet embedded in an immersive VR environment which resembled a hospital room. The study combined advanced EEG measurement techniques, learning tests, and cognitive load measures to compare conditions. Results show that the VR group performed significantly better on a knowledge transfer post-test. However, reading in VR was found to be more cognitively effortful and less time-efficient. Findings suggest the significance of environmental embeddedness for learning, and provide important considerations for the design of educational VR environments, as we remediate learning content from non-immersive to immersive media. © 2021 Elsevier Ltd","EEG; Embeddedness; Learning; Remediation; Virtual reality environments","E-learning; Knowledge management; Remediation; Cognitive loads; Immersive media; Immersive technologies; Knowledge transfer; Learning contents; Learning materials; Measurement techniques; University students; Virtual reality",Article,"Final","",Scopus,2-s2.0-85100105880
"Araiza-Alba P., Keane T., Chen W.S., Kaufman J.","57191667278;55582336900;57188973057;7403022831;","Immersive virtual reality as a tool to learn problem-solving skills",2021,"Computers and Education","164",, 104121,"","",,,"10.1016/j.compedu.2020.104121","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099353627&doi=10.1016%2fj.compedu.2020.104121&partnerID=40&md5=82079d081459ac2caf3cea01c4ad7087","Swinburne University of Technology, PO Box 218, Hawthorn, Victoria, Australia","Araiza-Alba, P., Swinburne University of Technology, PO Box 218, Hawthorn, Victoria, Australia; Keane, T., Swinburne University of Technology, PO Box 218, Hawthorn, Victoria, Australia; Chen, W.S., Swinburne University of Technology, PO Box 218, Hawthorn, Victoria, Australia; Kaufman, J., Swinburne University of Technology, PO Box 218, Hawthorn, Victoria, Australia","Immersive virtual reality (IVR) technology has demonstrated positive educational outcomes related to its use and is gaining traction in educational and training settings; IVR is expected to have widespread adoption within the classroom in the upcoming years. However, the educational potential of IVR with children has not been thoroughly investigated, especially as a tool for problem-solving skills. Therefore, this study was designed to answer the following questions: (1) Is IVR a useful tool to learn and practice problem-solving skills? More specifically, do children using IVR solve a game better than those using a tablet application or a board game? (2) Does IVR provide a more engaging experience for children to practice problem-solving skills than on a tablet or a board game? (3) Do problem-solving skills learned with IVR technology transfer to real-life (physical game)? Children (n = 120) aged 7–9.9 years were randomly assigned to a problem-solving game in one of three conditions: board game, tablet, or IVR. The results showed that, overall, the percentage of children who completed the problem-solving game was higher in the IVR condition (77.5%), compared with those in the tablet (32.5%) or board game (30%) conditions. We also found that the interest and enjoyment scores of participants using IVR were significantly higher than participants in the other two conditions, and that the children in the IVR condition were able to learn how to solve the problem and transfer their learning to the physical game. IVR is a technology capable of engaging interest and motivating the user, as well as having the potential to assist in cognitive processing and knowledge transfer. © 2021 Elsevier Ltd","21st century abilities; Elementary education; Games; Problem-solving skills; Virtual reality","Knowledge management; Technology transfer; Transfer learning; Board games; Cognitive processing; Educational potential; Immersive virtual reality; Knowledge transfer; Physical games; Problem solving skills; Tablet applications; Virtual reality",Article,"Final","",Scopus,2-s2.0-85099353627
"Ozcinar C., İmamoğlu N., Wang W., Smolic A.","57211460523;38061650600;57213601132;57204958271;","Delivery of omnidirectional video using saliency prediction and optimal bitrate allocation",2021,"Signal, Image and Video Processing","15","3",,"493","500",,,"10.1007/s11760-020-01769-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090784192&doi=10.1007%2fs11760-020-01769-2&partnerID=40&md5=09390fc7a72cc1d7c7f88d20468860a9","V-SENSE, Trinity College Dublin, Dublin, Ireland; Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology, Tokyo, Japan","Ozcinar, C., V-SENSE, Trinity College Dublin, Dublin, Ireland; İmamoğlu, N., Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; Wang, W., Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; Smolic, A., V-SENSE, Trinity College Dublin, Dublin, Ireland","In this work, we propose and investigate a user-centric framework for the delivery of omnidirectional video (ODV) on VR systems by taking advantage of visual attention (saliency) models for bitrate allocation module. For this purpose, we formulate a new bitrate allocation algorithm that takes saliency map and nonlinear sphere-to-plane mapping into account for each ODV and solve the formulated problem using linear integer programming. For visual attention models, we use both image- and video-based saliency prediction results; moreover, we explore two types of attention model approaches: (i) salient object detection with transfer learning using pre-trained networks, (ii) saliency prediction with supervised networks trained on eye-fixation dataset. Experimental evaluations on saliency integration of models are discussed with interesting findings on transfer learning and supervised saliency approaches. © 2020, Springer-Verlag London Ltd., part of Springer Nature.","360 ∘ Video streaming; Attention-based bitrate allocation; Saliency maps with transfer learning and supervision","Behavioral research; Forecasting; Integer programming; Object detection; Transfer learning; Bit-rate allocation; Experimental evaluation; Formulated problems; Linear integer programming; Salient object detection; Supervised network; Visual Attention; Visual attention model; Learning systems",Article,"Final","",Scopus,2-s2.0-85090784192
"Cheng M., Anderson M., Levac D.E.","57222585846;57222586805;25937323900;","Performance Variability During Motor Learning of a New Balance Task in a Non-immersive Virtual Environment in Children With Hemiplegic Cerebral Palsy and Typically Developing Peers",2021,"Frontiers in Neurology","12",, 623200,"","",,,"10.3389/fneur.2021.623200","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103329101&doi=10.3389%2ffneur.2021.623200&partnerID=40&md5=dabc59fc0853ed3646ac10dc4f0d0d8f","Rehabilitation Games and Virtual Reality Laboratory, Department of Physical Therapy, Movement and Rehabilitation Sciences, Northeastern University, Boston, MA, United States; Department of Biology, Macalester College, St. Paul, MN, United States","Cheng, M., Rehabilitation Games and Virtual Reality Laboratory, Department of Physical Therapy, Movement and Rehabilitation Sciences, Northeastern University, Boston, MA, United States; Anderson, M., Department of Biology, Macalester College, St. Paul, MN, United States; Levac, D.E., Rehabilitation Games and Virtual Reality Laboratory, Department of Physical Therapy, Movement and Rehabilitation Sciences, Northeastern University, Boston, MA, United States","Background: Motor impairments contribute to performance variability in children with cerebral palsy (CP) during motor skill learning. Non-immersive virtual environments (VEs) are popular interventions to promote motor learning in children with hemiplegic CP. Greater understanding of performance variability as compared to typically developing (TD) peers during motor learning in VEs may inform clinical decisions about practice dose and challenge progression. Purpose: (1) To quantify within-child (i.e., across different timepoints) and between-child (i.e., between children at the same timepoint) variability in motor skill acquisition, retention and transfer in a non-immersive VE in children with CP as compared to TD children; and (2) To explore the relationship between the amount of within-child variability during skill acquisition and learning outcomes. Methods: Secondary data analysis of 2 studies in which 13 children with hemiplegic CP and 67 TD children aged 7–14 years undertook repeated trials of a novel standing postural control task in acquisition, retention and transfer sessions. Changes in performance across trials and sessions in children with CP as compared to TD children and between younger (7–10 years) and older (11–14 years) children were assessed using mixed effects models. Raw scores were converted to z-scores to meet model distributional assumptions. Performance variability was quantified as the standard deviation of z-scores. Results: TD children outperformed children with CP and older children outperformed younger children at each session. Older children with CP had the least between-child variability in acquisition and the most in retention, while older TD children demonstrated the opposite pattern. Younger children with CP had consistently high between-child variability, with no difference between sessions. Within-child variability was highest in younger children, regardless of group. Within-child variability was more pronounced in TD children as compared to children with CP. The relationship between the amount of within-child variability in performance and performance outcome at acquisition, retention and transfer sessions was task-specific, with a positive correlation for 1 study and a negative correlation in the other. Conclusions: Findings, though preliminary and limited by small sample size, can inform subsequent research to explore VE-specific causes of performance variability, including differing movement execution requirements and individual characteristics such as motivation, attention and visuospatial abilities. © Copyright © 2021 Cheng, Anderson and Levac.","cerebral palsy; children; motor learning; variability; virtual environment; virtual reality",,Article,"Final","",Scopus,2-s2.0-85103329101
"Boller B., Ouellet É., Belleville S.","54402456500;55567624500;7003289069;","Using Virtual Reality to Assess and Promote Transfer of Memory Training in Older Adults With Memory Complaints: A Randomized Controlled Trial",2021,"Frontiers in Psychology","12",, 627242,"","",,,"10.3389/fpsyg.2021.627242","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103339822&doi=10.3389%2ffpsyg.2021.627242&partnerID=40&md5=cc313318f3471c64a1312494f31a565a","Department of Psychology, Université du Québec à Trois-Rivières, Trois-Rivières, QC, Canada; Research Centre, Institut Universitaire de Gériatrie de Montréal, Montréal, QC, Canada; Department of Psychology, Université de Montréal, Montréal, QC, Canada","Boller, B., Department of Psychology, Université du Québec à Trois-Rivières, Trois-Rivières, QC, Canada, Research Centre, Institut Universitaire de Gériatrie de Montréal, Montréal, QC, Canada; Ouellet, É., Research Centre, Institut Universitaire de Gériatrie de Montréal, Montréal, QC, Canada, Department of Psychology, Université de Montréal, Montréal, QC, Canada; Belleville, S., Research Centre, Institut Universitaire de Gériatrie de Montréal, Montréal, QC, Canada, Department of Psychology, Université de Montréal, Montréal, QC, Canada","In this proof-of-concept study, we assessed the potential for immersive virtual reality (VR) to measure transfer following strategic memory training, and whether efficacy and transfer are increased when training is complemented by practice in an immersive virtual environment. Forty older adults with subjective memory complaints were trained with the method of loci. They were randomized to either a condition where they practiced the strategy in VR (n = 20) or a control condition where they were familiarized with VR using a non-memory task (n = 20). Training efficacy was measured with word recall, and transfer of the training benefit was measured with a recall task completed in two VR tasks (primary outcomes) as well as a self-report memory questionnaire (secondary outcomes). Testing was administered before (PRE), midway (POST 3), and after (POST 6) training. Participants improved their scores on word recall. Regarding transfer measures, participants improved their performance in the two VR recall tasks but not on the self-report memory questionnaire. No significant group effect was observed. Improvement was found when comparing PRE to POST 3 with no further improvement at POST 6. Thus, strategic memory training improved the memory of seniors with memory complaints on word recall and a transfer task relying on a VR scenario that resembles real-life. However, no evidence supporting an increase in transfer effects was found when enriching training with VR memory exercises. © Copyright © 2021 Boller, Ouellet and Belleville.","aging; cognitive training; episodic memory; memory complaint; randomized controlled trial; virtual reality",,Article,"Final","",Scopus,2-s2.0-85103339822
"Brammer J.C., van Peer J.M., Michela A., van Rooij M.M.J.W., Oostenveld R., Klumpers F., Dorrestijn W., Granic I., Roelofs K.","57221854061;14038421600;57194195608;54404177300;6602927779;36101415600;57222585101;6603473048;35585571200;","Breathing Biofeedback for Police Officers in a Stressful Virtual Environment: Challenges and Opportunities",2021,"Frontiers in Psychology","12",, 586553,"","",,,"10.3389/fpsyg.2021.586553","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103308016&doi=10.3389%2ffpsyg.2021.586553&partnerID=40&md5=dd51c0adf17d11e68fa498779e15b2d9","Behavioural Science Institute, Radboud University, Nijmegen, Netherlands; Donders Institute for Brain, Cognition and Behaviour, Radboud University, Nijmegen, Netherlands; NatMEG, Department of Clinical Neuroscience, Karolinska Institutet, Stockholm, Sweden; Police Academy of the Netherlands, Apeldoorn, Netherlands; Faculty of Law, Radboud University, Nijmegen, Netherlands","Brammer, J.C., Behavioural Science Institute, Radboud University, Nijmegen, Netherlands; van Peer, J.M., Behavioural Science Institute, Radboud University, Nijmegen, Netherlands; Michela, A., Behavioural Science Institute, Radboud University, Nijmegen, Netherlands; van Rooij, M.M.J.W., Behavioural Science Institute, Radboud University, Nijmegen, Netherlands; Oostenveld, R., Donders Institute for Brain, Cognition and Behaviour, Radboud University, Nijmegen, Netherlands, NatMEG, Department of Clinical Neuroscience, Karolinska Institutet, Stockholm, Sweden; Klumpers, F., Behavioural Science Institute, Radboud University, Nijmegen, Netherlands, Donders Institute for Brain, Cognition and Behaviour, Radboud University, Nijmegen, Netherlands; Dorrestijn, W., Police Academy of the Netherlands, Apeldoorn, Netherlands, Faculty of Law, Radboud University, Nijmegen, Netherlands; Granic, I., Behavioural Science Institute, Radboud University, Nijmegen, Netherlands; Roelofs, K., Behavioural Science Institute, Radboud University, Nijmegen, Netherlands, Donders Institute for Brain, Cognition and Behaviour, Radboud University, Nijmegen, Netherlands","As part of the Dutch national science program “Professional Games for Professional Skills” we developed a stress-exposure biofeedback training in virtual reality (VR) for the Dutch police. We aim to reduce the acute negative impact of stress on performance, as well as long-term consequences for mental health by facilitating physiological stress regulation during a demanding decision task. Conventional biofeedback applications mainly train physiological regulation at rest. This might limit the transfer of the regulation skills to stressful situations. In contrast, we provide the user with the opportunity to practice breathing regulation while they carry out a complex task in VR. This setting poses challenges from a technical – (real-time processing of noisy biosignals) as well as from a user-experience perspective (multi-tasking). We illustrate how we approach these challenges in our training and hope to contribute a useful reference for researchers and developers in academia or industry who are interested in using biosignals to control elements in a dynamic virtual environment. © Copyright © 2021 Brammer, van Peer, Michela, van Rooij, Oostenveld, Klumpers, Dorrestijn, Granic and Roelofs.","biofeedback; physiological computing; stress exposure; user experience; virtual reality",,Article,"Final","",Scopus,2-s2.0-85103308016
"Liubogoshchev M., Korneev E., Khorov E.","57200496493;57222333639;34869950000;","Everest: Bitrate adaptation for cloud VR",2021,"Electronics (Switzerland)","10","6", 678,"1","17",,,"10.3390/electronics10060678","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102367580&doi=10.3390%2felectronics10060678&partnerID=40&md5=b8109a2394052392181695bfc8233c23","Kharkevich Institute for Information Transmission Problems of the Russian Academy of Sciences, Moscow, 127051, Russian Federation; Moscow Institute of Physics and Technology, Moscow, 141701, Russian Federation","Liubogoshchev, M., Kharkevich Institute for Information Transmission Problems of the Russian Academy of Sciences, Moscow, 127051, Russian Federation, Moscow Institute of Physics and Technology, Moscow, 141701, Russian Federation; Korneev, E., Kharkevich Institute for Information Transmission Problems of the Russian Academy of Sciences, Moscow, 127051, Russian Federation, Moscow Institute of Physics and Technology, Moscow, 141701, Russian Federation; Khorov, E., Kharkevich Institute for Information Transmission Problems of the Russian Academy of Sciences, Moscow, 127051, Russian Federation, Moscow Institute of Physics and Technology, Moscow, 141701, Russian Federation","Cloud Virtual Reality (VR) technology is expected to promote VR by providing a higher Quality of Experience (QoE) and energy efficiency at lower prices for the consumer. In cloud VR, the virtual environment is rendered on the remote server and transmitted to the headset as a video stream. To guarantee real-time experience, networks need to transfer huge amounts of data with much stricter delays than imposed by the state-of-the-art live video streaming applications. To reduce the burden imposed on the networks, cloud VR applications shall adequately react to the changing network conditions, including the wireless channel fluctuations and highly variable user activity. For that, they need to adjust the quality of the video stream adaptively. This paper studies video quality adaptation for cloud VR and improves the QoE for cloud VR users. It develops a distributed, i.e., with no assistance from the network, bitrate adaptation algorithm for cloud VR, called the Enhanced VR bitrate Estimator (EVeREst). The algorithm aims to optimize the average bitrate of cloud VR video flows subject to video frame delay and loss constraints. For that, the algorithm estimates both the current network load and the delay experienced by separate frames. It anticipates the changes in the users’ activity and limits the bitrate accordingly, which helps prevent excess interruptions of the playback. With simulations, the paper shows that the developed algorithm significantly improves the QoE for the end-users compared to the state-of-the-art adaptation algorithms developed for MPEG DASH live streaming, e.g., BOLA. Unlike these algorithms, the developed algorithm satisfies the frame loss requirements of multiple VR sessions and increases the network goodput by up to 10 times. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","Bitrate adaptation; Cloud VR; Quality of experience; Real-time adaptive video; Video traffic; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85102367580
"Kourtesis P., Collina S., Doumas L.A.A., MacPherson S.E.","57210959726;35309731500;12345301900;57212061035;","Validation of the Virtual Reality Everyday Assessment Lab (VR-EAL): An Immersive Virtual Reality Neuropsychological Battery with Enhanced Ecological Validity",2021,"Journal of the International Neuropsychological Society","27","2",,"181","196",,2,"10.1017/S1355617720000764","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095727298&doi=10.1017%2fS1355617720000764&partnerID=40&md5=682a1271572f8544a09deaa59f15dad1","Human Cognitive Neuroscience, Department of Psychology, University of Edinburgh, Edinburgh, United Kingdom; Department of Psychology, University of Edinburgh, Edinburgh, United Kingdom; Lab of Experimental Psychology, Suor Orsola Benincasa University of Naples, Naples, Italy; Interdepartmental Centre for Planning and Research Scienza Nuova, Suor Orsola Benincasa University of Naples, Naples, Italy","Kourtesis, P., Human Cognitive Neuroscience, Department of Psychology, University of Edinburgh, Edinburgh, United Kingdom, Department of Psychology, University of Edinburgh, Edinburgh, United Kingdom, Lab of Experimental Psychology, Suor Orsola Benincasa University of Naples, Naples, Italy, Interdepartmental Centre for Planning and Research Scienza Nuova, Suor Orsola Benincasa University of Naples, Naples, Italy; Collina, S., Lab of Experimental Psychology, Suor Orsola Benincasa University of Naples, Naples, Italy, Interdepartmental Centre for Planning and Research Scienza Nuova, Suor Orsola Benincasa University of Naples, Naples, Italy; Doumas, L.A.A., Department of Psychology, University of Edinburgh, Edinburgh, United Kingdom; MacPherson, S.E., Human Cognitive Neuroscience, Department of Psychology, University of Edinburgh, Edinburgh, United Kingdom, Department of Psychology, University of Edinburgh, Edinburgh, United Kingdom","The assessment of cognitive functions such as prospective memory, episodic memory, attention, and executive functions benefits from an ecologically valid approach to better understand how performance outcomes generalize to everyday life. Immersive virtual reality (VR) is considered capable of simulating real-life situations to enhance ecological validity. The present study attempted to validate the Virtual Reality Everyday Assessment Lab (VR-EAL), an immersive VR neuropsychological battery, against an extensive paper-and-pencil neuropsychological battery. Methods: Forty-one participants (21 females) were recruited: 18 gamers and 23 non-gamers who attended both an immersive VR and a paper-and-pencil testing session. Bayesian Pearson's correlation analyses were conducted to assess construct and convergent validity of the VR-EAL. Bayesian t-tests were performed to compare VR and paper-and-pencil testing in terms of administration time, similarity to real-life tasks (i.e., ecological validity), and pleasantness. Results: VR-EAL scores were significantly correlated with their equivalent scores on the paper-and-pencil tests. The participants' reports indicated that the VR-EAL tasks were significantly more ecologically valid and pleasant than the paper-and-pencil neuropsychological battery. The VR-EAL battery also had a shorter administration time. Conclusion: The VR-EAL appears as an effective neuropsychological tool for the assessment of everyday cognitive functions, which has enhanced ecological validity, a highly pleasant testing experience, and does not induce cybersickness. © 2020 INS. Published by Cambridge University Press.","Attention; Episodic memory; Everyday functioning; Executive function; Prospective memory; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85095727298
"Manasse S.M., Lampe E.W., Juarascio A.S., Zhu J., Forman E.M.","53865081900;57214314089;35753736200;43261949300;7006741975;","Using virtual reality to train inhibitory control and reduce binge eating: A proof-of-concept study",2021,"Appetite","157",, 104988,"","",,,"10.1016/j.appet.2020.104988","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092517372&doi=10.1016%2fj.appet.2020.104988&partnerID=40&md5=0a21c6f0536e96e3397274e8ad9eb5f1","Center for Weight, Eating, and Lifestyle Science, Drexel University, 3201 Chestnut St, Philadelphia, PA  19104, United States; Department of Psychology, Drexel University, 3201 Chestnut St, Philadelphia, PA  19104, United States; Westphal College of Media Arts & Design, Drexel University, 3141 Chestnut St, Philadelphia, PA  19104, United States","Manasse, S.M., Center for Weight, Eating, and Lifestyle Science, Drexel University, 3201 Chestnut St, Philadelphia, PA  19104, United States; Lampe, E.W., Center for Weight, Eating, and Lifestyle Science, Drexel University, 3201 Chestnut St, Philadelphia, PA  19104, United States, Department of Psychology, Drexel University, 3201 Chestnut St, Philadelphia, PA  19104, United States; Juarascio, A.S., Center for Weight, Eating, and Lifestyle Science, Drexel University, 3201 Chestnut St, Philadelphia, PA  19104, United States, Department of Psychology, Drexel University, 3201 Chestnut St, Philadelphia, PA  19104, United States; Zhu, J., Westphal College of Media Arts & Design, Drexel University, 3141 Chestnut St, Philadelphia, PA  19104, United States; Forman, E.M., Center for Weight, Eating, and Lifestyle Science, Drexel University, 3201 Chestnut St, Philadelphia, PA  19104, United States, Department of Psychology, Drexel University, 3201 Chestnut St, Philadelphia, PA  19104, United States","Objective: One reason for limited efficacy of treatments for binge eating disorder (BED) and bulimia nervosa (BN) is a failure to directly target deficits in inhibitory control (i.e., the ability to withhold a pre-potent response). Inhibitory control trainings (ICTs; computerized tasks meant to improve inhibitory control) have shown promise but appear not to be powerful enough to generalize to real-word eating behavior or engaging enough for to sustain long-term compliance. Delivering an ICT through virtual reality (VR) technology should increase intervention power because 3D imagery and actual real hand/arm movements are lifelike and may improve compliance because the VR environment is highly engaging. Thus, we created the first-ever VR-based ICT to test its initial feasibility, acceptability, and impact on binge eating. Method: We recruited participants (N = 14) with once-weekly loss-of-control (LOC) eating to use the VR ICT daily, at home, for two weeks, and measured feasibility, acceptability and change in LOC eating at post-intervention and 2-week follow-up. Results: The VR ICT was feasible to construct and deploy, and demonstrated high acceptability and compliance (i.e., 86.8% of daily trainings completed). Users of the VR ICT experienced large decreases in LOC eating at post-intervention and 2-week follow-up. Discussion: Results from this initial pilot indicate that delivering ICT through VR is feasible, acceptable, and is associated with reductions in binge eating. Future study is warranted and should examine whether a VR ICT can serve as a useful adjunct to standard treatment for BN and BED. © 2020 Elsevier Ltd","Binge eating; Brain training; Go/no-go; Inhibitory control; Virtual reality","adolescent; arm movement; Article; binge eating disorder; clinical article; feeding behavior; female; follow up; hand movement; human; imagery; inhibitory control training; male; patient compliance; proof of concept; psychotherapy; three-dimensional imaging; treatment duration; virtual reality",Article,"Final","",Scopus,2-s2.0-85092517372
"Parong J., Mayer R.E.","56520185200;7403065717;","Cognitive and affective processes for learning science in immersive virtual reality",2021,"Journal of Computer Assisted Learning","37","1",,"226","241",,3,"10.1111/jcal.12482","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089751070&doi=10.1111%2fjcal.12482&partnerID=40&md5=8ad3aa7f4645bc62203c9c281872a614","Department of Psychological and Brain Sciences, University of California, Santa Barbara, Santa Barbara, CA, United States; Department of Psychology, University of Wisconsin–Madison, Madison, WI, United States","Parong, J., Department of Psychological and Brain Sciences, University of California, Santa Barbara, Santa Barbara, CA, United States, Department of Psychology, University of Wisconsin–Madison, Madison, WI, United States; Mayer, R.E., Department of Psychological and Brain Sciences, University of California, Santa Barbara, Santa Barbara, CA, United States","As immersive virtual reality (IVR) systems proliferate in classrooms, it is important to understand how they affect learning outcomes and the underlying affective and cognitive processes that may cause these outcomes. Proponents argue that IVR could improve learning by increasing positive affective and cognitive processing, thereby supporting improved performance on tests of learning outcome, whereas opponents of IVR contend that it could hurt learning by increasing distraction, thereby disrupting cognitive learning processes and leading to poorer learning outcomes. In a media comparison study, students viewed a biology lesson either as an interactive animated journey in IVR or as a slideshow on a desktop monitor. Those who viewed the IVR lesson performed significantly worse on transfer tests, reported higher emotional arousal, reported more extraneous cognitive load and showed less engagement based on EEG measures than those who viewed the slideshow lesson, with or without practice questions added to the lessons. Mediational analyses showed that the lower retention scores for the IVR lesson were related to an increase in self-reported extraneous cognitive load and emotional arousal. These results support the notion that immersive environments create high affective and cognitive distraction, which leads to poorer learning outcomes than desktop environments. © 2020 John Wiley & Sons Ltd","affective processing; cognitive processing; multimedia; science learning; virtual reality",,Article,"Final","",Scopus,2-s2.0-85089751070
"Wilf M., Cerra Cheraka M., Jeanneret M., Ott R., Perrin H., Crottaz-Herbette S., Serino A.","36515832500;57222264361;57221090466;57221094468;57221091485;57202925776;23390163100;","Combined virtual reality and haptic robotics induce space and movement invariant sensorimotor adaptation",2021,"Neuropsychologia","150",, 107692,"","",,,"10.1016/j.neuropsychologia.2020.107692","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098145308&doi=10.1016%2fj.neuropsychologia.2020.107692&partnerID=40&md5=1d5ecc00fd2c0fe69faadad48c343573","MySpace Lab, Department of Clinical Neurosciences, Lausanne University Hospital (CHUV), Lausanne, Switzerland; MindMaze SA, Chemin de Roseneck 5, Lausanne, 1006, Switzerland; Neuropsychology and Neurorehabilitation Service, Lausanne University Hospital (CHUV), Lausanne, Switzerland","Wilf, M., MySpace Lab, Department of Clinical Neurosciences, Lausanne University Hospital (CHUV), Lausanne, Switzerland; Cerra Cheraka, M., MindMaze SA, Chemin de Roseneck 5, Lausanne, 1006, Switzerland; Jeanneret, M., MindMaze SA, Chemin de Roseneck 5, Lausanne, 1006, Switzerland; Ott, R., MindMaze SA, Chemin de Roseneck 5, Lausanne, 1006, Switzerland; Perrin, H., MySpace Lab, Department of Clinical Neurosciences, Lausanne University Hospital (CHUV), Lausanne, Switzerland; Crottaz-Herbette, S., Neuropsychology and Neurorehabilitation Service, Lausanne University Hospital (CHUV), Lausanne, Switzerland; Serino, A., MySpace Lab, Department of Clinical Neurosciences, Lausanne University Hospital (CHUV), Lausanne, Switzerland, MindMaze SA, Chemin de Roseneck 5, Lausanne, 1006, Switzerland","Prism adaptation is a method for studying visuomotor plasticity in healthy individuals, as well as for rehabilitating patients suffering spatial neglect. We developed a new set-up based on virtual-reality (VR) and haptic-robotics allowing us to induce sensorimotor adaptation and to reproduce the effect of prism adaptation in a more ecologically valid, yet experimentally controlled context. Participants were exposed to an immersive VR environment while controlling a virtual hand via a robotic-haptic device to reach virtual objects. During training, a rotational shift was induced between the position of the participant's real hand and that of the virtual hand in order to trigger sensorimotor recalibration. The use of VR and haptic-robotics allowed us to simulate and test multiple components of sensorimotor adaptation: training either peripersonal or extrapersonal space and testing generalization for the non-trained sector of space, and using active versus robot-guided reaching movements. Results from 60 neurologically intact participants show that participants exposed to the virtual shift were able to quickly adapt their reaching movements to aim correctly at the target objects. When the shift was removed, participants showed a systematic deviation of their movements during open-loop tasks in the direction opposite to that of the shift, which generalized to un-trained portions of space and occurred also when their movements were robotically-guided during the adaptation. Interestingly, follow-up questionnaires revealed that when the adaptation training was robotically-guided, participants were largely unaware of the mismatch between their hand and the virtual hand's position. The stability of the aftereffects, despite the changing experimental parameters, suggests that the induced sensory-motor adaptation does not rely on low-level processing of sensory stimuli during the training, but taps into high-level representations of space. Importantly, the flexibility of the trained space and the option of robotically-guided movements open novel possibilities of fine-tuning the training to patients’ level of spatial and motor impairment, thus possibly resulting in a better outcome. © 2020 The Author(s)","Far space; Guided movement; Haptic robot; Hemispatial neglect; Passive movement; Prism adaptation; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85098145308
"Harris D.J., Hardcastle K.J., Wilson M.R., Vine S.J.","57192429891;57221862684;55574207642;36811509000;","Assessing the learning and transfer of gaze behaviours in immersive virtual reality",2021,"Virtual Reality",,,,"","",,,"10.1007/s10055-021-00501-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100476971&doi=10.1007%2fs10055-021-00501-w&partnerID=40&md5=ad4779acdc2d1563f331327866d64c86","School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom; Counter Terrorism Protective Security Operations, Metropolitan Police Service, Lambeth HQ, London, SE1 7LP, United Kingdom","Harris, D.J., School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom; Hardcastle, K.J., Counter Terrorism Protective Security Operations, Metropolitan Police Service, Lambeth HQ, London, SE1 7LP, United Kingdom; Wilson, M.R., School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom; Vine, S.J., School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom","Virtual reality (VR) has clear potential for improving simulation training in many industries. Yet, methods for testing the fidelity, validity and training efficacy of VR environments are, in general, lagging behind their adoption. There is limited understanding of how readily skills learned in VR will transfer, and what features of training design will facilitate effective transfer. Two potentially important elements are the psychological fidelity of the environment, and the stimulus correspondence with the transfer context. In this study, we examined the effectiveness of VR for training police room searching procedures, and assessed the corresponding development of perceptual-cognitive skill through eye-tracking indices of search efficiency. Participants (n = 54) were assigned to a VR rule-learning and search training task (FTG), a search only training task (SG) or a no-practice control group (CG). Both FTG and SG developed more efficient search behaviours during the training task, as indexed by increases in saccade size and reductions in search rate. The FTG performed marginally better than the CG on a novel VR transfer test, but no better than the SG. More efficient gaze behaviours learned during training were not, however, evident during the transfer test. These findings demonstrate how VR can be used to develop perceptual-cognitive skills, but also highlight the challenges of achieving transfer of training. © 2021, The Author(s).","Fidelity; Police; Policing; Training; Validity; VR","E-learning; Eye tracking; Cognitive skill; Gaze behaviours; Immersive virtual reality; Search behaviours; Search efficiency; Simulation training; Training design; Transfer of trainings; Virtual reality",Article,"Article in Press","",Scopus,2-s2.0-85100476971
"Le Noury P., Buszard T., Reid M., Farrow D.","57219051674;55605085300;15136884800;7006613807;","Examining the representativeness of a virtual reality environment for simulation of tennis performance",2021,"Journal of Sports Sciences","39","4",,"412","420",,,"10.1080/02640414.2020.1823618","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091186202&doi=10.1080%2f02640414.2020.1823618&partnerID=40&md5=96877292c3a8a59e66088616130cba45","Institute of Health and Sport, Victoria University, Melbourne, Australia; Game Insight Group, Tennis Australia, Perth, Australia","Le Noury, P., Institute of Health and Sport, Victoria University, Melbourne, Australia; Buszard, T., Institute of Health and Sport, Victoria University, Melbourne, Australia; Reid, M., Game Insight Group, Tennis Australia, Perth, Australia; Farrow, D., Institute of Health and Sport, Victoria University, Melbourne, Australia","There has been a growing interest in using virtual reality (VR) for training perceptual-cognitive skill in sport. For VR training to effectively simulate real-world tennis performance, it must recreate the contextual information and movement behaviours present in the real-world environment. It is therefore critical to assess the representativeness of VR prior to implementing skill training interventions. We constructed a VR tennis environment designed for training perceptual-cognitive skill, with the aim of assessing its representativeness and validating its use. Participants movement behaviours were compared when playing tennis in VR and real-world environments. When performing groundstrokes, participants frequently used the same stance in VR as they did in the real-world condition. Participants experienced a high sense of presence in VR, evident through the factors of spatial presence, engagement and ecological validity being high, with minimal negative effects found. We conclude that Tennis VR is sufficiently representative of real-world tennis. Our discussion focuses on the opportunity for training perceptual-cognitive skill and the potential for skill transfer. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","artificial intelligence; interactive training; perception action coupling; Skill","adult; article; artificial intelligence; ecological validity; female; human; human experiment; male; perception; simulation training; skill; standing; tennis; virtual reality",Article,"Final","",Scopus,2-s2.0-85091186202
"Haar S., Sundar G., Faisal A.A.","56497714500;57221842054;6602900233;","Embodied virtual reality for the study of real-world motor learning",2021,"PLoS ONE","16","1 January", e0245717,"","",,,"10.1371/journal.pone.0245717","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100402457&doi=10.1371%2fjournal.pone.0245717&partnerID=40&md5=ea815d1c3bc8770fcd8183182d0d35ba","Brain and Behaviour Lab, Dept. of Bioengineering, Imperial College London, London, United Kingdom; Dept. of Computing, Imperial College London, London, United Kingdom; UKRI Centre for Doctoral Training in AI for Healthcare, Imperial College London, London, United Kingdom; MRC London Institute of Medical Sciences, Imperial College London, London, United Kingdom","Haar, S., Brain and Behaviour Lab, Dept. of Bioengineering, Imperial College London, London, United Kingdom; Sundar, G., Brain and Behaviour Lab, Dept. of Bioengineering, Imperial College London, London, United Kingdom; Faisal, A.A., Brain and Behaviour Lab, Dept. of Bioengineering, Imperial College London, London, United Kingdom, Dept. of Computing, Imperial College London, London, United Kingdom, UKRI Centre for Doctoral Training in AI for Healthcare, Imperial College London, London, United Kingdom, MRC London Institute of Medical Sciences, Imperial College London, London, United Kingdom","Motor-learning literature focuses on simple laboratory-tasks due to their controlled manner and the ease to apply manipulations to induce learning and adaptation. Recently, we introduced a billiards paradigm and demonstrated the feasibility of real-world-neuroscience using wearables for naturalistic full-body motion-tracking and mobile-brain-imaging. Here we developed an embodied virtual-reality (VR) environment to our real-world billiards paradigm, which allows to control the visual feedback for this complex real-world task, while maintaining sense of embodiment. The setup was validated by comparing real-world ball trajectories with the trajectories of the virtual balls, calculated by the physics engine. We then ran our short-term motor learning protocol in the embodied VR. Subjects played billiard shots when they held the physical cue and hit a physical ball on the table while seeing it all in VR. We found comparable short-term motor learning trends in the embodied VR to those we previously reported in the physical real-world task. Embodied VR can be used for learning real-world tasks in a highly controlled environment which enables applying visual manipulations, common in laboratory-tasks and rehabilitation, to a real-world full-body task. Embodied VR enables to manipulate feedback and apply perturbations to isolate and assess interactions between specific motor-learning components, thus enabling addressing the current questions of motor-learning in real-world tasks. Such a setup can potentially be used for rehabilitation, where VR is gaining popularity but the transfer to the real-world is currently limited, presumably, due to the lack of embodiment. Copyright: © 2021 Haar et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"adult; article; motor learning; physics; rehabilitation; virtual reality; visual feedback",Article,"Final","",Scopus,2-s2.0-85100402457
"Militello M., Tredway L., Hodgkins L., Simon K.","25223738500;18438543700;57191982516;57222469178;","Virtual reality classroom simulations: how school leaders improve instructional leadership capacity",2021,"Journal of Educational Administration",,,,"","",,,"10.1108/JEA-10-2020-0219","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102766946&doi=10.1108%2fJEA-10-2020-0219&partnerID=40&md5=e8138c82fa723f09ba433c11c0c4e374","Educational Leadership, East Carolina University, Greenville, NC, United States; Institute for Educational Leadership, Washington, District of Columbia, United States","Militello, M., Educational Leadership, East Carolina University, Greenville, NC, United States; Tredway, L., Institute for Educational Leadership, Washington, District of Columbia, United States; Hodgkins, L., Educational Leadership, East Carolina University, Greenville, NC, United States; Simon, K., Institute for Educational Leadership, Washington, District of Columbia, United States","Purpose: The purpose of this study was to explore the utility of a virtual reality (VR) classroom experience for improving the capacity of instructional leaders. Specifically, school leaders used VR to build their classroom observation and analysis skills to prepare to have more effective post-observation conversations with teachers. The authors provide insights from multiple data points that highlight the affordances of the virtual setting for improving classroom observation skills. Design/methodology/approach: Drawing on the application of simulations to practice classroom observations, the authors developed a VR experience in which participants tag observable elements of academic discourse using codes from two observation protocols. The protocols identify elements of equitable student access: how teachers call on students and how they design questions. Seventy-five school leaders used the VR platform to observe a classroom scenario and code evidence of equitable classroom access. The authors analyzed data from tagging in the virtual reality scenario and triangulated these data with survey data focused on observation practices from participants' schools. A reflection component is included on the platform to collect these qualitative data. Findings: The study results indicate that the virtual reality platform provides an innovative process for leadership professional development focused on building school leaders' capacity to identify elements of academic discourse during classroom observations. Participants reported that the opportunity to practice classroom observations in a risk-free environment was useful. However, for school leaders to fully transfer the data to using in conversations with teachers, they benefit from leadership coaching. Originality/value: This study ascertains the potential effectiveness of an advanced technology for enhancing instructional leadership by using evidence-based classrooms observations to drive improvements in teaching practice. Beyond the utility of the virtual reality tool, this study provides a proof of concept for the next generation of instructional leadership through teacher observations with augmented reality. © 2021, Emerald Publishing Limited.","Coaching; Instructional leadership; Teacher observation; Virtual reality",,Article,"Article in Press","",Scopus,2-s2.0-85102766946
"Harvey C., Selmanović E., O’Connor J., Chahin M.","48761392600;35218206600;57197835447;57204813574;","A comparison between expert and beginner learning for motor skill development in a virtual reality serious game",2021,"Visual Computer","37","1",,"3","17",,1,"10.1007/s00371-019-01702-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067692541&doi=10.1007%2fs00371-019-01702-w&partnerID=40&md5=bc2d985815aa255af972888f2dbf8fff","Birmingham City University, West Midlands, B4 7XG, United Kingdom; University of Sarajevo, Zmaja od Bosne 35, B&H, Sarajevo, Bosnia and Herzegovina","Harvey, C., Birmingham City University, West Midlands, B4 7XG, United Kingdom; Selmanović, E., University of Sarajevo, Zmaja od Bosne 35, B&H, Sarajevo, Bosnia and Herzegovina; O’Connor, J., Birmingham City University, West Midlands, B4 7XG, United Kingdom; Chahin, M., University of Sarajevo, Zmaja od Bosne 35, B&H, Sarajevo, Bosnia and Herzegovina","In order to be used for skill development and skill maintenance, virtual environments require accurate simulation of the physical phenomena involved in the process of the task being trained. The accuracy needs to be conveyed in a multimodal fashion with varying parameterisations still being quantified, and these are a function of task, prior knowledge, sensory efficacy and human perception. Virtual reality (VR) has been integrated from a didactic perspective in many serious games and shown to be effective in the pedological process. This paper interrogates whether didactic processes introduced into a VR serious game, by taking advantage of augmented virtuality to modify game attributes, can be effective for both beginners and experts to a task. The task in question is subjective performance in a clay pigeon shooting simulation. The investigation covers whether modified game attributes influence skill and learning in a complex motor task and also investigates whether this process is applicable to experts as well as beginners to the task. VR offers designers and developers of serious games the ability to provide information in the virtual world in a fashion that is impossible in the real world. This introduces the question of whether this is effective and transfers skill adoption into the real world and also if a-priori knowledge influences the practical nature of this information in the pedagogic process. Analysis is conducted via a between-subjects repeated measure ANOVA using a 2 × 2 factorial design to address these questions. The results show that the different training provided affects the performance in this task (N= 57). The skill improvement is still evidenced in repeated measures when information and guidance is removed. This effect does not exist under a control condition. Additionally, we separate by an expert and non-expert group to deduce if a-priori knowledge influences the effect of the presented information, it is shown that it does not. © 2019, The Author(s).","Learning; Serious game; Training; Virtual reality","E-learning; Personnel training; Sensory perception; Virtual reality; Augmented virtualities; Human perception; Learning; Physical phenomena; Priori knowledge; Repeated measures; Skill development; Subjective performance; Serious games",Article,"Final","",Scopus,2-s2.0-85067692541
"Summers B.J., Schwartzberg A.C., Wilhelm S.","56222187700;57221756087;7102310648;","A virtual reality study of cognitive biases in body dysmorphic disorder.",2021,"Journal of Abnormal Psychology","130","1",,"26","33",,,"10.1037/abn0000563","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100070104&doi=10.1037%2fabn0000563&partnerID=40&md5=f846b77a9e3c10dfface095eb58dfdae","Department of Psychology, University of North Carolina Wilmington, Wilmington, NC, United States; Department of Psychiatry, Massachusetts General Hospital/Harvard Medical School, Boston, MA, United States; Department of Psychiatry, Massachusetts General Hospital/Harvard Medical School, Boston, MA, United States","Summers, B.J., Department of Psychology, University of North Carolina Wilmington, Wilmington, NC, United States; Schwartzberg, A.C., Department of Psychiatry, Massachusetts General Hospital/Harvard Medical School, Boston, MA, United States; Wilhelm, S., Department of Psychiatry, Massachusetts General Hospital/Harvard Medical School, Boston, MA, United States","Previous research shows that individuals with body dysmorphic disorder (BDD) misinterpret ambiguous social information in a negative and threatening manner. These erroneous threat appraisals are thought to maintain disorder symptomatology and psychosocial impairment by reinforcing individuals’ distorted self-image and ideas of social undesirability. Thus, maladaptive interpretation biases represent an important treatment target for this population; however, existing bias assessments and modification protocols are limited by the hypothetical and distal nature of scenarios and do not capture momentary experiential threat processes. The current study tested virtual reality (VR) technology as a novel, in vivo means of eliciting, identifying, and measuring threat interpretation biases in a clinical sample to better understand the fear/threat structure activated during social interactions in BDD. Findings indicated that, relative to nonpsychiatric controls (N = 25), individuals with BDD (N = 25) evidenced greater in vivo threat interpretation biases and discomfort ratings (distress, fear, perceived threat, urge to check, urge to avoid) in response to interpersonal scenarios presented via VR. This pattern of findings was also observed for established dispositional interpretation bias measures. Study findings enhance our understanding of disorder maintenance and offer more nuanced treatment targets. This study represents a critical first step in the long-term goal of harnessing VR gaming technology to supercharge existing treatment approaches for this debilitating illness. (PsycInfo Database Record (c) 2021 APA, all rights reserved) <strong xmlns:lang=""en"">General Scientific Summary—This study is the first to demonstrate that erroneous threat interpretation biases characteristic of body dysmorphic disorder (BDD) can be reliably elicited and measured via a novel virtual reality (VR) paradigm. Compared to nonpsychiatric controls, participants with BDD evidenced greater threat interpretations and discomfort ratings in response to 13 brief ambiguous social scenarios presented in a virtual environment. The VR assessment was highly feasible and acceptable, and it may offer more ecologically valid information about momentary threat processes than previously established dispositional measures. (PsycInfo Database Record (c) 2021 APA, all rights reserved) © 2020 American Psychological Association","assessment; body dysmorphic disorder; cognitive bias; virtual reality","cannabis; agoraphobia; Article; avoidance behavior; binge eating disorder; bipolar disorder; body dysmorphic disorder; Brown Assessment of Beliefs Scale; bulimia; cannabis addiction; cognitive bias; comorbidity; controlled study; data analysis; distress syndrome; fear; generalized anxiety disorder; human; in vivo study; intelligence quotient; interpretation bias; major depression; obsessive compulsive disorder; panic; posttraumatic stress disorder; psychologic assessment; social interaction; social phobia; technology; threat; virtual reality; Yale Brown Obsessive Compulsive Scale",Article,"Final","",Scopus,2-s2.0-85100070104
"Kondo Y., Fukuhara K., Suda Y., Higuchi T.","57219251978;52163401400;57219255977;55702546800;","Training older adults with virtual reality use to improve collision-avoidance behavior when walking through an aperture",2021,"Archives of Gerontology and Geriatrics","92",, 104265,"","",,,"10.1016/j.archger.2020.104265","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091915778&doi=10.1016%2fj.archger.2020.104265&partnerID=40&md5=e8bc2b9c29fa499658d23b268614d2bb","Department of Health Promotion Science, Tokyo Metropolitan University, Tokyo, Japan; Department of Physical Rehabilitation, National Center Hospital, National Center of Neurology and Psychiatry, Tokyo, Japan","Kondo, Y., Department of Health Promotion Science, Tokyo Metropolitan University, Tokyo, Japan, Department of Physical Rehabilitation, National Center Hospital, National Center of Neurology and Psychiatry, Tokyo, Japan; Fukuhara, K., Department of Health Promotion Science, Tokyo Metropolitan University, Tokyo, Japan; Suda, Y., Department of Health Promotion Science, Tokyo Metropolitan University, Tokyo, Japan; Higuchi, T., Department of Health Promotion Science, Tokyo Metropolitan University, Tokyo, Japan","Many older adults perform collision-avoidance behavior either insufficiently (i.e., frequent collision) or inefficiently (i.e., exaggerated behavior to ensure collision-avoidance). The present study examined whether a training system using virtual reality (VR) simulation enhanced older adults’ collision-avoidance behavior in response to a VR image of an aperture during real walking. Twenty-five (n = 13 intervention group and n = 12 control group) older individuals participated. During training, a VR image of walking through an aperture was projected onto a large screen. Participants in the intervention group tried to avoid virtual collision with the minimum body rotation required to walk on the spot through a variety of narrow apertures. Participants in the control group remained without body rotation while walking on the spot through a wide aperture. A comparison between pre-test and post-test performances in the real environment indicated that after the training, significantly smaller body rotation angles were observed in the intervention group. This suggests that the training led participants to modify their behavior to try to move efficiently during real walking. However, although not significant, collision rates also tended to be greater, suggesting that, at least for some participants, the modification required to avoid collision was too difficult. Transfer of the learned behavior using the VR environment to real walking is discussed. © 2020 Elsevier B.V.","Cautious strategy; Obstacle avoidance; Stepping in place; Virtual reality; Walking","aged; article; avoidance behavior; clinical article; controlled study; female; human; human experiment; male; rotation; task performance; virtual reality; walking; avoidance behavior; walking; Aged; Avoidance Learning; Humans; Virtual Reality; Walking",Article,"Final","",Scopus,2-s2.0-85091915778
"Clay C.J., Schmitz B.A., Balakrishnan B., Hopfenblatt J.P., Evans A., Kahng S.","55362551400;57201501225;25931981700;57193741502;57221685293;21635542200;","Feasibility of virtual reality behavior skills training for preservice clinicians",2021,"Journal of Applied Behavior Analysis",,,,"","",,,"10.1002/jaba.809","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099796240&doi=10.1002%2fjaba.809&partnerID=40&md5=66587b6483c39392f35899c20e1b6efc","The University of Missouri, United States; The Thompson Center for Autism and Neurodevelopmental Disorders, United States; Rutgers University, United States","Clay, C.J., The University of Missouri, United States, The Thompson Center for Autism and Neurodevelopmental Disorders, United States; Schmitz, B.A., The University of Missouri, United States, The Thompson Center for Autism and Neurodevelopmental Disorders, United States; Balakrishnan, B., The University of Missouri, United States; Hopfenblatt, J.P., The University of Missouri, United States; Evans, A., The University of Missouri, United States; Kahng, S., Rutgers University, United States","Effective training procedures include behavioral skills training (BST), which involves providing written and verbal instructions, modeling of the skill, rehearsal of the skill, and feedback on the performance. This training typically involves in vivo experience in which trainees and students are exposed to risks such as proximity to infectious disease, behavioral issues such as aggression, and errors in teaching performance. Conducting BST in a virtual reality (VR) context involving virtual individuals with problem behavior may be an effective means of mitigating these risks. The purpose of this study was to examine the feasibility of training students to conduct functional communication training (FCT) in a VR environment using BST. We trained 13 preservice college students to implement FCT for attention and escape functions. We found VR BST was effective at increasing correct steps performed of FCT to mastery criterion levels with all participants. Future researchers should examine generalization and maintenance of VR BST. © 2021 Society for the Experimental Analysis of Behavior","behavioral skills training; functional communication training; virtual reality; virtual teaching; virtual training",,Article,"Article in Press","",Scopus,2-s2.0-85099796240
"Zhu Y., Zhai G., Min X., Zhou J.","57189598758;15847120000;56030205300;55938080200;","Learning a Deep Agent to Predict Head Movement in 360-Degree Images",2021,"ACM Transactions on Multimedia Computing, Communications and Applications","16","4", 3410455,"","",,,"10.1145/3410455","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100305639&doi=10.1145%2f3410455&partnerID=40&md5=50236f32dd2ed174b5431f405e66566a","Shanghai Jiao Tong University, Shanghai, China; University of Macau, Macau","Zhu, Y., Shanghai Jiao Tong University, Shanghai, China; Zhai, G., Shanghai Jiao Tong University, Shanghai, China; Min, X., Shanghai Jiao Tong University, Shanghai, China; Zhou, J., University of Macau, Macau","Virtual reality adequately stimulates senses to trick users into accepting the virtual environment. To create a sense of immersion, high-resolution images are required to satisfy human visual system, and low latency is essential for smooth operations, which put great demands on data processing and transmission. Actually, when exploring in the virtual environment, viewers only perceive the content in the current field of view. Therefore, if we can predict the head movements that are important behaviors of viewers, more processing resources can be allocated to the active field of view. In this article, we propose a model to predict the trajectory of head movement. Deep reinforcement learning is employed to mimic the decision making. In our framework, to characterize each state, features for viewport images are extracted by convolutional neural networks. In addition, the spherical coordinate maps and visited maps are generated for each viewport image, which facilitate the multiple dimensions of the state information by considering the impact of historical head movement and position information. To ensure the accurate simulation of visual behaviors during the watching of panoramas, we stipulate that the model imitates the behaviors of human demonstrators. To allow the model to generalize to more conditions, the intrinsic motivation is employed to guide the agent's action toward reducing uncertainty, which can enhance robustness during the exploration. The experimental results demonstrate the effectiveness of the proposed stepwise head movement predictor. © 2020 ACM.","360 degree; deep reinforcement learning (DRL); head movement prediction; omnidirectional; panoramic; saliency; VR","Behavioral research; Convolutional neural networks; Data handling; Decision making; Forecasting; Image processing; Reinforcement learning; Data processing and transmission; High resolution image; Human Visual System; Intrinsic motivation; Multiple dimensions; Position information; Processing resources; Spherical coordinates; Deep learning",Article,"Final","",Scopus,2-s2.0-85100305639
"Kittel A., Larkin P., Elsworthy N., Spittle M.","57189646376;55764354400;54917109200;16425117500;","Transfer of 360° virtual reality and match broadcast video-based tests to on-field decision-making",2021,"Science and Medicine in Football","5","1",,"79","86",,,"10.1080/24733938.2020.1802506","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088971174&doi=10.1080%2f24733938.2020.1802506&partnerID=40&md5=520e42b047599e9f94af9f1ec8cacd05","Institute for Health and Sport, Victoria University, Australia; Maribyrnong Sports Academy, Melbourne, Australia; School of Health, Medical and Applied Sciences, Central Queensland University, Rockhampton, Australia","Kittel, A., Institute for Health and Sport, Victoria University, Australia; Larkin, P., Institute for Health and Sport, Victoria University, Australia, Maribyrnong Sports Academy, Melbourne, Australia; Elsworthy, N., School of Health, Medical and Applied Sciences, Central Queensland University, Rockhampton, Australia; Spittle, M., Institute for Health and Sport, Victoria University, Australia","This study aimed to assess the level of transfer of two reliable and valid video modes to in-game decision-making performance. Two video-based tests of 25 clips each (360°VR and match broadcast vision) assessed off-field decision-making accuracy in elite Australian football umpires (n=21). Game performance was assessed across four games for each participant, classified into two groups based on this measure; “highly skilled” or ‘skilled’. Decision-making was assessed for correct, missed and unwarranted decisions in video-based tests and in-game assessments. Independent t-tests analysed differences between highly skilled and skilled in-game decision-makers for each test. Correlations also compared experience and in-game with video-based test decision-making performance. For both video-based tests, there were no significant differences between highly skilled and skilled in-game decision-makers, nor any significant correlations. Officials who made less unwarranted decisions in-game (highly skilled) made significantly less unwarranted decisions in the match broadcast test. There was a significant correlation between experience and 360°VR correct decision-making. Neither video-based test had the sensitivity to discriminate between elite officials, potentially due to the third-person perspective (match broadcast task) or sub-elite players presented (360°VR). Optimising the representativeness of off-field tasks through including similar constraints to performance environments is an important consideration for researchers and practitioners. © 2020 Informa UK Limited, trading as Taylor & Francis Group.","decision making; immersive video; officials; transfer; video-based test; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85088971174
"Ikbal M.S., Ramadoss V., Zoppi M.","57207710331;57192715243;35838978700;","Dynamic Pose Tracking Performance Evaluation of HTC Vive Virtual Reality System",2021,"IEEE Access","9",, 9309218,"3798","3815",,,"10.1109/ACCESS.2020.3047698","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099084093&doi=10.1109%2fACCESS.2020.3047698&partnerID=40&md5=79bded2f82e5d3b22c34a9aa8c53bef2","Department of Mechanical, Energy, Management, and Transportation Engineering, PMAR Robotics Group, University of Genoa, Genoa, (GE), Italy","Ikbal, M.S., Department of Mechanical, Energy, Management, and Transportation Engineering, PMAR Robotics Group, University of Genoa, Genoa, (GE), Italy; Ramadoss, V., Department of Mechanical, Energy, Management, and Transportation Engineering, PMAR Robotics Group, University of Genoa, Genoa, (GE), Italy; Zoppi, M., Department of Mechanical, Energy, Management, and Transportation Engineering, PMAR Robotics Group, University of Genoa, Genoa, (GE), Italy","Virtual reality tracking devices are rapidly becoming the go-to system for cost-effective motion tracking solutions across different communities such as robotics, biomechanics, sports, rehabilitation, motion simulators, etc. This article focuses on the spatial tracking performance of HTC Vive's lighthouse tracking system (VLTS) devices (tracker, controller, and head mount display). A comprehensive literature survey on the performance analysis of VLTS on the various aspects is presented along with its shortcomings in terms of spatial tracking evaluation. The two key limitations have been identified: in static cases, there is a lack of standard procedures and criteria, and in dynamic cases, the entire study of spatial tracking. We address the first by assessing VLTS using the optical tracking system standard specified by ASTM International, and the latter by revising the standards to determine the upper-velocity limit for reliable tracking. The findings are substantiated with the trajectories of human wrist motion. Each evaluation's results are systematically analyzed with statistical hypothesis tests and criteria fulfillment. Comau NS16, an industrial serial robot, was used as the ground truth motion generator due to its repeatability and 6 degrees of workspace freedom. One of the major reasons for not having more generalized spatial tracking studies is that the tracking performance heavily depends on the configurations of the setup, work volume, environment, etc. Thus, the guidelines for configuring VLTS and the approach adapted from ASTM standards for evaluating VLTS for custom applications using our reported findings for both static and dynamic cases are included in the appendix. © 2013 IEEE.","Lighthouse tracking; motion tracking; performance evaluation and bench-marking; virtual reality and interfaces","ASTM standards; Cost effectiveness; Display devices; Gesture recognition; Industrial robots; Testing; Tracking (position); Virtual reality; Head-mount displays; Optical tracking systems; Performance analysis; Standard procedures; Statistical hypothesis test; Tracking performance; Tracking solutions; Virtual reality system; Motion tracking",Article,"Final","",Scopus,2-s2.0-85099084093
"Sakib M.N., Chaspari T., Behzadan A.H.","57213424763;55351228300;15073914400;","Physiological Data Models to Understand the Effectiveness of Drone Operation Training in Immersive Virtual Reality",2021,"Journal of Computing in Civil Engineering","35","1", 04020053,"","",,,"10.1061/(ASCE)CP.1943-5487.0000941","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095978574&doi=10.1061%2f%28ASCE%29CP.1943-5487.0000941&partnerID=40&md5=e4034444de1c6b70a770491142771400","Dept. of Multidisciplinary Engineering, Texas A and M Univ., 3127 TAMU, College Station, TX  77843, United States; Dept. of Computer Science and Engineering, Texas A and M Univ., 3127 TAMU, College Station, TX  77843, United States; Dept. of Construction Science, Texas A and M Univ., 3137 TAMU, College Station, TX  77843, United States","Sakib, M.N., Dept. of Multidisciplinary Engineering, Texas A and M Univ., 3127 TAMU, College Station, TX  77843, United States; Chaspari, T., Dept. of Computer Science and Engineering, Texas A and M Univ., 3127 TAMU, College Station, TX  77843, United States; Behzadan, A.H., Dept. of Construction Science, Texas A and M Univ., 3137 TAMU, College Station, TX  77843, United States","Data collection using unmanned aerial vehicles (UAVs) in construction and heavy civil projects is subject to compliance with strict operational rules and safety regulations. Both the US Federal Aviation Administration (FAA) and the European Union Aviation Safety Agency (EASA) require drone operators to keep the drone in sight and avoid flying near people or other objects. From the perspective of the operator, remaining in standing or sitting position while always looking up to monitor the drone movements can cause awkward body postures, stress, and fatigue. Coupled with the mental load resulting from delegated tasks, this could potentially put the drone mission, people, and property at risk. This research investigates the reliability of using the drone operator's physiological indexes and self-assessments to predict performance, mental workload (MWL), and stress in immersive virtual reality training and outdoor deployment. A user study was carried out to collect physiological data using wearable devices and design general population and group-specific prediction models. Results show that in 83% of cases, these models can predict performance, MWL, and stress levels accurately or within one level. This paper contributes to the core body of knowledge by providing a scalable approach to objectively quantifying performance, MWL, and stress that can be used to design adaptive training systems for drone operators. Personalized models of physiological signals are presented as reliable indexes to describing the outcome of interest. Scalability is achieved through the application of generalizable machine learning models that learn the interdependencies between physiological and self-assessment inputs and their association with corresponding outcomes. © 2020 American Society of Civil Engineers.","Human performance; Machine learning (ML); Mental workload; Physiological signals; Unmanned aerial vehicle (UAV); Virtual reality (VR); Wearable technology","Adaptive systems; Antennas; Automobile bodies; Data acquisition; Drones; E-learning; Forecasting; Personnel training; Physiology; Population statistics; Predictive analytics; Safety engineering; Virtual reality; Adaptive training system; General population; Immersive virtual reality; Machine learning models; Personalized model; Physiological indices; Physiological signals; Us federal aviation administrations; Physiological models",Article,"Final","",Scopus,2-s2.0-85095978574
"Nguyen-Vo T., Riecke B.E., Stuerzlinger W., Pham D.-M., Kruijff E.","57021750000;6603396361;55902405400;57203971039;15022738100;","NaviBoard and NaviChair: Limited Translation Combined with Full Rotation for Efficient Virtual Locomotion",2021,"IEEE Transactions on Visualization and Computer Graphics","27","1", 8809840,"165","177",,2,"10.1109/TVCG.2019.2935730","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096885584&doi=10.1109%2fTVCG.2019.2935730&partnerID=40&md5=85d46ecc0f5cefd72f65aac054e1267c","School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC  V5A 1S6, Canada; Institute of Visual Computing, Bonn-Rhein-Sieg University of Applied Sciences, Sankt Augustin, 53757, Germany","Nguyen-Vo, T., School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC  V5A 1S6, Canada; Riecke, B.E., School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC  V5A 1S6, Canada; Stuerzlinger, W., School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC  V5A 1S6, Canada; Pham, D.-M., School of Interactive Arts + Technology, Simon Fraser University, Burnaby, BC  V5A 1S6, Canada; Kruijff, E., Institute of Visual Computing, Bonn-Rhein-Sieg University of Applied Sciences, Sankt Augustin, 53757, Germany","Walking has always been considered as the gold standard for navigation in Virtual Reality research. Though full rotation is no longer a technical challenge, physical translation is still restricted through limited tracked areas. While rotational information has been shown to be important, the benefit of the translational component is still unclear with mixed results in previous work. To address this gap, we conducted a mixed-method experiment to compare four levels of translational cues and control: none (using the trackpad of the HTC Vive controller to translate), upper-body leaning (sitting on a 'NaviChair', leaning the upper-body to locomote), whole-body leaning/stepping (standing on a platform called NaviBoard, leaning the whole body or stepping one foot off the center to navigate), and full translation (physically walking). Results showed that translational cues and control had significant effects on various measures including task performance, task load, and simulator sickness. While participants performed significantly worse when they used a controller with no embodied translational cues, there was no significant difference between the NaviChair, NaviBoard, and actual walking. These results suggest that translational body-based motion cues and control from a low-cost leaning/stepping interface might provide enough sensory information for supporting spatial updating, spatial awareness, and efficient locomotion in VR, although future work will need to investigate how these results might or might not generalize to other tasks and scenarios. © 1995-2012 IEEE.","Adaptive control; cognitive informatics; human computer interaction; human factors; user interface; virtual reality","Computer graphics; Software engineering; Efficient locomotion; Sensory information; Simulator sickness; Spatial awareness; Spatial updating; Technical challenges; Translational component; Virtual locomotion; Controllers",Article,"Final","",Scopus,2-s2.0-85096885584
"Lau K.W., Lee P.Y.","57211282004;36835177400;","Using virtual reality for professional training practices: exploring the factors of applying stereoscopic 3D technologies in knowledge transfer",2021,"Virtual Reality",,,,"","",,,"10.1007/s10055-021-00504-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101077739&doi=10.1007%2fs10055-021-00504-7&partnerID=40&md5=8289cf3850d93bac91546d72ef249966","The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong","Lau, K.W., The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong; Lee, P.Y., The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong","Current research has constantly highlighted the significance of developing a learning culture with a robust knowledge sharing and transfer process in knowledge-based societies. The emergence of stereoscopic 3D virtual technologies provides organizations with an opportunity to develop immersive and virtual professional training practices for employees’ transformative learning. This research gathered data from a survey of 326 respondents to investigate employees’ virtual learning experiences in a virtual learning environment (VLE). The results show that a successful VLE model could possibly enhance employees’ learning motivation, process and satisfaction. The empirical evidence of this research suggests that there are three key components of framework for actual implementation; they are (1) the careful selection of VLE; (2) the appropriate design of pedagogical strategies; and (3) the effective use of virtual stimuli which involves the factors of the stereoscopic 3D visualization, telepresence and multisensory interactions. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd. part of Springer Nature.","Knowledge transfer; Learning science; Professional training; Stereoscopic 3D technology; Virtual reality","Computer aided instruction; E-learning; Knowledge based systems; Knowledge management; Personnel training; Stereo image processing; Surveys; Three dimensional computer graphics; Visual communication; Knowledge-based society; Multisensory interaction; Pedagogical strategies; Professional training; Stereoscopic 3-d technologies; Stereoscopic 3D visualization; Transformative learning; Virtual learning environments; Virtual reality",Article,"Article in Press","",Scopus,2-s2.0-85101077739
"Wijewickrema S., Talks B.J., Lamtara J., Gerard J.-M., O’Leary S.","16178559900;57203980407;57216964797;57212361280;57211985645;","Automated assessment of cortical mastoidectomy performance in virtual reality",2021,"Clinical Otolaryngology",,,,"","",,,"10.1111/coa.13760","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103214703&doi=10.1111%2fcoa.13760&partnerID=40&md5=13123e4c7a285cf9299f2625920c85b7","Department of Surgery (Otolaryngology), University of Melbourne, Royal Victorian Eye and Ear Hospital, Melbourne, VIC, Australia","Wijewickrema, S., Department of Surgery (Otolaryngology), University of Melbourne, Royal Victorian Eye and Ear Hospital, Melbourne, VIC, Australia; Talks, B.J., Department of Surgery (Otolaryngology), University of Melbourne, Royal Victorian Eye and Ear Hospital, Melbourne, VIC, Australia; Lamtara, J., Department of Surgery (Otolaryngology), University of Melbourne, Royal Victorian Eye and Ear Hospital, Melbourne, VIC, Australia; Gerard, J.-M., Department of Surgery (Otolaryngology), University of Melbourne, Royal Victorian Eye and Ear Hospital, Melbourne, VIC, Australia; O’Leary, S., Department of Surgery (Otolaryngology), University of Melbourne, Royal Victorian Eye and Ear Hospital, Melbourne, VIC, Australia","Introduction: Cortical mastoidectomy is a core skill that Otolaryngology trainees must gain competency in. Automated competency assessments have the potential to reduce assessment subjectivity and bias, as well as reducing the workload for surgical trainers. Objectives: This study aimed to develop and validate an automated competency assessment system for cortical mastoidectomy. Participants: Data from 60 participants (Group 1) were used to develop and validate an automated competency assessment system for cortical mastoidectomy. Data from 14 other participants (Group 2) were used to test the generalisability of the automated assessment. Design: Participants drilled cortical mastoidectomies on a virtual reality temporal bone simulator. Procedures were graded by a blinded expert using the previously validated Melbourne Mastoidectomy Scale: a different expert assessed procedures by Groups 1 and 2. Using data from Group 1, simulator metrics were developed to map directly to the individual items of this scale. Metric value thresholds were calculated by comparing automated simulator metric values to expert scores. Binary scores per item were allocated using these thresholds. Validation was performed using random sub-sampling. The generalisability of the method was investigated by performing the automated assessment on mastoidectomies performed by Group 2, and correlating these with scores of a second blinded expert. Results: The automated binary score compared with the expert score per item had an accuracy, sensitivity and specificity of 0.9450, 0.9547 and 0.9343, respectively, for Group 1; and 0.8614, 0.8579 and 0.8654, respectively, for Group 2. There was a strong correlation between the total scores per participant assigned by the expert and calculated by the automatic assessment method for both Group 1 (r =.9144, P <.0001) and Group 2 (r =.7224, P <.0001). Conclusion: This study outlines a virtual reality-based method of automated assessment of competency in cortical mastoidectomy, which proved comparable to the assessment provided by human experts. © 2021 John Wiley & Sons Ltd","automated assessment; competency-based assessment; surgical simulation; surgical training; temporal bone surgery; virtual reality",,Article,"Article in Press","",Scopus,2-s2.0-85103214703
"Feng Y., Duives D., Daamen W., Hoogendoorn S.","57216936136;55630559900;6602658905;6701778851;","Data collection methods for studying pedestrian behaviour: A systematic review",2021,"Building and Environment","187",, 107329,"","",,1,"10.1016/j.buildenv.2020.107329","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095426073&doi=10.1016%2fj.buildenv.2020.107329&partnerID=40&md5=cdba405c4d43abf884b7f43d557c614d","Department of Transport & Planning, Delft University of Technology, Stevinweg 1, Delft, 2628 CN, Netherlands","Feng, Y., Department of Transport & Planning, Delft University of Technology, Stevinweg 1, Delft, 2628 CN, Netherlands; Duives, D., Department of Transport & Planning, Delft University of Technology, Stevinweg 1, Delft, 2628 CN, Netherlands; Daamen, W., Department of Transport & Planning, Delft University of Technology, Stevinweg 1, Delft, 2628 CN, Netherlands; Hoogendoorn, S., Department of Transport & Planning, Delft University of Technology, Stevinweg 1, Delft, 2628 CN, Netherlands","Collecting pedestrian behaviour data is vital to understand pedestrian behaviour. This systematic review of 145 studies aims to determine the capability of contemporary data collection methods in collecting different pedestrian behavioural data, identify research gaps and discuss the possibilities of using new technologies to study pedestrian behaviour. The review finds that there is an imbalance in the number of studies that feature various aspects of pedestrian behaviour, most importantly (1) pedestrian behaviour in large complex scenarios, and (2) pedestrian behaviour during new types of high-risk situations. Additionally, three issues are identified regarding current pedestrian behaviour studies, namely (3) little comprehensive data sets featuring multi-dimensional behaviour data simultaneously, (4) generalizability of most collected data sets is limited, and (5) costs of pedestrian behaviour experiments are relatively high. A set of new technologies offers opportunities to overcome some of these limitations. This review identifies three types of technologies that can become a valuable addition to pedestrian behaviour research methods, namely (1) applying VR experiments to study pedestrian behaviour in the environments that are difficult or cannot be mimicked in real-life, repeat experiments to determine the impact of factors on pedestrian behaviour and collect more accurate behavioural data to understand the decision-making process of pedestrian behaviour deeply, (2) applying large-scale crowd monitoring to study pedestrian movements in large complex environments and incident situations, and (3) utilising the Internet of Things to track pedestrian movements at various locations that are difficult to investigate at the moment. © 2020 The Authors","Crowd; Data collection method; IoT; Literature review; Pedestrian behaviour; Virtual reality","Data acquisition; Risk perception; Complex environments; Data collection method; Decision making process; High-risk situations; Multi dimensional; Pedestrian movement; Research gaps; Systematic Review; Behavioral research; decision making; Internet; literature review; pedestrian; travel behavior; virtual reality",Article,"Final","",Scopus,2-s2.0-85095426073
"Aydın A., Ahmed K., Baig U., Raison N., Lantz Powers A.G., Macchione N., Al-Jabir A., Abe T., Khan M.S., Dasgupta P., the SIMULATE Trial Contributors","55976433600;15764669400;57221872999;56491064400;57208242744;56418487900;57196036866;55477368000;57221871342;7201405986;","The SIMULATE ureteroscopy training curriculum: educational value and transfer of skills",2021,"World Journal of Urology",,,,"","",,,"10.1007/s00345-021-03604-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100502437&doi=10.1007%2fs00345-021-03604-w&partnerID=40&md5=7fca4fc3739ec99115bcf7549dcb5c85","MRC Centre for Transplantation, King’s College London, King’s Health Partners, London, United Kingdom; Department of Urology, King’s College Hospital NHS Foundation Trust, King’s Health Partners, London, United Kingdom; Department of Urology, Dalhousie University, Halifax, NS, Canada; Department of Urology, ASST Santi Paolo E Carlo, Università Degli Studi Di Milano, Milan, Italy; Department of Urology, Hokkaido University Graduate School of Medicine, Sapporo, Japan; Urology Centre, Guy’s and St. Thomas’ NHS Foundation Trust, King’s Health Partners, London, United Kingdom","Aydın, A., MRC Centre for Transplantation, King’s College London, King’s Health Partners, London, United Kingdom; Ahmed, K., MRC Centre for Transplantation, King’s College London, King’s Health Partners, London, United Kingdom, Department of Urology, King’s College Hospital NHS Foundation Trust, King’s Health Partners, London, United Kingdom; Baig, U., MRC Centre for Transplantation, King’s College London, King’s Health Partners, London, United Kingdom; Raison, N., MRC Centre for Transplantation, King’s College London, King’s Health Partners, London, United Kingdom; Lantz Powers, A.G., Department of Urology, Dalhousie University, Halifax, NS, Canada; Macchione, N., Department of Urology, ASST Santi Paolo E Carlo, Università Degli Studi Di Milano, Milan, Italy; Al-Jabir, A., MRC Centre for Transplantation, King’s College London, King’s Health Partners, London, United Kingdom; Abe, T., Department of Urology, Hokkaido University Graduate School of Medicine, Sapporo, Japan; Khan, M.S., MRC Centre for Transplantation, King’s College London, King’s Health Partners, London, United Kingdom, Urology Centre, Guy’s and St. Thomas’ NHS Foundation Trust, King’s Health Partners, London, United Kingdom; Dasgupta, P., MRC Centre for Transplantation, King’s College London, King’s Health Partners, London, United Kingdom, Urology Centre, Guy’s and St. Thomas’ NHS Foundation Trust, King’s Health Partners, London, United Kingdom; the SIMULATE Trial Contributors","Objective: Different simulation modalities may be utilised in a curricular fashion to benefit from the strengths of each training model. The aim of this study is to evaluate a novel multi-modality ureterorenoscopy (URS) simulation curriculum in terms of educational value, content validity, transfer of skills and inter-rater reliability. Methods: This international prospective study recruited urology residents (n = 46) with ≤ 10 URS experience and no prior simulation training. Participants were guided through each phase of the expert-developed SIMULATE URS curriculum by trainers and followed-up in the operating room (OR). Video recordings were obtained during training. A post-training evaluation survey was distributed to evaluate content validity and educational value, using descriptive statistics. Performance was evaluated using the objective structured assessment of technical skills (OSATS) scale to measure improvement in scores throughout the curriculum. Pearson’s correlation coefficient and Cohen’s kappa tests were utilised to investigate correlation and agreement between raters. Results: Participants reported gaining OR-transferrable skills (Mean: 4.33 ± 0.67) and demonstrated marked improvement in throughout the curriculum, transferred to the OR for both semi-rigid URS (p = 0.004) and flexible URS (p = 0.007). 70% of participants were successfully followed-up in the OR (n = 32). No differences were identified with the additional use of fresh frozen cadavers (p = 0.85, p = 0.90) and the URO Mentor VR simulator (p = 0.13, p = 0.22). A moderate level of correlation was noted on the video OSATS assessments, between two expert assessors (r = 0.70), but a poor agreement with the live rating. Conclusion: The SIMULATE URS training curriculum received high educational value from participants, who demonstrated statistically significant improvement with consecutive cases throughout the curriculum and transferability of skills to the OR in both semi-rigid and flexible URS. © 2021, The Author(s).","Curriculum; Education; Simulation; Ureterorenoscopy; Urology training",,Article,"Article in Press","",Scopus,2-s2.0-85100502437
"Gupta S., Singal G., Garg D.","57220722072;56892765700;57217740133;","Deep Reinforcement Learning Techniques in Diversified Domains: A Survey",2021,"Archives of Computational Methods in Engineering",,,,"","",,,"10.1007/s11831-021-09552-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100973427&doi=10.1007%2fs11831-021-09552-3&partnerID=40&md5=1f01a6bd6171c9bc12e404e7c39a3052","Computer Science, Bennett University, Plot No 8-11, TechZone, Street 2, Greater Noida, Uttar Pradesh  201310, India","Gupta, S., Computer Science, Bennett University, Plot No 8-11, TechZone, Street 2, Greater Noida, Uttar Pradesh  201310, India; Singal, G., Computer Science, Bennett University, Plot No 8-11, TechZone, Street 2, Greater Noida, Uttar Pradesh  201310, India; Garg, D., Computer Science, Bennett University, Plot No 8-11, TechZone, Street 2, Greater Noida, Uttar Pradesh  201310, India","There have been tremendous improvements in deep learning and reinforcement learning techniques. Automating learning and intelligence to the full extent remains a challenge. The amalgamation of Reinforcement Learning and Deep Learning has brought breakthroughs in games and robotics in the past decade. Deep Reinforcement Learning (DRL) involves training the agent with raw input and learning via interaction with the environment. Motivated by recent successes of DRL, we have explored its adaptability to different domains and application areas. This paper also presents a comprehensive survey of the work done in recent years and simulation tools used for DRL. The current focus of researchers is on recording the experience in a better way, and refining the policy for futuristic moves. It is found that even after obtaining good results in Atari, Go, Robotics, multi-agent scenarios, there are challenges such as generalization, satisfying multiple objectives, divergence, learning robust policy. Furthermore, the complex environment and multiple agents are throwing new challenges, which is an open area of research. © 2021, CIMNE, Barcelona, Spain.",,"Learning systems; Metals; Multi agent systems; Reinforcement learning; Robotics; Surveys; Application area; Complex environments; Different domains; Multi agent; Multiple agents; Multiple-objectives; Reinforcement learning techniques; Deep learning",Article,"Article in Press","",Scopus,2-s2.0-85100973427
"Aguiar D.F., McInnes K., Filho E.M., Romeu M.A.R., Fontoura J.A.S.","57194268375;7004524826;57222052023;55743676300;55021294300;","Extreme wave analysis based on 31 years data from ww3 model: Study off southern brazilian coast",2021,"Anais da Academia Brasileira de Ciencias","93","1", e20190011,"1","17",,,"10.1590/0001-3765202120190011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101155074&doi=10.1590%2f0001-3765202120190011&partnerID=40&md5=6ddaa0e1dc7d448774d8df23fbe3de57","Universidade Federal do Rio Grande, Escola de Engenharia, Av. Italia Km 9, Rio Grande, RS, 29201-900, Brazil; The Commonwealth Scientific and Industrial Research Organization/CSIRO, Division of Marine and Atmospheric Research, 107-121 Station Street, Postal code 3195, Aspendale, VIC, Australia","Aguiar, D.F., Universidade Federal do Rio Grande, Escola de Engenharia, Av. Italia Km 9, Rio Grande, RS, 29201-900, Brazil; McInnes, K., The Commonwealth Scientific and Industrial Research Organization/CSIRO, Division of Marine and Atmospheric Research, 107-121 Station Street, Postal code 3195, Aspendale, VIC, Australia; Filho, E.M., Universidade Federal do Rio Grande, Escola de Engenharia, Av. Italia Km 9, Rio Grande, RS, 29201-900, Brazil; Romeu, M.A.R., Universidade Federal do Rio Grande, Escola de Engenharia, Av. Italia Km 9, Rio Grande, RS, 29201-900, Brazil; Fontoura, J.A.S., Universidade Federal do Rio Grande, Escola de Engenharia, Av. Italia Km 9, Rio Grande, RS, 29201-900, Brazil","A long-term wave hindcast (1979-2009) based on the NCEP/NCAR Reanalysis and WAVEWATCH III has been assessed using 29 months of wave measurements over Rio Grande shelf, South Brazil to evaluate the skills and biases in the wave hindcast for this region. Extreme events were selected by Peaks Over Thresholds (POT) and fitted by a Generalized Pareto Distribution (GPD) to estimate the extreme significant wave height from the 31 years wave simulation. The significant wave heights from the hindcast and measurement show generally good agreement although the wave heights tended to be underestimated in the hindcast. This underestimation was more pronounced in extreme wave events. The estimated extreme waves, based on a hindcast, with 50 and 100 years return period in the offshore deep water over the Rio Grande shelf, feature large waves heights with 10.54 and 11.18 meters, respectively. The information presented here can be useful for those involved in coastal management and disaster response and also for the navigation and offshore operations. © 2021, Academia Brasileira de Ciencias. All rights reserved.","Extreme wave events; Peak over threshold; Return periods; WAVEWATCHIII","water; Brazil; computer simulation; Brazil; Computer Simulation; Water",Article,"Final","",Scopus,2-s2.0-85101155074
"Giesel M., Nowakowska A., Harris J.M., Hesse C.","23477051300;57191292034;7407315545;24824532100;","Perceptual uncertainty and action consequences independently affect hand movements in a virtual environment",2020,"Scientific Reports","10","1", 22307,"","",,,"10.1038/s41598-020-78378-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097750503&doi=10.1038%2fs41598-020-78378-z&partnerID=40&md5=c0f62f3784febd128933ff554e1c4fd4","School of Psychology, University of Aberdeen, Aberdeen, AB24 3FX, United Kingdom; School of Psychology and Neuroscience, University of St Andrews, St Andrews, KY16 9JP, United Kingdom","Giesel, M., School of Psychology, University of Aberdeen, Aberdeen, AB24 3FX, United Kingdom; Nowakowska, A., School of Psychology, University of Aberdeen, Aberdeen, AB24 3FX, United Kingdom; Harris, J.M., School of Psychology and Neuroscience, University of St Andrews, St Andrews, KY16 9JP, United Kingdom; Hesse, C., School of Psychology, University of Aberdeen, Aberdeen, AB24 3FX, United Kingdom","When we use virtual and augmented reality (VR/AR) environments to investigate behaviour or train motor skills, we expect that the insights or skills acquired in VR/AR transfer to real-world settings. Motor behaviour is strongly influenced by perceptual uncertainty and the expected consequences of actions. VR/AR differ in both of these aspects from natural environments. Perceptual information in VR/AR is less reliable than in natural environments, and the knowledge of acting in a virtual environment might modulate our expectations of action consequences. Using mirror reflections to create a virtual environment free of perceptual artefacts, we show that hand movements in an obstacle avoidance task systematically differed between real and virtual obstacles and that these behavioural differences occurred independent of the quality of the available perceptual information. This suggests that even when perceptual correspondence between natural and virtual environments is achieved, action correspondence does not necessarily follow due to the disparity in the expected consequences of actions in the two environments. © 2020, The Author(s).",,"article; artifact; augmented reality; avoidance behavior; expectation; hand movement; locomotion; motor performance; uncertainty; writing",Article,"Final","",Scopus,2-s2.0-85097750503
"Jeong D.C., Xu J.J., Miller L.C.","57195594176;57221749141;7404985693;","Inverse Kinematics and Temporal Convolutional Networks for Sequential Pose Analysis in VR",2020,"Proceedings - 2020 IEEE International Conference on Artificial Intelligence and Virtual Reality, AIVR 2020",,, 9319069,"274","281",,,"10.1109/AIVR50618.2020.00056","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100028648&doi=10.1109%2fAIVR50618.2020.00056&partnerID=40&md5=afd218807d2983a7da9f4e50b3ad921f","Santa Clara University, Department of Communication, Santa Clara, United States; University of Southern California, Annenberg School for Communication, Los Angeles, United States","Jeong, D.C., Santa Clara University, Department of Communication, Santa Clara, United States; Xu, J.J., University of Southern California, Annenberg School for Communication, Los Angeles, United States; Miller, L.C., University of Southern California, Annenberg School for Communication, Los Angeles, United States","Drawing from a recent call to advance generalizability and causal inference in psychological science using contextually representative research designs [1], we introduce a conceptual framework that integrates techniques in machine perception of poses with VR-driven inverse kinematic character animation, leveraging the Unity game engine to mediate between the human user and the machine learner. This Computational Virtual Reality (C-VR) system contains the following components: a) Human motion capture (VR), b) Human to avatar character animation (inverse kinematics), c) character animation recordings (virtual cameras), d) avatar pose detection (OpenPose), d) avatar pose classification (SVM), and e) sequential avatar moving pose analyses (TCN). By leveraging the precision in representation afforded in virtual environments and agents and the precision in perception afforded in computer vision and machine learning in a unified system, we may take steps towards understanding a wider range of human complexity. © 2020 IEEE.","avatars; computer vision; neural networks","Convolutional neural networks; Inverse kinematics; Learning systems; Support vector machines; Virtual reality; Causal inferences; Character animation; Conceptual frameworks; Convolutional networks; Human complexity; Human motion capture; Machine perception; Pose classifications; Animation",Conference Paper,"Final","",Scopus,2-s2.0-85100028648
"López Ríos O., Lechuga López L.J., Lechuga López G.","6602320190;57219186980;57219186115;","A comprehensive statistical assessment framework to measure the impact of immersive environments on skills of higher education students: a case study",2020,"International Journal on Interactive Design and Manufacturing","14","4",,"1395","1410",,,"10.1007/s12008-020-00698-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091611562&doi=10.1007%2fs12008-020-00698-1&partnerID=40&md5=9ea2c3ee7e6c8f12ca21f48c463182f0","Instituto Tecnológico y de Estudios Superiores de Monterrey, Campus CDMX, Mexico City, CDMX, Mexico; Université de Paris, UFR Informatique, 5 Rue Thomas Mann, Paris, France","López Ríos, O., Instituto Tecnológico y de Estudios Superiores de Monterrey, Campus CDMX, Mexico City, CDMX, Mexico; Lechuga López, L.J., Université de Paris, UFR Informatique, 5 Rue Thomas Mann, Paris, France; Lechuga López, G., Instituto Tecnológico y de Estudios Superiores de Monterrey, Campus CDMX, Mexico City, CDMX, Mexico","Universities are facing the challenge of updating the contents of their current study programs and adopting novel education strategies in order to prepare the next generation of engineers who can adapt to the highly competitive labor market of Industry 4.0. This new industrial era requires skills and competencies in state-of-the-art technologies which are constantly and rapidly evolving. This research presents an alternative approach to the current teaching–learning methodologies, focusing on the use of Virtual Reality (VR) as an educational tool and its contribution towards the upcoming industrial challenges, via what we call interactive education for future engineers (IE). Our IE strategy is supported by interactive simulation using the latest VR technologies, currently being Facebook’s Oculus Rift hardware and software. With this approach, we seek to enhance the “know-how” of our students by training them in the practical skills they will need for the technological innovations of the evolving labor market. Our work has been implemented in engineering courses at Tecnologico de Monterrey in Mexico, aligning with the university’s educational model “TEC21” which aims to increase the students’ self-learning capabilities using interactive teaching and hands-on practical work to develop new abilities and competencies in an expanded variety of domains. So far, our results have shown that the use of IE not only improves the way professors teach, but reinforces skills, competencies, enhances creativity and strongly motivates the students in their daily learning. © 2020, Springer-Verlag France SAS, part of Springer Nature.","Assessment; Competencies; Higher education; Industry 4.0; Interactive education; Virtual Reality","Commerce; Computer software; Education computing; Educational technology; Employment; Industrial research; Learning systems; Technology transfer; Virtual reality; Hardware and software; Higher education students; Industrial challenges; Interactive simulations; Self-learning capability; State-of-the-art technology; Statistical assessment; Technological innovation; Students",Article,"Final","",Scopus,2-s2.0-85091611562
"Rauscher M., Humpe A., Brehm L.","57212102453;57191606409;57125859600;","Virtual reality in tourism: Is it 'Real' enough?",2020,"Academica Turistica","13","2",,"127","138",,,"10.26493/2335-4194.13.127-138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099795988&doi=10.26493%2f2335-4194.13.127-138&partnerID=40&md5=f6a3055e8dfcd660b228e8aa2e759ef2","Munich University of Applied Sciences, Germany","Rauscher, M., Munich University of Applied Sciences, Germany; Humpe, A., Munich University of Applied Sciences, Germany; Brehm, L., Munich University of Applied Sciences, Germany","Virtual Reality Technology is increasingly becoming popular in the tourism sector. So far, the most researched application is the marketing of destinations. In contrast, the technology has also been mentioned as a means to limit or reduce the number of tourists at a specific sight or destination. In this respect vr is considered as a substitute for the actual trip. This paper addresses this issue by looking at the possibility to apply vr-technology to transfer the real-life experience into the digital world. In a qualitative research framework, visitor behaviour and experience are investigated when encountering vr sights in order to better understand items driving technology adoption. Structured content analysis is applied for data analysis where coding follows an adjusted Unified Theory of Acceptance and Use of Technology model. For interpretation purposes a pure qualitative framework was chosen. We find that enjoyment is an important driver for vr technology acceptance, whereas facilitating conditions and outcome expectations seem to be obstacles for it. Perceived usefulness is evaluated controversially. While the technology is not acknowledged as a substitute for a regular holiday trip, especially for travellers who take pleasure in active holidays or appreciate social interaction, it was recognised as an alternative for special occasions such as brief getaways from everyday life or short city trips. Overall, when appropriately implemented the technology might not only be useful to decrease visitor concentration in touristic hotspots or to decrease negative aspects associated with frequent travel but could further be applied to sites where visitors do not engage physically because sites are too distant, expensive, inhospitable, unsafe or fragile. © 2020 University of Primorska. All rights reserved.","Technology adoption; Tourism; Travel substitute; Utaut; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85099795988
"Rojas-Muñoz E., Lin C., Sanchez-Tamayo N., Cabrera M.E., Andersen D., Popescu V., Barragan J.A., Zarzaur B., Murphy P., Anderson K., Douglas T., Griffis C., McKee J., Kirkpatrick A.W., Wachs J.P.","57205650789;57193616240;57195214444;56661822000;56661805900;7103266698;57218000158;57207592471;57219322088;57212093286;57210912536;57210919543;55233918200;7103368482;9241519000;","Evaluation of an augmented reality platform for austere surgical telementoring: a randomized controlled crossover study in cricothyroidotomies",2020,"npj Digital Medicine","3","1", 75,"","",,3,"10.1038/s41746-020-0284-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087848610&doi=10.1038%2fs41746-020-0284-9&partnerID=40&md5=68d255c42100215022ef3ba3cf678424","School of Industrial Engineering, Purdue University, West Lafayette, IN, United States; Department of Computer Science, Purdue University, West Lafayette, IN, United States; Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, United States; Department of Surgery, School of Medicine, Indiana University, Indianapolis, IN, United States; Naval Medical Center Portsmouth, Portsmouth, VA, United States; Department of Surgery, and the Regional Trauma Services, University of Calgary, Calgary, AB, Canada; Department of Critical Care Medicine, University of Calgary, Calgary, AB, Canada; Canadian Forces Medical Services, Ottawa, ON, Canada","Rojas-Muñoz, E., School of Industrial Engineering, Purdue University, West Lafayette, IN, United States; Lin, C., Department of Computer Science, Purdue University, West Lafayette, IN, United States; Sanchez-Tamayo, N., School of Industrial Engineering, Purdue University, West Lafayette, IN, United States; Cabrera, M.E., Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, United States; Andersen, D., Department of Computer Science, Purdue University, West Lafayette, IN, United States; Popescu, V., Department of Computer Science, Purdue University, West Lafayette, IN, United States; Barragan, J.A., School of Industrial Engineering, Purdue University, West Lafayette, IN, United States; Zarzaur, B., Department of Surgery, School of Medicine, Indiana University, Indianapolis, IN, United States; Murphy, P., Department of Surgery, School of Medicine, Indiana University, Indianapolis, IN, United States; Anderson, K., Department of Surgery, School of Medicine, Indiana University, Indianapolis, IN, United States; Douglas, T., Naval Medical Center Portsmouth, Portsmouth, VA, United States; Griffis, C., Naval Medical Center Portsmouth, Portsmouth, VA, United States; McKee, J., Department of Surgery, and the Regional Trauma Services, University of Calgary, Calgary, AB, Canada; Kirkpatrick, A.W., Department of Surgery, and the Regional Trauma Services, University of Calgary, Calgary, AB, Canada, Department of Critical Care Medicine, University of Calgary, Calgary, AB, Canada, Canadian Forces Medical Services, Ottawa, ON, Canada; Wachs, J.P., School of Industrial Engineering, Purdue University, West Lafayette, IN, United States, Department of Surgery, School of Medicine, Indiana University, Indianapolis, IN, United States","Telementoring platforms can help transfer surgical expertise remotely. However, most telementoring platforms are not designed to assist in austere, pre-hospital settings. This paper evaluates the system for telementoring with augmented reality (STAR), a portable and self-contained telementoring platform based on an augmented reality head-mounted display (ARHMD). The system is designed to assist in austere scenarios: a stabilized first-person view of the operating field is sent to a remote expert, who creates surgical instructions that a local first responder wearing the ARHMD can visualize as three-dimensional models projected onto the patient’s body. Our hypothesis evaluated whether remote guidance with STAR could lead to performing a surgical procedure better, as opposed to remote audio-only guidance. Remote expert surgeons guided first responders through training cricothyroidotomies in a simulated austere scenario, and on-site surgeons evaluated the participants using standardized evaluation tools. The evaluation comprehended completion time and technique performance of specific cricothyroidotomy steps. The analyses were also performed considering the participants’ years of experience as first responders, and their experience performing cricothyroidotomies. A linear mixed model analysis showed that using STAR was associated with higher procedural and non-procedural scores, and overall better performance. Additionally, a binary logistic regression analysis showed that using STAR was associated to safer and more successful executions of cricothyroidotomies. This work demonstrates that remote mentors can use STAR to provide first responders with guidance and surgical knowledge, and represents a first step towards the adoption of ARHMDs to convey clinical expertise remotely in austere scenarios. © 2020, The Author(s).",,"adult; Article; augmented reality; controlled study; female; human; male; mentoring; priority journal; rating scale; surgeon; telementoring; tracheotomy; work experience",Article,"Final","",Scopus,2-s2.0-85087848610
"Lohre R., Bois A.J., Pollock J.W., Lapner P., McIlquham K., Athwal G.S., Goel D.P.","57215864647;55259753500;23980839200;55395887100;57215196711;6603148899;34881653400;","Effectiveness of Immersive Virtual Reality on Orthopedic Surgical Skills and Knowledge Acquisition Among Senior Surgical Residents: A Randomized Clinical Trial",2020,"JAMA network open","3","12",,"e2031217","",,,"10.1001/jamanetworkopen.2020.31217","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099115911&doi=10.1001%2fjamanetworkopen.2020.31217&partnerID=40&md5=9e49c1d4861330739cfc706cc3ef6346","Department of Orthopaedics, University of British Columbia, Vancouver, BC, Canada; Section of Orthopaedic Surgery, Department of Surgery, University of Calgary, Calgary, AB, Canada; Division of Orthopaedic Surgery, Department of Surgery, University of Ottawa, Ottawa, ON, Canada; Roth McFarlane Hand and Upper Limb Center, Western University Schulich School of Medicine and Dentistry, London, ON, Canada; Canadian Shoulder Elbow Society, Canadian Orthopaedic Association, Westmount, QC, Canada","Lohre, R., Department of Orthopaedics, University of British Columbia, Vancouver, BC, Canada; Bois, A.J., Section of Orthopaedic Surgery, Department of Surgery, University of Calgary, Calgary, AB, Canada; Pollock, J.W., Division of Orthopaedic Surgery, Department of Surgery, University of Ottawa, Ottawa, ON, Canada; Lapner, P., Division of Orthopaedic Surgery, Department of Surgery, University of Ottawa, Ottawa, ON, Canada; McIlquham, K., Division of Orthopaedic Surgery, Department of Surgery, University of Ottawa, Ottawa, ON, Canada; Athwal, G.S., Roth McFarlane Hand and Upper Limb Center, Western University Schulich School of Medicine and Dentistry, London, ON, Canada, Canadian Shoulder Elbow Society, Canadian Orthopaedic Association, Westmount, QC, Canada; Goel, D.P., Department of Orthopaedics, University of British Columbia, Vancouver, BC, Canada","Importance: Video learning prior to surgery is common practice for trainees and surgeons, and immersive virtual reality (IVR) simulators are of increasing interest for surgical training. The training effectiveness of IVR compared with video training in complex skill acquisition should be studied. Objectives: To evaluate whether IVR improves learning effectiveness for surgical trainees and to validate a VR rating scale through correlation to real-world performance. Design, Setting, and Participants: This block randomized, intervention-controlled clinical trial included senior (ie, postgraduate year 4 and 5) orthopedic surgery residents from multiple institutions in Canada during a single training course. An intention-to-treat analysis was performed. Data were collected from January 30 to February 1, 2020. Intervention: An IVR training platform providing a case-based module for reverse shoulder arthroplasty (RSA) for advanced rotator cuff tear arthropathy. Participants were permitted to repeat the module indefinitely. Main Outcomes and Measures: The primary outcome measure was a validated performance metric for both the intervention and control groups (Objective Structured Assessment of Technical Skills [OSATS]). Secondary measures included transfer of training (ToT), transfer effectiveness ratio (TER), and cost-effectiveness (CER) ratios of IVR training compared with control. Additional secondary measures included IVR performance metrics measured on a novel rating scale compared with real-world performance. Results: A total of 18 senior surgical residents participated; 9 (50%) were randomized to the IVR group and 9 (50%) to the control group. Participant demographic characteristics were not different for age (mean [SD] age: IVR group, 31.1 [2.8] years; control group, 31.0 [2.7] years), gender (IVR group, 8 [89%] men; control group, 6 [67%] men), surgical experience (mean [SD] experience with RSA: IVR group, 3.3 [0.9]; control group, 3.2 [0.4]), or prior simulator use (had experience: IVR group 6 [67%]; control group, 4 [44%]). The IVR group completed training 387% faster considering a single repetition (mean [SD] time for IVR group: 4.1 [2.5] minutes; mean [SD] time for control group: 16.1 [2.6] minutes; difference, 12.0 minutes; 95% CI, 8.8-14.0 minutes; P < .001). The IVR group had significantly better mean (SD) OSATS scores than the control group (15.9 [2.5] vs 9.4 [3.2]; difference, 6.9; 95% CI, 3.3-9.7; P < .001). The IVR group also demonstrated higher mean (SD) verbal questioning scores (4.1 [1.0] vs 2.2 [1.7]; difference, 1.9; 95% CI, 0.1-3.3; P = .03). The IVR score (ie, Precision Score) had a strong correlation to real-world OSATS scores (r = 0.74) and final implant position (r = 0.73). The ToT was 59.4%, based on the OSATS score. The TER was 0.79, and the system was 34 times more cost-effective than control, based on CER. Conclusions and Relevance: In this study, surgical training with IVR demonstrated superior learning efficiency, knowledge, and skill transfer. The TER of 0.79 substituted for 47.4 minutes of operating room time when IVR was used for 60 minutes. Trial Registration: ClinicalTrials.gov Identifier: NCT04404010.",,"adult; Canada; clinical competence; controlled study; education; female; human; male; medical education; orthopedic surgeon; orthopedic surgery; procedures; randomized controlled trial; simulation training; virtual reality; Adult; Canada; Clinical Competence; Female; Humans; Internship and Residency; Male; Orthopedic Procedures; Orthopedic Surgeons; Simulation Training; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85099115911
"Brickler D., Teather R.J., Duchowski A.T., Babu S.V.","57063224300;24588246800;6701824388;9039004700;","A fitts’ law evaluation of visuo-haptic fidelity and sensory mismatch on user performance in a near-field disc transfer task in virtual reality",2020,"ACM Transactions on Applied Perception","17","4", 15,"","",,,"10.1145/3419986","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098327645&doi=10.1145%2f3419986&partnerID=40&md5=405cfd1df7d08411fef108bce167fcb8","Clemson University, School of Computing, 100 McAdams Hall, Clemson, SC  29634, United States; Carleton University, School of Information Technology, 230 Azrieli Pavilion, 1125 Colonel By Drive, Ottawa, ON  K1S 5B6, Canada","Brickler, D., Clemson University, School of Computing, 100 McAdams Hall, Clemson, SC  29634, United States; Teather, R.J., Carleton University, School of Information Technology, 230 Azrieli Pavilion, 1125 Colonel By Drive, Ottawa, ON  K1S 5B6, Canada; Duchowski, A.T., Clemson University, School of Computing, 100 McAdams Hall, Clemson, SC  29634, United States; Babu, S.V., Clemson University, School of Computing, 100 McAdams Hall, Clemson, SC  29634, United States","The trade-off between speed and accuracy in precision tasks is important to evaluate during user interaction with input devices. When different sensory cues are added or altered in such interactions, those cues have an effect on this trade-off, and thus, they affect overall user performance. For instance, adding cues like haptic feedback and stereoscopic viewing will result in more realistic user interaction, thus improving performance in these tasks. Also, adding a noticeable disparity between physical and virtual movements creates a mismatch between visual and proprioceptive systems, which generally has a negative effect on performance. In this study, we investigate the effects of haptic feedback, stereoscopic viewing, and visuo-proprioceptive mismatch on how quickly and accurately users complete a virtual pick-and-place task using the PHANToM OMNI. Through this experiment, we find that in the movement phase of a ring transfer, movement time and user performance are affected by haptic feedback and visuo-proprioceptive mismatch, and the main effects of stereoscopic viewing appears to be limited to the more precise step when the ring is around the target peg. © 2020 Association for Computing Machinery.","Fitts’ law; Haptics; Near-field virtual reality; Stereo","Economic and social effects; Stereo image processing; Haptic feedbacks; Improving performance; Law evaluation; Movement time; Pick and place; Stereoscopic viewing; User interaction; User performance; Virtual reality",Article,"Final","",Scopus,2-s2.0-85098327645
"Nykänen M., Puro V., Tiikkaja M., Kannisto H., Lantto E., Simpura F., Uusitalo J., Lukander K., Räsänen T., Heikkilä T., Teperi A.-M.","57204180566;57193531916;51864912400;57210474667;57210417159;57210464151;57210465141;34976891300;7004111153;57219873265;36239398300;","Implementing and evaluating novel safety training methods for construction sector workers: Results of a randomized controlled trial",2020,"Journal of Safety Research","75",,,"205","221",,,"10.1016/j.jsr.2020.09.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095819636&doi=10.1016%2fj.jsr.2020.09.015&partnerID=40&md5=0f5de273bf90f1503b0331cdfff7f1e1","Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland","Nykänen, M., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Puro, V., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Tiikkaja, M., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Kannisto, H., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Lantto, E., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Simpura, F., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Uusitalo, J., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Lukander, K., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Räsänen, T., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Heikkilä, T., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland; Teperi, A.-M., Finnish Institute of Occupational Health, P.O. Box 40, Helsinki, FI-00032, Finland","Introduction: The construction industry is regarded as one of the most unsafe occupational fields worldwide. Despite general agreement that safety training is an important factor in preventing accidents in the construction sector, more studies are needed to identify effective training methods. To address the current research gap, this study evaluated the impact of novel, participatory safety training methods on construction workers’ safety competencies. Specifically, we assessed the efficacy of an immersive virtual reality (VR)-based safety training program and a participatory human factors safety training program (HFST) in construction industry workplaces. Method: In 2019, 119 construction sector workers from eight workplaces participated in a randomized controlled trial conducted in Finland. All the study participants were assessed using questionnaires at baseline, immediately after the intervention and at one-month follow-up. We applied generalized linear mixed modeling for statistical analysis. Results: Compared to lecture-based safety training, VR-based safety training showed a stronger impact on safety motivation, self-efficacy and safety-related outcome expectancies. In addition, the construction sector workers who participated in the VR-based safety training showed a greater increase in self-reported safety performance at one-month follow-up. Contrary to our study hypotheses, we found no significant differences between the study outcomes in terms of study participants in the HFST training condition and the comparison condition without HFST training. Conclusion: Our study indicates that VR technology as a safety training tool has potential to increase safety competencies and foster motivational change in terms of the safety performance of construction sector workers. In the future, the efficacy of participatory human factors safety training should be studied further using a version that targets both managerial and employee levels and is implemented in a longer format. Practical implications: Safety training in virtual reality provides a promising alternative to passive learning methods. Its motivating effect complements other safety training activities. © 2020","Human factors safety training; Safety locus of control; Safety motivation; Safety self-efficacy; Virtual reality","Accident prevention; Construction industry; Curricula; Human engineering; Learning systems; Motivation; Occupational risks; Safety factor; Surveys; Virtual reality; Construction sectors; Construction workers; Generalized linear mixed models; Immersive virtual reality; Randomized controlled trial; Safety performance; Safety training program; Training conditions; Personnel training; adult; article; building industry; comparative effectiveness; construction worker; controlled study; drug safety; employee; expectancy; female; Finland; follow up; human; human experiment; learning; locus of control; male; motivation; outcome assessment; questionnaire; randomized controlled trial; self concept; training; virtual reality; workplace",Article,"Final","",Scopus,2-s2.0-85095819636
"Hung S.C.-W., Ho A.Y.-N., Lai I.H.-W., Lee C.S.-W., Pong A.S.-K., Lai F.H.-Y.","57221111354;57221089186;57221107135;57221082203;57221100232;7202559750;","Meta-analysis on the effectiveness of virtual reality cognitive training (Vrct) and computer-based cognitive training (CBCT) for individuals with mild cognitive impairment (MCI)",2020,"Electronics (Switzerland)","9","12", 2185,"1","21",,,"10.3390/electronics9122185","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098193324&doi=10.3390%2felectronics9122185&partnerID=40&md5=1d7fc323c9ec04670313ebe5df17497b","Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hung Hom, Hong Kong","Hung, S.C.-W., Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; Ho, A.Y.-N., Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; Lai, I.H.-W., Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; Lee, C.S.-W., Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; Pong, A.S.-K., Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hung Hom, Hong Kong; Lai, F.H.-Y., Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hung Hom, Hong Kong","This meta-analysis aims to assess the effectiveness of virtual reality cognitive training (VRCT) and conventional computer-based cognitive training (CBCT) in five specific cognitive domains (i.e., global cognitive function (GCF), memory (Mem), executive function (EF), language (Lang) and visuospatial skills (VS)) of individuals with mild cognitive impairment. A total of 320 studies were yielded from five electronic databases. Eighteen randomized controlled trials met the PRISMA criteria, with 10 related to VRCT and 8 related to CBCT. A random-effect model was used in determining the main effect of cognitive training in five specific cognitive domains. VRCT provided the largest effect size on VS and Lang while the smallest on EF. CBCT provided the largest effect size on Mem and Lang while the smallest on EF. VRCT and CBCT generate an opposite effect on VS. VRCT outweighs CBCT in treatment effectiveness of GCF, EF, Lang and VS. More immersive and interactive experiences in VRCT may help individuals with MCI better engage in real-life experiences, which supports skill generalization and reduces external distractions. CBCT tends to improve Mem but no definite conclusions can be made. Further investigation with more stringent research design and specific protocol are required to reach consensus about the optimum intervention regime. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Cognitive training; Computer; Meta-analysis; Mild cognitive impairment; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85098193324
"Knierim P., Kiss F., Rauh M., Schmidt A.","55536806700;57194275301;57220211863;57204719065;","Tangibility is Overrated: Comparing Learning Experiences of Physical Setups and their Virtual Equivalent in Augmented Reality",2020,"ACM International Conference Proceeding Series",,,,"299","305",,1,"10.1145/3428361.3428379","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097281134&doi=10.1145%2f3428361.3428379&partnerID=40&md5=f2a3600f9efb5b510bc9846efe9c88ee","Lmu Munich, Germany; University of Stuttgart, Germany","Knierim, P., Lmu Munich, Germany; Kiss, F., University of Stuttgart, Germany; Rauh, M., Lmu Munich, Germany; Schmidt, A., Lmu Munich, Germany","Augmented Reality (AR) is gaining increasing importance in science, education, and entertainment. A fundamental characteristic of AR is blending the virtual and physical world into a coherent environment. In this paper, we examine the effect of substituting the physical components of lab experiments with tangible replicas and virtual representations. We conducted a user study with thirty participants who carried out the experiment in three different abstraction levels (original lab equipment, non-functional tangible props, virtual representation). We compared the users' performance regarding setup time, experienced workload, quality of measurements, and concept comprehension of the learning task. We found no effect on comprehension but significant differences in setup time and quality of measures. The results indicate that substitution reduces the experiment setup duration without affecting knowledge transfer. These results help to shape future AR learning environments, and we offer insights for creating complex mixed reality learning materials. © 2020 ACM.","Amplified Perception; Augmented Reality; Learning; Mixed Reality; Physical Substitution; Physics Lab Experiment; Thermal Vision","Augmented reality; Blending; Computer aided instruction; E-learning; Knowledge management; Abstraction level; Experiment set-up; Fundamental characteristics; Knowledge transfer; Learning environments; Learning experiences; Physical components; Virtual representations; Mixed reality",Conference Paper,"Final","",Scopus,2-s2.0-85097281134
"Saghafian M., Laumann K., Akhtar R.S., Skogstad M.R.","57220037198;6602490074;57220035991;57215534124;","The Evaluation of Virtual Reality Fire Extinguisher Training",2020,"Frontiers in Psychology","11",, 593466,"","",,,"10.3389/fpsyg.2020.593466","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096573932&doi=10.3389%2ffpsyg.2020.593466&partnerID=40&md5=fca9427d1ab4d858a5e268f33309576e","Department of Psychology, Faculty of Social and Educational Sciences, Norwegian University of Science and Technology, Trondheim, Norway","Saghafian, M., Department of Psychology, Faculty of Social and Educational Sciences, Norwegian University of Science and Technology, Trondheim, Norway; Laumann, K., Department of Psychology, Faculty of Social and Educational Sciences, Norwegian University of Science and Technology, Trondheim, Norway; Akhtar, R.S., Department of Psychology, Faculty of Social and Educational Sciences, Norwegian University of Science and Technology, Trondheim, Norway; Skogstad, M.R., Department of Psychology, Faculty of Social and Educational Sciences, Norwegian University of Science and Technology, Trondheim, Norway","The aim of this research was to explore trainees’ perceptions and evaluation of Virtual Reality fire extinguisher training. Virtual Reality technology is being adopted by many industries for various purposes including safety training for safety critical industries. The future direction of Virtual Reality training requires an understanding of trainees’ evaluation of it; this fact motivated this research. Data were collected from 85 participants using a questionnaire after the training. Observation notes were taken to provide a better understanding of the context. Qualitative research with a thematic analysis was used to analyze the data. The results of this analysis revealed that the most salient themes reflect on issues surrounding the realism of the Virtual Reality simulation, namely different emotional and bodily experiences during the training, while the benefits of the training (health, safety, environmental advantages, efficiency and convenience, repeatability and variety of scenarios) make it a good supplement. Nevertheless, improved realism is needed to make it more effective and enhance transfer and acceptance. This study encourages the consideration of important matters (such as realism and emotions) when using Virtual Reality for fire training. It also describes the positive perceptions of this type of training (repeatability of training, safety and environmental concerns). © Copyright © 2020 Saghafian, Laumann, Akhtar and Skogstad.","convenience; fire extinguisher training; realism; safety; virtual reality",,Article,"Final","",Scopus,2-s2.0-85096573932
"Ticala R., Ciupe A., Meza S., Orza B.","57221596383;57105700600;24829838400;24503681900;","Augmenting Learning through VR Storytelling",2020,"2020 14th International Symposium on Electronics and Telecommunications, ISETC 2020 - Conference Proceedings",,, 9301040,"","",,,"10.1109/ISETC50328.2020.9301040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099607360&doi=10.1109%2fISETC50328.2020.9301040&partnerID=40&md5=3d616e9bbba1803ae2f7470ab54f8174","Technical University of Cluj-Napoca, Multimedia Systems and Applications Laboratory, Cluj-Napoca, Romania","Ticala, R., Technical University of Cluj-Napoca, Multimedia Systems and Applications Laboratory, Cluj-Napoca, Romania; Ciupe, A., Technical University of Cluj-Napoca, Multimedia Systems and Applications Laboratory, Cluj-Napoca, Romania; Meza, S., Technical University of Cluj-Napoca, Multimedia Systems and Applications Laboratory, Cluj-Napoca, Romania; Orza, B., Technical University of Cluj-Napoca, Multimedia Systems and Applications Laboratory, Cluj-Napoca, Romania","This paper presents a narrative instructional model as an interaction framework in a Virtual Reality environment. Virtual Reality solutions provide the means to present a storytelling scenario through visual interactive models. The proposed implementation consists of a VR prototype developed to assist kindergarten and primary school pupils, in assimilating knowledge about different types of musical instruments, while developing a sense of practice-based interaction. The application is structured on three levels; each level is represented by an element of nature (water, earth and air), corresponding to the know-how complexity: water or level 0 which reflects an elementary level of intrinsic knowledge; towards the air environment that reflects the level of cumulative knowledge that will be reached by the end of the game. Knowledge is assimilated by interacting with elements in the virtual environment and by following the annotated guidelines. © 2020 IEEE.","animated characters; musical instruments; primary and kindergarten education; progressive knowledge; storytelling; virtual reality","Technology transfer; Air environment; Elementary levels; Instructional model; Interaction framework; Interactive models; Primary schools; Virtual-reality environment; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85099607360
"Sykownik P., Emmerich K., Masuch M.","57201134642;55376829000;6603274877;","Like in the good old times, but virtual - A case for simulating co-located multiplayer games in VR",2020,"CHI PLAY 2020 - Extended Abstracts of the 2020 Annual Symposium on Computer-Human Interaction in Play",,,,"379","383",,,"10.1145/3383668.3419885","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096774619&doi=10.1145%2f3383668.3419885&partnerID=40&md5=c45fe5c4daa7b0f98c34fdf17c296cc9","University Duisburg-Essen, Duisburg, Germany","Sykownik, P., University Duisburg-Essen, Duisburg, Germany; Emmerich, K., University Duisburg-Essen, Duisburg, Germany; Masuch, M., University Duisburg-Essen, Duisburg, Germany","In this paper, we present ongoing work on simulating the social setting of co-located multiplayer games in virtual reality (VR), to transfer the rich sociability associated with physical co-location to online gaming. We developed a VR application that allows two physically remote users to play games together on a virtual couch. Based on our initial experience in two small user tests, we assume that the VR version induces a social experience similar to the co-located gameplay. We will test this assumption in subsequent user studies. We also outline the theoretical and methodological relevance of VR-simulated couch-coop multiplayer games for researchers and practitioners. © 2020 ACM.","Co-located gaming; Multiplayer games; Online gaming; Social presence; Virtual reality","Interactive computer systems; User experience; Co-located; Colocations; Multiplayer games; On-line gaming; Remote users; Social settings; User study; VR applications; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-85096774619
"Doolani S., Owens L., Wessels C., Makedon F.","57219947037;57209983843;57219945746;57207521629;","Vis: An immersive virtual storytelling system for vocational training",2020,"Applied Sciences (Switzerland)","10","22", 8143,"1","15",,,"10.3390/app10228143","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096219073&doi=10.3390%2fapp10228143&partnerID=40&md5=49a6239c0b68d52f1173532bcf8a09c5","Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX  76019, United States","Doolani, S., Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX  76019, United States; Owens, L., Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX  76019, United States; Wessels, C., Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX  76019, United States; Makedon, F., Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX  76019, United States","Storytelling has been established as a proven method to effectively communicate and assist in knowledge transfer. In recent years, there has been growing interest in improving the training and learning domain by using advanced technology such as Virtual Reality (VR). However, a gap exists between storytelling and VR, and it is as yet unclear how they can be combined to form an effective system that not only maintains the level of engagement and immersion provided by VR technology but also provides the core strengths of storytelling. In this paper, we present vIS, a Vocational Immersive Storytelling system, which bridges the gap between storytelling and VR. vIS focuses on vocational training, in which users are trained on how to use a mechanical micrometer by employing a creative fictional story embedded inside a virtual manufacturing plant’s workplace. For the evaluation, a two-phase user study with 30 participants was conducted to measure the system’s effectiveness and improvements in long-term training, as well as to examine user experience against traditional methods of training—2D videos and textual manuals. The results indicate that the user’s ability to retain their training after seven days was nearly equal for vIS and the 2D video-based technique and was considerably higher than the text-based technique. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Storytelling; Usability testing; Virtual reality; Vocational training",,Article,"Final","",Scopus,2-s2.0-85096219073
"Monteiro D., Liang H.-N., Wang J., Chen H., Baghaei N.","57144011000;8636386200;57207048907;57221155309;14020983900;","An In-Depth Exploration of the Effect of 2D/3D Views and Controller Types on First Person Shooter Games in Virtual Reality",2020,"Proceedings - 2020 IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2020",,, 9284718,"713","724",,,"10.1109/ISMAR50242.2020.00102","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099294395&doi=10.1109%2fISMAR50242.2020.00102&partnerID=40&md5=9a9ee4dfccc97f04f5650a4b63a6eea1","Xi'an Jiaotong-Liverpool University, China; Massey University, New Zealand","Monteiro, D., Xi'an Jiaotong-Liverpool University, China; Liang, H.-N., Xi'an Jiaotong-Liverpool University, China; Wang, J., Xi'an Jiaotong-Liverpool University, China; Chen, H., Xi'an Jiaotong-Liverpool University, China; Baghaei, N., Massey University, New Zealand","The amount of interest in Virtual Reality (VR) research has significantly increased over the past few years, both in academia and industry. The release of commercial VR Head-Mounted Displays (HMDs) has been a major contributing factor. However, there is still much to be learned, especially how views and input techniques, as well as their interaction, affect the VR experience. There is little work done on First-Person Shooter (FPS) games in VR, and those few studies have focused on a single aspect of VR FPS. They either focused on the view, e.g., comparing VR to a typical 2D display or on the controller types. To the best of our knowledge, there are no studies investigating variations of 2D/3D views in HMDs, controller types, and their interactions. As such, it is challenging to distinguish findings related to the controller type from those related to the view. If a study does not control for the input method and finds that 2D displays lead to higher performance than VR, we cannot generalize the results because of the confounding variables. To understand their interaction, we propose to analyze in more depth, whether it is the view (2D vs. 3D) or the way it is controlled that gives the platforms their respective advantages. To study the effects of the 2D/3D views, we created a 2D visual technique, PlaneFrame, that was applied inside the VR headset. Our results show that the controller type can have a significant positive impact on performance, immersion, and simulator sickness when associated with a 2D view. They further our understanding of the interactions that controllers and views have and demonstrate that comparisons are highly dependent on how both factors go together. Further, through a series of three experiments, we developed a technique that can lead to a substantial performance, a good level of immersion, and can minimize the level of simulator sickness. © 2020 IEEE.","2D/3D Views; Controller types; First Person Shooter; Gaming; Head-Mounted Displays; Virtual Reality","Augmented reality; Controllers; Diseases; Helmet mounted displays; Contributing factor; First person shooter games; Head mounted displays; Input methods; Input techniques; Simulator sickness; Visual techniques; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85099294395
"Barsom E.Z., Duijm R.D., Dusseljee-Peute L.W.P., Landman-van der Boom E.B., van Lieshout E.J., Jaspers M.W., Schijven M.P.","57140782000;57209450976;57206834659;57218800815;57218802771;7005754901;6602492995;","Cardiopulmonary resuscitation training for high school students using an immersive 360-degree virtual reality environment",2020,"British Journal of Educational Technology","51","6",,"2050","2062",,1,"10.1111/bjet.13025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090308641&doi=10.1111%2fbjet.13025&partnerID=40&md5=f346cbaaca0fa9416060f7e3d520cd22","Public Health research institute, Department of Medical Informatics of the Amsterdam UMC, Netherlands; Amsterdam UMC, Netherlands","Barsom, E.Z.; Duijm, R.D.; Dusseljee-Peute, L.W.P., Public Health research institute, Department of Medical Informatics of the Amsterdam UMC, Netherlands; Landman-van der Boom, E.B.; van Lieshout, E.J.; Jaspers, M.W., Amsterdam UMC, Netherlands; Schijven, M.P., Amsterdam UMC, Netherlands","Cardiopulmonary resuscitation (CPR) is a lifesaving emergency procedure. To increase survival rates, it is recommended to increase the number of high school students who know how to perform CPR. We have developed an immersive “Virtual Reality (VR) Resuscitation Training” to train the theoretical knowledge of CPR in which trainees must save the life of the patient in a virtual environment. This paper presents a randomized controlled study with a pre-posttest design to explore whether a VR enhanced curriculum improves high school students’ theoretical CPR knowledge. Forty students without previous CPR experience in the past year were randomly assigned to either the VR group or the standard group. The VR group had a significant higher increase of correct answers in comparison with the Standard group. More importantly, the gain in score on taking the correct sequence of CPR steps was significant favouring the VR-enhanced protocol over the Standard protocol. Therefore, the use of a VR training for CPR training appears to be an effective learning method for non-medical students and may be of great value skilling high school students in becoming adequate CPR providers. © 2020 British Educational Research Association","Cardiopulmonary resuscitation; immersive environment; medical education; virtual reality","E-learning; Learning systems; Resuscitation; Students; Technology transfer; Cardiopulmonary resuscitation; Effective learning; Emergency procedures; High school students; Medical students; Standard groups; Standard protocols; Virtual-reality environment; Virtual reality",Article,"Final","",Scopus,2-s2.0-85090308641
"Gupta K., Lazarevic J., Pai Y.S., Billinghurst M.","57054785000;57203877361;56267209600;7006142663;","AffectivelyVR: Towards VR Personalized Emotion Recognition",2020,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,,,"","",,,"10.1145/3385956.3422122","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095811601&doi=10.1145%2f3385956.3422122&partnerID=40&md5=bd49b6691525d649e98b6259a1e2c72d","University of Auckland, Auckland, New Zealand; University of Novi Sad, Novi Sad, Serbia","Gupta, K., University of Auckland, Auckland, New Zealand; Lazarevic, J., University of Novi Sad, Novi Sad, Serbia; Pai, Y.S., University of Auckland, Auckland, New Zealand; Billinghurst, M., University of Auckland, Auckland, New Zealand","We present AffectivelyVR, a personalized real-time emotion recognition system in Virtual Reality (VR) that enables an emotion-adaptive virtual environment. We used off-the-shelf Electroencephalogram (EEG) and Galvanic Skin Response (GSR) physiological sensors to train user-specific machine learning models while exposing users to affective 360° VR videos. Since emotions are largely dependent on interpersonal experiences and expressed in different ways for different people, we personalize the model instead of generalizing it. By doing this, we achieved an emotion recognition rate of 96.5% using the personalized KNN algorithm, and 83.7% using the generalized SVM algorithm. © 2020 Owner/Author.","EEG; Emotion Recognition; GSR; Machine Learning; Personalized; Physiology; Virtual Reality","Electroencephalography; Electrophysiology; Speech recognition; Virtual reality; Adaptive virtual environments; Electro-encephalogram (EEG); Emotion recognition; Galvanic skin response; Machine learning models; Personalized emotion recognition; Physiological sensors; Real-time emotion recognition; Physiological models",Conference Paper,"Final","",Scopus,2-s2.0-85095811601
"Englmeier D., Fan F., Butz A.","57194090648;57221494100;55150450600;","Rock or Roll - Locomotion Techniques with a Handheld Spherical Device in Virtual Reality",2020,"Proceedings - 2020 IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2020",,, 9284676,"618","626",,1,"10.1109/ISMAR50242.2020.00089","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099291639&doi=10.1109%2fISMAR50242.2020.00089&partnerID=40&md5=2f5568c3878ae3680a3168bbb39af3dc","Lmu Munich, Munich, Germany","Englmeier, D., Lmu Munich, Munich, Germany; Fan, F., Lmu Munich, Munich, Germany; Butz, A., Lmu Munich, Munich, Germany","We investigate the use of a handheld spherical object as a controller for locomotion in VR. Rotating the object controls avatar movement in two different ways: As a zero order controller, it is continuously rotated to the target position as if rolling a ball on the floor. As a first order controller, it is tilted like a joystick to determine the direction and speed of movement. We describe how our prototype was built from low-cost commercially available hardware and discuss our design decisions. Then we evaluate both locomotion techniques in a user study (N=20) and compare them to established methods using handheld VR controllers. Our prototype matched and in some cases outperformed these methods regarding task time and accuracy. All results were obtained without any usage instructions, indicating easy learnability. Some of our insights may transfer to interaction with other naturally shaped objects in VR experiences. © 2020 IEEE.","Haptic devices; Human computer interaction (HCI); Human computer interaction (HCI); Human-centered computing; Human-centered computing; Interaction devices; Interaction paradigms; Virtual reality","Augmented reality; Costs; Virtual reality; Design decisions; First-order controller; Learnability; Locomotion technique; Spherical objects; Target position; User study; Zero order; Controllers",Conference Paper,"Final","",Scopus,2-s2.0-85099291639
"Martin N., Mathieu N., Pallamin N., Ragot M., Diverrez J.-M.","57188745225;57221495248;13405769400;57073515600;56928312300;","Virtual reality sickness detection: An approach based on physiological signals and machine learning",2020,"Proceedings - 2020 IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2020",,, 9284654,"387","399",,,"10.1109/ISMAR50242.2020.00065","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099321186&doi=10.1109%2fISMAR50242.2020.00065&partnerID=40&md5=eef96cc31598451773f458ec1c3fa5c9","Irt B<com, Cesson-Sevigne, France; Ubisoft, Montreuil, France","Martin, N., Irt B<com, Cesson-Sevigne, France; Mathieu, N., Ubisoft, Montreuil, France; Pallamin, N., Irt B<com, Cesson-Sevigne, France; Ragot, M., Irt B<com, Cesson-Sevigne, France; Diverrez, J.-M., Irt B<com, Cesson-Sevigne, France","Virtual Reality (VR) is spreading to the general public but still has a major issue: VR sickness. To take it into consideration and minimize its occurrence, evaluation methods are required. The current methods are mainly based on subjective measurements and therefore have several drawbacks (e.g., non-continuous, intrusive). Physiological signals combined with Machine Learning (ML) methods seem an interesting approach to go beyond these limits. In this paper, we present a large-scale experimentation (103 participants) where physiological data (cardiac and electrodermal activities) and subjective data (perceived VR sickness) were gathered during 30-minute VR video game sessions. Using ML methods, models were trained to predict VR sickness level (based on the physiological data labeled with the subjective data). Results showed an explained variance up to 75% (in a regression approach) and an accuracy up to 91% (in a classification approach). Despite generalization issues, this method seems promising and valuable for a real time, automatic and continuous evaluation of VR sickness, based on physiological signals and ML models. © 2020 IEEE.","Ergonomics; H.1.2 [Models and principles]: User/Machine Systems; Human factors; I.3.6 [Computer graphics]: Methodology and Techniques","Augmented reality; Diseases; E-learning; Machine learning; Physiology; Virtual reality; Classification approach; Electrodermal activity; Evaluation methods; General publics; Large-scale experimentations; Physiological data; Physiological signals; Subjective measurements; Physiological models",Conference Paper,"Final","",Scopus,2-s2.0-85099321186
"Souza V., Maciel A., Nedel L., Kopper R., Loges K., Schlemmer E.","57210972319;24329619800;8702986800;15022552000;57221603592;26424749700;","The Effect of Virtual Reality on Knowledge Transfer and Retention in Collaborative Group-Based Learning for Neuroanatomy Students",2020,"Proceedings - 2020 22nd Symposium on Virtual and Augmented Reality, SVR 2020",,, 9262701,"92","101",,,"10.1109/SVR51698.2020.00028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099538628&doi=10.1109%2fSVR51698.2020.00028&partnerID=40&md5=999be8e2249e7c159986b5ddaf469af4","Institute of Informatics (INF), Federal University of Rio Grande Do sul (UFRGS), Porto Alegre, Brazil; University of North Carolina at Greensboro (UNCG), Department of Computer Science, Greensboro, United States; University of Vale Do Rio Dos Sinos (UNISINOS), São Leopoldo, Brazil","Souza, V., Institute of Informatics (INF), Federal University of Rio Grande Do sul (UFRGS), Porto Alegre, Brazil; Maciel, A., Institute of Informatics (INF), Federal University of Rio Grande Do sul (UFRGS), Porto Alegre, Brazil; Nedel, L., Institute of Informatics (INF), Federal University of Rio Grande Do sul (UFRGS), Porto Alegre, Brazil; Kopper, R., University of North Carolina at Greensboro (UNCG), Department of Computer Science, Greensboro, United States; Loges, K., University of Vale Do Rio Dos Sinos (UNISINOS), São Leopoldo, Brazil; Schlemmer, E., University of Vale Do Rio Dos Sinos (UNISINOS), São Leopoldo, Brazil","There are many uses for virtual reality (VR) in education, and there is a consensus about its contribution in the teaching and learning processes. However, the majority of the studies assess the effectiveness of an individual learning in VR, and there is a need to explore more on the effects of VR using different levels of immersion and collaboration. This paper presents an experiment to investigate knowledge transfer in a group-based learning game. We introduce a VR serious game to support teaching and learning processes in neuroanatomy health education. A between-subjects experiment was conducted with 23 students to jointly assess learning, knowledge retention, and sense of presence. As a control condition, grouped students assembled a physical model of the human brain, while in the experimental condition, a virtual brain was assembled. In each group, one participant assembled the brain, while the others observed and verbally collaborated in a group-based learning strategy. Results shown high mean scores in the virtual condition. When comparing the knowledge test performance before and immediately after the experiment, we found significant difference only for the virtual condition. The same can be observed for retention. Because of the promising results achieved and motivated by the need of more engaging new tools for remote learning - fully used in quarantine conditions, such as the current one because of the Covid-19 pandemic - we conducted a pilot user study to evaluate the learning effect of a remote version of our collaborative VR game. © 2020 IEEE.","Presence; User Evaluation; Virtual Reality","Augmented reality; E-learning; Education computing; Knowledge management; Serious games; Teaching; Virtual reality; Collaborative groups; Experimental conditions; Individual learning; Knowledge retention; Knowledge transfer; Learning strategy; Sense of presences; Teaching and learning; Students",Conference Paper,"Final","",Scopus,2-s2.0-85099538628
"Vakaliuk T.A., Shevchuk L.D., Shevchuk B.V.","57211133927;57202217000;57219950205;","Possibilities of using AR and VR technologies in teaching mathematics to high school students",2020,"Universal Journal of Educational Research","8","11B",,"6280","6288",,,"10.13189/ujer.2020.082267","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096235416&doi=10.13189%2fujer.2020.082267&partnerID=40&md5=749ef820e7d73913b7f2a04b8e98ffe9","Department of Software Engineering, Faculty of Information and Computer Technologies, Zhytomyr Polytechnic State University, Ukraine; Mathematics Computer Science and Teaching Methods Department, Hryhorii Skovoroda University, Ukraine","Vakaliuk, T.A., Department of Software Engineering, Faculty of Information and Computer Technologies, Zhytomyr Polytechnic State University, Ukraine; Shevchuk, L.D., Mathematics Computer Science and Teaching Methods Department, Hryhorii Skovoroda University, Ukraine; Shevchuk, B.V., Mathematics Computer Science and Teaching Methods Department, Hryhorii Skovoroda University, Ukraine","Difficulties at the beginning of studying stereometry in 10 classes are well known from school practice. One of the main reasons for this is poorly developed spatial thinking and imagination. Therefore, the article describes some possibilities of using virtual and augmented reality in the process of teaching mathematics to students in 10-11 classes. It is established that pedagogical research in the field of theory of teaching mathematics should go this way. Undoubtedly, the lessons of mathematics with the addition of reality have a huge future in the field of education. The extensive use of virtual and augmented reality technologies in teaching mathematics proves the effectiveness and it is an attractive motivation for students. The use of augmented reality can be implemented in the teaching of mathematics from primary schools to universities. The object of research is the process of the formation of spatial imagination using virtual and augmented reality technologies in the process of teaching mathematics. The subject of the study is the environment of virtual and augmented reality. Research methods are analysis of publications on the problem, generalization of domestic and foreign experience, theoretical analysis, system analysis, systematization, and generalization of facts and patterns of research for the formation of spatial thinking using virtual and augmented reality environments, substantiation of the main conclusions. In our opinion, it is best to use free and well-made software such as ROAR AR for the Android operating system. Even in universities, it is advisable to use augmented reality systems in the training of future mathematics teachers, as they will be able to stop the decline in the popularity of mathematics studies in secondary and high schools by using such innovative teaching methods in their future pedagogical activities. © 2020 by authors.","Augmented Reality; Educational Technologies; Virtual Reality",,Article,"Final","",Scopus,2-s2.0-85096235416
"Klingenberg S., Jørgensen M.L.M., Dandanell G., Skriver K., Mottelson A., Makransky G.","57214077924;56015706700;6603030047;6701521625;57191531178;50361371800;","Investigating the effect of teaching as a generative learning strategy when learning through desktop and immersive VR: A media and methods experiment",2020,"British Journal of Educational Technology","51","6",,"2115","2138",,3,"10.1111/bjet.13029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091609462&doi=10.1111%2fbjet.13029&partnerID=40&md5=c050635d4c8cd7c89671a2651c5559af","Virtual Learning Lab at the Department of Psychology at the University of Copenhagen, United States; Department of Biology at the University of Copenhagen, United States; Department of Psychology at the University of Copenhagen, United States","Klingenberg, S., Virtual Learning Lab at the Department of Psychology at the University of Copenhagen, United States; Jørgensen, M.L.M., Department of Biology at the University of Copenhagen, United States; Dandanell, G., Department of Biology at the University of Copenhagen, United States; Skriver, K., Department of Biology at the University of Copenhagen, United States; Mottelson, A., Virtual Learning Lab at the Department of Psychology at the University of Copenhagen, United States; Makransky, G., Department of Psychology at the University of Copenhagen, United States","Immersive virtual reality (IVR) simulations for education have been found to increase affective outcomes compared to traditional media, but the effects on learning are mixed. As reflection has previously shown to enhance learning in traditional media, we investigated the efficacy of appropriate reflection exercises for IVR. In a 2 × 2 mixed-methods experiment, 89 (61 female) undergraduate biochemistry students learned about the electron transport chain through desktop virtual reality (DVR) and IVR (media conditions). Approximately, half of each group engaged in a subsequent generative learning strategy (GLS) of teaching in pairs (method conditions). A significant interaction between media and methods illustrated that the GLS of teaching significantly improved transfer (d = 1.26), retention (d = 0.60) and self-efficacy (d = 0.82) when learning through IVR, but not DVR. In the second part of the study, students switched media conditions and the experiment was repeated. This time, significant main effects favoring the IVR group on the outcomes of intrinsic motivation (d = 0.16), perceived enjoyment (d = 0.94) and presence (d = 1.29) were observed, indicating that students preferred IVR after having experienced both media conditions. The results support the view that methods enable media that affect learning and that the GLS of teaching is specifically relevant for IVR. © 2020 British Educational Research Association","biochemistry education; generative learning strategies; head-mounted displays; immersive virtual reality; learning; media versus methods","Electron transport properties; Students; Virtual reality; Desktop virtual reality; Electron transport chain; Enhance learning; Immersive virtual reality; Intrinsic motivation; Learning strategy; Perceived enjoyment; Self efficacy; Learning systems",Article,"Final","",Scopus,2-s2.0-85091609462
"Buttussi F., Chittaro L., Valent F.","16229748200;7004119007;6701724324;","A virtual reality methodology for cardiopulmonary resuscitation training with and without a physical mannequin",2020,"Journal of Biomedical Informatics","111",, 103590,"","",,,"10.1016/j.jbi.2020.103590","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092735575&doi=10.1016%2fj.jbi.2020.103590&partnerID=40&md5=442deb9abbf65196fa2e27093dd87c14","Human-Computer Interaction Lab, Department of Mathematics, Computer Science, and Physics, University of Udine, Udine, Italy; SOC Istituto di Igiene ed Epidemiologia Clinica, Azienda Sanitaria Universitaria Friuli Centrale, Udine, Italy","Buttussi, F., Human-Computer Interaction Lab, Department of Mathematics, Computer Science, and Physics, University of Udine, Udine, Italy, SOC Istituto di Igiene ed Epidemiologia Clinica, Azienda Sanitaria Universitaria Friuli Centrale, Udine, Italy; Chittaro, L., Human-Computer Interaction Lab, Department of Mathematics, Computer Science, and Physics, University of Udine, Udine, Italy; Valent, F., SOC Istituto di Igiene ed Epidemiologia Clinica, Azienda Sanitaria Universitaria Friuli Centrale, Udine, Italy","Background: Cardiopulmonary resuscitation (CPR) is an emergency procedure that can increase survival after a cardiac arrest. Performing CPR effectively requires both procedural knowledge and manual skills. Traditional CPR training methodology includes lessons led by instructors and supervised practice on mannequins, thus requiring considerable resources. Objective: This paper proposes a new methodology for low-cost CPR training based on virtual reality (VR) with and without the addition of a physical mannequin. Moreover, it describes an experimental evaluation of the methodology that assessed gain in manual skills during training, transfer of procedural knowledge and manual skills in a final assessment, and changes in self-efficacy with three measurements over time (pre-training, post-training, and post-assessment). Methods: We implemented a VR application that supports the proposed methodology, and can thus be used with or without a mannequin. The experimental evaluation involved 30 participants who tried CPR in VR twice, performing two repetitions of 30 chest compressions per trial. Half participants tried the VR application with the mannequin and half without it. Final assessment required all participants to perform CPR on the mannequin without the assistance of VR. To assess self-efficacy, participants filled in a questionnaire at the three times of measurement. Results: Mixed-design ANOVAs showed effects of repetition, effects of group, or interaction between the two variables on manual skills assessed during training. In the final assessment, participants in both groups correctly remembered most of the steps of the procedure. ANOVAs revealed differences between the two groups only in pressure-related skills (better with mannequin) and in the number of wrong steps added to the procedure (better without mannequin). Mixed-design ANOVA showed a self-efficacy increase in both groups after training, which was maintained after final assessment. Conclusions: The proposed VR methodology for CPR training has a positive effect on procedural knowledge, manual skills, and self-efficacy, with as well as without the physical mannequin. Trials on a mannequin are required to understand the correct pressure for chest compression. This supports the adoption of the proposed VR methodology to reduce instructor and mannequin time required to teach CPR to trainees. © 2020 Elsevier Inc.","Cardiopulmonary resuscitation; Experimental evaluation; Mannequin; Medical education; Training; Virtual reality","E-learning; Virtual reality; Cardiopulmonary resuscitation; Chest compressions; Considerable resources; Emergency procedures; Experimental evaluation; Post assessment; Procedural knowledge; VR applications; Resuscitation; adult; advanced life support; analysis of variance; Article; compression; computer simulation; controlled study; emergency health service; female; human; Likert scale; male; methodology; priority journal; protective glasses; questionnaire; resuscitation; skill; training; virtual reality; young adult",Article,"Final","",Scopus,2-s2.0-85092735575
"Lampen E., Lehwald J., Pfeiffer T.","57209683199;57202847650;14027435500;","Virtual Humans in AR: Evaluation of Presentation Concepts in an Industrial Assistance Use Case",2020,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,,,"","",,,"10.1145/3385956.3418974","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095834964&doi=10.1145%2f3385956.3418974&partnerID=40&md5=6990b67981dda33559c0b31456034299","EvoBus GmbH, Neu-Ulm, Germany; Faculty of Technology, University of Applied Sciences Emden/Leer, Emden, Germany","Lampen, E., EvoBus GmbH, Neu-Ulm, Germany; Lehwald, J., EvoBus GmbH, Neu-Ulm, Germany; Pfeiffer, T., Faculty of Technology, University of Applied Sciences Emden/Leer, Emden, Germany","Embedding virtual humans in educational settings enables the transfer of the approved concepts of learning by observation and imitation of experts to extended reality scenarios. Whilst various presentation concepts of virtual humans for learning have been investigated in sports and rehabilitation, little is known regarding industrial use cases. In prior work on manual assembly, Lampen et al. [21] show that three-dimensional (3D) registered virtual humans can provide assistance as effective as state-of-the-art HMD-based AR approaches. We extend this work by conducting a comparative user study (N=30) to verify implementation costs of assistive behavior features and 3D registration. The results reveal that the basic concept of a 3D registered virtual human is limited and comparable to a two-dimensional screen aligned presentation. However, by incorporating additional assistive behaviors, the 3D assistance concept is enhanced and shows significant advantages in terms of cognitive savings and reduced errors. Thus, it can be concluded, that this presentation concept is valuable in situations where time is less crucial, e.g. in learning scenarios or during complex tasks. © 2020 ACM.","Augmented Reality; Expert-Based Learning; Virtual Human","E-learning; Educational settings; Implementation cost; Industrial use case; Learning by observation; Learning scenarios; Sports and rehabilitations; State of the art; Threedimensional (3-d); Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85095834964
"Pletz C., Zinn B.","57218546432;36770118100;","Evaluation of an immersive virtual learning environment for operator training in mechanical and plant engineering using video analysis",2020,"British Journal of Educational Technology","51","6",,"2159","2179",,1,"10.1111/bjet.13024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089538860&doi=10.1111%2fbjet.13024&partnerID=40&md5=f0549fc6714395b5221f74594500ae9d","Department of Vocational Education focused on Teaching Technology (BPT) at the, University of Stuttgart, Germany; Department of Vocational Education focused on Teaching Technology (BPT), University of Stuttgart, Germany","Pletz, C., Department of Vocational Education focused on Teaching Technology (BPT) at the, University of Stuttgart, Germany; Zinn, B., Department of Vocational Education focused on Teaching Technology (BPT), University of Stuttgart, Germany","A structural evaluation is imperative for developing an effective virtual learning environment. Understanding the extent to which content that has been learned virtually can be applied practically holds particular importance. A group of persons from the technical field of mechanical and plant engineering (N = 13) participated in a virtual operator training for a case application of additive manufacturing. To evaluate the virtual learning environment the participants answered quantitative questionnaires and were asked to apply what they had learned virtually to the real machine. Both the virtual training and testing phase on the real machine were recorded by video (800 minutes in total). The category system resulting from a structured qualitative video analysis with a total of 568 codes contains design-, instruction- and interaction-related optimisation potentials for further development of the virtual learning sequence. Mistakes, difficulties and other anomalies during the application on the real machine provide further revision options. The study uses video data for the first time to derive optimisation potentials and to investigate the learning transfer of virtually learned action knowledge to the real-world activity. © 2020 The Authors. British Journal of Educational Technology published by John Wiley & Sons Ltd on behalf of British Educational Research Association",,"Computer aided instruction; Engineering education; Learning systems; Personnel training; Surveys; Virtual reality; Learning Transfer; Operator training; Plant engineering; Real-world activities; Structural evaluation; Virtual learning; Virtual learning environments; Virtual operators; E-learning",Article,"Final","",Scopus,2-s2.0-85089538860
"Armstrong M., Tsuchiya K., Liang F., Kunze K., Pai Y.S.","57219866273;57194083287;57191504624;21743317500;56267209600;","Multiplex Vision: Understanding Information Transfer and F-Formation with Extended 2-Way FOV",2020,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,,,"","",,,"10.1145/3385956.3418954","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095814394&doi=10.1145%2f3385956.3418954&partnerID=40&md5=89c416380a230628f82185e756df2444","Keio University, Graduate School of Media Design, Tokyo, Japan; INNOCC Ignition Point Inc., Tokyo, Japan; University of Auckland, Auckland, New Zealand","Armstrong, M., Keio University, Graduate School of Media Design, Tokyo, Japan; Tsuchiya, K., Keio University, Graduate School of Media Design, Tokyo, Japan; Liang, F., INNOCC Ignition Point Inc., Tokyo, Japan; Kunze, K., Keio University, Graduate School of Media Design, Tokyo, Japan; Pai, Y.S., University of Auckland, Auckland, New Zealand","Research in sociology shows that effective conversation relates to people's spatial and orientational relationship, namely the proxemics (distance, eye contact, synchrony) and the F-formation (orientation and arrangement). In this work, we introduce novel conversational paradigms that effects conventional F-formation by introducing the concept of multi-directional conversation. Multiplex Vision is a head-mounted device capable of providing a 360° field-of-view (FOV) and facilitating multi-user interaction multi-directionally, thereby providing novel methods on how people can interact with each other. We propose 3 possible new forms of interactions from our prototype: one-to-one, one-to-many, and many-to-many. To facilitate them, we manipulate 2 key variables, which are the viewing parameter and the display parameter. To gather feedback for our system, we conducted a study to understand information transfer between various modes, as well as a user study on how different proposed paradigms effect conversation. Finally, we discuss present and future use cases that can benefit from our system. © 2020 ACM.","360 field-of-view; conversation; F-formation; vision augmentation","Sociology; Display parameters; Field of views; Information transfers; Key variables; Multi-user interaction; Novel methods; Orientational relationship; Viewing parameters; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85095814394
"Petersen G.B., Klingenberg S., Mayer R.E., Makransky G.","57205735672;57214077924;7403065717;50361371800;","The virtual field trip: Investigating how to optimize immersive virtual learning in climate change education",2020,"British Journal of Educational Technology","51","6",,"2098","2114",,6,"10.1111/bjet.12991","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087505916&doi=10.1111%2fbjet.12991&partnerID=40&md5=95f409f7b19bb124fd571c95d712bfb7","Department of Psychology, University of Copenhagen, Denmark; University of Copenhagen, Denmark; University of California, Santa Barbara, United States; Department of Psychology at the University of Copenhagen, Denmark","Petersen, G.B., Department of Psychology, University of Copenhagen, Denmark; Klingenberg, S., University of Copenhagen, Denmark; Mayer, R.E., University of California, Santa Barbara, United States; Makransky, G., Department of Psychology at the University of Copenhagen, Denmark","Immersive Virtual Reality (IVR) is being used for educational virtual field trips (VFTs) involving scenarios that may be too difficult, dangerous or expensive to experience in real life. We implemented an immersive VFT within the investigation phase of an inquiry-based learning (IBL) climate change intervention. Students investigated the consequences of climate change by virtually traveling to Greenland and exploring albedo and greenhouse effects first hand. A total of 102 seventh and eighth grade students were randomly assigned to one of two instructional conditions: (1) narrated pretraining followed by IVR exploration or (2) the same narrated training material integrated within the IVR exploration. Students in both conditions showed significant increases in declarative knowledge, self-efficacy, interest, STEM intentions, outcome expectations and intentions to change behavior from the pre- to post-assessment. However, there was a significant difference between conditions favoring the pretraining group on a transfer test consisting of an oral presentation to a fictitious UN panel. The findings suggest that educators can choose to present important prerequisite learning content before or during a VFT. However, adding pretraining may lead to better transfer test performance, presumably because it helps reduce cognitive load while learning in IVR. © 2020 British Educational Research Association",,"Climate change; Students; Virtual reality; Declarative knowledge; Immersive virtual reality; Inquiry based learning (IBL); Learning contents; Oral presentations; Training material; Virtual field trips; Virtual learning; E-learning",Article,"Final","",Scopus,2-s2.0-85087505916
"Gummadi S., Kadiyala M.D.M., Rao K.P.C., Athanasiadis I., Mulwa R., Kilavi M., Legesse G., Amede T.","57188588085;55480964500;55797688000;57210555473;26039342200;56161885900;56112043200;56294007700;","Simulating adaptation strategies to offset potential impacts of climate variability and change on maize yields in Embu County, Kenya",2020,"PLoS ONE","15","11 November", e0241147,"","",,,"10.1371/journal.pone.0241147","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095723253&doi=10.1371%2fjournal.pone.0241147&partnerID=40&md5=189e60852f80eea540f7507764c22809","International Crops Research Institute for the Semi-Arid Tropics (ICRISAT), Addis Ababa, Ethiopia; Acharya N. G. Ranga Agricultural University (ANGRAU), Guntur, Andhra Pradesh, India; Wageningen University, Gelderland, Netherlands; Centre for Advanced Studies in Environmental Law and policy (CASELAP), University of Nairobi, Nairobi, Kenya; Kenya Meteorological Department, Nairobi, Kenya","Gummadi, S., International Crops Research Institute for the Semi-Arid Tropics (ICRISAT), Addis Ababa, Ethiopia; Kadiyala, M.D.M., Acharya N. G. Ranga Agricultural University (ANGRAU), Guntur, Andhra Pradesh, India; Rao, K.P.C., International Crops Research Institute for the Semi-Arid Tropics (ICRISAT), Addis Ababa, Ethiopia; Athanasiadis, I., Wageningen University, Gelderland, Netherlands; Mulwa, R., Centre for Advanced Studies in Environmental Law and policy (CASELAP), University of Nairobi, Nairobi, Kenya; Kilavi, M., Kenya Meteorological Department, Nairobi, Kenya; Legesse, G., International Crops Research Institute for the Semi-Arid Tropics (ICRISAT), Addis Ababa, Ethiopia; Amede, T., International Crops Research Institute for the Semi-Arid Tropics (ICRISAT), Addis Ababa, Ethiopia","In this study, we assessed the possible impacts of climate variability and change on growth and performance of maize using multi-climate, multi-crop model approaches built on Agricultural Model Intercomparison and Improvement Project (AgMIP) protocols in five different agro-ecological zones (AEZs) of Embu County in Kenya and under different management systems. Adaptation strategies were developed that are locally relevant by identifying a set of technologies that help to offset potential impacts of climate change on maize yields. Impacts and adaptation options were evaluated using projections by 20 Coupled Model Intercomparison Project-Phase 5 (CMIP5) climate models under two representative concentration pathways (RCPs) 4.5 and 8.5. Two widely used crop simulation models, Agricultural Production Systems Simulator (APSIM) and Decision Support System for Agrotechnology Transfer (DSSAT) was used to simulate the potential impacts of climate change on maize. Results showed that 20 CMIP5 models are consistent in their projections of increased surface temperatures with different magnitude. Projections by HadGEM2-CC, HadGEM2-ES, and MIROC-ESM tend to be higher than the rest of 17 CMIP5 climate models under both emission scenarios. The projected increase in minimum temperature (Tmin) which ranged between 2.7 and 5.8°C is higher than the increase in maximum temperature (Tmax) that varied between 2.2 and 4.8°C by end century under RCP 8.5. Future projections in rainfall are less certain with high variability projections by GFDL-ESM2G, MIROC5, and NorESM1-M suggest 8 to 25% decline in rainfall, while CanESM2, IPSL-CM5A-MR and BNU-ESM suggested more than 85% increase in rainfall under RCP 8.5 by end of 21st century. Impacts of current and future climatic conditions on maize yields varied depending on the AEZs, soil type, crop management and climate change scenario. Impacts are largely negative in the low potential AEZs such as Lower Midlands (LM4 and LM5) compared with the high potential AEZs Upper Midlands (UM2 and UM3). However, impacts of climate change are largely positive across all AEZs and management conditions when CO2 fertilization is included. Using the differential impacts of climate change, a strategy to adapt maize cultivation to climate change in all the five AEZs was identified by consolidating those practices that contributed to increased yields under climate change. We consider this approach as more appropriate to identify operational adaptation strategies using readily available technologies that contribute positively under both current and future climatic conditions. This approach when adopted in strategic manner will also contribute to further strengthen the development of adaptation strategies at national and local levels. The methods and tools validated and applied in this assessment allowed estimating possible impacts of climate change and adaptation strategies which can provide valuable insights and guidance for adaptation planning. © 2020 Gummadi et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"carbon dioxide; rain; adaptation; Article; climate change; concentration (parameter); crop management; environmental impact; environmental impact assessment; environmental management; environmental planning; environmental temperature; field emission; Kenya; magnitude estimation method; maize; nonhuman; plant growth; plant yield; simulation; soil; soil fertilization; surface area; tillage; zeta potential; adaptation; agriculture; climate change; computer simulation; crop; growth, development and aging; maize; physiology; procedures; temperature; Adaptation, Physiological; Agriculture; Climate Change; Computer Simulation; Crops, Agricultural; Kenya; Soil; Temperature; Zea mays",Article,"Final","",Scopus,2-s2.0-85095723253
"Schwarz S., Regal G., Kempf M., Schatz R.","56785127800;55848939000;57204063955;35609979600;","Learning Success in Immersive Virtual Reality Training Environments: Practical Evidence from Automotive Assembly",2020,"ACM International Conference Proceeding Series",,,,"","",,,"10.1145/3419249.3420182","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095803774&doi=10.1145%2f3419249.3420182&partnerID=40&md5=eeef469f019ee50a6111f03a2664300c","Austrian Institute of Technology GmbH, Vienna, Austria; Innovation.rocks GmbH, Vienna, Austria","Schwarz, S., Austrian Institute of Technology GmbH, Vienna, Austria; Regal, G., Austrian Institute of Technology GmbH, Vienna, Austria; Kempf, M., Innovation.rocks GmbH, Vienna, Austria; Schatz, R., Austrian Institute of Technology GmbH, Vienna, Austria","Learning success in assembly training using immersive virtual reality technologies depends on multiple factors ranging from quality levels of process and technical documentation, visual 3D rendering quality, maturity of didactic concepts to individual differences and attitudes of workers and trainers. In this paper, we present the results of a field study conducted in an automotive factory to evaluate an immersive virtual reality training environment (VTE). Set up under real training conditions, the VTE was operated by trainers to train novice assembly line workers on a specific task: the assembly of a vehicle center console. Using a between-subject design we compare training performance in terms of skill transfer and retention between workers being trained in the VTE to workers who had been trained conventionally on the physical car. Our results suggest positive transfer of the acquired procedures from the VTE to physical assembly and even performance improvements over time. We discuss learning success in the VTE in contrast to user experience feedback and the implemented sequence steps for mounting assembly parts, based on comprehensive behavioral data. Finally, reflections on trainer feedback lead the way to implications for the adaption of didactic strategies and operational procedures towards increasing overall effectiveness of VTE-supported assembly training. © 2020 ACM.","Automotive Assembly; Learning Transfer; Trainers.; Training; Virtual Reality; Workers","E-learning; Human computer interaction; Three dimensional computer graphics; User experience; Assembly-line workers; Automotive assemblies; Experience feedback; Immersive virtual reality; Individual Differences; Operational procedures; Overall effectiveness; Technical documentations; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85095803774
"Zhang Z., Zhu Y., Zhu S.-C.","57218422359;57140988800;22236080700;","Graph-based hierarchical knowledge representation for robot task transfer from virtual to physical world",2020,"IEEE International Conference on Intelligent Robots and Systems",,, 9340843,"11139","11145",,,"10.1109/IROS45743.2020.9340843","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102396402&doi=10.1109%2fIROS45743.2020.9340843&partnerID=40&md5=44bd1fe0c3ab85426ae801dd12f7dc4a","Tencent; UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA), Statistics Department","Zhang, Z., Tencent; Zhu, Y., UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA), Statistics Department; Zhu, S.-C., UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA), Statistics Department","We study the hierarchical knowledge transfer problem using a cloth-folding task, wherein the agent is first given a set of human demonstrations in the virtual world using an Oculus Headset, and later transferred and validated on a physical Baxter robot. We argue that such an intricate robot task transfer across different embodiments is only realizable if an abstract and hierarchical knowledge representation is formed to facilitate the process, in contrast to prior literature of sim2real in a reinforcement learning setting. Specifically, the knowledge in both the virtual and physical worlds are measured by information entropy built on top of a graph-based representation, so that the problem of task transfer becomes the minimization of the relative entropy between the two worlds. An And-Or-Graph (AOG) is introduced to represent the knowledge, induced from the human demonstrations performed across six virtual scenarios inside the Virtual Reality (VR). During the transfer, the success of a physical Baxter robot platform across all six tasks demonstrates the efficacy of the graph-based hierarchical knowledge representation. © 2020 IEEE.",,"Agricultural robots; Graphic methods; Intelligent robots; Knowledge management; Reinforcement learning; Virtual reality; Graph-based representations; Hierarchical knowledge; Human demonstrations; Information entropy; Relative entropy; Robot platform; Virtual scenario; Virtual worlds; Knowledge representation",Conference Paper,"Final","",Scopus,2-s2.0-85102396402
"Reidy L., Chan D., Nduka C., Gunes H.","57219692602;7402215873;6701344479;7005067251;","Facial Electromyography-based Adaptive Virtual Reality Gaming for Cognitive Training",2020,"ICMI 2020 - Proceedings of the 2020 International Conference on Multimodal Interaction",,,,"174","183",,,"10.1145/3382507.3418845","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096675924&doi=10.1145%2f3382507.3418845&partnerID=40&md5=90924d4272dc8c02fa5721a1381ffeac","University of Cambridge, Cambridge, United Kingdom; University College London, London, United Kingdom; Emteq Ltd, United Kingdom","Reidy, L., University of Cambridge, Cambridge, United Kingdom; Chan, D., University College London, London, United Kingdom; Nduka, C., Emteq Ltd, United Kingdom; Gunes, H., University of Cambridge, Cambridge, United Kingdom","Cognitive training has shown promising results for delivering improvements in human cognition related to attention, problem solving, reading comprehension and information retrieval. However, two frequently cited problems in cognitive training literature are a lack of user engagement with the training programme, and a failure of developed skills to generalise to daily life. This paper introduces a new cognitive training (CT) paradigm designed to address these two limitations by combining the benefits of gamification, virtual reality (VR), and affective adaptation in the development of an engaging, ecologically valid, CT task. Additionally, it incorporates facial electromyography (EMG) as a means of determining user affect while engaged in the CT task. This information is then utilised to dynamically adjust the game's difficulty in real-time as users play, with the aim of leading them into a state of flow. Affect recognition rates of 64.1% and 76.2%, for valence and arousal respectively, were achieved by classifying a DWT-Haar approximation of the input signal using kNN. The affect-aware VR cognitive training intervention was then evaluated with a control group of older adults. The results obtained substantiate the notion that adaptation techniques can lead to greater feelings of competence and a more appropriate challenge of the user's skills. © 2020 Owner/Author.","adaptive gaming; affective computing; cognitive training; facial electromyography; virtual reality","E-learning; Interactive computer systems; Virtual addresses; Adaptation techniques; Affect recognition; Cognitive training; Facial electromyographies; Human cognition; Reading comprehension; Training programmes; User engagement; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85096675924
"McIntosh J., Zajac H.D., Stefan A.N., Bergström J., Hornbæk K.","57188763518;57220116799;57220115883;57210962041;6602385484;","Iteratively adapting avatars using task-integrated optimisation",2020,"UIST 2020 - Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology",,, 3415832,"709","721",,,"10.1145/3379337.3415832","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096968994&doi=10.1145%2f3379337.3415832&partnerID=40&md5=335c57f6515e33f2e0a9ad2ad2c2a6ad","University of Copenhagen, Copenhagen, Denmark","McIntosh, J., University of Copenhagen, Copenhagen, Denmark; Zajac, H.D., University of Copenhagen, Copenhagen, Denmark; Stefan, A.N., University of Copenhagen, Copenhagen, Denmark; Bergström, J., University of Copenhagen, Copenhagen, Denmark; Hornbæk, K., University of Copenhagen, Copenhagen, Denmark","Virtual Reality allows users to embody avatars that do not match their real bodies. Earlier work has selected changes to the avatar arbitrarily and it therefore remains unclear how to change avatars to improve users' performance. We propose a systematic approach for iteratively adapting the avatar to perform better for a given task based on users' performance. The approach is evaluated in a target selection task, where the forearms of the avatar are scaled to improve performance. A comparison between the optimised and real arm lengths shows a significant reduction in average tapping time by 18.7%, for forearms multiplied in length by 5.6. Additionally, with the adapted avatar, participants moved their real body and arms significantly less, and subjective measures show reduced physical demand and frustration. In a second study, we modify finger lengths for a linear tapping task to achieve a better performing avatar, which demonstrates the generalisability of the approach. © 2020 ACM.","Avatar adaptation; Optimisation; Virtual reality","Iterative methods; Arm lengths; Improve performance; Optimisations; Physical demand; Tapping time; Target selection; Task-based; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-85096968994
"Du J., Yu F.R., Lu G., Wang J., Jiang J., Chu X.","57188706756;57213980384;7403460635;13613533800;57198571713;8536386700;","MEC-Assisted Immersive VR Video Streaming over Terahertz Wireless Networks: A Deep Reinforcement Learning Approach",2020,"IEEE Internet of Things Journal","7","10", 9120235,"9517","9529",,10,"10.1109/JIOT.2020.3003449","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092709939&doi=10.1109%2fJIOT.2020.3003449&partnerID=40&md5=9d415f1ee32084295aa918f217856727","Shaanxi Key Laboratory of Information Communication Network and Security, School of Communications and Information Engineering, Xi'an University of Posts and Telecommunications, Xi'an, 710121, China; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON  K1S 5B6, Canada; Department of Electronic and Electrical Engineering, University of Sheffield, Sheffield, S1 3JD, United Kingdom","Du, J., Shaanxi Key Laboratory of Information Communication Network and Security, School of Communications and Information Engineering, Xi'an University of Posts and Telecommunications, Xi'an, 710121, China; Yu, F.R., Department of Systems and Computer Engineering, Carleton University, Ottawa, ON  K1S 5B6, Canada; Lu, G., Shaanxi Key Laboratory of Information Communication Network and Security, School of Communications and Information Engineering, Xi'an University of Posts and Telecommunications, Xi'an, 710121, China; Wang, J., Shaanxi Key Laboratory of Information Communication Network and Security, School of Communications and Information Engineering, Xi'an University of Posts and Telecommunications, Xi'an, 710121, China; Jiang, J., Shaanxi Key Laboratory of Information Communication Network and Security, School of Communications and Information Engineering, Xi'an University of Posts and Telecommunications, Xi'an, 710121, China; Chu, X., Department of Electronic and Electrical Engineering, University of Sheffield, Sheffield, S1 3JD, United Kingdom","Immersive virtual reality (VR) video is becoming increasingly popular owing to its enhanced immersive experience. To enjoy ultrahigh resolution immersive VR video with wireless user equipments, such as head-mounted displays (HMDs), ultralow-latency viewport rendering, and data transmission are the core prerequisites, which could not be achieved without a huge bandwidth and superior processing capabilities. Besides, potentially very high energy consumption at the HMD may impede the rapid development of wireless panoramic VR video. Multiaccess edge computing (MEC) has emerged as a promising technology to reduce both the task processing latency and the energy consumption for HMD, while bandwidth-rich terahertz (THz) communication is expected to enable ultrahigh-speed wireless data transmission. In this article, we propose to minimize the long-term energy consumption of a THz wireless access-based MEC system for high quality immersive VR video services support by jointly optimizing the viewport rendering offloading and downlink transmit power control. Considering the time-varying nature of wireless channel conditions, we propose a deep reinforcement learning-based approach to learn the optimal viewport rendering offloading and transmit power control policies and an asynchronous advantage actor-critic (A3C)-based joint optimization algorithm is proposed. The simulation results demonstrate that the proposed algorithm converges fast under different learning rates, and outperforms existing algorithms in terms of minimized energy consumption and maximized reward. © 2014 IEEE.","Asynchronous advantage actor-critic (A3C); computation offloading; deep reinforcement learning (DRL); terahertz (THz) communication; virtual reality (VR)","Bandwidth; Data communication equipment; Data transfer; Deep learning; Energy utilization; Green computing; Helmet mounted displays; Learning algorithms; Power control; Quality control; Reinforcement learning; Rendering (computer graphics); Video streaming; Wave transmission; Wireless networks; Head mounted displays; Immersive virtual reality; Processing capability; Reinforcement learning approach; Terahertz(THz) communications; Transmit power control; Wireless channel condition; Wireless data transmission; Virtual reality",Article,"Final","",Scopus,2-s2.0-85092709939
"Zhang X.","57222575025;","The Construction of Realistic Environment of Deep Learning Based on Virtual Reality",2020,"Proceedings - 2020 International Conference on Computers, Information Processing and Advanced Education, CIPAE 2020",,, 9373657,"186","190",,,"10.1109/CIPAE51077.2020.00056","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103299812&doi=10.1109%2fCIPAE51077.2020.00056&partnerID=40&md5=561124e638c202ca2d8e674d480159f0","Village, Chenjia Town, Chongming District, Shanghai, China","Zhang, X., Village, Chenjia Town, Chongming District, Shanghai, China","Virtual environment created based on virtual reality can promote learners' deep learning experience. It enables learners' immersive exploration and interaction with the real environment. In this way they can have their personalized learning experience and continuous feedback. Virtual reality, which creates an immersive and interactive environment, leads to a better teaching model where students' previous learning pattern is changed. At present, virtual reality technology is becoming increasingly mature, and research on the application of virtual reality in education is drawing more attention from educators. The article analyzes the learning pattern enabled by virtual reality, and I believe that the advantages of virtual reality in the construction of deep learning mainly lie in environment construction, experience design, behavior guidance, and learning transfer. © 2020 IEEE.","deep empathy; deep learning; immersive reaction; virtual reality technology","E-learning; Education computing; Virtual reality; Environment constructions; Experience design; Interactive Environments; Learning experiences; Learning Transfer; Personalized learning; Realistic environments; Virtual reality technology; Deep learning",Conference Paper,"Final","",Scopus,2-s2.0-85103299812
"Varras M., Loukas C., Nikiteas N., Varra V.K., Varra F.N., Georgiou E.","7003684793;6603074122;9243558300;57208602370;57208599932;7004603021;","Comparison of laparoscopic surgical skills acquired on a virtual reality simulator and a box trainer: an analysis for obstetrics-gynecology residents",2020,"Clinical and Experimental Obstetrics and Gynecology","47","5",,"755","763",,,"10.31083/J.CEOG.2020.05.4988","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095688126&doi=10.31083%2fJ.CEOG.2020.05.4988&partnerID=40&md5=25e32d1ee28859647e8c5bd7c28b24ed","Fifth Department of Obstetrics and Gynecology, ‘Elena Venizelou’ General Maternity Hospital, Athens, Greece; Simulation Center, Medical Physics Laboratory, School of Medicine, National and Kapodistrian University of Athens, Greece; Department of Pharmacy, University of Patras, Greece; Department of Pharmacy, Frederick University, Nicosia, Cyprus","Varras, M., Fifth Department of Obstetrics and Gynecology, ‘Elena Venizelou’ General Maternity Hospital, Athens, Greece; Loukas, C., Simulation Center, Medical Physics Laboratory, School of Medicine, National and Kapodistrian University of Athens, Greece; Nikiteas, N., Simulation Center, Medical Physics Laboratory, School of Medicine, National and Kapodistrian University of Athens, Greece; Varra, V.K., Department of Pharmacy, University of Patras, Greece; Varra, F.N., Department of Pharmacy, Frederick University, Nicosia, Cyprus; Georgiou, E., Simulation Center, Medical Physics Laboratory, School of Medicine, National and Kapodistrian University of Athens, Greece","Background/Aims: It is well known that laparoscopic surgery requires the demonstration of a different set of technical skills when compared to open surgery. Laparoscopic training using simulators has been shown to accelerate learning in an efficient and standardized manner. Significant research has been conducted for skills acquisition in abdominal surgery, but in the field of gynecologic laparoscopy the relevant studies are limited. The aim of this study was to compare the training efficacy of virtual reality (VR) simulators and box-trainers (BTs) for skills acquisition in gynecologic surgery, and also to study the transferability of these skills in the performance of more advanced gynecologic operations. Methods: Twenty residents in obstetrics-gynecology with minimal laparoscopic experience were randomized into two equal groups to be trained on either a VR simulator (Group-A) or a BT (Group-B). Group-A was trained on basic tasks (clipping, peg transfer, and cutting), whereas Group-B was trained on ovarian cystectomy and salpingotomy using custom training models. After training, the two groups were assessed on the performance of two laparoscopic gynecologic procedures on a VR simulator (salpingotomy and salpingectomy). Performance metrics included time, instrument pathlength, and various task-specific errors. Results: Both groups demonstrated significant performance improvement in all training tasks, for all but one of the metrics (p < 0.05). After training, both groups had improved performance in the laparoscopic operations using the VR simulator, but this trend was not statistically significant in any metric considered (p > 0.05). Similarly, the post-training performance between the two groups was not statistically different (p > 0.05). Conclusions: Basic skills training on either a VR simulator or BT results in equivalent but not statistically significant performance improvement with more advanced gynecologic laparoscopic tasks on a VR simulator. ©2020 Varras et al. Published by IMR Press.","Box-trainer; Ectopic pregnancy; Gynecologic surgical training; Salpingectomy; Salpingotomy; Virtual reality simulator","adult; Article; comparative study; controlled study; cystectomy; ectopic pregnancy; female; gynecologic surgery; human; human tissue; laparoscopic surgery; male; minimally invasive surgery; ovary cyst; psychomotor performance; randomized controlled trial; residency education; salpingectomy; simulation training; surgical training; trophoblast; work experience",Article,"Final","",Scopus,2-s2.0-85095688126
"Cheah C.S.L., Barman S., Vu K.T.T., Jung S.E., Mandalapu V., Masterson T.D., Zuber R.J., Boot L., Gong J.","7007112847;57215324988;57204359659;57215315964;57202788973;56543054000;57215331782;35781520200;55512650400;","Validation of a Virtual Reality Buffet environment to assess food selection processes among emerging adults",2020,"Appetite","153",, 104741,"","",,1,"10.1016/j.appet.2020.104741","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085559744&doi=10.1016%2fj.appet.2020.104741&partnerID=40&md5=7437bcd0f7ff0a777e94e3a78b2df10d","Department of Psychology, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Department of Information Systems, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Department of Nutritional Sciences, The Pennsylvania State University, 110 Chandlee Laboratory, University ParkPA  16802, United States; Imaging Research Center, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States","Cheah, C.S.L., Department of Psychology, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Barman, S., Department of Psychology, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Vu, K.T.T., Department of Psychology, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Jung, S.E., Department of Psychology, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Mandalapu, V., Department of Information Systems, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Masterson, T.D., Department of Nutritional Sciences, The Pennsylvania State University, 110 Chandlee Laboratory, University ParkPA  16802, United States; Zuber, R.J., Imaging Research Center, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Boot, L., Imaging Research Center, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States; Gong, J., Department of Information Systems, University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD  21250, United States","Emerging adulthood is a critical developmental period for examining food- and eating-related behaviors as long-term weight-related behavioral patterns are established. Virtual reality (VR) technology is a promising tool for basic and applied research on eating and food-related processes. Thus, the present study tested the validity and user perceptions of a highly immersive and realistic VR food buffet by: (1) comparing participants' food selections made in the VR buffet and a real-world (RW) food buffet cafeteria one-week apart, and (2) assessing participants' rated perceptions of their VR experience (0–100 scale). Participants comprised an ethnically diverse sample of emerging adults (N = 35, Mage = 20.49, SD = 2.17). Results revealed that participants' food selections in the VR and RW food buffets were significantly and positively correlated in Kcals, grams, carbohydrates, and protein (all p's &lt; 0.05). Moreover, participants perceived that: (a) the VR buffet was natural (M = 70.97, SD = 20.92), (b) their lunch selection in the VR buffet represented a lunch they would select on an average day (M = 84.11, SD = 15.92); and (c) their selection represented a lunch they would select if the same foods were available (M = 91.29, SD = 11.00). Our findings demonstrated the validity and acceptability of our highly immersive and realistic VR buffet for assessing food selection that is generalizable to RW food settings one-week apart without precisely matched foods. The findings of this study support the utility of VR as a validated tool for research on psychological and behavioral food-related processes and training interventions among emerging adults. © 2020 Elsevier Ltd","Emerging adults; Food buffet; Food selection; Virtual reality","adult; Article; controlled study; critical period (psychology); environmental factor; female; food preference; human; human experiment; hunger; male; meal; normal human; nutritional value; perception; portion size; validation process; virtual reality",Article,"Final","",Scopus,2-s2.0-85085559744
"Zhou T., Zhu Q., Du J.","57218949339;57209806243;57219889677;","Intuitive robot teleoperation for civil engineering operations with virtual reality and deep learning scene reconstruction",2020,"Advanced Engineering Informatics","46",, 101170,"","",,,"10.1016/j.aei.2020.101170","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090898690&doi=10.1016%2fj.aei.2020.101170&partnerID=40&md5=908bb4c201303c8747d6ecb275b0542a","Engineering School of Sustainable Infrastructure & Environment, University of Florida, 1949 Stadium Road 454A Weil Hall, Gainesville, FL  32611, United States; Engineering School of Sustainable Infrastructure & Environment, University of Florida, 1949 Stadium Road 460F Weil Hall, Gainesville, FL  32611, United States","Zhou, T., Engineering School of Sustainable Infrastructure & Environment, University of Florida, 1949 Stadium Road 454A Weil Hall, Gainesville, FL  32611, United States; Zhu, Q., Engineering School of Sustainable Infrastructure & Environment, University of Florida, 1949 Stadium Road 454A Weil Hall, Gainesville, FL  32611, United States; Du, J., Engineering School of Sustainable Infrastructure & Environment, University of Florida, 1949 Stadium Road 460F Weil Hall, Gainesville, FL  32611, United States","Robotic teleoperation, i.e., manipulating remote robotic systems at a distance, has gained its popularity in various industrial applications, including construction operations. The key to a successful teleoperation robot system is the delicate design of the human-robot interface that helps strengthen the human operator's situational awareness. Traditional human-robot interface for robotic teleoperation is usually based on imagery data (e.g., video streaming), causing the limited field of view (FOV) and increased cognitive burden for processing additional spatial information. As a result, 3D scene reconstruction methods based on point cloud models captured by scanning technologies (e.g., depth camera and LiDAR) have been explored to provide immersive and intuitive feedback to the human operator. Despite the added benefits of applying reconstructed 3D scenes in telerobotic systems, challenges still present. Most 3D reconstruction methods utilize raw point cloud data due to the difficulty of real-time model rendering. The significant size of point cloud data makes the processing and transfer between robots and human operators difficult and slow. In addition, most reconstructed point cloud models do not contain physical properties such as weight and colliders. A more enriched control mechanism based on physics engine simulations is impossible. This paper presents an intelligent robot teleoperation interface that collects, processes, transfers, and reconstructs the immersive scene model of the workspace in Virtual Reality (VR) and enables intuitive robot controls accordingly. The proposed system, Telerobotic Operation based on Auto-reconstructed Remote Scene (TOARS), utilizes a deep learning algorithm to automatically detect objects in the captured scene, along with their physical properties, based on the point cloud data. The processed information is then transferred to the game engine where rendered virtual objects replace the original point cloud models in the VR environment. TOARS is expected to significantly improve the efficiency of 3D scene reconstruction and situational awareness of human operators in robotic teleoperation. © 2020 Elsevier Ltd","Deep learning; Robot; Scene reconstruction; Teleoperation; Virtual reality","Biofeedback; Cloud computing; Data handling; Deep learning; E-learning; Image reconstruction; Industrial robots; Intelligent robots; Learning algorithms; Machine design; Object detection; Personnel; Physical properties; Remote control; Rendering (computer graphics); Robotics; Social robots; Virtual reality; 3D scene reconstruction; Construction operations; Engineering operation; Human-Robot Interface; Processed information; Robot teleoperation interfaces; Robotic teleoperation; Situational awareness; Three dimensional computer graphics",Article,"Final","",Scopus,2-s2.0-85090898690
"Lécuyer F., Gouranton V., Lamercerie A., Reuzeau A., Caillaud B., Arnaldi B.","57209417146;6506588443;57215823769;56741393700;55605009400;6603383416;","Unveiling the implicit knowledge, one scenario at a time",2020,"Visual Computer","36","10-12",,"1951","1963",,,"10.1007/s00371-020-01904-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087744022&doi=10.1007%2fs00371-020-01904-7&partnerID=40&md5=768db087b10889f5bf375586c542d6d8","INSA Rennes, Univ Rennes, Inria, CNRS, IRISA, Rennes, France; Univ Rennes, Inria, CNRS, IRISA, Rennes, France; IRISA, Univ Rennes, Inria, CNRS, IRISA, Rennes, France","Lécuyer, F., INSA Rennes, Univ Rennes, Inria, CNRS, IRISA, Rennes, France; Gouranton, V., INSA Rennes, Univ Rennes, Inria, CNRS, IRISA, Rennes, France; Lamercerie, A., IRISA, Univ Rennes, Inria, CNRS, IRISA, Rennes, France; Reuzeau, A., INSA Rennes, Univ Rennes, Inria, CNRS, IRISA, Rennes, France; Caillaud, B., Univ Rennes, Inria, CNRS, IRISA, Rennes, France; Arnaldi, B., INSA Rennes, Univ Rennes, Inria, CNRS, IRISA, Rennes, France","When defining virtual reality applications with complex procedures, such as medical operations or mechanical assembly or maintenance procedures, the complexity and the variability of the procedures make the definition of the scenario difficult and time-consuming. Indeed, the variability complicates the definition of the scenario by the experts, and its combinatorics demand a comprehension effort for the developer, which is often out of reach. Additionally, the experts have a hard time explaining the procedures with a sufficient level of details, as they usually forget to mention some actions that are, in fact, important for the application. To ease the creation of scenario, we propose a complete methodology, based on (1) an iterative process composed of: (2) the recording of actions in virtual reality to create sequences of actions and (3) the use of mathematical tools that can generate a complete scenario from a few of those sequences, with (4) graphical visualization of the scenarios and complexity indicators. This process helps the expert to determine the sequences that must be recorded to obtain a scenario with the required variability. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Authoring; Generalization; Scenario; Virtual reality","Virtual reality; Complexity indicators; Graphical visualization; Implicit knowledge; Iterative process; Maintenance procedures; Mathematical tools; Mechanical assembly; Medical operations; Iterative methods",Article,"Final","",Scopus,2-s2.0-85087744022
"Pinardi D., Ebri L., Belicchi C., Farina A., Binelli M.","57195467991;56770178100;57219547851;7202992441;55354577100;","Direction Specific Analysis of Psychoacoustics Parameters inside Car Cockpit: A Novel Tool for NVH and Sound Quality",2020,"SAE Technical Papers",,"2020",,"","",,,"10.4271/2020-01-1547","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093822780&doi=10.4271%2f2020-01-1547&partnerID=40&md5=c96cd017a73014350d0726971591bd1f","University of Parma, Italy; University of Parma, Ask Industries SpA, Italy","Pinardi, D., University of Parma, Italy; Ebri, L., University of Parma, Ask Industries SpA, Italy; Belicchi, C., University of Parma, Italy; Farina, A., University of Parma, Italy; Binelli, M., University of Parma, Italy","Psychoacoustics parameters are widely employed in automotive field for objective evaluation of Sound Quality (SQ) of vehicle cabins and their components. The standard approach relies on binaural recordings from which numerical values and curves are calculated. In addition, head-locked binaural listening playback can be performed. The Virtual Reality (VR) technology recently started to diffuse also in automotive field, bringing new possibilities for enhanced and immersive listening sessions, thanks to the usage of massive microphone arrays instead of binaural microphones. In this paper, we combine both solutions: the principal SQ parameters are derived from multichannel recordings. This allows computing a map of direction-dependent values of SQ parameters. The acquisition system consists in a spherical microphone array with 32 capsules and a multiple-lens camera for capturing a panoramic equirectangular background image. The audio recording is encoded into High Order Ambisonics (HOA) format for being compared with a classic omnidirectional microphone and into Spatial PCM Sampling (SPS) format for producing 360° equirectangular color maps. The SPS encoding is used to plot over the background image the distribution of SPL values in dB (A) and of the SQ parameters: by adding to them the directional information, it results into a novel 360° diagnostic tool for localizing the most annoying sources. Furthermore, the playback of the HOA soundtrack can be performed both on a loudspeaker rig inside an Ambisonics listening room or on binaural headphones attached to a Head Mounted Display (HMD), benefiting from head-tracking and personalized Head Related Transfer Functions (HRTFs), allowing to make quick subjective evaluations with a degree of realism unattainable with the older static binaural approach. © 2020SAE International. All Rights Reserved.",,"Acoustic noise; Acoustic variables measurement; Helmet mounted displays; Loudspeakers; Microphones; Parameter estimation; Quality control; Virtual reality; Binaural recordings; Directional information; Head mounted displays; Head related transfer function; Multi-channel recording; Objective evaluation; Spherical microphone array; Subjective evaluations; Audio recordings",Conference Paper,"Final","",Scopus,2-s2.0-85093822780
"Tarkkanen K., Lehto A., Oliva D., Somerkoski B., Haavisto T., Luimula M.","25642288100;57208750395;42061986700;56297992300;57219971101;17435411000;","Research study design for teaching and testing fire safety skills with AR and VR Games",2020,"11th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2020 - Proceedings",,, 9237831,"167","172",,,"10.1109/CogInfoCom50765.2020.9237831","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096361007&doi=10.1109%2fCogInfoCom50765.2020.9237831&partnerID=40&md5=44575e2d89999555aca8e9be53dd6969","ICT, Turku University of Applied Sciences, Turku, Finland; RDI Services, Turku University of Applied Sciences, Turku, Finland; University of Turku, Department of Teacher Education, Turku, Finland","Tarkkanen, K., ICT, Turku University of Applied Sciences, Turku, Finland; Lehto, A., RDI Services, Turku University of Applied Sciences, Turku, Finland; Oliva, D., ICT, Turku University of Applied Sciences, Turku, Finland; Somerkoski, B., University of Turku, Department of Teacher Education, Turku, Finland; Haavisto, T., ICT, Turku University of Applied Sciences, Turku, Finland; Luimula, M., ICT, Turku University of Applied Sciences, Turku, Finland","Virtual and augmented reality (VR AR) games can provide innovative methods for teaching and learning important skills relating to fire safety. However, in an emergency context, testing the acquired knowledge and skills, i.e. verifying the learning, can be challenging. In this paper, we ask how the interplay between AR and VR could support learning verification. We describe two standalone games of both types, which interchangeably teach fire safety skills to children and verify their learning results. In particular, we describe the planned learning paths and research study designs for verification studies within and between these games to answer the above question. By operationalizing the two cases, the paper ends in proposing more generalized study design for AR and VR research in a fire safety context. © 2020 IEEE.","Augmented reality; Fire safety; Research design; Serious games; Virtual reality","Augmented reality; Fires; Emergency contexts; Innovative method; Planned learning; Research study design; Study design; Support learning; Teaching and learning; Virtual and augmented reality; Safety testing",Conference Paper,"Final","",Scopus,2-s2.0-85096361007
"Kaarlela T., Pieska S., Pitkaaho T.","57217675359;6507168349;36184573800;","Digital twin and virtual reality for safety training",2020,"11th IEEE International Conference on Cognitive Infocommunications, CogInfoCom 2020 - Proceedings",,, 9237812,"115","120",,,"10.1109/CogInfoCom50765.2020.9237812","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096353792&doi=10.1109%2fCogInfoCom50765.2020.9237812&partnerID=40&md5=c6e4f43dd18d48bdcc09406601905405","Centria University of Applied Sciences, Ylivieska, Finland","Kaarlela, T., Centria University of Applied Sciences, Ylivieska, Finland; Pieska, S., Centria University of Applied Sciences, Ylivieska, Finland; Pitkaaho, T., Centria University of Applied Sciences, Ylivieska, Finland","In this paper, our latest research related to digital twins and virtual reality environments for safety training purposes will be described and evaluated. We will present three practical use cases to outline the current maturity level of virtual reality technology for industrial environments. Two of our use cases are virtual reality applications for safety and emergency training scenarios. In addition, one use case is the implementation of a digital twin for off-site safety training. This use case presents a seamless real-time transfer of data between the physical and virtual worlds. Use cases were developed based on the needs of, and in co-operation with, local small and medium-sized enterprises (SMEs). The proposed affordable and simple approaches provide virtual safety training solutions that can be utilized by SMEs of different industries. © 2020 IEEE.",,"Accident prevention; Data transfer; Digital twin; E-learning; Emergency training; Industrial environments; Maturity levels; Real-time transfer; Simple approach; Small and medium-sized enterprise; Virtual reality technology; Virtual-reality environment; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85096353792
"Torda A.","55915596000;","CLASSIE teaching - Using virtual reality to incorporate medical ethics into clinical decision making",2020,"BMC Medical Education","20","1", 326,"","",,1,"10.1186/s12909-020-02217-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091550365&doi=10.1186%2fs12909-020-02217-y&partnerID=40&md5=a77d40ab6a43ee32177fa090d7265519","Faculty of Medicine, UNSW Sydney, Kensington, NSW  2052, Australia","Torda, A., Faculty of Medicine, UNSW Sydney, Kensington, NSW  2052, Australia","Background: Teaching medical ethics (ME) in the clinical environment is often difficult, uncalibrated and medical students get variable exposure to skilled educators. Explicit discussion of ethical dimensions of patient management is often neglected, as clinical teachers may feel inadequately skilled to do this. Methods: We developed a suite of online modules. Each consisted of a clinical scenario filmed using virtual reality (VR) technology, linked to an adaptive, interactive, online tutorial which explicitly discussed the relevant ethical issues and guidelines. These were embedded in clinical placements of students to encourage the transfer of knowledge from these modules to clinical skill competency. We conducted a pilot study to evaluate these modules which examined student engagement, knowledge gains (self-perceived and measured) and user experience. We also reviewed reflections to assess the incorporation of these modules and transfer of knowledge into the clinical learning and skill development of the students. Results: Engagement and self-perceived knowledge gains were extremely high. Students found these modules realistic, interesting and helpful. The measured knowledge gains (module exit quiz) were moderate. User experience was positive overall, although students were intolerant of any technical glitches. There was mixed feedback on whether the VR aspect of the clinical scenarios added value. Student reflections showed high level incorporation of these modules into clinical practice of the students and evidence of knowledge transfer (level 3 Kirkpatrick model of evaluation) in over ¾ of students. Conclusions: This study showed that the use VR clinical scenarios combined with interactive online learning modules resulted in demonstrable high-level student engagement and learning gains in medical ethics and transfer of knowledge to clinical application. It standardised and ensured the student experience of high-quality educational deliverables in clinical years of medical education. This use of VR and online technology can be adapted for use in many areas of the medical curricula where we need to ensure the delivery of well calibrated, high quality, educational deliverables at scale for students. © 2020 The Author(s).",,"article; clinical decision making; e-learning; human; human experiment; medical education; medical ethics; pilot study; practice guideline; skill; virtual reality",Article,"Final","",Scopus,2-s2.0-85091550365
"Knopp B., Velychko D., Dreibrodt J., Schütz A.C., Endres D.","56307867500;57219361918;57211058203;21743919300;7004010222;","Evaluating Perceptual Predictions based on Movement Primitive Models in VR-and Online-Experiments",2020,"Proceedings - SAP 2020: ACM Symposium on Applied Perception",,, 3407940,"","",,,"10.1145/3385955.3407940","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092379746&doi=10.1145%2f3385955.3407940&partnerID=40&md5=ba08f9fee7a689f63e03698142dba169","Philipps Universität Marburg, Germany; University of Marburg, Germany","Knopp, B., Philipps Universität Marburg, Germany; Velychko, D., Philipps Universität Marburg, Germany; Dreibrodt, J., Philipps Universität Marburg, Germany; Schütz, A.C., Philipps Universität Marburg, Germany; Endres, D., University of Marburg, Germany","We investigate the role of prediction in biological movement perception by comparing different representations of human movement in a virtual reality (VR) and online experiment. Predicting movement enables quick and appropriate action by both humans and artificial agents in many situations, e.g. when the interception of objects is important. We use different predictive movement primitive (MP) models to probe the visual system for the employed prediction mechanism. We hypothesize that MP-models, originally devised to address the degrees-of-freedom (DOF) problem in motor production, might be used for perception as well. In our study we consider object passing movements. Our paradigm is a predictive task, where participants need to discriminate movement continuations generated by MP models from the ground truth of the natural continuation. This experiment was conducted first in VR, and later on continued as online experiment. We found that results transfer from the controlled and immersive VR setting with movements rendered as realistic avatars to a simple and COVID-19 safe online setting with movements rendered as stick figures. In the online setting we further investigate the effect of different occlusion timings. We found that contact events during the movement might provide segmentation points that render the lead-in movement independent of the continuation and thereby make perceptual predictions much harder for subjects. We compare different MP-models by their capability to produce perceptually believable movement continuations and their usefulness to predict this perceptual naturalness. Our research might provide useful insight for application in computer animation, by showing how movements can be continued without violating the expectation of the user. Our results also contribute towards an efficient method of animating avatars by combining simple movements into complex movement sequences. © 2020 Owner/Author.","dynamical movement primitives; dynamical systems; Gaussian process dynamical model; human animation; movement primitives; perception; psychophysics","Animation; Degrees of freedom (mechanics); Forecasting; Virtual reality; Artificial agents; Biological movements; Computer animation; Human movements; Movement primitives; On-line experiments; On-line setting; Prediction mechanisms; Motion estimation",Conference Paper,"Final","",Scopus,2-s2.0-85092379746
"Houshmand B., Khan N.M.","57219792826;38361516100;","Facial Expression Recognition under Partial Occlusion from Virtual Reality Headsets based on Transfer Learning",2020,"Proceedings - 2020 IEEE 6th International Conference on Multimedia Big Data, BigMM 2020",,, 9232653,"70","75",,,"10.1109/BigMM50055.2020.00020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097241474&doi=10.1109%2fBigMM50055.2020.00020&partnerID=40&md5=b69f6f1256f605345e4e4028c5b57250","Ryerson University Data Science, Toronto, Canada; Ryerson University Electrical and Computer Engineering, Toronto, Canada","Houshmand, B., Ryerson University Data Science, Toronto, Canada; Khan, N.M., Ryerson University Electrical and Computer Engineering, Toronto, Canada","Facial expressions of emotion are a major channel in our daily communications, and it has been subject of intense research in recent years. To automatically infer facial expressions, convolutional neural network based approaches has become widely adopted due to their proven applicability to Facial Expression Recognition (FER) task.On the other hand Virtual Reality (VR) has gained popularity as an immersive multimedia platform, where FER can provide enriched media experiences. However, recognizing facial expression while wearing a head-mounted VR headset is a challenging task due to the upper half of the face being completely occluded. In this paper we attempt to overcome these issues and focus on facial expression recognition in presence of a severe occlusion where the user is wearing a head-mounted display in a VR setting. We propose a geometric model to simulate occlusion resulting from a Samsung Gear VR headset that can be applied to existing FER datasets. Then, we adopt a transfer learning approach, starting from two pretrained networks, namely VGG and ResNet. We further fine-tune the networks on FER+ and RAF-DB datasets. Experimental results show that our approach achieves comparable results to existing methods while training on three modified benchmark datasets that adhere to realistic occlusion resulting from wearing a commodity VR headset. Code for this paper is available at: https://github.com/bita-github/MRP-FER © 2020 IEEE.","Facial expression recognition; Facial occlusion; Transfer learning; VR","Big data; Convolutional neural networks; E-learning; Face recognition; Helmet mounted displays; Transfer learning; Wear of materials; Benchmark datasets; Facial expression recognition; Facial Expressions; Geometric modeling; Head mounted displays; Multimedia platforms; Partial occlusions; Virtual-reality headsets; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85097241474
"Delamarre A., Lisetti C., Buche C.","57195671754;6602670860;8349259000;","A Cross-Platform Classroom Training Simulator: Interaction Design and EvaluationA Cross-Platform Classroom Training Simulator: Interaction Design and Evaluation",2020,"Proceedings - 2020 International Conference on Cyberworlds, CW 2020",,, 9240533,"86","93",,,"10.1109/CW49994.2020.00020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099535199&doi=10.1109%2fCW49994.2020.00020&partnerID=40&md5=0afab14bfbc31f31c90b991bafa5ee8d","Florida International University, Visage Lab, Scis, Miami, United States; LAB-STICC Cnrs, Enib, Brest, France","Delamarre, A., Florida International University, Visage Lab, Scis, Miami, United States; Lisetti, C., Florida International University, Visage Lab, Scis, Miami, United States; Buche, C., LAB-STICC Cnrs, Enib, Brest, France","Virtual training environments experienced with different immersive technologies can accommodate users' preferences, proficiency, and platform availability. Whereas research comparing the effects of immersive technologies can provide important insights about their impact on users' experience (e.g. engagement, transfer of learning), current studies do not address how to design the user interface (UI) to ensure sound comparisons across platforms. For effective comparisons, however, the UI designs must be adapted for the platform used to provide comparable usability. In this article we describe our UI design methodology for the development of an effective and usable virtual classroom training simulator built for three technologies: (1) desktop; (2) Head-Mounted Display (HMD); and (3) Cave Automatic Virtual Environment (CAVE). Usability and other user experience factors were evaluated for each platform with concurrent think-aloud protocol and semi-structured interviews indicating that all three UIs were easy to use and to learn. We discuss insights for future development of cross-platform VTEs. © 2020 IEEE.","Design; Human Computer Interaction; Immersive Virtual Environment; User Study; Virtual Reality","Availability; Caves; Computer aided instruction; Design; E-learning; Helmet mounted displays; Simulators; Transfer learning; User experience; User interfaces; Cave automatic virtual environments; Head mounted displays; Immersive technologies; Platform availabilities; Semi structured interviews; Think-aloud protocol; Transfer of learning; Virtual training environments; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85099535199
"Harris D.J., Buckingham G., Wilson M.R., Brookes J., Mushtaq F., Mon-Williams M., Vine S.J.","57192429891;14069958400;55574207642;57197801653;56999078200;7006287402;36811509000;","The effect of a virtual reality environment on gaze behaviour and motor skill learning",2020,"Psychology of Sport and Exercise","50",, 101721,"","",,3,"10.1016/j.psychsport.2020.101721","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086586041&doi=10.1016%2fj.psychsport.2020.101721&partnerID=40&md5=608f65aed21033b6e58a9a8feac30da8","School of Sport and Health Sciences, University of Exeter, Exeter, EX1 2LU, United Kingdom; School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Centre for Immersive Technologies, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Bradford Teaching Hospitals NHS Foundation Trust, Bradford, West Yorkshire, United Kingdom; National Centre for Optics, Vision and Eye Care, University of South-Eastern Norway, Kongsberg, Hasbergs Vei 363616, Norway","Harris, D.J., School of Sport and Health Sciences, University of Exeter, Exeter, EX1 2LU, United Kingdom; Buckingham, G., School of Sport and Health Sciences, University of Exeter, Exeter, EX1 2LU, United Kingdom; Wilson, M.R., School of Sport and Health Sciences, University of Exeter, Exeter, EX1 2LU, United Kingdom; Brookes, J., School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Mushtaq, F., School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom, Centre for Immersive Technologies, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Mon-Williams, M., School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom, Centre for Immersive Technologies, University of Leeds, Leeds, LS2 9JZ, United Kingdom, Bradford Teaching Hospitals NHS Foundation Trust, Bradford, West Yorkshire, United Kingdom, National Centre for Optics, Vision and Eye Care, University of South-Eastern Norway, Kongsberg, Hasbergs Vei 363616, Norway; Vine, S.J., School of Sport and Health Sciences, University of Exeter, Exeter, EX1 2LU, United Kingdom","Objective: Virtual reality (VR) systems hold significant potential for training skilled behaviours and are currently receiving intense interest in the sporting domain. They offer both practical and pedagogical benefits, but there are concerns about the effect that perceptual deficiencies in VR systems (e.g. reduced haptic information, and stereoscopic display distortions) may have on learning and performance. ‘Specificity of learning’ theories suggest that VR could be ineffective (or even detrimental) if important differences (e.g. perceptual deficiencies) exist between practice and real task performance conditions. Nevertheless, ‘structural learning’ theories suggest VR could be a useful training tool, despite these deficiencies, because a trainee can still learn the underlying structure of the behaviour. We explored these theoretical predictions using golf putting as an exemplar skill. Method: In Experiment 1 we used a repeated measures design to assess putting accuracy (radial error) and quiet eye duration of expert golfers (n = 18) on real putts before and after 40 VR ‘warm up’ putts. In Experiment 2, novice golfers (n = 40) were assigned to either VR or real-world putting training. Putting accuracy and quiet eye durations were then assessed on a real-world retention test. Results: Both visual guidance (quiet eye) and putting accuracy were disrupted temporarily when moving from VR to real putting (Experiment 1). However, real-world and VR practice produced comparable improvements in putting accuracy in novice golfers (Experiment 2). Conclusion: Overall, the results suggest that: (i) underlying skill structures can be learned in VR and transferred to the real-world; (ii) perceptual deficiencies will place limits on the use of VR. These findings demonstrate the challenges and opportunities for VR as a training tool, and emphasise the need to empirically test the costs and benefits of specific systems before deploying VR training. © 2020 Elsevier Ltd","Quiet eye; Skill acquisition; Sport; Stereoscopic; Transfer; VR","article; clinical article; gaze; golf; human; human experiment; learning; motor performance; prediction; virtual reality; warm up",Article,"Final","",Scopus,2-s2.0-85086586041
"Sankaranarayanan G., Odlozil C.A., Wells K.O., Leeds S.G., Chauhan S., Fleshman J.W., Jones D.B., De S.","15623319200;57215189669;57191846917;54794199400;57213529357;7005800609;55387240300;7202304567;","Training with cognitive load improves performance under similar conditions in a real surgical task",2020,"American Journal of Surgery","220","3",,"620","629",,1,"10.1016/j.amjsurg.2020.02.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080099947&doi=10.1016%2fj.amjsurg.2020.02.002&partnerID=40&md5=284ec746c03fb9a99a40c4d49d4bc712","Department of Surgery, Baylor University Medical Center at Dallas, Dallas, TX, United States; Center for Modeling, Simulation, and Imaging in Medicine, Rensselaer Polytechnic Institute, Troy, NY, United States; Beth Israel Deaconess Medical Center, Boston, MA, United States","Sankaranarayanan, G., Department of Surgery, Baylor University Medical Center at Dallas, Dallas, TX, United States; Odlozil, C.A., Department of Surgery, Baylor University Medical Center at Dallas, Dallas, TX, United States; Wells, K.O., Department of Surgery, Baylor University Medical Center at Dallas, Dallas, TX, United States; Leeds, S.G., Department of Surgery, Baylor University Medical Center at Dallas, Dallas, TX, United States; Chauhan, S., Department of Surgery, Baylor University Medical Center at Dallas, Dallas, TX, United States; Fleshman, J.W., Department of Surgery, Baylor University Medical Center at Dallas, Dallas, TX, United States; Jones, D.B., Beth Israel Deaconess Medical Center, Boston, MA, United States; De, S., Center for Modeling, Simulation, and Imaging in Medicine, Rensselaer Polytechnic Institute, Troy, NY, United States","Background: Enhancing cognitive load while performing a bimanual surgical task affects performance. Whether repeated training under this condition could benefit performance in an operating room was tested using a virtual reality simulator with cognitive load applied through two-digit math multiplication questions. Method: 11 subjects were randomized to Control, VR and VR + CL groups. After a pre-test, VR and VR + CL groups repeated the peg transfer task 150 times over 15 sessions with cognitive load applied only for the last 100 trials. After training, all groups took a post-test and two weeks later the retention test with and without cognitive load and the transfer task on a pig intestine of 150 cm long under cognitive load. Results and conclusion: Mixed ANOVA analysis showed significant differences between the control and VR and VR + CL groups (p = 0.013, p = 0.009) but no differences between the VR + CL and the VR groups (p = 1.0). GOALS bimanual dexterity score on transfer test show that VR + CL group outperformed both Control and VR groups (p = 0.016, p = 0.03). Training under cognitive load benefitted performance on an actual surgical task under similar conditions. © 2020 Elsevier Inc.","Cognitive load; Laparoscopy; Surgical education; Virtual reality simulation","cognition; cognitive load; Conference Paper; controlled study; female; GOALS bimanual dexterity score; human; intestine; male; nonhuman; pig; priority journal; randomized controlled trial; scoring system; surgical technique; training; virtual reality; animal; clinical competence; education; laparoscopy; medical education; procedures; simulation training; task performance; videorecording; virtual reality; young adult; Animals; Clinical Competence; Cognition; Education, Medical, Undergraduate; Female; Humans; Laparoscopy; Male; Simulation Training; Task Performance and Analysis; Video Recording; Virtual Reality; Young Adult",Conference Paper,"Final","",Scopus,2-s2.0-85080099947
"Tychkov A.Y., Grachev A.V., Alimuradov A.K.","36731632400;56982633900;56595170300;","Virtual Reality in Information Transfer",2020,"Proceedings - 2020 International Russian Automation Conference, RusAutoCon 2020",,, 9208101,"826","830",,,"10.1109/RusAutoCon49822.2020.9208101","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093936152&doi=10.1109%2fRusAutoCon49822.2020.9208101&partnerID=40&md5=b588ffda22ded34bf60a388b377b648f","Penza State University, Research Institute for Basic and Applied Studies, Penza, Russian Federation; Penza State University, Department of Radioengineering and Radioelectronic Systems, Penza, Russian Federation; Penza State University, Student Research and Production Business Incubator, Penza, Russian Federation","Tychkov, A.Y., Penza State University, Research Institute for Basic and Applied Studies, Penza, Russian Federation; Grachev, A.V., Penza State University, Department of Radioengineering and Radioelectronic Systems, Penza, Russian Federation; Alimuradov, A.K., Penza State University, Student Research and Production Business Incubator, Penza, Russian Federation","The article is devoted to technologies and virtual reality systems as comprehensive solutions for immersion of the user into virtual reality using specialized devices and interfaces. Technologies for wire/wireless transfer of audio-visual and parametric information in virtual reality systems are discussed. The aim of the article is to analyze and summarize advantages and disadvantages of modern facilities for multimedia and parametric information transfer used in virtual reality systems. A search method for research materials in Russian and international journals included in scientific citation databases was used. The paper analyzes the features (advantages and disadvantages) of using virtual reality in conditions of optical information transfer, wireless protocols (WiFi, Bluetooth, Wireless USB, LIDAR, ZigBee), and wire interfaces (Display Port, HDMI, USB) that provide user communication with virtual reality system. Virtual reality forms a new artificial real world transferred to the user via various wire/wireless (WiGig (802.11ad), WiFi 6 (802.11ax), WiHD (802.15.3c), and Display Port 2.0) interfaces, taking into account physiological, physical and psychometric indicators. Modern technical solutions should give impetus to the creation of adaptive virtual reality with a total immersion effect, when the user cannot distinguish a virtual world from real events. © 2020 IEEE.","adaptive virtual reality; tactile interfaces; wireless/wire information transfer","Audio systems; IEEE Standards; Optical communication; Optical radar; System buses; Virtual reality; Wi-Fi; Wire; Wireless local area networks (WLAN); Information transfers; International journals; Optical information; Parametric information; Technical solutions; User communication; Virtual reality system; Wireless protocol; Data communication systems",Conference Paper,"Final","",Scopus,2-s2.0-85093936152
"Chen J., Liu C., Chang R., Gui P., Na S.","23090323300;57220998631;57219899921;57212382631;57200312577;","From traditional to vr-based online education platforms: A model of the mechanism influencing user migration",2020,"Information (Switzerland)","11","9", 423,"1","19",,,"10.3390/info11090423","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097974976&doi=10.3390%2finfo11090423&partnerID=40&md5=2014b0cd71a30650376d848607f8a5be","School of Business Administration, Wonkwang University, 460 Iksandae-ro, Iksan, Jeonbuk  54538, South Korea","Chen, J., School of Business Administration, Wonkwang University, 460 Iksandae-ro, Iksan, Jeonbuk  54538, South Korea; Liu, C., School of Business Administration, Wonkwang University, 460 Iksandae-ro, Iksan, Jeonbuk  54538, South Korea; Chang, R., School of Business Administration, Wonkwang University, 460 Iksandae-ro, Iksan, Jeonbuk  54538, South Korea; Gui, P., School of Business Administration, Wonkwang University, 460 Iksandae-ro, Iksan, Jeonbuk  54538, South Korea; Na, S., School of Business Administration, Wonkwang University, 460 Iksandae-ro, Iksan, Jeonbuk  54538, South Korea","VR technology can help create optimal virtual learning spaces. Such spaces offer new visual experiences that break through the limitations of time and space and greatly stimulate people’s imagination and creativity in learning. Currently, the bandwidth required for such spaces limits the large-scale application of virtual reality (VR) technology for this purpose. With the large-scale deployment and application of high-speed networks, however, online education platforms based on VR technology will be better able to meet the diversified and personalized learning needs of learners. To promote the development and popularization of new online education platforms based on VR, the factors influencing the migration of learners from traditional online education platforms to new platforms need to be understood more clearly. A model based on the theory of negative, positive, and anchoring effects can explain learners’ migration behavior in this connection. To this end, a structural equation model based on the PLS variance algorithm was used to analyze data obtained through offline and online questionnaires. It was found that in terms of “negative effects”, the afunction and loyalty associated with traditional online education platforms reduced learners’ willingness to migrate to new platforms based on VR technology. In terms of “positive effects”, the novel interactivity and personalization brought by the new platform increased the willingness of users of traditional platforms to migrate to new platforms. In terms of “anchoring effects”, the system quality and relationship quality of learners’ use of traditional online education platforms, as well as the transfer costs associated with the new platform, generated learners’ risk perception about platform migration. In addition, risk perception not only negatively affects learners’ migration to the new platforms, but also strengthens their cognition of the system quality and relationship quality of the traditional platforms, while reducing their interactive awareness of those platforms. Therefore, by adjusting the psychological component of virtual learning, the online education platforms based on VR technology can create high-quality platforms migrating from traditional platforms. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.","Migration mechanism; Online education; VR technology","Behavioral research; Electronic assessment; HIgh speed networks; Learning systems; Risk perception; Surveys; Anchoring effects; Large-scale applications; Large-scale deployment; Online questionnaire; Personalized learning; Relationship qualities; Structural equation modeling; Visual experiences; E-learning",Article,"Final","",Scopus,2-s2.0-85097974976
"Catal C., Akbulut A., Tunali B., Ulug E., Ozturk E.","22633325800;25960607500;57211942369;57211949025;57211945039;","Evaluation of augmented reality technology for the design of an evacuation training game",2020,"Virtual Reality","24","3",,"359","368",,2,"10.1007/s10055-019-00410-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075481004&doi=10.1007%2fs10055-019-00410-z&partnerID=40&md5=1f2c3d6562a0c05b9c1b4538db9f7821","Information Technology Group, Wageningen University & Research, Wageningen, Netherlands; Department of Computer Engineering, Istanbul Kultur University, Istanbul, Turkey","Catal, C., Information Technology Group, Wageningen University & Research, Wageningen, Netherlands; Akbulut, A., Department of Computer Engineering, Istanbul Kultur University, Istanbul, Turkey; Tunali, B., Department of Computer Engineering, Istanbul Kultur University, Istanbul, Turkey; Ulug, E., Department of Computer Engineering, Istanbul Kultur University, Istanbul, Turkey; Ozturk, E., Department of Computer Engineering, Istanbul Kultur University, Istanbul, Turkey","Building evacuation training systems and training employees in an organization have a vital role in emergency cases in which people need to know what to do exactly. In every building, procedures, rules, and actions are attractively shown on the walls, but most of the people living in that building are not aware of these procedures and do not have any experience what to do in these dangerous situations. In order to be able to apply these procedures properly in an emergency situation, community members should be trained with the state-of-the-art equipment and technologies, but to do so, up-front investment and development of such a system are necessary. In this study, augmented reality (AR) technology was applied to realize a game-based evacuation training system that implements gamification practices. The architectural plans of a university were used to model the floors and the relevant environment. Employees are trained to learn how to reach the nearest exit location in the event of a fire or earthquake, and also, the system provides the shortest path for the evacuation. In addition to these features, our training game has educational animations about the fire, chemical attack, and earthquake events. A mobile application was implemented to train employees working in the building and inform them to know how to escape in an emergency situation. The technology acceptance model and the related questionnaire form were applied, and the response of 36 participants was analyzed. It was demonstrated that AR and relevant tools provide a flexible environment to develop evacuation systems in a university, our mobile application enabled participants to be trained in a realistic environment, and trainees were highly satisfied with the system. Educational animations were also another benefit for the trainees. © 2019, The Author(s).","Animation; ARKit framework; Augmented reality; Evacuation training system; Game engine; Software; Training; Unity3D","Animation; Augmented reality; Chemical attack; Computer software; Earthquakes; Investments; Mobile computing; Technology transfer; ARKit framework; Augmented reality technology; Game Engine; Realistic environments; State-of-the-art equipments; Technology acceptance model; Training Systems; Unity3d; Personnel training",Article,"Final","",Scopus,2-s2.0-85075481004
"Andreatta M., Genheimer H., Wieser M.J., Pauli P.","23967624100;56902628900;11440385900;7003473881;","Context-dependent generalization of conditioned responses to threat and safety signals",2020,"International Journal of Psychophysiology","155",,,"140","151",,,"10.1016/j.ijpsycho.2020.06.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086791198&doi=10.1016%2fj.ijpsycho.2020.06.006&partnerID=40&md5=8776b6a8522ce26abb9e5d46829a7bb7","Department of Psychology (Biological Psychology, Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany; Department of Psychology, Education, and Child Studies, University of Rotterdam, Netherlands; Center for Mental Health, University of Würzburg, Würzburg, Germany","Andreatta, M., Department of Psychology (Biological Psychology, Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany, Department of Psychology, Education, and Child Studies, University of Rotterdam, Netherlands; Genheimer, H., Department of Psychology (Biological Psychology, Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany; Wieser, M.J., Department of Psychology (Biological Psychology, Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany, Department of Psychology, Education, and Child Studies, University of Rotterdam, Netherlands; Pauli, P., Department of Psychology (Biological Psychology, Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany, Center for Mental Health, University of Würzburg, Würzburg, Germany","Contextual information can modulate the conditioned response to a threat signal (conditioned stimulus, CS+): fear responses are either potentiated or attenuated depending on whether the context is threatening or safe. In this study, we investigated the influence of context on conditioned fear as well as on generalization of conditioned fear. Thirty-two participants underwent a cue-in-context learning protocol in virtual reality (VR). On Day 1 (acquisition), participants received a mild painful electric shock (unconditioned stimulus, US) in one virtual room (fear context, CTX+) at the offset of one colored light (CS+), but never at the offset of another colored light (CS-). In a second room (safety context, CTX-), the two lights were also presented, but not the US. Successful cue conditioning was indicated by aversive ratings and startle potentiation but not skin conductance responses (SCR) to CS+ versus CS- in CTX+ and not in CTX-. On Day 2 (generalization), participants re-visited both fear and safety contexts plus a generalization context (G-CTX), which was an equal mix of CTX+ and CTX-. The two CSs were shown again in all three contexts. Generalization of conditioned fear was revealed in affective ratings (CS+ was rated more aversive than CS- in G-CTX), but not in physiological measures (equal startle potentiation to CS+ versus CS- in all contexts). In sum, contextual information modulates the responses to a threat signal such that a safety context can inhibit conditioned fear. Interestingly, generalization processes also depend on contextual information. © 2020 Elsevier B.V.","Classical conditioning; Context conditioning; Fear generalization; Startle response; Virtual reality","adult; anxiety; arousal; Article; association; conditioned reflex; electric shock; electrodermal response; expectancy; fear; fear conditioning test; female; generalization (psychology); human; human experiment; male; normal human; questionnaire; safety; startle reflex; threat; virtual reality",Article,"Final","",Scopus,2-s2.0-85086791198
"Barhorst-Cates E.M., Stefanucci J.K., Creem-Regehr S.H.","57191624633;6507336056;6602436425;","A comparison of virtual locomotion methods in movement experts and non-experts: testing the contributions of body-based and visual translation for spatial updating",2020,"Experimental Brain Research","238","9",,"1911","1923",,1,"10.1007/s00221-020-05851-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086594787&doi=10.1007%2fs00221-020-05851-6&partnerID=40&md5=cd2a819784104b3581a81300f8442e5e","Moss Rehabilitation Research Institute, Elkins Park, PA, United States; Psychology Department, University of Utah, Salt Lake City, UT, United States","Barhorst-Cates, E.M., Moss Rehabilitation Research Institute, Elkins Park, PA, United States; Stefanucci, J.K., Psychology Department, University of Utah, Salt Lake City, UT, United States; Creem-Regehr, S.H., Psychology Department, University of Utah, Salt Lake City, UT, United States","Both visual and body-based (vestibular and proprioceptive) information contribute to spatial updating, or the way a navigator keeps track of self-position during movement. Research has tested the relative contributions of these sources of information and found mixed results, with some studies demonstrating the importance of body-based information, especially for translation, and some demonstrating the sufficiency of visual information. Here, we invoke an individual differences approach to test whether some individuals may be more dependent on certain types of information compared to others. Movement experts tend to be dependent on motor processes in small-scale spatial tasks, which can help or hurt performance, but it is unknown if this effect extends into large-scale spatial tasks like spatial updating. In the current study, expert dancers and non-dancers completed a virtual reality point-to-origin task with three locomotion methods that varied the availability of body-based and visual information for translation: walking, joystick, and teleporting. We predicted decrements in performance in both groups as self-motion information was reduced, and that dancers would show a larger cost. Surprisingly, both dancers and non-dancers performed with equal accuracy in walking and joystick and were impaired in teleporting, with no large differences between groups. We found slower response times for both groups with reductions in self-motion information, and minimal evidence for a larger cost for dancers. While we did not see strong dance effects, more participation in spatial activities related to decreased angular error. Together, the results suggest a flexibility in reliance on visual or body-based information for translation in spatial updating that generalizes across dancers and non-dancers, but significant decrements associated with removing both of these sources of information. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Dance expertise; Spatial updating; Virtual locomotion methods","adult; article; dancing; female; human; human experiment; intermethod comparison; male; motion; reaction time; virtual reality; visual information; walking",Article,"Final","",Scopus,2-s2.0-85086594787
"Allevato A.D., Schaertl Short E., Pryor M., Thomaz A.L.","57194037735;35957168900;7004159251;13007283900;","Iterative residual tuning for system identification and sim-to-real robot learning",2020,"Autonomous Robots","44","7",,"1167","1182",,,"10.1007/s10514-020-09925-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087301119&doi=10.1007%2fs10514-020-09925-w&partnerID=40&md5=9fa42e973cbb6ae699f4fe2b38f8e8bb","The University of Texas at Austin, Austin, TX  78712, United States; Tufts University, Medford, MA  02155, United States","Allevato, A.D., The University of Texas at Austin, Austin, TX  78712, United States; Schaertl Short, E., The University of Texas at Austin, Austin, TX  78712, United States, Tufts University, Medford, MA  02155, United States; Pryor, M., The University of Texas at Austin, Austin, TX  78712, United States; Thomaz, A.L., The University of Texas at Austin, Austin, TX  78712, United States","Robots are increasingly learning complex skills in simulation, increasing the need for realistic simulation environments. Existing techniques for approximating real-world physics with a simulation require extensive observation data and/or thousands of simulation samples. This paper presents iterative residual tuning (IRT), a deep learning system identification technique that modifies a simulator’s parameters to better match reality using minimal real-world observations. IRT learns to estimate the parameter difference between two parameterized models, allowing repeated iterations to converge on the true parameters similarly to gradient descent. In this paper, we develop and analyze IRT in depth, including its similarities and differences with gradient descent. Our IRT implementation, TuneNet, is pre-trained via supervised learning over an auto-generated simulated dataset. We show that TuneNet can perform rapid, efficient system identification even when the true parameter values lie well outside those in the network’s training data, and can also learn real-world parameter values from visual data. We apply TuneNet to a sim-to-real task transfer experiment, allowing a robot to perform a dynamic manipulation task with a new object after a single observation. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Physics prediction; Sim-to-real transfer; Simulation; System identification","Agricultural robots; Deep learning; Educational robots; Gradient methods; Parameter estimation; Religious buildings; Robots; Scattering parameters; Gradient descent; Manipulation task; Observation data; Parameterized model; Realistic simulation; Task transfer; Training data; Visual data; Learning systems",Article,"Final","",Scopus,2-s2.0-85087301119
"Dehn L.B., Piefke M., Toepper M., Kohsik A., Rogalewski A., Dyck E., Botsch M., Schäbitz W.-R.","55893825700;6507173176;23981202600;55661098600;12809201800;55661585100;6602523499;6603920841;","Cognitive training in an everyday-like virtual reality enhances visual-spatial memory capacities in stroke survivors with visual field defects",2020,"Topics in Stroke Rehabilitation","27","6",,"442","452",,,"10.1080/10749357.2020.1716531","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078452461&doi=10.1080%2f10749357.2020.1716531&partnerID=40&md5=675a4e38587c77db3b7eeab3f89cb40e","Department of Psychiatry and Psychotherapy, Research Division, Evangelisches Klinikum Bethel, Bielefeld, Germany; Faculty of Health, Witten/Herdecke University, Witten, Germany; Department of Neurology, Evangelisches Klinikum Bethel, Bielefeld, Germany; Computer Graphics and Geometry Processing, Bielefeld University, Bielefeld, Germany","Dehn, L.B., Department of Psychiatry and Psychotherapy, Research Division, Evangelisches Klinikum Bethel, Bielefeld, Germany; Piefke, M., Faculty of Health, Witten/Herdecke University, Witten, Germany; Toepper, M., Department of Psychiatry and Psychotherapy, Research Division, Evangelisches Klinikum Bethel, Bielefeld, Germany; Kohsik, A., Department of Neurology, Evangelisches Klinikum Bethel, Bielefeld, Germany; Rogalewski, A., Department of Neurology, Evangelisches Klinikum Bethel, Bielefeld, Germany; Dyck, E., Computer Graphics and Geometry Processing, Bielefeld University, Bielefeld, Germany; Botsch, M., Computer Graphics and Geometry Processing, Bielefeld University, Bielefeld, Germany; Schäbitz, W.-R., Department of Neurology, Evangelisches Klinikum Bethel, Bielefeld, Germany","Objectives: Visual field defects due to hemi- or quadrantanopia after stroke represent an under-recognized neurological symptom with inefficient instruments for neurorehabilitation to date. We here examined the effects of training in a virtual reality (VR) supermarket on cognitive functions, depressive symptoms, and subjective cognitive complaints in patients with hemianopia/quadrantanopia and healthy controls. Methods: During a 14-day rehabilitation program, 20 patients and 20 healthy controls accomplished a real-life-like shopping task in a VR supermarket. A comparison between pre- and post-training standard neuropsychological measures, depressive symptoms, and subjective memory complaints allowed us to assess a putative transfer of rehabilitation effects from the training tasks to specific cognitive functions. Results: The results indicate that VR training may improve performance not only in the trained task but also in specific neuropsychological functions. After the training, both patients and controls showed improved performances in visual scanning, mental rotation, visuoconstruction, and cognitive flexibility. Moreover, depressive symptoms were attenuated in both groups. In the patient group compared to the control group, the training particularly resulted in improved visual memory retrieval and reduced memory complaints. Conclusions: The results of the current study suggest that VR training can improve particularly visual-spatial skills in patients with hemianopia or quadrantanopia. Our study thus introduces an interesting novel treatment approach to improve cognitive functions relevant to daily life in stroke patients with visual field defects. © 2020, © 2020 Taylor & Francis Group, LLC.","cognition; hemianopia; neuropsychology; rehabilitation; Stroke","adult; aged; Article; cerebrovascular accident; clinical article; cognition; comparative study; controlled study; depression; female; group dynamics; hemianopia; human; male; neuropsychological test; neurorehabilitation; spatial memory; stroke patient; stroke survivor; task performance; virtual reality; visual field defect; visual memory; walking distance; working memory; cerebrovascular accident; cognitive defect; procedures; spatial memory; stroke rehabilitation; survivor; visual field; Cognition; Cognition Disorders; Humans; Neurological Rehabilitation; Spatial Memory; Stroke; Stroke Rehabilitation; Survivors; Virtual Reality; Visual Fields",Article,"Final","",Scopus,2-s2.0-85078452461
"Leijte E., De Blaauw I., Rosman C., Botden S.M.B.I.","57202080193;6701566895;6602590209;16067890000;","Assessment of validity evidence for the RobotiX robot assisted surgery simulator on advanced suturing tasks",2020,"BMC Surgery","20","1", 183,"","",,,"10.1186/s12893-020-00839-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089610556&doi=10.1186%2fs12893-020-00839-z&partnerID=40&md5=97b28548e1768260646ddc9c19844714","Department of Surgery, Radboud University Medical Center, Geert grooteplein 10 route 618, Nijmegen, 6500HB, Netherlands; Department of Pediatric Surgery, Radboud University Medical Center, Geert grooteplein 10 route 618, Nijmegen, 6500HB, Netherlands","Leijte, E., Department of Surgery, Radboud University Medical Center, Geert grooteplein 10 route 618, Nijmegen, 6500HB, Netherlands, Department of Pediatric Surgery, Radboud University Medical Center, Geert grooteplein 10 route 618, Nijmegen, 6500HB, Netherlands; De Blaauw, I., Department of Pediatric Surgery, Radboud University Medical Center, Geert grooteplein 10 route 618, Nijmegen, 6500HB, Netherlands; Rosman, C., Department of Surgery, Radboud University Medical Center, Geert grooteplein 10 route 618, Nijmegen, 6500HB, Netherlands; Botden, S.M.B.I., Department of Pediatric Surgery, Radboud University Medical Center, Geert grooteplein 10 route 618, Nijmegen, 6500HB, Netherlands","Background: Robot assisted surgery has expanded considerably in the past years. Compared to conventional open or laparoscopic surgery, virtual reality (VR) training is an essential component in learning robot assisted surgery. However, for tasks to be implemented in a curriculum, the levels of validity should be studied for proficiency-based training. Therefore, this study was aimed to assess the validity evidence of advanced suturing tasks on a robot assisted VR simulator. Method: Participants were voluntary recruited and divided in the robotic experienced, laparoscopic experienced or novice group, based on self-reported surgical experience. Subsequently, a questionnaire on a five-point Likert scale was completed to assess the content validity. Three component tasks of complex suturing were performed on the RobotiX simulator (Task1: tilted plane needle transfer, Task: 2 intracorporal suturing, Task 3: anastomosis needle transfer). Accordingly, the outcome of the parameters was used to assess construct validity between robotic experienced and novice participants. Composite scores (0-100) were calculated from the construct parameters and corresponding pass/fail scores with false positive (FP) and false negative (FN) percentages. Results: Fifteen robotic experienced, 26 laparoscopic experienced and 29 novices were recruited. Overall content validity outcomes were scored positively on the realism (mean 3.7), didactic value (mean 4.0) and usability (mean 4.2). Robotic experienced participants significantly outperformed novices and laparoscopic experienced participants on multiple parameters on all three tasks of complex suturing. Parameters showing construct validity mainly consisted of movement parameters, needle precision and task completion time. Calculated composite pass/fail scores between robotic experienced and novice participants resulted for Task 1 in 73/100 (FP 21%, FN 5%), Task 2 in 85/100 (FP 28%, FN 4%) and Task 3 in 64/100 (FP 49%, FN 22%). Conclusion: This study assessed the validity evidence on multiple levels of the three studied tasks. The participants score the RobotiX good on the content validity level. The composite pass/fail scores of Tasks 1 and 2 allow for proficiency-based training and could be implemented in a robot assisted surgery training curriculum. © 2020 The Author(s).","Proficiency based training; Robotic surgery; Validation; Virtual reality simulation","adult; clinical competence; computer simulation; curriculum; devices; female; human; laparoscopy; male; middle aged; procedures; questionnaire; robot assisted surgery; suture technique; young adult; Adult; Clinical Competence; Computer Simulation; Curriculum; Female; Humans; Laparoscopy; Male; Middle Aged; Robotic Surgical Procedures; Surveys and Questionnaires; Suture Techniques; Young Adult",Article,"Final","",Scopus,2-s2.0-85089610556
"Lamb R., Etopio E.A.","36634407300;55377820300;","Virtual Reality: a Tool for Preservice Science Teachers to Put Theory into Practice",2020,"Journal of Science Education and Technology","29","4",,"573","585",,1,"10.1007/s10956-020-09837-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086093371&doi=10.1007%2fs10956-020-09837-5&partnerID=40&md5=cd13439157dd46a931e0208a267b9983","Neurocognition Science Laboratory, East Carolina University, Greenville, NC  27858, United States; University at Buffalo, Buffalo, NY, United States","Lamb, R., Neurocognition Science Laboratory, East Carolina University, Greenville, NC  27858, United States; Etopio, E.A., University at Buffalo, Buffalo, NY, United States","The purpose of the present study was to investigate, compare, and characterize interactive VR-based preservice science teacher clinical teaching environments with those of real-life teaching environments. Fifty-four college-aged students were assigned randomly to either real-life conditions or VR conditions. The main effect of the VR condition versus real-life was not statistically significant in terms of the retrospective engagement survey, psychological measures, and composite neuroimaging. This finding suggests that use of VR, in terms of the realism of the environment for the preservice science teachers allowed them to learn from modeled real-life situations for transfer of skills from VR to classroom use. © 2020, Springer Nature B.V.","Methods courses; Professional learning; Science education; Teacher preparation; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85086093371
"Colombo M., Dolhasz A., Harvey C.","57220106721;57193614682;48761392600;","A Computer Vision Inspired Automatic Acoustic Material Tagging System for Virtual Environments",2020,"IEEE Conference on Computatonal Intelligence and Games, CIG","2020-August",, 9231689,"736","739",,,"10.1109/CoG47356.2020.9231689","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096928895&doi=10.1109%2fCoG47356.2020.9231689&partnerID=40&md5=5ddcf3873d31b91b857e59df2851414c","Birmingham City University, Dmt Lab, United Kingdom","Colombo, M., Birmingham City University, Dmt Lab, United Kingdom; Dolhasz, A., Birmingham City University, Dmt Lab, United Kingdom; Harvey, C., Birmingham City University, Dmt Lab, United Kingdom","This paper presents the ongoing work on an approach to material information retrieval in virtual environments (VEs). Our approach uses convolutional neural networks to classify materials by performing semantic segmentation on images captured in the VE. Class maps obtained are then re-projected onto the environment. We use transfer learning and fine-tune a pretrained segmentation model on images captured in our VEs. The geometry and semantic information can then be used to create mappings between objects in the VE and acoustic absorption coefficients. This can then be input for physically-based audio renderers, allowing a significant reduction in manual material tagging. © 2020 IEEE.","acoustic applications; games; machine vision; rendering (computer graphics); semantic networks","Computer vision; Convolutional neural networks; Image segmentation; Semantics; Transfer learning; Acoustic absorption coefficients; Acoustic materials; Material information; Physically based; Segmentation models; Semantic information; Semantic segmentation; Tagging systems; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85096928895
"Qiao Q., Yunusa-Kaltungo A., Edwards R.","57219745555;56285338100;7403979110;","Predicting building energy consumption based on meteorological data",2020,"2020 IEEE PES/IAS PowerAfrica, PowerAfrica 2020",,, 9219909,"","",,,"10.1109/PowerAfrica49420.2020.9219909","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095112822&doi=10.1109%2fPowerAfrica49420.2020.9219909&partnerID=40&md5=3e55f1ea5d391773e8a2e45d4452f83f","Unversity of Manchester, Department of Mechanical, Aerospace and Civil Engineering (MACE), Manchester, United Kingdom","Qiao, Q., Unversity of Manchester, Department of Mechanical, Aerospace and Civil Engineering (MACE), Manchester, United Kingdom; Yunusa-Kaltungo, A., Unversity of Manchester, Department of Mechanical, Aerospace and Civil Engineering (MACE), Manchester, United Kingdom; Edwards, R., Unversity of Manchester, Department of Mechanical, Aerospace and Civil Engineering (MACE), Manchester, United Kingdom","The reliability of building energy prediction results is often threatened by lack of comprehensive and continuous data, especially when dealing with older buildings that are not furnished with building energy management systems. In order to investigate the performance of building energy prediction models under limited data, this paper utilises four distinct machine learning methods - decision tree (DT), support vector machine (SVM), random forest (RF) and voting regression (VR) to predict energy consumption of the Chemistry building of a prominent higher institution, based on just meteorological data. The results indicate that SVM is unable to accurately predict building energy consumption based on the prescribed input variables alone. However, in general, DT, RF and VR offered far more reliable and accurate energy consumption prediction outcomes with the same training and testing data sets. More specifically, RF outperformed all other included methods. It was also observed that the extension of the time span for the training data sets offered insignificant improvement to the prediction accuracy as postulated by some earlier studies. With regards to overall generalisation capability, VR outperformed all approaches, with outcomes from RF also marginally better than those from DT. © 2020 IEEE.","Building energy consumption prediction; decision tree; meteorological data; random forest; support vector machine; voting regression","Buildings; Decision trees; Energy management systems; Energy utilization; Forecasting; Information management; Learning systems; Meteorology; Predictive analytics; Random forests; Support vector machines; Support vector regression; Building energy consumption; Building energy management systems; Energy consumption prediction; Machine learning methods; Meteorological data; Performance of buildings; Prediction accuracy; Training and testing; Energy conservation",Conference Paper,"Final","",Scopus,2-s2.0-85095112822
"Nie J., Wu B.","57219057682;57213495940;","Investigating the effect of immersive virtual reality and planning on the outcomes of simulation-based learning: A media and method experiment",2020,"Proceedings - IEEE 20th International Conference on Advanced Learning Technologies, ICALT 2020",,, 9155971,"329","332",,,"10.1109/ICALT49669.2020.00106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091147966&doi=10.1109%2fICALT49669.2020.00106&partnerID=40&md5=0cfc6e5a1bd46be168e53bd114e7a60d","East China Normal University, Department of Educational Informational Technology, Shanghai, China","Nie, J., East China Normal University, Department of Educational Informational Technology, Shanghai, China; Wu, B., East China Normal University, Department of Educational Informational Technology, Shanghai, China","The application of the immersive virtual reality (VR) has injected new vitality into educational innovation, but there are also some voices of doubt on its practical learning effects. Considering two aspects of media and instructional methods, the study investigated the effect of immersive virtual reality and planning strategy on simulation-based learning by a 2×2 experimental cross-panel design. The results showed that both of them had a significant main effect, indicating that the immersive VR and planning led to better behavioral transfer performance and immersive VR increased sense of presence and self-efficacy as well. No interaction effect between media and method was found. © 2020 IEEE.","Immersive virtual reality; Planning Strategy; Simulation-based learning; Virtual simulation","E-learning; Learning systems; Educational innovations; Immersive virtual reality; Instructional methods; Interaction effect; Planning strategies; Sense of presences; Simulation-based learning; Transfer performance; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85091147966
"Rout S.P.","57220038960;","6G Wireless Communication: Its Vision, Viability, Application, Requirement, Technologies, Encounters and Research",2020,"2020 11th International Conference on Computing, Communication and Networking Technologies, ICCCNT 2020",,, 9225680,"","",,1,"10.1109/ICCCNT49239.2020.9225680","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096544829&doi=10.1109%2fICCCNT49239.2020.9225680&partnerID=40&md5=58c77867b3e94be4b5a2d9b5edf945cb","Electronics and Communication Engineering, TempleCity Institute of Technology Engineering, Bhubaneswar, India","Rout, S.P., Electronics and Communication Engineering, TempleCity Institute of Technology Engineering, Bhubaneswar, India","The fast development of multiband ultrafast seamless network and super reliable data transmission system to support heavy traffic applications such as artificial intelligence, machine learning, deep learning, augmented reality, virtual reality, 3D media, Internet of Things, Enterprise Internet of Thing and the Internet of Nano-things that involves with the real time transfer of data, voice and video in terabytes per second (Tb/s), the current cellular network (5G Network is insufficient to meet the growth of usage of triple play services in fraction of time). To meet the expectation of heavy data users is a big challenge in today's generation. To handle the situation of drastic demand of data, the sixth generation of mobile technology (6G) should be deeply studied along with its potential in terms of bandwidth, low latency, channel capacity, channel modeling techniques, loss propagation models, energy spectrum efficiency, faster network connectivity and data security. In this paper the vision in terms intelligent computing and wireless massive connectivity, feasibility, requirement in terms of modifying the existing 5G network, technologies in terms of artificial intelligence, 3D networking, SM-MIMO and optical computing, challenges after deployment, research to promote good health for 6G and application of 6G in the field of industry, automation sector, health, and transport has been studied and presented. © 2020 IEEE.","AR; BCI; BY5G; E-IoT; eMBB; Io-BNT; IoE; M2M; mMTC; MR; OAM; QoE; SM-MIMO; UAV; URLLC; VR","Augmented reality; Data transfer; Deep learning; Intelligent computing; Internet of things; MIMO systems; Optical data processing; Queueing networks; Security of data; Telecommunication equipment; Three dimensional computer graphics; Virtual corporation; Virtual reality; Cellular network; Mobile Technology; Network connectivity; Propagation models; Real-time transfer; Reliable data transmission; Triple Play services; Wireless communications; 5G mobile communication systems",Conference Paper,"Final","",Scopus,2-s2.0-85096544829
"Lopez C.E., Ashour O., Cunningham J.D., Tucker C., Lynch P.C.","57193163382;36080456300;57194829435;15833577900;56300591400;","The CLICK approach and its impact on learning introductory probability concepts in an industrial engineering course",2020,"ASEE Annual Conference and Exposition, Conference Proceedings","2020-June",, 1339,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095792991&partnerID=40&md5=2b11cbd2f228cb0f4a897f4e2b19ce26","Lafayette College, United States; Penn State Erie, Behrend College, United States; Carnegie Mellon University, United States; Pennsylvania State University, Behrend College, United States","Lopez, C.E., Lafayette College, United States; Ashour, O., Penn State Erie, Behrend College, United States; Cunningham, J.D., Carnegie Mellon University, United States; Tucker, C., Carnegie Mellon University, United States; Lynch, P.C., Pennsylvania State University, Behrend College, United States","The objective of this work is to present an initial investigation of the impact the Connected Learning and Integrated Course Knowledge (CLICK) approach has had on students' motivation, engineering identity, and learning outcomes. CLICK is an approach that leverages Virtual Reality (VR) technology to provide an integrative learning experience in the Industrial Engineering (IE) curriculum. To achieve this integration, the approach aims to leverage VR learning modules to simulate a variety of systems. The VR learning modules offer an immersive experience and provide the context for real-life applications. The virtual simulated system represents a theme to transfer the system concepts and knowledge across multiple IE courses as well as connect the experience with real-world applications. The CLICK approach has the combined effect of immersion and learning-by-doing benefits. In this work, VR learning modules are developed for a simulated manufacturing system. The modules teach the concepts of measures of location and dispersion, which are used in an introductory probability course within the IE curriculum. This work presents the initial results of comparing the motivation, engineering identity, and knowledge gain between a control and an intervention group (i.e., traditional vs. CLICK teaching groups). The CLICK approach group showed greater motivation compared to a traditional teaching group. However, there were no effects on engineering identity and knowledge gain. Nevertheless, it is hypothesized that the VR learning modules will have a positive impact on the students' motivation, engineering identity, and knowledge gain over the long run and when used across the curriculum. Moreover, IE instructors interested in providing an immersive and integrative learning experience to their students could leverage the VR learning modules developed for this project. © American Society for Engineering Education 2020.",,"Curricula; Learning systems; Manufacture; Motivation; Students; Teaching; Virtual reality; Industrial engineering course; Integrated course; Integrative learning; Learning by doing; Learning modules; Learning outcome; Probability concepts; Real-life applications; Engineering education",Conference Paper,"Final","",Scopus,2-s2.0-85095792991
"Faria A.L., Faria A.L., Faria A.L., Pinho M.S., Pinho M.S., Bermúdez I Badia S., Bermúdez I Badia S., Bermúdez I Badia S.","56003804800;56003804800;56003804800;15052258800;15052258800;6506360007;6506360007;57210840066;","A comparison of two personalization and adaptive cognitive rehabilitation approaches: A randomized controlled trial with chronic stroke patients",2020,"Journal of NeuroEngineering and Rehabilitation","17","1", 78,"","",,3,"10.1186/s12984-020-00691-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086622926&doi=10.1186%2fs12984-020-00691-5&partnerID=40&md5=fa31ad259684fecbc4f8d5bb5394bf4e","Madeira Interactive Technologies Institute, Universidade da Madeira, Funchal, Portugal; Faculdade de Psicologia e de Ciências da Educação, Universidade de Coimbra, Coimbra, Portugal; NOVA-LINCS, Universidade NOVA de Lisboa, Lisbon, Portugal; Laboratório de Memória, Linguagem e Funções Executivas, Coimbra, Portugal; Centro de Ciências Exatas e da Engenharia, Universidade da Madeira, Funchal, Portugal","Faria, A.L., Madeira Interactive Technologies Institute, Universidade da Madeira, Funchal, Portugal, Faculdade de Psicologia e de Ciências da Educação, Universidade de Coimbra, Coimbra, Portugal, NOVA-LINCS, Universidade NOVA de Lisboa, Lisbon, Portugal; Faria, A.L., Madeira Interactive Technologies Institute, Universidade da Madeira, Funchal, Portugal, Faculdade de Psicologia e de Ciências da Educação, Universidade de Coimbra, Coimbra, Portugal, NOVA-LINCS, Universidade NOVA de Lisboa, Lisbon, Portugal; Faria, A.L., Madeira Interactive Technologies Institute, Universidade da Madeira, Funchal, Portugal, Faculdade de Psicologia e de Ciências da Educação, Universidade de Coimbra, Coimbra, Portugal, NOVA-LINCS, Universidade NOVA de Lisboa, Lisbon, Portugal; Pinho, M.S., Faculdade de Psicologia e de Ciências da Educação, Universidade de Coimbra, Coimbra, Portugal, Laboratório de Memória, Linguagem e Funções Executivas, Coimbra, Portugal; Pinho, M.S., Faculdade de Psicologia e de Ciências da Educação, Universidade de Coimbra, Coimbra, Portugal, Laboratório de Memória, Linguagem e Funções Executivas, Coimbra, Portugal; Bermúdez I Badia, S., Madeira Interactive Technologies Institute, Universidade da Madeira, Funchal, Portugal, NOVA-LINCS, Universidade NOVA de Lisboa, Lisbon, Portugal; Bermúdez I Badia, S., Madeira Interactive Technologies Institute, Universidade da Madeira, Funchal, Portugal, NOVA-LINCS, Universidade NOVA de Lisboa, Lisbon, Portugal; Bermúdez I Badia, S., Centro de Ciências Exatas e da Engenharia, Universidade da Madeira, Funchal, Portugal","Background: Paper-and-pencil tasks are still widely used for cognitive rehabilitation despite the proliferation of new computer-based methods, like VR-based simulations of ADL's. Studies have established construct validity of VR assessment tools with their paper-and-pencil version by demonstrating significant associations with their traditional construct-driven measures. However, VR rehabilitation intervention tools are mostly developed to include mechanisms such as personalization and adaptation, elements that are disregarded in their paper-and-pencil counterparts, which is a strong limitation of comparison studies. Here we compare the clinical impact of a personalized and adapted paper-and-pencil training and a content equivalent and more ecologically valid VR-based ADL's simulation. Methods: We have performed a trial with 36 stroke patients comparing Reh@City v2.0 (adaptive cognitive training through everyday tasks VR simulations) with Task Generator (TG: content equivalent and adaptive paper-and-pencil training). The intervention comprised 12 sessions, with a neuropsychological assessment pre, post-intervention and follow-up, having as primary outcomes: general cognitive functioning (assessed by the Montreal Cognitive Assessment - MoCA), attention, memory, executive functions and language specific domains. Results: A within-group analysis revealed that the Reh@City v2.0 improved general cognitive functioning, attention, visuospatial ability and executive functions. These improvements generalized to verbal memory, processing speed and self-perceived cognitive deficits specific assessments. TG only improved in orientation domain on the MoCA, and specific processing speed and verbal memory outcomes. However, at follow-up, processing speed and verbal memory improvements were maintained, and a new one was revealed in language. A between-groups analysis revealed Reh@City v2.0 superiority in general cognitive functioning, visuospatial ability, and executive functions on the MoCA. Conclusions: The Reh@City v2.0 intervention with higher ecological validity revealed higher effectiveness with improvements in different cognitive domains and self-perceived cognitive deficits in everyday life, and the TG intervention retained fewer cognitive gains for longer. Trial registration: The trial is registered at ClinicalTrials.gov, number NCT02857803. Registered 5 August 2016,. © 2020 The Author(s).","Cognitive rehabilitation; Ecological validity; Stroke; Virtual reality","adult; aged; Article; attention; cerebrovascular accident; clinical article; cognition; cognitive rehabilitation; controlled study; executive function; female; follow up; human; intermethod comparison; language ability; male; Montreal cognitive assessment; priority journal; processing speed; randomized controlled trial; stroke patient; trail making test; verbal memory; virtual reality; Wechsler adult intelligence scale; Wechsler memory scale; cerebrovascular accident; cognitive defect; comparative study; complication; middle aged; neuropsychological test; procedures; psychology; stroke rehabilitation; virtual reality exposure therapy; Aged; Cognition Disorders; Executive Function; Female; Humans; Male; Middle Aged; Neuropsychological Tests; Stroke; Stroke Rehabilitation; Virtual Reality Exposure Therapy",Article,"Final","",Scopus,2-s2.0-85086622926
"Hartless J.F., Ayer S.K., London J.S., Wu W.","57208328848;55358381000;38561546100;55707471100;","Comparison of Building Design Assessment Behaviors of Novices in Augmented-and Virtual-Reality Environments",2020,"Journal of Architectural Engineering","26","2", 04020002,"","",,2,"10.1061/(ASCE)AE.1943-5568.0000396","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082121907&doi=10.1061%2f%28ASCE%29AE.1943-5568.0000396&partnerID=40&md5=56136f424798e28dea0e25c612fa4a0b","Emerging Technologies BIM Research Group, School of Sustainable Engineering and the Built Environment, Arizona State Univ., 660 S. College Ave., Tempe, AZ  85281, United States; Dept. of Engineering Education, Virginia Tech, 363 Goodwin Hall, 635 Prices Fork Rd., Blacksburg, VA  24061, United States; Lyles College of Engineering, Californian State Univ. Fresno, 2320 E San Ramon Ave., Fresno, CA  93740, United States","Hartless, J.F., Emerging Technologies BIM Research Group, School of Sustainable Engineering and the Built Environment, Arizona State Univ., 660 S. College Ave., Tempe, AZ  85281, United States; Ayer, S.K., Emerging Technologies BIM Research Group, School of Sustainable Engineering and the Built Environment, Arizona State Univ., 660 S. College Ave., Tempe, AZ  85281, United States; London, J.S., Dept. of Engineering Education, Virginia Tech, 363 Goodwin Hall, 635 Prices Fork Rd., Blacksburg, VA  24061, United States; Wu, W., Lyles College of Engineering, Californian State Univ. Fresno, 2320 E San Ramon Ave., Fresno, CA  93740, United States","Design and construction professionals must make well-informed decisions for every project that meets both industry standards and building codes and also the specific needs of building users and clients. In order to make effective decisions, research suggests that explicit knowledge, defined as easily codified and communicated information, and tacit knowledge, considered to be the know-how of completing a task, must be effectively applied. While there is recognition of the need for both forms of knowledge, architecture engineering and construction (AEC) education has historically focused on covering content-related explicit knowledge in the classroom. As a result, students generally develop tacit knowledge over their careers. Due to an aging AEC workforce, there is a need to support tacit knowledge development in the classroom to enable students entering the industry to supplement the collective tacit knowledge that will exit the industry as the current generation of practitioners retires. Therefore, the authors of this paper explore the use of augmented reality (AR) and virtual reality (VR) to provide immersive virtual experiences aimed at replicating the types of scenarios that students might experience in their careers that would require them to apply tacit knowledge. The authors tasked students in construction-related disciplines with assessing a building design and making judgments about how the design should be modified to support an occupant in a wheelchair in both VR and AR. Using two similar models and a counterbalanced research methodology, the authors coded the statements and behaviors of the student participants during this design assessment exercise. The results of this work indicate that both technologies elicited statements that were indicative of explicit knowledge related to the needs of a wheelchair-bound occupant. When AR and VR were found to directly encourage physical exploration in the experience, both led to behaviors that simulated the completion of tasks that might be performed by a wheelchair-bound occupant. These behaviors were frequently followed by comments that were indicative of tacit knowledge. While this type of behavior was observed in both AR and VR, AR seemed to more directly encourage this type of interaction among participants. The contribution of this work is in providing observational evidence to demonstrate how the physical exploration affordances of AR and VR may be able to support experiences that foster the use and development of tacit knowledge related to AEC-related decision-making. © 2020 American Society of Civil Engineers.",,"Architectural design; Augmented reality; Building codes; Construction; Decision making; Education computing; Students; Technology transfer; Virtual reality; Wheelchairs; Architecture engineering; Augmented and virtual realities; Current generation; Design and construction; Design assessments; Explicit knowledge; Industry standards; Research methodologies; Structural design",Article,"Final","",Scopus,2-s2.0-85082121907
"Mogessie M., Wolf S.D., Barbosa M., Jones N., McLaren B.M.","57209507489;56839569300;57219194303;57219201077;25652179400;","Work-in-Progress-A Generalizable Virtual Reality Training and Intelligent Tutor for Additive Manufacturing",2020,"Proceedings of 6th International Conference of the Immersive Learning Research Network, iLRN 2020",,, 9155119,"355","358",,,"10.23919/iLRN47897.2020.9155119","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091627468&doi=10.23919%2fiLRN47897.2020.9155119&partnerID=40&md5=34bb3ec1e1c3c639d26419a77d160553","Carnegie Mellon University, Human-Computer Interaction Institute, Pittsburgh, PA, United States; Carnegie Mellon University, Next Manufacturing Center, Pittsburgh, PA, United States","Mogessie, M., Carnegie Mellon University, Human-Computer Interaction Institute, Pittsburgh, PA, United States; Wolf, S.D., Carnegie Mellon University, Next Manufacturing Center, Pittsburgh, PA, United States; Barbosa, M., Carnegie Mellon University, Human-Computer Interaction Institute, Pittsburgh, PA, United States; Jones, N., Carnegie Mellon University, Next Manufacturing Center, Pittsburgh, PA, United States; McLaren, B.M., Carnegie Mellon University, Human-Computer Interaction Institute, Pittsburgh, PA, United States","There is currently significant demand for training in how to use metals additive manufacturing (AM) machines. Such training is important not only for the technicians who run and maintain the machines, but also for engineers and strategic decision makers who need to support AM part fabrication. Furthermore, there are a variety of AM machines, each with different details to be learned and potential hazards to overcome, and it is difficult to train more than a handful of users at one time. To address these challenges, a prototype training system has been developed, the AM Training Tutor, which uses interactive virtual reality (VR) to train users on a specific AM machine-the EOS M290. To make the training technology more widely available and expand its use across a variety of different AM machines, efforts are underway to develop a modularized and generic version of the AM Training Tutor that can be customized with relatively little effort to train users to operate other AM machines. This work-in-progress paper details the progress to-date, challenges and proposed solutions with the aim to demonstrate how standalone VR-based training systems can be redesigned for relatively easy repurposing and generalization. © 2020 Immersive Learning Research Network.","3D printing; additive manufacturing; advanced manufacturing; cognitive tutor; generalized VR; VR-based training; workforce training","3D printers; Additives; Decision making; E-learning; Virtual addresses; Virtual reality; Intelligent tutors; Interactive virtual reality; Potential hazards; Repurposing; Strategic decisions; Training Systems; Virtual reality training; Work in progress; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-85091627468
"Montoya Y.Y., Pillajo C.G., Ortiz J.S.","57218385133;55832576100;56425030300;","Training Assistant for LACT Process Through Augmented Reality",2020,"Iberian Conference on Information Systems and Technologies, CISTI","2020-June",, 9141081,"","",,,"10.23919/CISTI49556.2020.9141081","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089026636&doi=10.23919%2fCISTI49556.2020.9141081&partnerID=40&md5=b0b81b5d80320a73617779f8c2f674ed","Universidad Politécnica Salesiana, Quito, Ecuador; Universidad de Las Fuerzas Armadas Espe, Sangolquí, Ecuador","Montoya, Y.Y., Universidad Politécnica Salesiana, Quito, Ecuador; Pillajo, C.G., Universidad Politécnica Salesiana, Quito, Ecuador; Ortiz, J.S., Universidad de Las Fuerzas Armadas Espe, Sangolquí, Ecuador","This article proposes the development of a 3D augmented reality app for mobile devices focused on staff training (training of operators) in the oil industry on the operation of Lease Automatic Custody Transfer Units (LACT Units). First, existing information about LACT Units was collected to define the basic and specific parameters for the virtual creation of a 3D model of the LACT Units (CAD files) which allows the visualization of the equipment and instruments commonly used in the LACT Units, also through the Unity 3D graphic engine a specific sequence of operation is defined attached to a real system. The application focuses on the recognition of PID through a smartphone allowing users to make changes in the variables involved in the process, e.g., pressure, temperature and flow, such that, if the user makes any changes to the variables, the system responds according to these changes based on mathematical models of the plant, achieving a more realistic experience between the user and the process. © 2020 AISTI.","Augmented Reality; LACT Unit; P ID; Unity 3D","3D modeling; Augmented reality; Computer aided design; Information systems; Information use; Petroleum industry; Three dimensional computer graphics; User experience; 3D graphics; CAD files; Custody transfer; Oil industries; Real systems; Specific sequences; Staff training; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-85089026636
"Yang K., Jiang F., Zhang S., Zhao H., Shi Z., Liu J., Cao X.","57196390535;57206660117;57203847838;57216802261;57216802565;57208211682;8963608700;","Extradural Contralateral C7 Nerve Root Transfer in a Cervical Posterior Approach for Treating Spastic Limb Paralysis: A Cadaver Feasibility Study",2020,"Spine","45","11",,"E608","E615",,,"10.1097/BRS.0000000000003349","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084721728&doi=10.1097%2fBRS.0000000000003349&partnerID=40&md5=77091d639922769c763f815d714e44e4","Department of Orthopaedics, Second Affiliated Hospital of Nanjing Medical University, Nanjing, Jiangsu, China; Department of Orthopaedics, First Affiliated Hospital of Nanjing Medical University, Nanjing, Jiangsu, China; Department of Orthopaedics, Jen Ching Memorial Hospital, Kun Shan, Jiangsu, China","Yang, K., Department of Orthopaedics, Second Affiliated Hospital of Nanjing Medical University, Nanjing, Jiangsu, China; Jiang, F., Department of Orthopaedics, First Affiliated Hospital of Nanjing Medical University, Nanjing, Jiangsu, China; Zhang, S., Department of Orthopaedics, First Affiliated Hospital of Nanjing Medical University, Nanjing, Jiangsu, China; Zhao, H., Department of Orthopaedics, Jen Ching Memorial Hospital, Kun Shan, Jiangsu, China; Shi, Z., Department of Orthopaedics, Second Affiliated Hospital of Nanjing Medical University, Nanjing, Jiangsu, China; Liu, J., Department of Orthopaedics, Second Affiliated Hospital of Nanjing Medical University, Nanjing, Jiangsu, China; Cao, X., Department of Orthopaedics, First Affiliated Hospital of Nanjing Medical University, Nanjing, Jiangsu, China","Study Design.Anatomic study in nine fresh-frozen cadavers.Objective.To confirm the anatomical feasibility of transferring the extradural ventral roots (VRs) and dorsal roots (DRs) of contralateral C7 nerves to those of the ipsilateral C7 nerves respectively through a cervical posterior approach.Summary of Background Data.The contralateral C7 nerve root transfer technique makes breakthrough for treating spastic limb paralysis. However, its limitations include large surgical trauma and limited indications.Methods.Nine fresh-frozen cadavers (four females and five males) were placed prone, and the feasibility of exposing the bilateral extradural C7 nerve roots, separation of the extradural C7 VR and DR, and transfer of the VR and DR of the contralateral C7 to those of the ipsilateral C7 on the dural mater were assessed. The pertinent distances and the myelography results of each specimen were analyzed. The acetylcholinesterase (AChE) and antineurofilament 200 (NF200) double immunofluorescent staining were preformed to determine the nerve fiber properties.Results.A cervical posterior midline approach was made and the laminectomy was performed to expose the bilateral extradural C7 nerve roots. After the extradural C7 VR and DR are separated, the VR and DR of the contralateral C7 have sufficient lengths to be transferred to those of the ipsilateral C7 on the dural mater. The myelography results showed that the spinal cord is not compressed after the nerve anastomosis. The AChE and NF200 double immunofluorescent staining showed the distal ends of the contralateral C7 VRs were mostly motor nerve fibers, and the distal ends of the contralateral C7 DRs were mostly sensory nerve fibers.Conclusion.Extradural contralateral C7 nerve root transfer in a cervical posterior approach for treating spastic limb paralysis is anatomically feasible.Level of Evidence: 5. © 2020 Wolters Kluwer Health, Inc. All rights reserved.","accurate anastomosis; anatomical feasibility; cervical posterior approach; contralateral C7 nerve root; dorsal root; extradural nerve roots; nerve transfer; spastic limb paralysis; surgical trauma; ventral root","acetylcholinesterase; neurofilament 200; neurofilament protein; unclassified drug; anastomosis; Article; cadaver; cervical spine; dorsal root; feasibility study; female; fluorescence; fluoroscopy; human; immunofluorescence; immunofluorescence test; immunohistochemistry; laminectomy; male; motor nerve; myelinated nerve; myelography; nerve anastomosis; nerve root; nerve transplantation; paralysis; priority journal; spasticity; surgical injury; ventral root; adult; aged; cervical vertebra; middle aged; paralysis; pathology; procedures; reconstructive surgery; spasticity; spinal cord injury; spinal root; Adult; Aged; Cadaver; Cervical Vertebrae; Feasibility Studies; Female; Humans; Laminectomy; Male; Middle Aged; Muscle Spasticity; Paralysis; Reconstructive Surgical Procedures; Spinal Cord Injuries; Spinal Nerve Roots",Article,"Final","",Scopus,2-s2.0-85084721728
"Zahedi E., Khosravian F., Wang W., Armand M., Dargahi J., Zadeh M.","57213036379;57211668159;57211670337;35236429300;6603763357;15520363400;","Towards Skill Transfer via Learning-Based Guidance in Human-Robot Interaction: An Application to Orthopaedic Surgical Drilling Skill",2020,"Journal of Intelligent and Robotic Systems: Theory and Applications","98","3-4",,"667","678",,1,"10.1007/s10846-019-01082-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074756992&doi=10.1007%2fs10846-019-01082-2&partnerID=40&md5=54eb9229bd5fd84057bb67122a06a943","Department of Mechanical, Industrial, Aerospace Engineering, Concordia University, Montreal, QC  H3G 1M8, Canada; Johns Hopkins University, Baltimore, MD  21218, United States","Zahedi, E., Department of Mechanical, Industrial, Aerospace Engineering, Concordia University, Montreal, QC  H3G 1M8, Canada; Khosravian, F., Johns Hopkins University, Baltimore, MD  21218, United States; Wang, W., Johns Hopkins University, Baltimore, MD  21218, United States; Armand, M., Johns Hopkins University, Baltimore, MD  21218, United States; Dargahi, J., Department of Mechanical, Industrial, Aerospace Engineering, Concordia University, Montreal, QC  H3G 1M8, Canada; Zadeh, M., Johns Hopkins University, Baltimore, MD  21218, United States","This paper presents a machine learning-based guidance (LbG) approach for kinesthetic human-robot interaction (HRI) that can be used in virtual training simulations. Demonstrated positional and force skills are learned to both discriminate the skill levels of users and produce LbG forces. Force information is obtained from virtual forces, which developed based on real computed tomography (CT) data, rather than force sensors. A femur bone drilling simulation is developed to provide a practice environment for orthopaedic residents. The residents are provided with haptic feedback that enable them to feel the variable stiffness of bone layers. The X-ray views of the bone are also presented to them for better tracking of a pre-defined path inside the bone. The simulation is capable of planning a drill path, generating X-rays based on user defined orientation, and recording motion data for user assessment and skill modeling. The knowledge of expert surgeons is also incorporated into the simulation to provide LbG forces for improving the unpredictable motions of the residents. To discriminate the skill level of users, machine learning tools are used to develop surgical expert and resident models. In addition, to improve residents performance, the expert HCRF is used to generate adaptive LbG forces regarding the similarities between residents motions and the expert model. Experimental results show that the learning-based approach is able to assess the skill of users and improve residents performance. © 2019, Springer Nature B.V.","Human-robot interaction; Machine learning-based guidance; Virtual surgical simulation","Air navigation; Bone; Computerized tomography; Infill drilling; Learning algorithms; Machine learning; Man machine systems; Robotic surgery; Surgery; Virtual reality; X rays; Haptic feedbacks; Human robot Interaction (HRI); Learning-based approach; Skill transfer; Surgical drilling; Surgical simulation; Variable stiffness; Virtual training; Human robot interaction",Article,"Final","",Scopus,2-s2.0-85074756992
"Johnson D., Damian D., Tzanetakis G.","57214167710;57192297254;6602262192;","Evaluating the effectiveness of mixed reality music instrument learning with the theremin",2020,"Virtual Reality","24","2",,"303","317",,5,"10.1007/s10055-019-00388-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068827721&doi=10.1007%2fs10055-019-00388-8&partnerID=40&md5=7e681b8efa8420e7e54ec8a41f3173ea","University of Victoria, 3800 Finnerty Rd, Victoria, BC  V8P 5C2, Canada","Johnson, D., University of Victoria, 3800 Finnerty Rd, Victoria, BC  V8P 5C2, Canada; Damian, D., University of Victoria, 3800 Finnerty Rd, Victoria, BC  V8P 5C2, Canada; Tzanetakis, G., University of Victoria, 3800 Finnerty Rd, Victoria, BC  V8P 5C2, Canada","Learning music is a challenging process that requires years of practice to master, either with lessons from a professional teacher or through self-teaching. While practicing, students are expected to self-evaluate their performance which may be difficult without timely feedback from a professional. Research into computer-assisted music instrument tutoring (CAMIT) attempts to address this through the use of emerging technologies. In this paper, we study CAMIT for mixed reality (MR) by developing MR:emin, an immersive MR music learning environment for the theremin, an electronic music instrument that is controlled without physical contact. MR:emin integrates a physical theremin with the immersive learning environment. To better understand the effectiveness of such environments, we perform a user study with MR:emin comparing traditional music learning with two virtual learning environments, an immersive one and a non-immersive one. In a between-groups study, 30 participants were trained to play a sequence of notes on the theremin using one of the three training environments. Results of our statistical analysis show that performance error during training is significantly smaller in the immersive MR environment. This does not necessarily lead to improved performance after training; analysis of post-training improvement indicates that immersive training results in the smallest amount of improvement. Participants, however, indicate that the MR:emin environment is more engaging and increases confidence during practice. We discuss potential factors leading to the decrease in learning and provide some environment guidelines to aid in the design of engaging immersive music learning environments. © 2019, Springer-Verlag London Ltd., part of Springer Nature.","Immersive learning environments; Learning transfer; Mixed reality; Music pedagogy; Training","Computer aided instruction; Computer music; Mixed reality; Personnel training; Emerging technologies; Environment guidelines; Immersive learning; Learning environments; Learning Transfer; Music pedagogy; Performance error; Virtual learning environments; E-learning",Article,"Final","",Scopus,2-s2.0-85068827721
"Tcha-Tokey K., Schmidt C.T., Geslin E., Richir S.","57188737906;14036157300;36168103100;55917685500;","Improving humans enhancing the complex sociological being with the virtual",2020,"ACM International Conference Proceeding Series",,,,"","",,,"10.1145/3396339.3396401","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086142743&doi=10.1145%2f3396339.3396401&partnerID=40&md5=21e5057c9f2f7522f43367755992b898","Polytech Nantes University, Arts et Metiers Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France; Le Mans University and Arts et Metiers, Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France; UCO Laval and Arts et Metiers, Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France; Arts et Metiers Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France","Tcha-Tokey, K., Polytech Nantes University, Arts et Metiers Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France; Schmidt, C.T., Le Mans University and Arts et Metiers, Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France; Geslin, E., UCO Laval and Arts et Metiers, Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France; Richir, S., Arts et Metiers Institute of Technology, LAMPA, HESAM Université, Change, F-53810, France","In this paper, we argue in favour of using an immersive Virtual Environment (VE) in order to improve human capabilities. We develop this idea in order to advance the potential of VEs in enhancing humans. Training with VEs has proven in some cases to be more efficient than training in real world situations in terms of the reduction of time consumption, risk reduction, easily presenting specific simulation realism, all of which improve learning capabilities. The VE would be an environment for extending human capabilities, the goal being to increase experiences. This last affirmation could renew the scope of action for AH research: acquiring new needed capabilities from the virtual world that would be usable in both worlds, real and virtual. © 2020 Association for Computing Machinery.","Augmented human; Complex system; Knowledge transfer; Novel therapeutic discovery; Virtual environment","Human capability; Immersive virtual environments; Learning capabilities; Real world situations; Risk reductions; Time consumption; Virtual worlds; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85086142743
"Mohamadipanah H., Perrone K.H., Peterson K., Nathwani J., Huang F., Garren A., Garren M., Witt A., Pugh C.","56674684400;55940642100;57201881114;57189064682;7401516638;57199163977;6506533959;57192085240;8833944500;","Sensors and Psychomotor Metrics: A Unique Opportunity to Close the Gap on Surgical Processes and Outcomes",2020,"ACS Biomaterials Science and Engineering","6","5",,"2630","2640",,1,"10.1021/acsbiomaterials.9b01019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085662931&doi=10.1021%2facsbiomaterials.9b01019&partnerID=40&md5=313e75ed8c2cca1e9537064a04c56fa7","Department of Surgery, Stanford University School of Medicine, 300 Pasteur Drive, Stanford, CA  94305, United States; Department of Surgery, School of Medicine and Public Health, University of Wisconsin-Madison, 600 Highland Avenue, Madison, WI  53726, United States; Department of Physical Medicine and Rehabilitation, Feinberg School of Medicine, Northwestern University, 710 North Lake Shore Drive, #1022, Chicago, IL  60611, United States","Mohamadipanah, H., Department of Surgery, Stanford University School of Medicine, 300 Pasteur Drive, Stanford, CA  94305, United States; Perrone, K.H., Department of Surgery, Stanford University School of Medicine, 300 Pasteur Drive, Stanford, CA  94305, United States; Peterson, K., Department of Surgery, School of Medicine and Public Health, University of Wisconsin-Madison, 600 Highland Avenue, Madison, WI  53726, United States; Nathwani, J., Department of Surgery, School of Medicine and Public Health, University of Wisconsin-Madison, 600 Highland Avenue, Madison, WI  53726, United States; Huang, F., Department of Physical Medicine and Rehabilitation, Feinberg School of Medicine, Northwestern University, 710 North Lake Shore Drive, #1022, Chicago, IL  60611, United States; Garren, A., Department of Surgery, School of Medicine and Public Health, University of Wisconsin-Madison, 600 Highland Avenue, Madison, WI  53726, United States; Garren, M., Department of Surgery, School of Medicine and Public Health, University of Wisconsin-Madison, 600 Highland Avenue, Madison, WI  53726, United States; Witt, A., Department of Surgery, Stanford University School of Medicine, 300 Pasteur Drive, Stanford, CA  94305, United States; Pugh, C., Department of Surgery, Stanford University School of Medicine, 300 Pasteur Drive, Stanford, CA  94305, United States","The surgical process remains elusive to many. This paper presents two independent empirical investigations where psychomotor skill metrics were used to quantify elements of the surgical process in a procedural context during surgical tasks in a simulated environment. The overarching goal of both investigations was to address the following hypothesis: Basic motion metrics can be used to quantify specific aspects of the surgical process including instrument autonomy, psychomotor efficiency, procedural readiness, and clinical errors. Electromagnetic motion tracking sensors were secured to surgical trainees' (N = 64) hands for both studies, and several motion metrics were investigated as a measure of surgical skill. The first study assessed performance during a bowel repair and laparoscopic ventral hernia (LVH) repair in comparison to a suturing board task. The second study assessed performance in a VR task in comparison to placement of a subclavian central line. The findings of the first study support our subhypothesis that motion metrics have a generalizable application to surgical skill by showing significant correlations in instrument autonomy and psychomotor efficiency during the suturing task and bowel repair (idle time: r = 0.46, p < 0.05; average velocity: r = 0.57, p < 0.05) and the suturing task and LVH repair (jerk magnitude: r = 0.36, p < 0.05; bimanual dexterity: r = 0.35, p < 0.05). In the second study, performance in VR (steering and jerkiness) correlated to clinical errors (r = 0.58, p < 0.05) and insertion time (r = 0.55, p < 0.05) in placement of a subclavian central line. Both gross (dexterity) and fine motor skills (steering) were found to be important as well as efficiency (i.e., idle time, duration, velocity) when seeking to understand the quality of surgical performance. Both studies support our hypotheses that basic motion metrics can be used to quantify specific aspects of the surgical process and that the use of different technologies and metrics are important for comprehensive investigations of surgical skill. Copyright © 2020 American Chemical Society.","laparoscopic surgery; motion metrics; objective assessment; psychomotor skills; sensors; virtual reality","Efficiency; Instrument errors; Motion tracking; Surgery; Average velocity; Electromagnetic motion tracking; Empirical investigation; Fine motors; Idle time; Simulated environment; Surgical tasks; Ventral hernia; Time and motion study; abdominal wall hernia; Article; bimanual dexterity; controlled study; electromagnetism; female; hernioplasty; human; intestine surgery; laparoscopic surgery; male; motion; motor coordination; motor performance; predictive value; priority journal; psychomotor performance; quantitative analysis; resident; simulation training; subclavian vein; surgical error; surgical technique; surgical training; task performance; virtual reality",Article,"Final","",Scopus,2-s2.0-85085662931
"Streuber S., Saalfeld P., Podulski K., Hüttl F., Huber T., Buggenhagen H., Boedecker C., Preim B., Hansen C.","57220273134;56537022300;57219598585;57214720246;18535462800;6505541978;57216913553;57195333478;55890379200;","Training of patient handover in virtual reality",2020,"Current Directions in Biomedical Engineering","6","1", 20200040,"","",,,"10.1515/cdbme-2020-0040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094109314&doi=10.1515%2fcdbme-2020-0040&partnerID=40&md5=731ca08cb53a069a29a16c9e92962315","Faculty of Computer Science and Research Campus STIMULATE, Otto-von-Guericke University Magdeburg, Magdeburg, Germany; Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Mainz, Germany; Rudolph-Frey-Lernklinik, University Medicine of the Johannes Gutenberg-University Mainz, Mainz, Germany","Streuber, S., Faculty of Computer Science and Research Campus STIMULATE, Otto-von-Guericke University Magdeburg, Magdeburg, Germany; Saalfeld, P., Faculty of Computer Science and Research Campus STIMULATE, Otto-von-Guericke University Magdeburg, Magdeburg, Germany; Podulski, K., Faculty of Computer Science and Research Campus STIMULATE, Otto-von-Guericke University Magdeburg, Magdeburg, Germany; Hüttl, F., Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Mainz, Germany; Huber, T., Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Mainz, Germany; Buggenhagen, H., Rudolph-Frey-Lernklinik, University Medicine of the Johannes Gutenberg-University Mainz, Mainz, Germany; Boedecker, C., Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Mainz, Germany; Preim, B., Faculty of Computer Science and Research Campus STIMULATE, Otto-von-Guericke University Magdeburg, Magdeburg, Germany; Hansen, C., Faculty of Computer Science and Research Campus STIMULATE, Otto-von-Guericke University Magdeburg, Magdeburg, Germany","Patient handover is an important part for information transfer between medical professionals in a clinical setting. Yet, in current medical education, these conversations are only trained sparsely, since they are costly to perform as they take place in offsite courses and are led by experts over several days. Virtual reality (VR)-based training courses could increase the availability of training, by eliminating travel costs and reducing the time-commitment of the teaching experts. This work presents a VR prototype of a multi-user training and examination application for patient handover. To ensure a similar interaction quality to its current real world counterpart, this work used omni-directional video recordings to create a realistic setting and compared different projection methods. A pilot study highlighted distinct use-cases of sphere and mesh projections to visualize the recordings. The results suggest enhanced spatial presence relating to the usage of omni-directional videos in VR-applications. © 2020 Sebastian Streuber et al., published by De Gruyter, Berlin/Boston 2020.","human-computer-interaction; medical training; patient handover; virtual reality",,Article,"Final","",Scopus,2-s2.0-85094109314
"Nataraj R., Hollinger D., Liu M., Shah A.","36671846700;57216889466;57216706155;57216709318;","Disproportionate positive feedback facilitates sense of agency and performance for a reaching movement task with a virtual hand",2020,"PLoS ONE","15","5", e0233175,"","",,2,"10.1371/journal.pone.0233175","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085155142&doi=10.1371%2fjournal.pone.0233175&partnerID=40&md5=d0f10aa1f53c2d8bf07393fd564768a2","Movement Control Rehabilitation (MOCORE) Laboratory, Stevens Institute of Technology, Hoboken, NJ, United States; Department of Biomedical Engineering, Stevens Institute of Technology, Hoboken, NJ, United States","Nataraj, R., Movement Control Rehabilitation (MOCORE) Laboratory, Stevens Institute of Technology, Hoboken, NJ, United States, Department of Biomedical Engineering, Stevens Institute of Technology, Hoboken, NJ, United States; Hollinger, D., Movement Control Rehabilitation (MOCORE) Laboratory, Stevens Institute of Technology, Hoboken, NJ, United States, Department of Biomedical Engineering, Stevens Institute of Technology, Hoboken, NJ, United States; Liu, M., Movement Control Rehabilitation (MOCORE) Laboratory, Stevens Institute of Technology, Hoboken, NJ, United States, Department of Biomedical Engineering, Stevens Institute of Technology, Hoboken, NJ, United States; Shah, A., Movement Control Rehabilitation (MOCORE) Laboratory, Stevens Institute of Technology, Hoboken, NJ, United States, Department of Biomedical Engineering, Stevens Institute of Technology, Hoboken, NJ, United States","This study investigated the generalized effects of positive feedback (PF) versus negative feedback (NF) during training on performance and sense of agency for a reach-to-touch task with a virtual hand. Virtual reality (VR) is increasingly employed for rehabilitation after neuromuscular traumas such as stroke and spinal cord injury. However, VR methods still need to be optimized for greater effectiveness and engagement to increase rates of clinical retention. In this study, we observed that training with disproportionate PF subsequently produced greater reaching performance (minimizing path length) and greater agency (perception of control) than with disproportionate NF. During PF training, there was also progressive increase in agency, but conversely a decrease in performance. Thus, the increase in performance after training may not be due to positively bolstered learning, but rather priming higher confidence reflected in greater agency. Agency was positively measured as compression in perceived time-intervals between the action of touch to a sound consequence, as standard with intentional binding paradigms. Positive feedback desirably increased agency (∼180 msec) and reduced path length (1.8 cm) compared to negative feedback, which itself showed insignificant, or neutral, effects. Future investigations into optimizing virtual reality paradigms for neuromotor rehabilitation should consider agency as a driving factor for performance. These studies may serve to optimize how feedback is better presented with performance results for complex motor learning. Investigators should also ponder how personal characteristics, both cognitive and physical, may further affect sensitivity to feedback and the rate of neuromotor rehabilitation. © 2020 Nataraj et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"adult; Article; cohort analysis; controlled study; female; hand movement; human; human experiment; male; motor learning; motor performance; negative feedback; pilot study; positive feedback; task performance; virtual reality; young adult; clinical trial; hand; movement (physiology); pathophysiology; prospective study; touch; Adult; Female; Hand; Humans; Male; Movement; Prospective Studies; Touch; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85085155142
"Huang K., Shi Y., Zhao F., Zhang Z., Tu S.","57215859408;57218086060;57215859691;57215863076;36642846800;","Multiple instance deep learning for weakly-supervised visual object tracking",2020,"Signal Processing: Image Communication","84",, 115807,"","",,3,"10.1016/j.image.2020.115807","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082121044&doi=10.1016%2fj.image.2020.115807&partnerID=40&md5=0a806e348c327e0097cc931c5dff4a1b","BengBu University, Bengbu City, Anhui Province233000, China; Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China","Huang, K., BengBu University, Bengbu City, Anhui Province233000, China; Shi, Y., BengBu University, Bengbu City, Anhui Province233000, China; Zhao, F., BengBu University, Bengbu City, Anhui Province233000, China; Zhang, Z., BengBu University, Bengbu City, Anhui Province233000, China; Tu, S., Faculty of Information Technology, Beijing University of Technology, Beijing, 100124, China","Intelligently tracking objects with varied shapes, color, lighting conditions, and backgrounds is an extremely useful application in many HCI applications, such as human body motion capture, hand gesture recognition, and virtual reality (VR) games. However, accurately tracking different objects under uncontrolled environments is a tough challenge due to the possibly dynamic object parts, varied lighting conditions, and sophisticated backgrounds. In this work, we propose a novel semantically-aware object tracking framework, wherein the key is weakly-supervised learning paradigm that optimally transfers the video-level semantic tags into various regions. More specifically, give a set of training video clips, each of which is associated with multiple video-level semantic tags, we first propose a weakly-supervised learning algorithm to transfer the semantic tags into various video regions. The key is a MIL (Zhong et al., 2020) [1]-based manifold embedding algorithm that maps the entire video regions into a semantic space, wherein the video-level semantic tags are well encoded. Afterward, for each video region, we use the semantic feature combined with the appearance feature as its representation. We designed a multi-view learning algorithm to optimally fuse the above two types of features. Based on the fused feature, we learn a probabilistic Gaussian mixture model to predict the target probability of each candidate window, where the window with the maximal probability is output as the tracking result. Comprehensive comparative results on a challenging pedestrian tracking task as well as the human hand gesture recognition have demonstrated the effectiveness of our method. Moreover, visualized tracking results have shown that non-rigid objects with moderate occlusions can be well localized by our method. © 2020","Gaussian mixture model; Multi-view feature learning; Multiple instance learning (MIL); Object tracking; Weakly-supervised","Deep learning; Gaussian distribution; Learning algorithms; Learning systems; Lighting; Motion capture; Motion tracking; Object recognition; Palmprint recognition; Semantics; Supervised learning; Transfer learning; Virtual reality; Embedding algorithms; Feature learning; Gaussian Mixture Model; Hand-gesture recognition; Multiple-instance learning; Visual object tracking; Weakly supervised learning; Weakly-supervised; Object tracking",Article,"Final","",Scopus,2-s2.0-85082121044
"Tewari A., Fried O., Thies J., Sitzmann V., Lombardi S., Sunkavalli K., Martin-Brualla R., Simon T., Saragih J., Nießner M., Pandey R., Fanello S., Wetzstein G., Zhu J.-Y., Theobalt C., Agrawala M., Shechtman E., Goldman D.B., Zollhöfer M.","57200618272;56695318400;56312656700;57195995941;57204687314;23052896200;36028239400;36444916900;16178291100;35772871600;57204394554;36170215300;24462821700;56316642900;6507027272;57204250599;55924548800;13007964200;36245738500;","State of the Art on Neural Rendering",2020,"Computer Graphics Forum","39","2",,"701","727",,11,"10.1111/cgf.14022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090397976&doi=10.1111%2fcgf.14022&partnerID=40&md5=5441f08963176bece23beed58e80ccfb","MPI Informatics, Germany; Stanford University, United States; Technical University of Munich, Germany; Facebook Reality Labs, United States; Adobe Research, United States; Google Inc, United States","Tewari, A., MPI Informatics, Germany; Fried, O., Stanford University, United States; Thies, J., Technical University of Munich, Germany; Sitzmann, V., Stanford University, United States; Lombardi, S., Facebook Reality Labs, United States; Sunkavalli, K., Adobe Research, United States; Martin-Brualla, R., Google Inc, United States; Simon, T., Facebook Reality Labs, United States; Saragih, J., Facebook Reality Labs, United States; Nießner, M., Technical University of Munich, Germany; Pandey, R., Google Inc, United States; Fanello, S., Google Inc, United States; Wetzstein, G., Stanford University, United States; Zhu, J.-Y., Adobe Research, United States; Theobalt, C., MPI Informatics, Germany; Agrawala, M., Stanford University, United States; Shechtman, E., Adobe Research, United States; Goldman, D.B., Google Inc, United States; Zollhöfer, M., Facebook Reality Labs, United States","Efficient rendering of photo-realistic virtual worlds is a long standing effort of computer graphics. Modern graphics techniques have succeeded in synthesizing photo-realistic images from hand-crafted scene representations. However, the automatic generation of shape, materials, lighting, and other aspects of scenes remains a challenging problem that, if solved, would make photo-realistic computer graphics more widely accessible. Concurrently, progress in computer vision and machine learning have given rise to a new approach to image synthesis and editing, namely deep generative models. Neural rendering is a new and rapidly emerging field that combines generative machine learning techniques with physical knowledge from computer graphics, e.g., by the integration of differentiable rendering into network training. With a plethora of applications in computer graphics and vision, neural rendering is poised to become a new area in the graphics community, yet no survey of this emerging field exists. This state-of-the-art report summarizes the recent trends and applications of neural rendering. We focus on approaches that combine classic computer graphics techniques with deep generative models to obtain controllable and photorealistic outputs. Starting with an overview of the underlying computer graphics and machine learning concepts, we discuss critical aspects of neural rendering approaches. Specifically, our emphasis is on the type of control, i.e., how the control is provided, which parts of the pipeline are learned, explicit vs. implicit control, generalization, and stochastic vs. deterministic synthesis. The second half of this state-of-the-art report is focused on the many important use cases for the described algorithms such as novel view synthesis, semantic photo manipulation, facial and body reenactment, relighting, free-viewpoint video, and the creation of photo-realistic avatars for virtual and augmented reality telepresence. Finally, we conclude with a discussion of the social implications of such technology and investigate open research problems. © 2020 The Author(s) Computer Graphics Forum © 2020 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.",,"Augmented reality; Computer vision; Machine learning; Semantics; Stochastic systems; Virtual reality; Visual communication; Automatic Generation; Free-viewpoint video; Machine learning techniques; Novel view synthesis; Photorealistic images; Scene representation; Social implication; Virtual and augmented reality; Rendering (computer graphics)",Article,"Final","",Scopus,2-s2.0-85090397976
"Mozgai S., Hartholt A., Leeds A., Rizzo A.'.","56089503400;23008897300;56104019700;57213231655;","Iterative participatory design for VRET domain transfer: From combat exposure to military sexual trauma",2020,"Conference on Human Factors in Computing Systems - Proceedings",,, 3375219,"","",,,"10.1145/3334480.3375219","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090200167&doi=10.1145%2f3334480.3375219&partnerID=40&md5=ffd0c58b3c3d09f9639b2ca607688438","University of Southern California, Playa Vista, CA, United States","Mozgai, S., University of Southern California, Playa Vista, CA, United States; Hartholt, A., University of Southern California, Playa Vista, CA, United States; Leeds, A., University of Southern California, Playa Vista, CA, United States; Rizzo, A.'., University of Southern California, Playa Vista, CA, United States","This case study describes the expansion of the BRAVEMIND virtual reality exposure therapy (VRET) system from the domain of combat-related posttraumatic stress disorder (PTSD) to the domain of PTSD due to Military Sexual Trauma (MST). As VRET continues to demonstrate efficacy in treating PTSD across multiple trauma types and anxiety disorders, adapting existing systems and content to new domains while simultaneously maintaining clinical integrity is becoming a high priority. To develop BRAVEMIND-MST we engaged in an iterative participatory design process with psychologists, engineers, and artists. This first-person account of our collaborative development process focuses on three key areas (1) VR Environment, (2) User-Avatar State, and (3) Events, while detailing the challenges we encountered and lessons learned. This process culminated in eight design guidelines as a first-step in defining a VRET domain transfer methodology. © 2020 Owner/Author.","Military sexual trauma; Posttraumatic stress disorder; Virtual reality; Virtual reality exposure therapy","Human engineering; Iterative methods; Collaborative development process; Domain transfers; Existing systems; First person; Participatory design; Posttraumatic stress disorder; Virtual reality exposure therapies; Design",Conference Paper,"Final","",Scopus,2-s2.0-85090200167
"Brun D., George S., Gouin-Vallerand C.","57193572581;56911617500;24464753700;","Keycube: Text entry evaluation with a cubic device",2020,"Conference on Human Factors in Computing Systems - Proceedings",,, 3382837,"","",,,"10.1145/3334480.3382837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090240646&doi=10.1145%2f3334480.3382837&partnerID=40&md5=9f979c43b59c70ab8ef51b249597d339","Université TÉLUQ, Montreal, PQ, Canada; Le Mans University, Le Mans, France; Université de Sherbrooke, Sherbrooke, Canada","Brun, D., Université TÉLUQ, Montreal, PQ, Canada; George, S., Le Mans University, Le Mans, France; Gouin-Vallerand, C., Université de Sherbrooke, Sherbrooke, Canada","The keycube is a tangible cubic device including a text entry interface for different apparatuses such as augmented, mixed or virtual reality headsets, as well as smart TVs, desktop computers, laptops, tablets. The keycube comprises 80 keys equally disposed on 5 faces. In this paper we investigate keycube text entry performances and the potential typing skill transfer from traditional keyboard. Using prototype implementations, we conducted a user study comparing different cubic layouts and included a baseline from traditional keyboards. Experiments show that users are able to attain about 19 words per minute within one hundred minutes of practice with a QWERTY-based cubic layout, more than twice the speed of an unknown-based cubic layout with similar error rate, and about 30% of their speed with a traditional keyboard. © 2020 Owner/Author.","Cube; Device; Evaluation; Input speed; Keyboard; Text entry","Human engineering; Personal computers; Error rate; Prototype implementations; Skill transfer; Text entry; User study; Virtual-reality headsets; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85090240646
"Wentzel J., D'Eon G., Vogel D.","57188763196;57219111871;8435582600;","Improving Virtual Reality Ergonomics Through Reach-Bounded Non-Linear Input Amplification",2020,"Conference on Human Factors in Computing Systems - Proceedings",,, 3376687,"","",,4,"10.1145/3313831.3376687","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091311186&doi=10.1145%2f3313831.3376687&partnerID=40&md5=a2a6f22213bc5a2fc765a1f66b3d95ef","University of Waterloo, Waterloo, ON, Canada; Universiy of British Columbia, Vancouver, BC, Canada","Wentzel, J., University of Waterloo, Waterloo, ON, Canada; D'Eon, G., Universiy of British Columbia, Vancouver, BC, Canada; Vogel, D., University of Waterloo, Waterloo, ON, Canada","Input amplification enables easier movement in virtual reality (VR) for users with mobility issues or in confined spaces. However, current techniques either do not focus on maintaining feelings of body ownership, or are not applicable to general VR tasks. We investigate a general purpose non-linear transfer function that keeps the user's reach within reasonable bounds to maintain body ownership. The technique amplifies smaller movements from a user-definable neutral point into the expected larger movements using a configurable Hermite curve. Two experiments evaluate the approach. The first establishes that the technique has comparable performance to the state-of-the-art, increasing physical comfort while maintaining task performance and body ownership. The second explores the characteristics of the technique over a wide range of amplification levels. Using the combined results, design and implementation recommendations are provided with potential applications to related VR transfer functions. © 2020 ACM.","ergonomics; input re-mapping; interaction techniques","Ergonomics; Virtual reality; Confined space; Design and implementations; Hermite curves; Neutral points; Non linear; State of the art; Task performance; Transfer functions",Conference Paper,"Final","",Scopus,2-s2.0-85091311186
"Missaka R.F.B.G., Souto F.M.S., Albornoz N.C.D.A., Gaspar Carvalho da Silva F.T.B., Lavezzo M.M., Oyamada M.K., Hirata C.E., Yamamoto J.H.","55512528000;55510164700;57216276347;57216275117;16203255600;36055154000;7003793787;7402741930;","Self-Reported Quality of Life in Patients with Long-Standing Vogt-Koyanagi-Harada Disease",2020,"Ocular Immunology and Inflammation","28","3",,"409","420",,,"10.1080/09273948.2019.1595672","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083003409&doi=10.1080%2f09273948.2019.1595672&partnerID=40&md5=1c9db394da11611818ec131db36f42e3","Department of Ophthalmology, LIM-33, Hospital das Clínicas HCFMUSP, Faculdade de Medicina, Universidade de São Paulo, São Paulo, Brazil","Missaka, R.F.B.G., Department of Ophthalmology, LIM-33, Hospital das Clínicas HCFMUSP, Faculdade de Medicina, Universidade de São Paulo, São Paulo, Brazil; Souto, F.M.S., Department of Ophthalmology, LIM-33, Hospital das Clínicas HCFMUSP, Faculdade de Medicina, Universidade de São Paulo, São Paulo, Brazil; Albornoz, N.C.D.A., Department of Ophthalmology, LIM-33, Hospital das Clínicas HCFMUSP, Faculdade de Medicina, Universidade de São Paulo, São Paulo, Brazil; Gaspar Carvalho da Silva, F.T.B., Department of Ophthalmology, LIM-33, Hospital das Clínicas HCFMUSP, Faculdade de Medicina, Universidade de São Paulo, São Paulo, Brazil; Lavezzo, M.M., Department of Ophthalmology, LIM-33, Hospital das Clínicas HCFMUSP, Faculdade de Medicina, Universidade de São Paulo, São Paulo, Brazil; Oyamada, M.K., Department of Ophthalmology, LIM-33, Hospital das Clínicas HCFMUSP, Faculdade de Medicina, Universidade de São Paulo, São Paulo, Brazil; Hirata, C.E., Department of Ophthalmology, LIM-33, Hospital das Clínicas HCFMUSP, Faculdade de Medicina, Universidade de São Paulo, São Paulo, Brazil; Yamamoto, J.H., Department of Ophthalmology, LIM-33, Hospital das Clínicas HCFMUSP, Faculdade de Medicina, Universidade de São Paulo, São Paulo, Brazil","Purpose: To assess health-related (HR-) and vision-related (VR-) quality of life (QoL) in patients with long-standing Vogt-Koyanagi-Harada disease (VKHD). Methods: Cross-sectional study of 49 patients with disease duration ≥12 months followed at Uveitis Service, Universidade de São Paulo, BR, for at least 12 months. HR- and VR-QoL were evaluated using SF-36 and NEI VFQ-25 questionnaires, respectively. Demographic, clinical and visual function data were compared with questionnaire scores. Results: After generalized linear models, lower mensal household income was associated with lower scores in both questionnaires while unemployment was associated with SF-36 questionnaire only. Treatment with peri-/intraocular medications and ocular surgery were associated with higher scores on SF-36 questionnaire. Worse visual acuity (VA), ocular complications and no ocular surgery were related to lower scores on NEI VFQ-25 questionnaire. Conclusions: On HR- and VR-QoL questionnaires difficulties perceived by patients with long-standing VKHD were mainly associated with socio-economic aspects, VA, local treatment and ocular complications. © 2019, © 2019 Taylor & Francis Group, LLC.","Inflammation; quality of life; surveys and questionnaires; Uveitis; Uveomeningoencephalitic syndrome","corticosteroid; immunosuppressive agent; adolescent; age; aged; Article; clinical article; comorbidity; consultation; corticosteroid therapy; cross-sectional study; disease duration; educational status; electroretinogram; emotion; employment status; eye surgery; female; gender; household income; human; immunotherapy; local therapy; male; mental health; National Eye Institute Visual Function Questionnaire; pain; physical activity; quality of life; race; self report; Short Form 36; social interaction; socioeconomics; unemployment; vision; visual acuity; Vogt Koyanagi syndrome; adult; anterior eye segment; diagnostic imaging; electroretinography; eye fundus; fluorescence angiography; follow up; health status; health survey; meningoencephalitis; middle aged; ophthalmoscopy; optical coherence tomography; procedures; psychology; questionnaire; retrospective study; self report; severity of illness index; time factor; visual acuity; young adult; Adolescent; Adult; Aged; Anterior Eye Segment; Cross-Sectional Studies; Electroretinography; Female; Fluorescein Angiography; Follow-Up Studies; Fundus Oculi; Health Status; Health Surveys; Humans; Male; Middle Aged; Ophthalmoscopy; Quality of Life; Retrospective Studies; Self Report; Severity of Illness Index; Socioeconomic Factors; Surveys and Questionnaires; Time Factors; Tomography, Optical Coherence; Uveomeningoencephalitic Syndrome; Visual Acuity; Young Adult",Article,"Final","",Scopus,2-s2.0-85083003409
"Lin R.-C., Chiang S.-L., Heitkemper M.M., Weng S.-M., Lin C.-F., Yang F.-C., Lin C.-H.","57205327087;9942517800;56759647100;57215876000;57215873309;23989895200;56110341400;","Effectiveness of Early Rehabilitation Combined With Virtual Reality Training on Muscle Strength, Mood State, and Functional Status in Patients With Acute Stroke: A Randomized Controlled Trial",2020,"Worldviews on Evidence-Based Nursing","17","2",,"158","167",,1,"10.1111/wvn.12429","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082185856&doi=10.1111%2fwvn.12429&partnerID=40&md5=dec5c8ee13768f1cf67d7aff72953b7b","Department of Nursing, Tri-Service General Hospital, Taipei, Taiwan; Department of Physical Medicine and Rehabilitation, Tri-Service General Hospital, National Defense Medical Center, Taipei, Taiwan; Department of Biobehavioral Nursing and Health Informatics, University of Washington, Seattle, WA, United States; Division of Gastroenterology, University of Washington, Seattle, WA, United States; Center for Research on Management of Sleep Disturbances, University of Washington, Seattle, WA, United States; Department of Neurology, Tri-Service General Hospital, National Defense Medical Center, Taipei, Taiwan; School of Nursing, National Defense Medical Center, Taipei, Taiwan; Department of Nursing, Songshan Branch of Tri-Service General Hospital, Taipei, Taiwan","Lin, R.-C., Department of Nursing, Tri-Service General Hospital, Taipei, Taiwan; Chiang, S.-L., Department of Physical Medicine and Rehabilitation, Tri-Service General Hospital, National Defense Medical Center, Taipei, Taiwan; Heitkemper, M.M., Department of Biobehavioral Nursing and Health Informatics, University of Washington, Seattle, WA, United States, Division of Gastroenterology, University of Washington, Seattle, WA, United States, Center for Research on Management of Sleep Disturbances, University of Washington, Seattle, WA, United States; Weng, S.-M., Department of Nursing, Tri-Service General Hospital, Taipei, Taiwan; Lin, C.-F., Department of Nursing, Tri-Service General Hospital, Taipei, Taiwan; Yang, F.-C., Department of Neurology, Tri-Service General Hospital, National Defense Medical Center, Taipei, Taiwan; Lin, C.-H., School of Nursing, National Defense Medical Center, Taipei, Taiwan, Department of Nursing, Songshan Branch of Tri-Service General Hospital, Taipei, Taiwan","Background: Early rehabilitation has been shown to enhance functional outcomes. Whether the addition of virtual reality (VR) training could further improve muscle strength, mood state, and functional status for patients with acute stroke is unknown. Aims: To investigate the effectiveness of VR training on muscle strength, mood state (depression, anxiety), and functional status in patients following acute stroke. Methods: A randomized controlled trial was conducted. Patients with acute ischemic stroke (N = 152) were selected and randomly assigned with a 1:3 randomization ratio to either experimental group (EG) or comparison group (CG). Both groups received early rehabilitation. The EG received an extra 5 days of VR training (15 min of time, two times a day), started 24 hr to 3 days poststroke. Muscle strength, mood state, and functional status were collected at admission and at the day of discharge. Generalized estimating equations were applied to examine the intervention effects. Results: A total of 143 participants (94%) completed the study, and 145 were included in the intention-to-treat analysis. Participants in the EG reported increased muscle strength of upper and lower limbs in both affected and unaffected sides, decreased depression and anxiety, and increased functional status at discharge. When the group–time interaction was examined, the EG had greater increased upper limb muscle strength of the unaffected side (ß = 0.34, p <.001) and decreased depression and anxiety scores (ß = −2.31, p =.011; ß = −1.63, p =.047) at discharge compared with the CG. However, there was no difference in the functional status change scores from baseline between EG and CG. Linking Evidence to Action: A poststroke program that includes both early rehabilitation and VR training has greater benefit in relation to mood state and muscle strength at discharge than early rehabilitation alone. Therefore, an early physical rehabilitation program that includes VR training for acute stroke inpatients should be considered for implementation in clinical settings. © 2020 Sigma Theta Tau International","anxiety; depression; early rehabilitation; functional status; mood state; muscle strength; stroke; virtual reality training","affect; aged; cerebrovascular accident; complication; controlled study; convalescence; female; functional status; human; male; middle aged; muscle strength; pathophysiology; physiology; procedures; randomized controlled trial; stroke rehabilitation; time factor; treatment outcome; virtual reality exposure therapy; Affect; Aged; Female; Functional Status; Humans; Male; Middle Aged; Muscle Strength; Recovery of Function; Stroke; Stroke Rehabilitation; Time Factors; Treatment Outcome; Virtual Reality Exposure Therapy",Article,"Final","",Scopus,2-s2.0-85082185856
"Pallavicini F., Pepe A.","6701879031;55744410200;","Virtual reality games and the role of body involvement in enhancing positive emotions and decreasing anxiety: Within-subjects pilot study",2020,"JMIR Serious Games","8","2", e15635,"","",,1,"10.2196/15635","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097499071&doi=10.2196%2f15635&partnerID=40&md5=c7fbb876de190177fb7d8f4c6dfacc7b","Department of Human Sciences for Education, University of Milano-Bicocca, Milan, Italy","Pallavicini, F., Department of Human Sciences for Education, University of Milano-Bicocca, Milan, Italy; Pepe, A., Department of Human Sciences for Education, University of Milano-Bicocca, Milan, Italy","Background: In the last few years, the introduction of immersive technologies, especially virtual reality, into the gaming market has dramatically altered the traditional concept of video games. Given the unique features of virtual reality in terms of interaction and its ability to completely immerse the individual into the game, this technology should increase the propensity for video games to effectively elicit positive emotions and decrease negative emotions and anxiety in the players. However, to date, few studies have investigated the ability of virtual reality games to induce positive emotions, and the possible effect of this new type of video game in diminishing negative emotions and anxiety has not yet been tested. Furthermore, given the critical role of body movement in individuals’ well-being and in emotional responses to video games, it seems critical to investigate how body involvement can be exploited to modulate the psychological benefits of virtual reality games in terms of enhancing players’ positive emotions and decreasing negative emotions and anxiety. Objective: This within-subjects study aimed to explore the ability of commercial virtual reality games to induce positive emotions and diminish negative emotions and state anxiety of the players, investigating the effects of the level of body involvement requested by the game (ie, high vs low). Methods: A total of 36 young adults played a low body-involvement (ie, Fruit Ninja VR) and a high body-involvement (ie, Audioshield) video game in virtual reality. The Visual Analogue Scale (VAS) and the State-Trait Anxiety Inventory, Form-Y1 (STAI-Y1) were used to assess positive and negative emotions and state anxiety. Results: Results of the generalized linear model (GLM) for repeated-measures multivariate analysis of variance (MANOVA) revealed a statistically significant increase in the intensity of happiness (P<.001) and surprise (P=.003) and, in parallel, a significant decrease in fear (P=.01) and sadness (P<.001) reported by the users. Regarding the ability to improve anxiety in the players, the results showed a significant decrease in perceived state anxiety after game play, assessed with both the STAI-Y1 (P=.003) and the VAS-anxiety (P=.002). Finally, the results of the GLM MANOVA showed a greater efficacy of the high body-involvement game (ie, Audioshield) compared to the low body-involvement game (ie, Fruit Ninja VR), both for eliciting positive emotions (happiness, P<.001; and surprise, P=.01) and in reducing negative emotions (fear, P=.05; and sadness, P=.05) and state anxiety, as measured by the STAI-Y1 (P=.05). Conclusions: The two main principal findings of this study are as follows: (1) virtual reality video games appear to be effective tools to elicit positive emotions and to decrease negative emotions and state anxiety in individuals and (2) the level of body involvement of the virtual video game has an important effect in determining the ability of the game to improve positive emotions and decrease negative emotions and state anxiety of the players. © 2020 JMIR Publications. All Rights Reserved.","Anxiety; Emotions; Positive emotions; State anxiety; Video games; Virtual reality; Virtual reality gaming",,Article,"Final","",Scopus,2-s2.0-85097499071
"Lohre R., Bois A.J., Athwal G.S., Goel D.P.","57215864647;55259753500;6603148899;34881653400;","Improved Complex Skill Acquisition by Immersive Virtual Reality Training: A Randomized Controlled Trial",2020,"Journal of Bone and Joint Surgery - American Volume","102","6",,"","",,10,"10.2106/JBJS.19.00982","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082147105&doi=10.2106%2fJBJS.19.00982&partnerID=40&md5=4e329e9a54ded568ebd592911773531d","Department of Orthopaedics, University of British Columbia, Vancouver, BC, Canada; Section of Orthopaedic Surgery, Department of Surgery, University of Calgary, Calgary, AB, Canada; Roth McFarlane Hand and Upper Limb Center, Schulich School of Medicine and Dentistry, Western University, London, ON, Canada","Lohre, R., Department of Orthopaedics, University of British Columbia, Vancouver, BC, Canada; Bois, A.J., Section of Orthopaedic Surgery, Department of Surgery, University of Calgary, Calgary, AB, Canada; Athwal, G.S., Roth McFarlane Hand and Upper Limb Center, Schulich School of Medicine and Dentistry, Western University, London, ON, Canada; Goel, D.P., Department of Orthopaedics, University of British Columbia, Vancouver, BC, Canada","Background:There has been limited literature on immersive virtual reality (VR) simulation in orthopaedic education. The purpose of this multicenter, blinded, randomized controlled trial was to determine the validity and efficacy of immersive VR training in orthopaedic resident education.Methods:Nineteen senior orthopaedic residents (resident group) and 7 consultant shoulder arthroplasty surgeons (expert group) participated in the trial comparing immersive VR with traditional learning using a technical journal article as a control. The examined task focused on achieving optimal glenoid exposure. Participants completed demographic questionnaires, knowledge tests, and a glenoid exposure on fresh-frozen cadavers while being examined by blinded shoulder arthroplasty surgeons. Training superiority was determined by the outcome measures of the Objective Structured Assessment of Technical Skills (OSATS) score, a developed laboratory metric, verbal answers, and time to task completion.Results:Immersive VR had greater realism and was superior in teaching glenoid exposure than the control (p = 0.01). The expert group outperformed the resident group on knowledge testing (p = 0.04). The immersive VR group completed the learning activity and knowledge tests significantly faster (p < 0.001) at a mean time (and standard deviation) of 11 ± 3 minutes than the control group at 20 ± 4 minutes, performing 3 to 5 VR repeats for a reduction in learning time of 570%. The immersive VR group completed the glenoid exposure significantly faster (p = 0.04) at a mean time of 14 ± 7 minutes than the control group at 21 ± 6 minutes, with superior OSATS instrument handling scores (p = 0.03). The immersive VR group scored equivalently in surprise verbal scores (p = 0.85) and written knowledge scores (p = 1.0).Conclusions:Immersive VR demonstrated substantially improved translational technical and nontechnical skills acquisition over traditional learning in senior orthopaedic residents. Additionally, the results demonstrate the face, content, construct, and transfer validity for immersive VR.Clinical Relevance:This adequately powered, randomized controlled trial demonstrated how an immersive VR system can efficiently (570%) teach a complex surgical procedure and also demonstrate improved translational skill and knowledge acquisition when compared with a traditional learning method. © 2020 Lippincott Williams and Wilkins. All rights reserved.",,"Article; cadaver; cohort analysis; comparative study; controlled study; demography; glenoid cavity; human; medical expert; multicenter study; Objective Structured Assessment of Technical Skills score; orthopedic specialist; orthopedic surgeon; orthopedics; priority journal; professional knowledge; questionnaire; randomized controlled trial; residency education; scientific literature; scoring system; shoulder arthroplasty; virtual reality; work experience; Canada; clinical competence; clinical trial; education; medical education; procedures; reproducibility; shoulder replacement; simulation training; single blind procedure; Arthroplasty, Replacement, Shoulder; Canada; Clinical Competence; Humans; Internship and Residency; Orthopedics; Reproducibility of Results; Simulation Training; Single-Blind Method; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85082147105
"Logishetty K., Gofton W.T., Rudran B., Beaulé P.E., Cobb J.P.","35574197100;6508101071;57205023949;7003898709;7202728836;","Fully Immersive Virtual Reality for Total Hip Arthroplasty: Objective Measurement of Skills and Transfer of Visuospatial Performance after a Competency-Based Simulation Curriculum",2020,"Journal of Bone and Joint Surgery - American Volume","102","6", e27,"","",,4,"10.2106/JBJS.19.00629","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082148057&doi=10.2106%2fJBJS.19.00629&partnerID=40&md5=ce3c4083d57c9a883f9025c6bef05f48","MSk Lab, Department of Surgery and Cancer, Imperial College, London, United Kingdom; Division of Orthopaedic Surgery, Ottawa Hospital, Ottawa, ON, Canada","Logishetty, K., MSk Lab, Department of Surgery and Cancer, Imperial College, London, United Kingdom; Gofton, W.T., Division of Orthopaedic Surgery, Ottawa Hospital, Ottawa, ON, Canada; Rudran, B., MSk Lab, Department of Surgery and Cancer, Imperial College, London, United Kingdom; Beaulé, P.E., Division of Orthopaedic Surgery, Ottawa Hospital, Ottawa, ON, Canada; Cobb, J.P., MSk Lab, Department of Surgery and Cancer, Imperial College, London, United Kingdom","Background:Fully immersive virtual reality (VR) uses headsets to situate a surgeon in a virtual operating room to perform open surgical procedures. The aims of this study were to determine (1) if a VR curriculum for training residents to perform anterior approach total hip replacement (AA-THR) was feasible, (2) if VR enabled residents' performance to be measured objectively, and (3) if cognitive and motor skills that were learned with use of VR were transferred to the physical world.Methods:The performance of 32 orthopaedic residents (surgical postgraduate years [PGY]-1 through 4) with no prior experience with AA-THR was measured during 5 consecutive VR training and assessment sessions. Outcome measures were related to procedural sequence, efficiency of movement, duration of surgery, and visuospatial precision in acetabular component positioning and femoral neck osteotomy, and were compared with the performance of 4 expert hip surgeons to establish competency-based criteria. Pretraining and post-training assessments on dry bone models were used to assess the transfer of visuospatial skills from VR to the physical world.Results:Residents progressively developed surgical skills in VR on a learning curve through repeated practice, plateauing, on average, after 4 sessions (4.1 ± 0.6 hours); they reached expert VR levels for 9 of 10 metrics (except femoral osteotomy angle). Procedural errors were reduced by 79%, assistive prompts were reduced by 70%, and procedural duration was reduced by 28%. Dominant and nondominant hand movements were reduced by 35% and 36%, respectively, and head movement was reduced by 44%. Femoral osteotomy was performed more accurately, and acetabular implant orientation improved in VR assessments. In the physical world assessments, experts were more accurate than residents prior to simulation, but were matched by residents after simulation for all of the metrics except femoral osteotomy angle. The residents who performed best in VR were the most accurate in the physical world, while 2 residents were unable to achieve competence despite sustained practice.Conclusions:For novice surgeons learning AA-THR skills, fully immersive VR technology can objectively measure progress in the acquisition of surgical skills as measured by procedural sequence, efficiency of movement, and visuospatial accuracy. Skills learned in this environment are transferred to the physical environment. © 2020 Lippincott Williams and Wilkins. All rights reserved.",,"adult; Article; clinical practice; cognition; depth perception; education program; female; femur osteotomy; hand movement; head movement; human; learning curve; male; motor performance; normal human; operation duration; orthopedic surgeon; outcome assessment; postgraduate education; priority journal; professional competence; residency education; resident; simulation; surgical approach; technology; total hip replacement; virtual reality; anatomic model; Canada; clinical competence; curriculum; economics; education; hip replacement; medical education; orthopedics; procedures; psychomotor performance; simulation training; single blind procedure; Adult; Arthroplasty, Replacement, Hip; Canada; Clinical Competence; Competency-Based Education; Female; Humans; Internship and Residency; Learning Curve; Male; Models, Anatomic; Orthopedics; Psychomotor Performance; Simulation Training; Single-Blind Method; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85082148057
"Maier M., Ballester B.R., Leiva Bañuelos N., Duarte Oller E., Verschure P.F.M.J.","56185676700;55672044700;57215574774;6504204489;7006315557;","Adaptive conjunctive cognitive training (ACCT) in virtual reality for chronic stroke patients: A randomized controlled pilot trial",2020,"Journal of NeuroEngineering and Rehabilitation","17","1", 42,"","",,3,"10.1186/s12984-020-0652-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081272083&doi=10.1186%2fs12984-020-0652-3&partnerID=40&md5=7a4ff1f4ee8fa215578412c45e46f474","Laboratory of Synthetic, Perceptive, Emotive and Cognitive Systems (SPECS), Institute for Bioengineering of Catalonia (IBEC), Barcelona Institute of Science and Technology, Av. d'Eduard Maristany 10-14, Barcelona, 08930, Spain; Rehabilitation Research Group, Institut Hospital Del Mar d'Investigacions Mèdiques (IMIM), Phys. Med. and Rehab. Department Parc de Salut Mar (Hospital Del Mar, Hospital de l'Esperanca), Barcelona, Spain; Institució Catalana de Recerca i Estudis Avançats (ICREA), Barcelona, Spain","Maier, M., Laboratory of Synthetic, Perceptive, Emotive and Cognitive Systems (SPECS), Institute for Bioengineering of Catalonia (IBEC), Barcelona Institute of Science and Technology, Av. d'Eduard Maristany 10-14, Barcelona, 08930, Spain; Ballester, B.R., Laboratory of Synthetic, Perceptive, Emotive and Cognitive Systems (SPECS), Institute for Bioengineering of Catalonia (IBEC), Barcelona Institute of Science and Technology, Av. d'Eduard Maristany 10-14, Barcelona, 08930, Spain; Leiva Bañuelos, N., Rehabilitation Research Group, Institut Hospital Del Mar d'Investigacions Mèdiques (IMIM), Phys. Med. and Rehab. Department Parc de Salut Mar (Hospital Del Mar, Hospital de l'Esperanca), Barcelona, Spain; Duarte Oller, E., Rehabilitation Research Group, Institut Hospital Del Mar d'Investigacions Mèdiques (IMIM), Phys. Med. and Rehab. Department Parc de Salut Mar (Hospital Del Mar, Hospital de l'Esperanca), Barcelona, Spain; Verschure, P.F.M.J., Laboratory of Synthetic, Perceptive, Emotive and Cognitive Systems (SPECS), Institute for Bioengineering of Catalonia (IBEC), Barcelona Institute of Science and Technology, Av. d'Eduard Maristany 10-14, Barcelona, 08930, Spain, Institució Catalana de Recerca i Estudis Avançats (ICREA), Barcelona, Spain","Background: Current evidence for the effectiveness of post-stroke cognitive rehabilitation is weak, possibly due to two reasons. First, patients typically express cognitive deficits in several domains. Therapies focusing on specific cognitive deficits might not address their interrelated neurological nature. Second, co-occurring psychological problems are often neglected or not diagnosed, although post-stroke depression is common and related to cognitive deficits. This pilot trial aims to test a rehabilitation program in virtual reality that trains various cognitive domains in conjunction, by adapting to the patient's disability and while investigating the influence of comorbidities. Methods: Thirty community-dwelling stroke patients at the chronic stage and suffering from cognitive impairment performed 30 min of daily training for 6 weeks. The experimental group followed, so called, adaptive conjunctive cognitive training (ACCT) using RGS, whereas the control group solved standard cognitive tasks at home for an equivalent amount of time. A comprehensive test battery covering executive function, spatial awareness, attention, and memory as well as independence, depression, and motor impairment was applied at baseline, at 6 weeks and 18-weeks follow-up. Results: At baseline, 75% of our sample had an impairment in more than one cognitive domain. The experimental group showed improvements in attention (χ F 2 $$ {\chi}_F^2 $$ (2) = 9.57, p <.01), spatial awareness (χ F 2 $$ {\chi}_F^2 $$ (2) = 11.23, p <.01) and generalized cognitive functioning (χ F 2 $$ {\chi}_F^2 $$ (2) = 15.5, p <.001). No significant change was seen in the executive function and memory domain. For the control group, no significant change over time was found. Further, they worsened in their depression level after treatment (T = 45, r =.72, p <.01) but returned to baseline at follow-up. The experimental group displayed a lower level of depression than the control group after treatment (Ws = 81.5, z =-2.76, r =-.60, p <.01) and (Ws = 92, z =-2.03, r =-.44, p <.05). Conclusions: ACCT positively influences attention and spatial awareness, as well as depressive mood in chronic stroke patients. Trial registration: The trial was registered prospectively at ClinicalTrials.gov (NCT02816008) on June 21, 2016. © 2020 The Author(s).","Cognitive deficits; Depression; Rehabilitation; Stroke; Virtual reality","adaptive conjunctive cognitive training; adult; aged; Article; attention; awareness; cerebrovascular accident; clinical article; cognition; cognitive defect; cognitive rehabilitation; community living; comorbidity; controlled study; depression; disability; disease classification; executive function; female; follow up; health program; human; male; memory; motor dysfunction; pilot study; priority journal; randomized controlled trial; task performance; virtual reality; cerebrovascular accident; cognitive defect; complication; middle aged; procedures; stroke rehabilitation; Aged; Cognitive Dysfunction; Female; Humans; Male; Middle Aged; Pilot Projects; Stroke; Stroke Rehabilitation; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85081272083
"Xiao S., Ye X., Guo Y., Gao B., Long J.","57216950659;57216952687;57214783652;57054714700;36094130900;","Transfer of Coordination Skill to the Unpracticed Hand in Immersive Environments",2020,"Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2020",,, 9089455,"258","265",,,"10.1109/VR46266.2020.1580775954370","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085471846&doi=10.1109%2fVR46266.2020.1580775954370&partnerID=40&md5=e436207a769c58353b6c079248db0c5a","Jinan University, College of Information Science and Technology, Guangzhou, 510640, China","Xiao, S., Jinan University, College of Information Science and Technology, Guangzhou, 510640, China; Ye, X., Jinan University, College of Information Science and Technology, Guangzhou, 510640, China; Guo, Y., Jinan University, College of Information Science and Technology, Guangzhou, 510640, China; Gao, B., Jinan University, College of Information Science and Technology, Guangzhou, 510640, China; Long, J., Jinan University, College of Information Science and Technology, Guangzhou, 510640, China","Physical practice with one hand results in performance gains of the other (un-practiced) hand in a unilateral motor task. Yet how it induces performance gains of interlimb coordination in the bimanual movements between trained limb and the opposite, untrained limb is unclear. The present study designed a game-like interactive system for physical practice, in which an avatar's hands could be controlled itself or by the subject during a bimanual movement task in an immersive virtual reality environment. Participants practiced with the bimanual task by simultaneously drawing non-symmetric three-sided squares (e.g., U and C) to learn limb coordination with the following training strategies: (1) performing and seeing a bimanual task (BH-BH); (2) performing a unimanual task with right hand and seeing a bimanual action (RH-BH); (3) not performing a task but seeing a bimanual action (noH-BH); (4) performing and seeing a unimanual task (RH-RH). We found that the learning performance was better after BH-BH and RH-BH compared with other training strategies. In addition, we examined the effects of virtual hand representations on the learning performance after RH-BH. We found that the performance after training was increased with the realism level of virtual hands. These findings suggest that the proposed approach of RH-BH with realistic virtual hand would result in transfer of coordination skill to the unpracticed hand, which puts forward a new approach for learning and rehabilitation of coordination skill in patients with unilateral motor deficit in immersive environments. © 2020 IEEE.","Avatar hands; bimanual movement; coordination skill; virtual reality","Patient rehabilitation; Transfer learning; User interfaces; Bimanual movement; Co-ordination skills; Immersive environment; Immersive virtual reality; Interactive system; Learning performance; Performance Gain; Training strategy; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85085471846
"Tsuchiya K., Koizumi N.","57205476444;36117906000;","An Optical Design for Avatar-User Co-axial Viewpoint Telepresence",2020,"Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2020",,, 9089599,"108","116",,1,"10.1109/VR46266.2020.1581039456803","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085502301&doi=10.1109%2fVR46266.2020.1581039456803&partnerID=40&md5=c03cd4ec5a2d9c8038db72edce4b185e","University of Electro-Communications, Japan; University of Electro-Communications, JST PRESTO, Japan","Tsuchiya, K., University of Electro-Communications, Japan; Koizumi, N., University of Electro-Communications, JST PRESTO, Japan","We propose a mid-air image system for telepresence. Virtual reality (VR) social networks enable users to interact with each other through CG avatars and choose their appearances freely. However, this is only possible in VR space. We propose a system that takes the avatar from VR space to real space with the help of mid-air imaging technology. In this system, the micro-mirror array plates (MMAPs) display the mid-air image and optically transfer the camera viewpoint to capture users from the mid-air image position. Luminance measurement and modulation transfer function (MTF) measurement were performed to evaluate the image capturing performance of this system. As a result, we found that the MMAPs ccause a decrease in brightness and an increase in blur. In addition, the stray light generated by the MMAPs was in the captured video. We also confirmed that face detection works correctly on the captured video by adjusting the ISO sensitivity of the camera. Furthermore, we designed an application for telepresence called Levitar, which uses a dual camera to output the captured video to the HMD and controls the camera gaze direction. © 2020 IEEE.","Displays and imagers; Human computer interaction (HCI); Human-centered computing; Interaction devices","Cameras; Face recognition; Imaging techniques; Luminance; Optical design; Stray light; User interfaces; Visual communication; Gaze direction; Image capturing; Image position; Image systems; Imaging technology; Luminance measurements; Micromirror array; Modulation transfer function measurements; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85085502301
"Kalkofen D., Mori S., Ladinig T., Daling L., Abdelrazeq A., Ebner M., Ortega M., Feiel S., Gabl S., Shepel T., Tibbett J., Laine T.H., Hitch M., Drebenstedt C., Moser P.","24822405100;57216934724;57191445046;57207299893;57209209532;56903912500;57216935226;57201155199;57216938368;56418693800;57189056968;57217452784;26027504900;35614644400;7102945424;","Tools for Teaching Mining Students in Virtual Reality based on 360° Video Experiences",2020,"Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VRW 2020",,, 9090430,"455","459",,1,"10.1109/VRW50115.2020.00096","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085391640&doi=10.1109%2fVRW50115.2020.00096&partnerID=40&md5=dae08611357938adaf178d8e5b5c711c","Graz University of Technology, Austria; Montanuniversit at Leoben, Austria; RWTH Aachen University, Germany; Pilot; Tallinn University of Technology, Estonia; TU Bergakademie Freiberg, Germany; Lulea University of Technology, Sweden","Kalkofen, D., Graz University of Technology, Austria; Mori, S., Graz University of Technology, Austria; Ladinig, T., Montanuniversit at Leoben, Austria; Daling, L., RWTH Aachen University, Germany; Abdelrazeq, A., RWTH Aachen University, Germany; Ebner, M., Graz University of Technology, Austria; Ortega, M., Montanuniversit at Leoben, Austria; Feiel, S., Montanuniversit at Leoben, Austria; Gabl, S., Graz University of Technology, Austria; Shepel, T., TU Bergakademie Freiberg, Germany; Tibbett, J., Pilot; Laine, T.H., Lulea University of Technology, Sweden; Hitch, M., Tallinn University of Technology, Estonia; Drebenstedt, C., TU Bergakademie Freiberg, Germany; Moser, P., Montanuniversit at Leoben, Austria","In recent years, Virtual Reality (VR) technology has found their way into higher education. Its power lays in its ability to provide immersive three-dimensional (3D) experiences that help conveying educational content whilst providing rich interaction possibilities. Especially in mining engineering education, VR has high potential to reshape the provided learning content. Field trips, i.e. mine visits, are an integral part of the education and necessary to transfer knowledge to students. However, field trips are time and cost intensive and mines often have tight entry regulations. As a result, the number of field trips is limited. VR-based field trips offer a considerable alternative presupposed they replicate the complex mining environment realistically. In addition, VR mines have the advantage of taking students close to events (e.g. explosions) that are impossible to demonstrate in a real mine. However, generating realistic 3D content for VR still involves complex, and thus time consuming tasks. Therefore, we present the design of a VR Framework for teaching mining students based on 360° video data, its evaluation in three different lectures, and its extension based on the feedback we received from students and teachers from four different universities. © 2020 IEEE.",,"E-learning; Mining engineering; Students; User interfaces; Cost-intensive; Educational contents; Higher education; ITS evaluation; Learning contents; Mining environments; Threedimensional (3-d); Time-consuming tasks; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85085391640
"Jakl A., Lienhart A.-M., Baumann C., Jalaeefar A., Schlager A., Schoffer L., Bruckner F.","35242591600;57216955058;57216949185;57216948882;57216950067;57205459948;56562723100;","Enlightening Patients with Augmented Reality",2020,"Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2020",,, 9089476,"195","203",,1,"10.1109/VR46266.2020.1581532258804","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085526448&doi=10.1109%2fVR46266.2020.1581532258804&partnerID=40&md5=4538f04908530fbf0229b5588000429e","University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria","Jakl, A., University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria; Lienhart, A.-M., University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria; Baumann, C., University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria; Jalaeefar, A., University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria; Schlager, A., University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria; Schoffer, L., University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria; Bruckner, F., University of Applied Sciences, Institute of Creative\Media/Technologies, St. Pölten, Austria","Enlightening Patients with Augmented Reality (EPAR) enhances patient education with new possibilities offered by Augmented Reality. Medical procedures are becoming increasingly complex and printed information sheets are often hard to understand for patients. EPAR developed an augmented reality prototype that helps patients with strabismus to better understand the processes of examinations and eye surgeries. By means of interactive storytelling, three identified target groups based on user personas were able to adjust the level of information transfer based on their interests. We performed a 2-phase evaluation with a total of 24 test subjects, resulting in a final system usability score of 80.0. For interaction prompts concerning virtual 3D content, visual highlights were considered to be sufficient. Overall, participants thought that an AR system as a complementary tool could lead to a better understanding of medical procedures. © 2020 IEEE.","concepts and paradigms Human-centered computing; Human-centered computing; Interaction design theory; Interface design prototyping Human-centered computing; Mixed / augmented reality Human-centered computing; Usability testing","Augmented reality; User interfaces; Complementary tools; Information sheets; Information transfers; Interactive storytelling; Medical procedures; Patient education; System usability; Target group; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85085526448
"DiCesare C.A., Kiefer A.W., Bonnette S., Myer G.D.","55620685100;35316086800;55004035700;6701852696;","High-Risk Lower-Extremity Biomechanics Evaluated in Simulated Soccer-Specific Virtual Environments",2020,"Journal of sport rehabilitation","29","3",,"294","300",,2,"10.1123/jsr.2018-0237","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101728285&doi=10.1123%2fjsr.2018-0237&partnerID=40&md5=49dc941cbee3deb809250b6b745e0bc7",,"DiCesare, C.A.; Kiefer, A.W.; Bonnette, S.; Myer, G.D.","CONTEXT: Laboratory-based biomechanical analyses of sport-relevant movements such as landing and cutting have classically been used to quantify kinematic and kinetic factors in the context of injury risk, which are then used to inform targeted interventions designed to improve risky movement patterns during sport. However, the noncontextual nature of standard assessments presents challenges for assessing sport-relevant skill transfer. OBJECTIVE: To examine injury-risk biomechanical differences exhibited by athletes during a jump-landing task performed as part of both a standard biomechanical assessment and a simulated, sport-specific virtual reality (VR)-based assessment. DESIGN: Observational study. SETTING: Medical center laboratory. PARTICIPANTS: Twenty-two female adolescent soccer athletes (age = 16.0 [1.4] y, height = 165.6 [4.9] cm, and weight = 60.2 [11.4] kg). INTERVENTIONS: The landing performance was analyzed for a drop vertical jump task and a VR-based, soccer-specific corner-kick scenario in which the athletes were required to jump to head a virtual soccer ball and land. MAIN OUTCOME MEASURES: Hip, knee, and ankle joint kinematic differences in the frontal and sagittal planes. RESULTS: Athletes exhibited reduced hip and ankle flexion, hip abduction, and frontal plane ankle excursion during landing in realistic sport scenario compared with the standard drop vertical jump task. CONCLUSION: VR-based assessments can provide a sport-specific context in which to assess biomechanical deficits that predispose athletes for lower-extremity injury and offer a promising approach to better evaluate skill transfer to sport that can guide future injury prevention efforts.","injury risk; sport biomechanics; virtual reality",,Article,"Final","",Scopus,2-s2.0-85101728285
"Gamito P., Oliveira J., Alves C., Santos N., Coelho C., Brito R.","35217715700;35243297300;57194008447;57214563802;57194009326;23472136800;","Virtual Reality-Based Cognitive Stimulation to Improve Cognitive Functioning in Community Elderly: A Controlled Study",2020,"Cyberpsychology, Behavior, and Social Networking","23","3",,"150","156",,4,"10.1089/cyber.2019.0271","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081623044&doi=10.1089%2fcyber.2019.0271&partnerID=40&md5=78337838ca3b1c5b0f0cbd40f673327a","HEI-Lab: Digital Human-Environment Interaction Lab, University Lusophone of Humanities and Technologies, Lisboa, Portugal; Junta de Freguesia de Benfica, Lisboa, Portugal","Gamito, P., HEI-Lab: Digital Human-Environment Interaction Lab, University Lusophone of Humanities and Technologies, Lisboa, Portugal; Oliveira, J., HEI-Lab: Digital Human-Environment Interaction Lab, University Lusophone of Humanities and Technologies, Lisboa, Portugal; Alves, C., Junta de Freguesia de Benfica, Lisboa, Portugal; Santos, N., Junta de Freguesia de Benfica, Lisboa, Portugal; Coelho, C., Junta de Freguesia de Benfica, Lisboa, Portugal; Brito, R., HEI-Lab: Digital Human-Environment Interaction Lab, University Lusophone of Humanities and Technologies, Lisboa, Portugal","The advantages of using naturalistic virtual reality (VR) environments based on everyday life tasks for cognitive intervention in the elderly are not yet well understood. The literature suggests that the similarity of such exercises with real life activities may improve generalizability by extending the transfer of gains of training to everyday living. This study aimed to investigate the gains associated with this ecologically-oriented virtual reality cognitive stimulation (VR-CS) versus standard cognitive stimulation in the elderly. Forty-three healthy older adults were divided into two groups: an experimental group underwent a VR-based cognitive stimulation and an active control group underwent a paper-and-pencil cognitive stimulation. The outcomes assessed at the pre-treatment and posttreatment assessment consisted in well-established tests for cognitive and executive functioning, depression, subjective well-being, and functionality. The results showed positive outcomes on dimensions of general cognition, executive functioning, attention, and visual memory in the group that underwent VR-CS. Improvements in executive functioning in this group was supported by consistent evidence of increases in attention abilities but little evidence of increases in memory abilities. Both effects may have contributed to improvements in general cognition. Further studies are needed to test whether these effects may extend to well-being and functionality in cognitively impaired older adults. Copyright © 2020 Mary Ann Liebert, Inc.","cognitive stimulation; daily life activities; elderly; serious games","aged; article; attention; clinical article; controlled study; daily life activity; executive function; female; human; human experiment; male; virtual reality; visual memory; wellbeing; cognition; daily life activity; health promotion; physiology; psychologic test; very elderly; Activities of Daily Living; Aged; Aged, 80 and over; Cognition; Executive Function; Female; Health Promotion; Humans; Male; Psychological Tests; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85081623044
"Gainer S., Eadara S., Haskins J., Huse W., Zhu B., Boyd B., Laird C., Farantatos J.J., Jerald J.","57210917259;57216937631;57210912110;57210916941;57216935372;57210914790;57210912932;57216935098;6507201978;","A Customized Input Device for Simulating the Detection of Hazardous Materials",2020,"Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VRW 2020",,, 9090446,"7","12",,1,"10.1109/VRW50115.2020.0-267","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085388847&doi=10.1109%2fVRW50115.2020.0-267&partnerID=40&md5=39fb1b83ac3d65296b85cb03779968a6","NextGen Interactions","Gainer, S., NextGen Interactions; Eadara, S., NextGen Interactions; Haskins, J., NextGen Interactions; Huse, W., NextGen Interactions; Zhu, B., NextGen Interactions; Boyd, B., NextGen Interactions; Laird, C., NextGen Interactions; Farantatos, J.J., NextGen Interactions; Jerald, J., NextGen Interactions","Although consumer VR controllers work well for gaming and general VR usage, they are not necessarily appropriate for specific professional needs. Instead of attempting to build generalized hand controllers with the goal of satisfying a broad range of users, we built a novel input device for the specific needs of a specific target audience - firefighters. We accomplished this by talking with over 30 firefighters. Their input was in the form of one-on-one discussions, focus groups, questionnaires, and feedback on our work in progress. Based on their input, we 1) identified a specific need - the simulation of detecting hazardous materials, 2) built a physical air monitoring device, that more closely matches firefighters actual air monitoring devices than standard VR controllers, and 3) implemented a hazardous materials scenario that consist of both physical and virtual elements. © 2020 IEEE.","Hardware - Emerging technologies - Emerging interfaces; Human-centered computing - Human computer interaction (HCI) - Interaction devices - Haptic devices; Human-centered computing - Human computer interaction (HCI) - Interaction paradigms - Virtual reality","Air pollution; Controllers; Fire extinguishers; Hazardous materials; Hazards; Knobs; Surveys; User interfaces; Air monitoring; Detection of hazardous materials; Focus groups; Input devices; Target audience; Virtual elements; Work in progress; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85085388847
"Zhang Z., Guo J., Weng D., Liu Y., Wang Y.","57218422359;55709458000;24386043400;54926684200;57211417484;","Extracting and Transferring Hierarchical Knowledge to Robots Using Virtual Reality",2020,"Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VRW 2020",,, 9090512,"669","670",,1,"10.1109/VRW50115.2020.00185","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085359010&doi=10.1109%2fVRW50115.2020.00185&partnerID=40&md5=fce7e89587c64767814e0f6e0b739d8f","Tencent; Beijing Institute of Technology, Beijing Engineering Research Center of MRAD, School of Optics and Photonics, Beijing, China","Zhang, Z., Tencent; Guo, J., Beijing Institute of Technology, Beijing Engineering Research Center of MRAD, School of Optics and Photonics, Beijing, China; Weng, D., Beijing Institute of Technology, Beijing Engineering Research Center of MRAD, School of Optics and Photonics, Beijing, China; Liu, Y., Beijing Institute of Technology, Beijing Engineering Research Center of MRAD, School of Optics and Photonics, Beijing, China; Wang, Y., Tencent","We study the knowledge transfer problem by training a task of folding clothes in the virtual world using an Oculus Headset and validating with a physical Baxter robot. We argue such complex transfer is realizable if an abstract graph-based knowledge representation is adopted to facilitate the process. An And-Or-Graph (AOG) grammar model is introduced to represent the knowledge, which can be learned from the human demonstrations performed in the Virtual Reality (VR), followed by the case analysis of folding clothes represented and learned by the AOG grammar model. In the experiment, the learned knowledge from the given six virtual scenarios is implemented on a physical robot platform, demonstrating that the grammar-based knowledge is an effective representation. © 2020 IEEE.","Human computer interaction (HCI); Human-centered computing; Interaction paradigms; Virtual reality","Clothes; Graphic methods; Knowledge management; Knowledge representation; Robots; User interfaces; Case analysis; Graph-based; Hierarchical knowledge; Human demonstrations; Knowledge transfer; Physical robots; Virtual scenario; Virtual worlds; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85085359010
"McAfee R., Haxton C., Harrison M., Gess J.","57211430363;57219341623;57203269478;56377503700;","Thermal Characterization of a Virtual Reality Headset during Transient and Resting Operation",2020,"36th Annual Semiconductor Thermal Measurement, Modeling and Management Symposium, SEMI-THERM 2020 - Proceedings",,, 9142850,"131","136",,,"10.23919/SEMI-THERM50369.2020.9142850","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092285747&doi=10.23919%2fSEMI-THERM50369.2020.9142850&partnerID=40&md5=22b521e31bbda9480fddc59b5f1cfd82","Oregon State University, 204 Rogers Hall, Corvallis, OR  97331, United States","McAfee, R., Oregon State University, 204 Rogers Hall, Corvallis, OR  97331, United States; Haxton, C., Oregon State University, 204 Rogers Hall, Corvallis, OR  97331, United States; Harrison, M., Oregon State University, 204 Rogers Hall, Corvallis, OR  97331, United States; Gess, J., Oregon State University, 204 Rogers Hall, Corvallis, OR  97331, United States","Virtual Reality (VR) is a powerful tool for maintenance process development, engineering design, pedagogy, and combat training. The evolution of the gaming industry has driven the demand for comfortable and reliable VR performance. By using the headset's user datasheet defined MicroController Unit's (MCU) operational temperature, the thermal resistance of the headset used in this study was found to have an external resistance, Rja, of 29.1 K/W, but 28.6% of this heat load is transmitted to the user. Relying on the user's body, specifically the forehead, as a heat sink results in uncomfortable perspiration during usage. Collected data show that after 2 hours of operation, the temperature increases 2.8°C on average when the headset is removed from the user and placed at rest while still operational. The maximum temperature increase is 5.6°C at the top of the VR headset, the surface nearest the internal MCU. This temperature spike proves that the headset needs more effective convective surface area in order to maintain a steady and comfortable operational temperature during 'headset on' and 'headset off' usage as the user's body was not available as a heat sink in the latter mode. A copper sheet has been added inside the headset to thermally connect all of the external surfaces on the device, effectively increasing the optimal convective heat transfer by 61%. The temperature nearest the MCU dropped 6.5°C with the improved thermal management solution and users reported a 25% reduction in perspiration during prolonged use. © 2020 STEF.","comfort measurements; consumer products; free convection; heat transfer; thermal management; Virtual Reality; Wearable","Heat convection; Heat resistance; Heat sinks; Microcontrollers; Thermal variables measurement; Convective heat transfer; Convective surfaces; Maximum temperature; Microcontroller unit; Operational temperature; Temperature increase; Thermal characterization; Virtual-reality headsets; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85092285747
"Verhulst A., Verhulst E., Manabe M., Saito H., Kasahara S., Inami M.","56767789100;57189309310;57216936425;57216934136;55542648700;9640047900;","Investigating the Influence of Odors Visuals Representations on the Sense of Smell, a pilot study",2020,"Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VRW 2020",,, 9090667,"727","728",,,"10.1109/VRW50115.2020.00214","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085389252&doi=10.1109%2fVRW50115.2020.00214&partnerID=40&md5=ff75fe82a5d580b1720c8373bec5a40e","University of Tokyo, Japan; University of Angers, France; University of Tokyo, Sony CSL, Tokyo, Japan","Verhulst, A., University of Tokyo, Japan; Verhulst, E., University of Angers, France; Manabe, M., University of Tokyo, Japan; Saito, H., University of Tokyo, Japan; Kasahara, S., University of Tokyo, Sony CSL, Tokyo, Japan; Inami, M., University of Tokyo, Japan","This pilot study researches the representation of smells in Virtual Reality and its association with real smells. Olfactive stimuli in VR remains limited and difficult for effective use. We propose a work-around with a 'synesthesia-like' approach (e.g. the smell of perfume is associated to a pink smoke / seeing a violet can elicit its odor; etc.). We present 2 studies (N=14) where: 1/ We compare 3 smell representations (smoke-based, image-based, visually physically-based) to know the best representation; and 2/ We compare good / bad real smells with good / bad virtual smells to know how the user associates them. © 2020 IEEE.","Human computer interaction (HCI); Human-centered computing; Interaction paradigms; Virtual reality","Odors; Smoke; Technology transfer; User interfaces; Image-based; Physically based; Pilot studies; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85085389252
"Liu S., Wang B., Ban X.","57198888042;57203891308;55967253500;","Multiple-scale Simulation Method for Liquid with Trapped Air under Particle-based Framework",2020,"Proceedings - 2020 IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2020",,, 9089636,"842","850",,2,"10.1109/VR46266.2020.1581218089381","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085478962&doi=10.1109%2fVR46266.2020.1581218089381&partnerID=40&md5=2a0061bb24da886c610da73c55735cac","University of Science and Technology, Beijing Advanced Innovation Center for Materials Genome Engineering, School of computer and communication Engineering, Beijing, China","Liu, S., University of Science and Technology, Beijing Advanced Innovation Center for Materials Genome Engineering, School of computer and communication Engineering, Beijing, China; Wang, B., University of Science and Technology, Beijing Advanced Innovation Center for Materials Genome Engineering, School of computer and communication Engineering, Beijing, China; Ban, X., University of Science and Technology, Beijing Advanced Innovation Center for Materials Genome Engineering, School of computer and communication Engineering, Beijing, China","Trapped air in liquid is an important factor which affect the realism of fluid simulation. However, due to the complex physical properties, simulating the interaction and transformation between air and Liquid is extremely challenging and time-consuming. In this paper, we propose a multi-scale simulation method under particle-based framework to achieve the realistic and efficient simulation of air-liquid fluid. A unified generation rule is proposed according to the kinetic energy and the velocity difference between fluid particles. Two velocity-based dynamic models are then established for different size of air materials respectively. The Brownian motion of small scale air materials is achieved by Schilk random function. The interaction and air transfer between large scale air materials is achieved by inverse diffusion equation and a new high-order kernel function. Experimental results show that the proposed method can improve the fidelity and richness of the fluid simulation. The post-processing scheme makes it able to be integrated with existing particle method easily. © 2020 IEEE.","Animation; Computer graphics; Computing methodologies; Physical simulation","Diffusion in liquids; Inverse problems; Kinetic energy; Kinetics; Liquids; User interfaces; Virtual reality; Efficient simulation; Fluid simulations; Inverse diffusion; Multi-scale simulation method; Particle methods; Post-processing scheme; Velocity difference; Velocity-based dynamics; Air",Conference Paper,"Final","",Scopus,2-s2.0-85085478962
"Chirico A., Giovannetti T., Neroni P., Simone S., Gallo L., Galli F., Giancamilli F., Predazzi M., Lucidi F., De Pietro G., Giordano A.","56736363600;6603442366;56449399500;57208625839;24072878600;57216654873;57190075356;57204580043;6603819858;6508247659;57211929456;","Virtual Reality for the Assessment of Everyday Cognitive Functions in Older Adults: An Evaluation of the Virtual Reality Action Test and Two Interaction Devices in a 91-Year-Old Woman",2020,"Frontiers in Psychology","11",, 123,"","",,1,"10.3389/fpsyg.2020.00123","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086524265&doi=10.3389%2ffpsyg.2020.00123&partnerID=40&md5=33521c197f288a9b3c08c5978e8e3e06","Department of Psychology of Developmental and Socialization Processes, Sapienza University of Rome, Rome, Italy; Psychology Department, Temple University, Philadelphia, PA, United States; Institute for High Performance Computing and Networking, National Research Council, Naples, Italy; Department of Engineering, Parthenope University of Naples, Naples, Italy; Fondazione Il Melo Onlus, Gallarate, Italy; Sbarro Institute for Cancer Research and Molecular Medicine, Center for Biotechnology, College of Science and Technology, Temple University, Philadelphia, PA, United States; Department of Medical Biotechnologies, University of Siena, Siena, Italy","Chirico, A., Department of Psychology of Developmental and Socialization Processes, Sapienza University of Rome, Rome, Italy; Giovannetti, T., Psychology Department, Temple University, Philadelphia, PA, United States; Neroni, P., Institute for High Performance Computing and Networking, National Research Council, Naples, Italy, Department of Engineering, Parthenope University of Naples, Naples, Italy; Simone, S., Psychology Department, Temple University, Philadelphia, PA, United States; Gallo, L., Institute for High Performance Computing and Networking, National Research Council, Naples, Italy; Galli, F., Department of Psychology of Developmental and Socialization Processes, Sapienza University of Rome, Rome, Italy; Giancamilli, F., Department of Psychology of Developmental and Socialization Processes, Sapienza University of Rome, Rome, Italy; Predazzi, M., Fondazione Il Melo Onlus, Gallarate, Italy; Lucidi, F., Department of Psychology of Developmental and Socialization Processes, Sapienza University of Rome, Rome, Italy; De Pietro, G., Institute for High Performance Computing and Networking, National Research Council, Naples, Italy; Giordano, A., Sbarro Institute for Cancer Research and Molecular Medicine, Center for Biotechnology, College of Science and Technology, Temple University, Philadelphia, PA, United States, Department of Medical Biotechnologies, University of Siena, Siena, Italy","Performance-based functional tests for the evaluation of daily living activities demonstrate strong psychometric properties and solve many of the limitations associated with self- and informant-report questionnaires. Virtual reality (VR) technology, which has gained interest as an effective medium for administering interventions in the context of healthcare, has the potential to minimize the time-demands associated with the administration and scoring of performance-based assessments. To date, efforts to develop VR systems for assessment of everyday function in older adults generally have relied on non-immersive systems. The aim of the present study was to evaluate the feasibility of an immersive VR environment for the assessment of everyday function in older adults. We present a detailed case report of an elderly woman who performed an everyday activity in an immersive VR context (Virtual Reality Action Test) with two different types of interaction devices (controller vs. sensor). VR performance was compared to performance of the same task with real objects outside of the VR system (Real Action Test). Comparisons were made on several dimensions, including (1) quality of task performance (e.g., order of task steps, errors, use and speed of hand movements); (2) subjective impression (e.g., attitudes), and (3) physiological markers of stress. Subjective impressions of performance with the different controllers also were compared for presence, cybersickness, and usability. Results showed that the participant was capable of using controllers and sensors to manipulate objects in a purposeful and goal-directed manner in the immersive VR paradigm. She performed the everyday task similarly across all conditions. She reported no cybersickness and even indicated that interactions in the VR environment were pleasant and relaxing. Thus, immersive VR is a feasible approach for function assessment even with older adults who might have very limited computer experience, no prior VR exposure, average educational experiences, and mild cognitive difficulties. Because of inherent limitations of single case reports (e.g., unknown generalizability, potential practice effects, etc.), group studies are needed to establish the full psychometric properties of the Virtual Reality Action Test. © Copyright © 2020 Chirico, Giovannetti, Neroni, Simone, Gallo, Galli, Giancamilli, Predazzi, Lucidi, De Pietro and Giordano.","activities of daily living; cognitive aging; everyday action; psychometric assessment; virtual reality",,Article,"Final","",Scopus,2-s2.0-85086524265
"de Moraes Í.A.P., Monteiro C.B.D.M., Silva T.D.D., Massetti T., Crocetta T.B., de Menezes L.D.C., Andrade G.P.D.R., Alessandro Hervaldo Nicolai R.E., Dawes H., Coe S., Magalhães F.H.","57195930904;55481862300;55546962700;55546122700;54898013000;57191485293;57211442029;57214918552;7003895377;55901034900;35345153300;","Motor learning and transfer between real and virtual environments in young people with autism spectrum disorder: A prospective randomized cross over controlled trial",2020,"Autism Research","13","2",,"307","319",,6,"10.1002/aur.2208","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073925009&doi=10.1002%2faur.2208&partnerID=40&md5=a7e6539428b6756cf19811f5da50d924","School of Arts, Sciences and Humanities, University of São Paulo, São Paulo, SP, Brazil; Post-Graduate Programme in Rehabilitation Sciences, Faculty of Medicine, University of São Paulo, São Paulo, SP, Brazil; Department of Morphology and Physiology, Faculty of Medicine of ABC, Santo André, SP, Brazil; Integrated Psycho-pedagogical Support Group (GAPI) Special Education School in São Bernardo do Campo, São Paulo, Brazil; Institute of Nursing and Allied Health Research, Oxford Brookes University, Oxford, United Kingdom; Department of Clinical Neurology, University of Oxford, Oxford, United Kingdom","de Moraes, Í.A.P., School of Arts, Sciences and Humanities, University of São Paulo, São Paulo, SP, Brazil, Post-Graduate Programme in Rehabilitation Sciences, Faculty of Medicine, University of São Paulo, São Paulo, SP, Brazil; Monteiro, C.B.D.M., School of Arts, Sciences and Humanities, University of São Paulo, São Paulo, SP, Brazil, Post-Graduate Programme in Rehabilitation Sciences, Faculty of Medicine, University of São Paulo, São Paulo, SP, Brazil; Silva, T.D.D., Post-Graduate Programme in Rehabilitation Sciences, Faculty of Medicine, University of São Paulo, São Paulo, SP, Brazil; Massetti, T., Post-Graduate Programme in Rehabilitation Sciences, Faculty of Medicine, University of São Paulo, São Paulo, SP, Brazil; Crocetta, T.B., Department of Morphology and Physiology, Faculty of Medicine of ABC, Santo André, SP, Brazil; de Menezes, L.D.C., Post-Graduate Programme in Rehabilitation Sciences, Faculty of Medicine, University of São Paulo, São Paulo, SP, Brazil; Andrade, G.P.D.R., Integrated Psycho-pedagogical Support Group (GAPI) Special Education School in São Bernardo do Campo, São Paulo, Brazil; Alessandro Hervaldo Nicolai, R.E., School of Arts, Sciences and Humanities, University of São Paulo, São Paulo, SP, Brazil; Dawes, H., Institute of Nursing and Allied Health Research, Oxford Brookes University, Oxford, United Kingdom, Department of Clinical Neurology, University of Oxford, Oxford, United Kingdom; Coe, S., Department of Clinical Neurology, University of Oxford, Oxford, United Kingdom; Magalhães, F.H., School of Arts, Sciences and Humanities, University of São Paulo, São Paulo, SP, Brazil","Autism spectrum disorder (ASD) is associated with persistent deficits in social communication and social interaction, including impaired multisensory integration, which might negatively impact cognitive and motor skill performance, and hence negatively affect learning of tasks. Considering that tasks in virtual environment may provide an engaging tool as adjuncts to conventional therapies, we set out to compare motor performance between young people with ASD and a typically developing (TD) control group that underwent coincident timing tasks based on Kinect (no physical contact) and on Keyboard (with physical contact) environments. Using a randomized repeated cross-over controlled trial design, 50 young people with ASD and 50 with TD, matched by age and sex were divided into subgroups of 25 people that performed the two first phases of the study (acquisition and retention) on the same device—real or virtual—and then switched to the other device to repeat acquisition and retention phases and finally switched on to a touch screen (transfer phase). Results showed that practice in the virtual task was more difficult (producing more errors), but led to a better performance in the subsequent practice in the real task, with more pronounced improvement in the ASD as compared to the TD group. It can be concluded that the ASD group managed to transfer the practice from a virtual to a real environment, indicating that virtual methods may enhance learning of motor and cognitive skills. A need for further exploration of its effect across a number of tasks and activities is warranted. Autism Res 2020, 13: 307–319. © 2019 International Society for Autism Research, Wiley Periodicals, Inc. Lay Summary: Individuals with autism spectrum disorder are known to have difficulties with learning motor tasks. Considering that performing motor tasks in virtual environment may be an engaging tool as adjuncts to conventional therapies, we aimed to estimate performance in tasks regardless of physical touch. Results showed that participants had more difficulty using the non-touch task; however, virtual training improved performance on the physical (real) task. This result indicates that virtual methods could be a promising therapeutic approach for the ASD population. © 2019 International Society for Autism Research, Wiley Periodicals, Inc.","autistic disorder; developmental disabilities; motor skills; virtual reality","accuracy; adolescent; Article; autism; child; clinical article; controlled study; disease severity; female; gesture; human; male; motor learning; motor performance; priority journal; skill; systematic error; task performance; touch; virtual reality; age; autism; crossover procedure; pathophysiology; physiology; prospective study; psychology; randomized controlled trial; sex factor; Adolescent; Age Factors; Autism Spectrum Disorder; Child; Cross-Over Studies; Female; Humans; Male; Motor Skills; Prospective Studies; Sex Factors; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85073925009
"Maier J., Weiherer M., Huber M., Palm C.","57200637391;57201076105;35518121600;23474896800;","Optically tracked and 3D printed haptic phantom hand for surgical training system",2020,"Quantitative Imaging in Medicine and Surgery","10","2",,"340","355",,2,"10.21037/qims.2019.12.03","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090217330&doi=10.21037%2fqims.2019.12.03&partnerID=40&md5=d7eaa1ed03fef06c6544f9404694bac3","Regensburg Medical Image Computing (ReMIC), Ostbayerische Technische Hochschule Regensburg (OTH Regensburg), Regensburg, Germany; Department of Trauma Surgery & Emergency, University Hospital Regensburg, Regensburg, Germany; Regensburg Center of Biomedical Engineering (RCBE), OTH Regensburg and Regensburg University, Regensburg, Germany","Maier, J., Regensburg Medical Image Computing (ReMIC), Ostbayerische Technische Hochschule Regensburg (OTH Regensburg), Regensburg, Germany; Weiherer, M., Regensburg Medical Image Computing (ReMIC), Ostbayerische Technische Hochschule Regensburg (OTH Regensburg), Regensburg, Germany; Huber, M., Department of Trauma Surgery & Emergency, University Hospital Regensburg, Regensburg, Germany; Palm, C., Regensburg Medical Image Computing (ReMIC), Ostbayerische Technische Hochschule Regensburg (OTH Regensburg), Regensburg, Germany, Regensburg Center of Biomedical Engineering (RCBE), OTH Regensburg and Regensburg University, Regensburg, Germany","Background: For surgical fixation of bone fractures of the human hand, so-called Kirschner-wires (K-wires) are drilled through bone fragments. Due to the minimally invasive drilling procedures without a view of risk structures like vessels and nerves, a thorough training of young surgeons is necessary. For the development of a virtual reality (VR) based training system, a three-dimensional (3D) printed phantom hand is required. To ensure an intuitive operation, this phantom hand has to be realistic in both, its position relative to the driller as well as in its haptic features. The softest 3D printing material available on the market, however, is too hard to imitate human soft tissue. Therefore, a support-material (SUP) filled metamaterial is used to soften the raw material. Realistic haptic features are important to palpate protrusions of the bone to determine the drilling starting point and angle. An optical real-time tracking is used to transfer position and rotation to the training system. Methods: A metamaterial already developed in previous work is further improved by use of a new unit cell. Thus, the amount of SUP within the volume can be increased and the tissue is softened further. In addition, the human anatomy is transferred to the entire hand model. A subcutaneous fat layer and penetration of air through pores into the volume simulate shiftability of skin layers. For optical tracking, a rotationally symmetrical marker attached to the phantom hand with corresponding reference marker is developed. In order to ensure trouble-free position transmission, various types of marker point applications are tested. Results: Several cuboid and forearm sample prints lead to a final 30 centimeter long hand model. The whole haptic phantom could be printed faultless within about 17 hours. The metamaterial consisting of the new unit cell results in an increased SUP share of 4.32%. Validated by an expert surgeon study, this allows in combination with a displacement of the uppermost skin layer a good palpability of the bones. Tracking of the hand marker in dodecahedron design works trouble-free in conjunction with a reference marker attached to the worktop of the training system. Conclusions: In this work, an optically tracked and haptically correct phantom hand was developed using dual-material 3D printing, which can be easily integrated into a surgical training system. © 2020 AME Publishing Company. All rights reserved.","Dual-material 3D printing; Hand surgery training; Metamaterial; Optical tracking; Support-material (SUP); Tissue imitating phantom hand","adult; anatomy; Article; bone structure; controlled study; elasticity; evaluation study; eye tracking; feedback system; female; forearm; hand; hand surgery; hardness; human; human cell; human tissue; K562/A02 cell line; major clinical study; male; medical student; orthopedic surgery; periosteum; plastic surgery; skin; skin penetration; skinfold thickness; soft tissue; subcutaneous fat; subcutaneous tissue; surgical training; three dimensional printing; touch; traumatology; virtual reality",Article,"Final","",Scopus,2-s2.0-85090217330
"Kaplan A.D., Cruit J., Endsley M., Beers S.M., Sawyer B.D., Hancock P.A.","57203577853;55957076800;7003719103;57215654078;36025972800;7102723856;","The Effects of Virtual Reality, Augmented Reality, and Mixed Reality as Training Enhancement Methods: A Meta-Analysis",2020,"Human Factors",,,,"","",,12,"10.1177/0018720820904229","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081603757&doi=10.1177%2f0018720820904229&partnerID=40&md5=23181c622324b7e6e21a3cb74deec76b","University of Central Florida, Orlando, United States; SA Technologies, Gold Canyon, AZ, United States; MITRE Corporation, Colorado Springs, CO, United States","Kaplan, A.D., University of Central Florida, Orlando, United States; Cruit, J., University of Central Florida, Orlando, United States; Endsley, M., SA Technologies, Gold Canyon, AZ, United States; Beers, S.M., MITRE Corporation, Colorado Springs, CO, United States; Sawyer, B.D., University of Central Florida, Orlando, United States; Hancock, P.A., University of Central Florida, Orlando, United States","Objective: The objective of this meta-analysis is to explore the presently available, empirical findings on transfer of training from virtual (VR), augmented (AR), and mixed reality (MR) and determine whether such extended reality (XR)-based training is as effective as traditional training methods. Background: MR, VR, and AR have already been used as training tools in a variety of domains. However, the question of whether or not these manipulations are effective for training has not been quantitatively and conclusively answered. Evidence shows that, while extended realities can often be time-saving and cost-saving training mechanisms, their efficacy as training tools has been debated. Method: The current body of literature was examined and all qualifying articles pertaining to transfer of training from MR, VR, and AR were included in the meta-analysis. Effect sizes were calculated to determine the effects that XR-based factors, trainee-based factors, and task-based factors had on performance measures after XR-based training. Results: Results showed that training in XR does not express a different outcome than training in a nonsimulated, control environment. It is equally effective at enhancing performance. Conclusion: Across numerous studies in multiple fields, extended realities are as effective of a training mechanism as the commonly accepted methods. The value of XR then lies in providing training in circumstances, which exclude traditional methods, such as situations when danger or cost may make traditional training impossible. © Copyright 2020, Commonwealth of Australia, as represented by the Department of Defence, Science, and Technology.","immersive environments; meta-analysis; transfer of training; virtual environments","Augmented reality; Mixed reality; Virtual reality; Control environment; Empirical findings; Immersive environment; Meta analysis; Performance measure; Training enhancement; Training methods; Transfer of trainings; E-learning; article; augmented reality; effect size; human; meta analysis; transfer of learning; virtual reality",Article,"Article in Press","",Scopus,2-s2.0-85081603757
"Carreon A., Smith S.J., Mosher M., Rao K., Rowland A.","57200799882;8063955600;57219305897;57221021182;56821362700;","A Review of Virtual Reality Intervention Research for Students With Disabilities in K–12 Settings",2020,"Journal of Special Education Technology",,,,"","",,,"10.1177/0162643420962011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092143583&doi=10.1177%2f0162643420962011&partnerID=40&md5=24117c6927194ddf8e5de88897d87620","The University of Kansas, Lawrence, KS, United States; University of Hawaii, Honolulu, HI, United States","Carreon, A., The University of Kansas, Lawrence, KS, United States; Smith, S.J., The University of Kansas, Lawrence, KS, United States; Mosher, M., The University of Kansas, Lawrence, KS, United States; Rao, K., University of Hawaii, Honolulu, HI, United States; Rowland, A., The University of Kansas, Lawrence, KS, United States","Virtual reality (VR) technology has improved in access and availability in the area of K–12 instruction, increasingly being cited for its promise to meet the varied learning needs of individuals with disabilities. This descriptive review of 25 research studies conducted in K–12 settings examined the defining characteristics of immersion levels associated with VR, the purpose and application of the augmented reality intervention, the outcomes associated with the current use of VR, and the possibility of generalization beyond VR. The results of the review reveal that a majority of studies are utilizing nonimmersive screen-based simulations. While still considered under the VR domain, these technologies do not take advantage of the features of semi- and fully immersive VR which make it an appealing intervention for students with disabilities. Based on the results of this review, we provide recommendations to establish a strong research base on emerging VR technology and its use for students with disabilities in the K–12 classroom. © The Author(s) 2020.","assistive technology; instructional technology; literature review; methodologies; mixed reality; mobile devices; technology perspectives; virtual reality",,Article,"Article in Press","",Scopus,2-s2.0-85092143583
"Hejtmanek L., Starrett M., Ferrer E., Ekstrom A.D.","14008461600;56442554600;7101784591;7005951533;","How much of what we learn in virtual reality transfers to real-world navigation?",2020,"Multisensory Research","33","4-5",,"479","503",,1,"10.1163/22134808-20201445","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082813726&doi=10.1163%2f22134808-20201445&partnerID=40&md5=a5f02f4195dd7bc0560e2209286c8f3e","Third Faculty of Medicine, Charles University, Ruská 87, Prague 10, 100 00, Czech Republic; Center for Neuroscience, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States; Department of Psychology, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States; Department of Psychology, University of Arizona, 1503 E. University Blvd., Tucson, AZ  85719, United States","Hejtmanek, L., Third Faculty of Medicine, Charles University, Ruská 87, Prague 10, 100 00, Czech Republic, Center for Neuroscience, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States; Starrett, M., Center for Neuroscience, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States, Department of Psychology, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States, Department of Psychology, University of Arizona, 1503 E. University Blvd., Tucson, AZ  85719, United States; Ferrer, E., Department of Psychology, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States; Ekstrom, A.D., Center for Neuroscience, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States, Department of Psychology, University of California, Davis, 1 Shields Ave, Davis, CA  95618, United States, Department of Psychology, University of Arizona, 1503 E. University Blvd., Tucson, AZ  85719, United States","Past studies suggest that learning a spatial environment by navigating on a desktop computer can lead to significant acquisition of spatial knowledge, although typically less than navigating in the real world. Exactly how this might differ when learning in immersive virtual interfaces that offer a rich set of multisensory cues remains to be fully explored. In this study, participants learned a campus building environment by navigating (1) the real-world version, (2) an immersive version involving an omnidirectional treadmill and head-mounted display, or (3) a version navigated on a desktop computer with a mouse and a keyboard. Participants first navigated the building in one of the three different interfaces and, afterward, navigated the real-world building to assess information transfer. To determine how well they learned the spatial layout, we measured path length, visitation errors, and pointing errors. Both virtual conditions resulted in significant learning and transfer to the real world, suggesting their efficacy in mimicking some aspects of real-world navigation. Overall, real-world navigation outperformed both immersive and desktop navigation, effects particularly pronounced early in learning. This was also suggested in a second experiment involving transfer from the real world to immersive virtual reality (VR). Analysis of effect sizes of going from virtual conditions to the real world suggested a slight advantage for immersive VR compared to desktop in terms of transfer, although at the cost of increased likelihood of dropout. Our findings suggest that virtual navigation results in significant learning, regardless of the interface, with immersive VR providing some advantage when transferring to the real world. Copyright © 2020 by Koninklijke Brill NV, Leiden, The Netherlands.","Navigation; Proprioception; Spatial cognition; Transfer; Virtual reality","Helmet mounted displays; Mammals; Navigation; Sensory perception; Transfer learning; Head mounted displays; Immersive virtual reality; Information transfers; Spatial cognition; Spatial environments; Transfer; Virtual interfaces; Virtual navigation; Virtual reality",Article,"Final","",Scopus,2-s2.0-85082813726
"Balzerkiewitz H.-P., Stechert C.","57219207718;24448259400;","Use of Virtual Reality in Product Development by Distributed Teams",2020,"Procedia CIRP","91",,,"577","582",,,"10.1016/j.procir.2020.02.216","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091709372&doi=10.1016%2fj.procir.2020.02.216&partnerID=40&md5=b9c2cf61ceefb8d3f8b8d602c11ebcad","Ostfalia University of Applied Science, Wolfenbüttel, Germany","Balzerkiewitz, H.-P., Ostfalia University of Applied Science, Wolfenbüttel, Germany; Stechert, C., Ostfalia University of Applied Science, Wolfenbüttel, Germany","This paper shows how future VR software improvements can support work in distributed teams. The comprehensive summary to the topics ""VR-technology"" and ""working in distributed teams"" lead to the following recommendations. In order to improve distributed teamwork in product development in the future the VR-technology can be a suitable tool. Therefor the data transfer between CAD and VR must be smooth. Moreover, existing or new VR-Software must be adapted in a way that allows the creation of 3D objects directly in the virtual environment. © 2017 The Authors. Published by Elsevier B.V.","Distributed Teams; Product Development; Virtual Reality","Computer aided design; Data transfer; Product development; 3D object; Distributed teams; VR technology; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85091709372
"Cristea D.S., Rusu C.C., Mistodie L.R., Ivanov M., Leontin A.","39860898100;18435404300;8531354900;57220005717;57220008357;","Immersive data analytics for enhancing organisational knowledge transfer processes through a custom developed virtual reality framework",2020,"eLearning and Software for Education Conference",,,,"92","100",,,"10.12753/2066-026X-20-097","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096497931&doi=10.12753%2f2066-026X-20-097&partnerID=40&md5=0f6fe1ccb533535691d1258b52874aba","University ‘Dunărea de Jos’, Str. Domnească 47, Galati, Romania; S.C. ALTFACTOR SRL, Str. Domnească 47, Galati, Romania","Cristea, D.S., University ‘Dunărea de Jos’, Str. Domnească 47, Galati, Romania; Rusu, C.C., University ‘Dunărea de Jos’, Str. Domnească 47, Galati, Romania; Mistodie, L.R., University ‘Dunărea de Jos’, Str. Domnească 47, Galati, Romania; Ivanov, M., S.C. ALTFACTOR SRL, Str. Domnească 47, Galati, Romania; Leontin, A., S.C. ALTFACTOR SRL, Str. Domnească 47, Galati, Romania","During the past years, virtual reality (VR) and augmented reality (AR) improved a lot from both accessibility and hardware capabilities perspectives. Currently, this type of software applications is encouraged to be part of various domains. This paper presents how virtual reality technologies can provide a novel, immersive, approach of one of the most used data science tasks, respectively data analytics, that can be used to enhance the effectiveness of the organizational knowledge transfer. Knowledge transfer, a process used in various industries including education, business, social and technology, plays an important role in the overall learning process, introducing new ways of sharing resources and people experience. As a data scientist, it is usually said that about 80% of the time will be used doing EDA (exploratory data analytics scenarios). Our research targeted the enhancement of organizational knowledge transfer processes by using immersive EDA. Our paper emphasizes the fact that VR offers extended possibilities for sustaining data analytics strategies, improving them with a new immersive perspective. Virtual learning environments can be used to build skills and one challenge for virtual reality, when applied in education or training, is to assess Virtual Environments effectiveness. Immersive data analytics can ease the effort of quantifying how effective a specific virtual scenario was for a group of users. The presented study also emphasises on how VR technologies can provide more detailed immersive analytics that can be used in optimizing knowledge transfer and implicitly learning processes, by potentially analysing every move of the learners, assessing the evolution of the user learning/performance, respectively understanding user reaction speed (response times) in various contexts similar to real world scenarios. Also, through immersive analytics, it is possible to determine learners emotional state and their level of attention, being possible to provide a more personalised interactive experience for enhancing learning efficiency. © 2020, National Defence University - Carol I Printing House. All rights reserved.","Data science; E-learning; Immersive data analytics; Knowledge transfer; Virtual reality",,Conference Paper,"Final","",Scopus,2-s2.0-85096497931
"Bellalouna F.","18933453600;","New approach for industrial training using virtual reality technology",2020,"Procedia CIRP","93",,,"262","267",,,"10.1016/j.procir.2020.03.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092432354&doi=10.1016%2fj.procir.2020.03.008&partnerID=40&md5=05e8e2f253a68a1c8bc857d201728f9f","University of Applied Sciences Karlsruhe, Moltkestraße 30, Karlsruhe, 76133, Germany","Bellalouna, F., University of Applied Sciences Karlsruhe, Moltkestraße 30, Karlsruhe, 76133, Germany","This paper presents two case studies achieved within industrial cooperation projects between the University of Applied Sciences Karlsruhe and German manufacturers for special appliances. The aim of the case studies is development and implementation of training applications for the use and the handling of special vehicle using the virtual reality technology. Based on the experiences gathered during these cooperation projects the challenges that face the VR introduction in the industrial area is outlined in this paper. Furthermore, a best practice approach on how to transfer CAD to VR data to implement industrial VR application is presented in this contribution. © 2020 The Authors.","CAD data; Cognitive approach; Intuitive approach; Virtual reality; VR data","Automobile manufacture; E-learning; Industrial area; Industrial cooperation; Industrial training; IS development; Training applications; University of applied science; Virtual reality technology; VR applications; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85092432354
"Matsangidou M., Otkhmezuri B., Ang C.S., Avraamides M., Riva G., Gaggioli A., Iosif D., Karekla M.","57196007400;57196009850;15831174100;6506947139;56962750600;6603138127;57219454910;7801543407;","“Now i can see me” designing a multi-user virtual reality remote psychotherapy for body weight and shape concerns",2020,"Human-Computer Interaction",,,,"","",,3,"10.1080/07370024.2020.1788945","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092795269&doi=10.1080%2f07370024.2020.1788945&partnerID=40&md5=67a8f0e1d96c2ded63dded4a70672b50","School of Engineering and Digital Arts, University of Kent, Kent, United Kingdom; Research Center on Interactive Media, Smart systems and Emerging technologies ltd, Nicosia, Cyprus; School of Psychology, University of Cyprus, Nicosia, Cyprus; School of Psychology, Università Cattolica Del Sacro Cuore, Milan, Italy; Applied Technology for Neuro-Psychology Lab, Milan, Italy","Matsangidou, M., School of Engineering and Digital Arts, University of Kent, Kent, United Kingdom, Research Center on Interactive Media, Smart systems and Emerging technologies ltd, Nicosia, Cyprus; Otkhmezuri, B., School of Engineering and Digital Arts, University of Kent, Kent, United Kingdom; Ang, C.S., School of Engineering and Digital Arts, University of Kent, Kent, United Kingdom; Avraamides, M., Research Center on Interactive Media, Smart systems and Emerging technologies ltd, Nicosia, Cyprus, School of Psychology, University of Cyprus, Nicosia, Cyprus; Riva, G., School of Psychology, Università Cattolica Del Sacro Cuore, Milan, Italy, Applied Technology for Neuro-Psychology Lab, Milan, Italy; Gaggioli, A., School of Psychology, Università Cattolica Del Sacro Cuore, Milan, Italy, Applied Technology for Neuro-Psychology Lab, Milan, Italy; Iosif, D., School of Psychology, University of Cyprus, Nicosia, Cyprus; Karekla, M., School of Psychology, University of Cyprus, Nicosia, Cyprus","Recent years have seen a growing research interest towards designing computer-assisted health interventions aiming to improve mental health services. Digital technologies are becoming common methods for diagnosis, therapy, and training. With the advent of lower-cost VR head-mounted-displays (HMDs) and high internet data transfer capacity, there is a new opportunity for applying immersive VR tools to augment existing interventions. This study is among the first to explore the use of a Multi-User Virtual Reality (MUVR) system as a therapeutic medium for participants at high-risk for developing Eating Disorders. This paper demonstrates the positive effect of using MUVR remote psychotherapy to enhance traditional therapeutic practices. The study capitalises on the opportunities which are offered by a MUVR remote psychotherapeutic session to enhance the outcome of Acceptance and Commitment Therapy, Play Therapy and Exposure Therapy for sufferers with body shape and weight concerns. Moreover, the study presents the design opportunities and challenges of such technology, while strengths on the feasibility, and the positive user acceptability of introducing MUVR to facilitate remote psychotherapy. Finally, the appeal of using VR for remote psychotherapy and its observed positive impact on both therapists and participants is discussed. © 2020 The Author(s). Published with license by Taylor & Francis Group, LLC.","Acceptance and Commitment Therapy (ACT); high-risk for eating disorders; Multi-User virtual reality; Play Therapy; Exposure Therapy; remote psychotherapy","Data transfer; Helmet mounted displays; Computer assisted; Digital technologies; Head mounted displays; Health interventions; Mental health services; Research interests; Therapeutic practices; Transfer capacities; Virtual reality",Article,"Article in Press","",Scopus,2-s2.0-85092795269
"Rothe S., Schmidt A., Montagud M., Buschek D., Hußmann H.","57199996760;57219418508;35868074700;55850134500;23389275800;","Social viewing in cinematic virtual reality: a design space for social movie applications",2020,"Virtual Reality",,,,"","",,1,"10.1007/s10055-020-00472-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092676924&doi=10.1007%2fs10055-020-00472-4&partnerID=40&md5=def8d44ae1a903490a6dd20957473a4d","Institute of Informatics, Ludwig-Maximilians-University Munich, Munich, Germany; Universitat de València & i2CAT Foundation, Valencia, Spain; Research Group HCI + AI, Department of Computer Science, University of Bayreuth, Bayreuth, Germany","Rothe, S., Institute of Informatics, Ludwig-Maximilians-University Munich, Munich, Germany; Schmidt, A., Institute of Informatics, Ludwig-Maximilians-University Munich, Munich, Germany; Montagud, M., Universitat de València & i2CAT Foundation, Valencia, Spain; Buschek, D., Research Group HCI + AI, Department of Computer Science, University of Bayreuth, Bayreuth, Germany; Hußmann, H., Institute of Informatics, Ludwig-Maximilians-University Munich, Munich, Germany","Since watching movies is a social experience for most people, it is important to know how an application should be designed for enabling shared cinematic virtual reality (CVR) experiences via head-mounted displays (HMDs). Viewers can feel isolated when watching omnidirectional movies with HMDs. Even if they are watching the movie simultaneously, they do not automatically see the same field of view, since they can freely choose their viewing direction. Our goal is to explore interaction techniques to efficiently support social viewing and to improve social movie experiences in CVR. Based on the literature review and insights from earlier work, we identify seven challenges that need to be addressed: communication, field-of-view (FoV) awareness, togetherness, accessibility, interaction techniques, synchronization, and multiuser environments. We investigate four aspects (voice chat, sending emotion states, FoV indication, and video chat) to address some of the challenges and report the results of four user studies. Finally, we present and discuss a design space for CVR social movie applications and highlight directions for future work. © 2020, The Author(s).","360° video; Cinematic virtual reality; Interactive TV; Omnidirectional video; Social viewing","Helmet mounted displays; Motion pictures; Technology transfer; Design spaces; Field of views; Head mounted displays; Interaction techniques; Literature reviews; Multiuser environments; User study; Viewing directions; Virtual reality",Article,"Article in Press","",Scopus,2-s2.0-85092676924
"Eiris R., Gheisari M., Esmaeili B.","57196006104;36459705300;35388139800;","Desktop-based safety training using 360-degree panorama and static virtual reality techniques: A comparative experimental study",2020,"Automation in Construction","109",, 102969,"","",,6,"10.1016/j.autcon.2019.102969","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073757844&doi=10.1016%2fj.autcon.2019.102969&partnerID=40&md5=910f18b71dc4dced51aa43348f942f02","Rinker School of Construction Management, University of Florida, United States; Sid and Reva Dewberry Department of Civil, Environmental, and Infrastructure Engineering, George Mason University, United States","Eiris, R., Rinker School of Construction Management, University of Florida, United States; Gheisari, M., Sid and Reva Dewberry Department of Civil, Environmental, and Infrastructure Engineering, George Mason University, United States; Esmaeili, B., Sid and Reva Dewberry Department of Civil, Environmental, and Infrastructure Engineering, George Mason University, United States","Virtual reality (VR)-based approaches have been used to facilitate safety knowledge transfer and increase hazard awareness by providing safe and controlled experiences of unsafe scenarios in construction safety training applications. However, the long development times and high computational costs associated with existing VR methods have posed significant challenges to using such VR-based safety training platforms. Unlike VR settings that deliver computer-generated reproductions of the environment, 360-degree panorama can create true-to-reality simulations of construction jobsites. This research developed and compared two hazard-identification training platforms based on VR and 360-degree panorama. Construction students and professionals participated in an experiment to determine their perception of realism and evaluate their hazard-identification skills. It was found that students perceived the 360-degree panorama conditions as more realistic than the VR conditions, but professionals perceived no difference between them. Moreover, differences were found in the average hazard identification index (HII) scores for all participants, with higher scores for the VR conditions than for the 360-degree panorama conditions. Finally, it was found that there was an inverse correlation between the presence scores and the average HII scores for the participants in the study. © 2019 Elsevier B.V.","360-degree panorama; Construction safety training; Hazard recognition; Virtual reality","E-learning; Hazardous materials; Knowledge management; Students; Virtual reality; 360-degree panorama; Computational costs; Computer generated; Construction safety; Hazard identification; Inverse correlation; Training platform; Virtual reality techniques; Hazards",Article,"Final","",Scopus,2-s2.0-85073757844
"Harris D.J., Buckingham G., Wilson M.R., Brookes J., Mushtaq F., Mon-Williams M., Vine S.J.","57192429891;14069958400;55574207642;57197801653;56999078200;7006287402;36811509000;","Exploring sensorimotor performance and user experience within a virtual reality golf putting simulator",2020,"Virtual Reality",,,,"","",,,"10.1007/s10055-020-00480-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092909275&doi=10.1007%2fs10055-020-00480-4&partnerID=40&md5=c0dd2e10981714f6c085f31365d25818","School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom; School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Centre for Immersive Technologies, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Bradford Teaching Hospitals NHS Foundation Trust, Bradford, West Yorkshire, United Kingdom; National Centre for Optics, Vision and Eye Care, University of South-Eastern Norway, Hasbergs vei 36, Kongsberg, 3616, Norway","Harris, D.J., School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom; Buckingham, G., School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom; Wilson, M.R., School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom; Brookes, J., School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Mushtaq, F., School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom, Centre for Immersive Technologies, University of Leeds, Leeds, LS2 9JZ, United Kingdom; Mon-Williams, M., School of Psychology, University of Leeds, Leeds, LS2 9JZ, United Kingdom, Centre for Immersive Technologies, University of Leeds, Leeds, LS2 9JZ, United Kingdom, Bradford Teaching Hospitals NHS Foundation Trust, Bradford, West Yorkshire, United Kingdom, National Centre for Optics, Vision and Eye Care, University of South-Eastern Norway, Hasbergs vei 36, Kongsberg, 3616, Norway; Vine, S.J., School of Sport and Health Sciences, University of Exeter, St Luke’s Campus, Exeter, EX1 2LU, United Kingdom","In light of recent advances in technology, there has been growing interest in virtual reality (VR) simulations for training purposes in a range of high-performance environments, from sport to nuclear decommissioning. For a VR simulation to elicit effective transfer of training to the real-world, it must provide a sufficient level of validity, that is, it must be representative of the real-world skill. In order to develop the most effective simulations, assessments of validity should be carried out prior to implementing simulations in training. The aim of this work was to test elements of the physical fidelity, psychological fidelity and construct validity of a VR golf putting simulation. Self-report measures of task load and presence in the simulation were taken following real and simulated golf putting to assess psychological and physical fidelity. The performance of novice and expert golfers in the simulation was also compared as an initial test of construct validity. Participants reported a high degree of presence in the simulation, and there was little difference between real and virtual putting in terms of task demands. Experts performed significantly better in the simulation than novices (p =.001, d = 1.23), and there was a significant relationship between performance on the real and virtual tasks (r =.46, p =.004). The results indicated that the simulation exhibited an acceptable degree of construct validity and psychological fidelity. However, some differences between the real and virtual tasks emerged, suggesting further validation work is required. © 2020, The Author(s).","Construct validity; Simulation; Sport; Training; VR","Golf; User experience; Construct validity; Nuclear decommissioning; Real-world; Task demand; Test elements; Training purpose; Transfer of trainings; VR simulation; Virtual reality",Article,"Article in Press","",Scopus,2-s2.0-85092909275
"Ojelade A., Paige F.","57203984321;57202021599;","Virtual reality postural training for construction",2020,"Construction Research Congress 2020: Safety, Workforce, and Education - Selected Papers from the Construction Research Congress 2020",,,,"565","573",,,"10.1061/9780784482872.061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096943100&doi=10.1061%2f9780784482872.061&partnerID=40&md5=3f57eb8f400f3d339c7ab720e408cc14","Occupational Ergonomics and Safety, Dept. of Industrial and Systems Engineering, Virginia Tech, Blacksburg, VA, United States; Construction and Engineering Management, Dept. of Civil Engineering, Virginia Tech, Blacksburg, VA, United States","Ojelade, A., Occupational Ergonomics and Safety, Dept. of Industrial and Systems Engineering, Virginia Tech, Blacksburg, VA, United States; Paige, F., Construction and Engineering Management, Dept. of Civil Engineering, Virginia Tech, Blacksburg, VA, United States","Currently, the U.S. construction workforce is aging faster than the next generation is being trained. While an insufficient workforce will cause major issues with the advancement of infrastructure, it also causes less discussed worker health safety hazards. Traditional experiential learning is a major limitation of the construction industry's growth rate due to the non-availability of real environments, time, and training supervisors. Virtual reality (VR) allows for a virtual environment to efficiently mimic dangerous, expensive, and difficult to set up training scenarios. This paper presents an exploration of a virtual approach to training future construction workers. VR environments and a RGB camera based pose estimation pedagogical tool are evaluated for their ability to improve the training process of future construction workers. Study participants will be assessed on their ability to learn, identify, and assess health safety risks, specifically proper lifting and postural techniques associated with construction tasks. Findings of this work in progress will provide quantified learning gains by measuring training time, changes in behavior, and risk assessment ability; and a qualitative understanding of the experience in the virtual environment through participant interviews. Findings from this study transfer to a much-needed digitization of pedagogical approaches for blue collar industries. © 2020 American Society of Civil Engineers.",,"Construction industry; Health hazards; Health risks; Occupational risks; Personnel training; Risk assessment; Virtual reality; Construction workers; Construction workforces; Experiential learning; Pedagogical approach; Pedagogical tools; Postural training; Real environments; Training scenario; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85096943100
"Riemann T., Kreß A., Roth L., Klipfel S., Metternich J., Grell P.","57216947870;57194567019;57216952566;57216945850;6507096724;57216945501;","Agile implementation of virtual reality in learning factories",2020,"Procedia Manufacturing","45",,,"1","6",,5,"10.1016/j.promfg.2020.04.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085522794&doi=10.1016%2fj.promfg.2020.04.029&partnerID=40&md5=7eb2225c75269422795ea229476aa652","Technische Universität Darmstadt, Otto-Berndt-Str. 2, Darmstadt, 64287, Germany","Riemann, T., Technische Universität Darmstadt, Otto-Berndt-Str. 2, Darmstadt, 64287, Germany; Kreß, A., Technische Universität Darmstadt, Otto-Berndt-Str. 2, Darmstadt, 64287, Germany; Roth, L., Technische Universität Darmstadt, Otto-Berndt-Str. 2, Darmstadt, 64287, Germany; Klipfel, S., Technische Universität Darmstadt, Otto-Berndt-Str. 2, Darmstadt, 64287, Germany; Metternich, J., Technische Universität Darmstadt, Otto-Berndt-Str. 2, Darmstadt, 64287, Germany; Grell, P., Technische Universität Darmstadt, Otto-Berndt-Str. 2, Darmstadt, 64287, Germany","The concept of learning factories fulfills current learning theoretical requirements in terms of the situation, process orientation, as well as authenticity. Nevertheless, due to the high complexity of the industrial production environment, it is challenging to transfer learned skills into the operational application situation. With Virtual Reality, training participants have the ability to learn with transfer-oriented action tasks in virtual space directly after the training in physical learning environments. The learning process can be personalized and adapted in the virtual learning environment. Each participant in the training can individually determine elements of the learning situation. For example, the entire learning environment can be adapted to the individual real production environment of the training participant. Through Virtual Reality, new forms of reflection are possible, e.g. recording the learning process. Technical, didactic and organizational requirements were identified by a systematic literature analysis. The research project is based on training courses in the process learning factory “Center for industrial Productivity” (CiP) located at TU Darmstadt. In order to assess and prioritize the requirements, expert surveys were conducted. The surveys are based on the Kano model in order to classify requirements. Must-be quality requirements are implemented in a minimum viable product (MVP). The MVP allows fast learning by testing and experimenting. Based on the agile manifesto, further requirements can be implemented agilely in the virtual environment. © 2020 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0/) Peer-review under responsibility of the scientific committee of the 10th Conference on Learning Factories 2020.","Agile Project Management; Kano Model; Learning Factory; Learning Scenario; Virtual Reality",,Conference Paper,"Final","",Scopus,2-s2.0-85085522794
"Li L., Qiao X., Lu Q., Ren P., Lin R.","57216895263;7101964811;57216900710;57203302963;57216892225;","Rendering Optimization for Mobile Web 3D Based on Animation Data Separation and On-Demand Loading",2020,"IEEE Access","8",, 9090999,"88474","88486",,,"10.1109/ACCESS.2020.2993613","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085213056&doi=10.1109%2fACCESS.2020.2993613&partnerID=40&md5=9b9586c3fcbcc5772777743625e47b13","School of Electronics and Information, Communication University of Zhejiang, Hangzhou, 310037, China; State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, 100876, China","Li, L., School of Electronics and Information, Communication University of Zhejiang, Hangzhou, 310037, China; Qiao, X., State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Lu, Q., School of Electronics and Information, Communication University of Zhejiang, Hangzhou, 310037, China; Ren, P., State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Lin, R., School of Electronics and Information, Communication University of Zhejiang, Hangzhou, 310037, China","Based on advances in image processing technology and Web-enabling technologies for mobile devices, mobile Augmented Reality (AR) and Virtual Reality (VR) has developed rapidly. The rendering and interaction of 3D models is an important part of AR and VR applications and is closely related to user experience. However, since the existing WebGL 3D JavaScript libraries for Web-based mobile 3D (represented by three.js and babylon.js) load the entire model file at once, large-size 3D models with complex interactions cannot be rendered smoothly due to limited data transmission, the weak computation capabilities of mobile Web browsers, and the latency of 3D model rendering. In this paper, we first propose model-animation data separation and an on-demand loading mechanism to improve the data request and loading process of Web 3D models. The main mechanisms are the following: (1) The model data are segmented into topological data and animation data sequences, and only the necessary data of the model are loaded when the Web-based mobile 3D model is first rendered. (2) The 3D model animation data sequence is semantically decomposed, and a multigranular model animation data service is established to provide continuous animation data support. (3) An asynchronous request-response mechanism is used to optimize the loading method of the model data. The model rendering mechanism uses an on-demand request and rendering method to transform the centralized loading process of the 3D model into a decentralized process. According to the testing and verification results, this optimization method can reduce the latency of mobile Web 3D in model data transmission and rendering by 24.72% for the experiment models. The interaction experience of Web-based mobile AR and VR is substantially improved relative to existing Web 3D rendering engines and rendering mechanisms, especially in complex interactive service scenarios. © 2013 IEEE.","augmented reality; interfacing data services; Mobile Web 3D; on-demand loading; rendering interactive computing; virtual reality","3D modeling; Animation; Augmented reality; Data transfer; Image processing; Rendering (computer graphics); Topology; Transmissions; User experience; Virtual reality; Web browsers; Websites; Image processing technology; Interaction experiences; Interactive services; Mobile augmented reality; Optimization method; Rendering optimizations; Response mechanisms; Verification results; Three dimensional computer graphics",Article,"Final","",Scopus,2-s2.0-85085213056
"Jo Y., Kim Y.J., Cho M., Lee C., Kim M., Moon H.-M., Kim S.","57205540634;57192997836;56783471200;56355435600;57203250886;57202368179;27169083000;","Virtual Reality-based Control of Robotic Endoscope in Laparoscopic Surgery",2020,"International Journal of Control, Automation and Systems","18","1",,"150","162",,1,"10.1007/s12555-019-0244-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076135225&doi=10.1007%2fs12555-019-0244-9&partnerID=40&md5=74f6156009a611709ac375d667bb9aa3","Program for Bioengineering, Seoul National University, 103, Daehak-ro, Jongno-gu, Seoul, 03080, South Korea; Institute of Medical and Biological Engineering, Seoul National University, Seoul, 08826, South Korea; Korea Electrotechnology Research Institute, Ansan, 15588, South Korea; Institute of Medical and Biological Engineering, Seoul National University, Seoul, 03080, South Korea; Department of Biomedical Engineering, Seoul National University College of Medicine, Seoul, 03080, South Korea","Jo, Y., Program for Bioengineering, Seoul National University, 103, Daehak-ro, Jongno-gu, Seoul, 03080, South Korea; Kim, Y.J., Institute of Medical and Biological Engineering, Seoul National University, Seoul, 08826, South Korea; Cho, M., Program for Bioengineering, Seoul National University, 103, Daehak-ro, Jongno-gu, Seoul, 03080, South Korea; Lee, C., Korea Electrotechnology Research Institute, Ansan, 15588, South Korea; Kim, M., Korea Electrotechnology Research Institute, Ansan, 15588, South Korea; Moon, H.-M., Program for Bioengineering, Seoul National University, 103, Daehak-ro, Jongno-gu, Seoul, 03080, South Korea; Kim, S., Institute of Medical and Biological Engineering, Seoul National University, Seoul, 03080, South Korea, Department of Biomedical Engineering, Seoul National University College of Medicine, Seoul, 03080, South Korea","Robotic laparoscopic surgery has provided various benefits, but during the surgery, the surgeons are experiencing uncomfortable positioning issue which leads to neck pain and back pain. So, for an enhanced & efficient ergonomic robot-assisted surgery, a novel virtual reality (VR)-based endoscope control system (ECS) is proposed in this research. The overall system in this study is composed of a da Vinci research kit (dVRK), 4-degree-of-freedom ECS, three-dimensional endoscope, and VR headset with a built-in attitude and heading reference system (AHRS) module. Also, the proposed VR headset could replace a stereo viewer in the dVRK which could reduce the size of surgical robot system. Furthermore, the three dimensional endoscope could be controlled by a built-in AHRS module in the VR headset. The proposed system has been verified with four novice volunteers. They showed rapid learning through the peg-transfer task. Additionally, a collision avoidance strategy for VR-based ECS control was developed and verified by performing computer-based simulations. The ergonomic VR-based ECS proposed in this research could greatly reduce surgeon’s pains in both neck and back which potentially reduce surgeon’s workload during the surgery. © 2019, ICROS, KIEE and Springer.","Collision avoidance; dVRK; ergonomic system; robot-assisted surgery; virtual reality","Collision avoidance; Endoscopy; Ergonomics; Laparoscopy; Robotics; Robots; Surgery; Surgical equipment; Virtual reality; Attitude and heading reference systems (AHRS); Computer based simulation; dVRK; Ergonomic systems; Laparoscopic surgery; Neck pains; Rapid learning; Robot-assisted surgery; Robotic surgery",Article,"Final","",Scopus,2-s2.0-85076135225
"Zhang L., Weitlauf A.S., Amat A.Z., Swanson A., Warren Z.E., Sarkar N.","55803949700;57191707622;57203133051;53265026200;25032282500;7201361624;","Assessing Social Communication and Collaboration in Autism Spectrum Disorder Using Intelligent Collaborative Virtual Environments",2020,"Journal of Autism and Developmental Disorders","50","1",,"199","211",,4,"10.1007/s10803-019-04246-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074351511&doi=10.1007%2fs10803-019-04246-z&partnerID=40&md5=dac49c257ecb6445127a7b2978757a8c","Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States; Department of Pediatrics, Vanderbilt University Medical Center, Nashville, United States; Vanderbilt Kennedy Center, Treatment and Research Institute of Autism Spectrum Disorders, Vanderbilt University Medical Center, 230 Appleton Pl., PMB 74, Nashville, TN  37212, United States; Department of Special Education, Vanderbilt University, Nashville, TN, United States; Department of Psychiatry, Vanderbilt University Medical Center, Nashville, TN, United States; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, United States","Zhang, L., Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States; Weitlauf, A.S., Department of Pediatrics, Vanderbilt University Medical Center, Nashville, United States, Vanderbilt Kennedy Center, Treatment and Research Institute of Autism Spectrum Disorders, Vanderbilt University Medical Center, 230 Appleton Pl., PMB 74, Nashville, TN  37212, United States; Amat, A.Z., Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States; Swanson, A., Vanderbilt Kennedy Center, Treatment and Research Institute of Autism Spectrum Disorders, Vanderbilt University Medical Center, 230 Appleton Pl., PMB 74, Nashville, TN  37212, United States; Warren, Z.E., Department of Pediatrics, Vanderbilt University Medical Center, Nashville, United States, Vanderbilt Kennedy Center, Treatment and Research Institute of Autism Spectrum Disorders, Vanderbilt University Medical Center, 230 Appleton Pl., PMB 74, Nashville, TN  37212, United States, Department of Special Education, Vanderbilt University, Nashville, TN, United States, Department of Psychiatry, Vanderbilt University Medical Center, Nashville, TN, United States; Sarkar, N., Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN, United States, Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, United States","Existing literature regarding social communication outcomes of interventions in autism spectrum disorder (ASD) depends upon human raters, with limited generalizability to real world settings. Technological innovation, particularly virtual reality (VR) and collaborative virtual environments (CVE), could offer a replicable, low cost measurement platform when endowed with intelligent agent technology and peer-based interactions. We developed and piloted a novel collaborative virtual environment and intelligent agent (CRETA) for the assessment of social communication and collaboration within system and peer interactions. The system classified user statements with moderate to high accuracies. We found moderate to high agreement in displayed communication and collaboration skills between human–human and human–agent interactions. CRETA offers a promising avenue for future development of autonomous measurement systems for ASD research. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Autism; Collaboration; Communication; Measurement; Technology; Virtual reality","adolescent; Article; autism; automatic speech recognition; clinical article; communication skill; controlled study; DSM-5; feasibility study; female; human; machine learning; male; pilot study; priority journal; social competence; task performance; verbal communication; virtual reality; autism; case control study; interpersonal communication; peer group; psychology; social behavior; Adolescent; Autism Spectrum Disorder; Case-Control Studies; Communication; Female; Humans; Male; Peer Group; Social Behavior; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85074351511
"Bogaerts B., Sels S., Vanlanduit S., Penne R.","57191575116;57193554563;7004271926;6701922997;","Connecting the CoppeliaSim robotics simulator to virtual reality",2020,"SoftwareX","11",, 100426,"","",,,"10.1016/j.softx.2020.100426","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080071825&doi=10.1016%2fj.softx.2020.100426&partnerID=40&md5=031766ad9c44d9d74d77dd43b781e8d1","Faculty of Applied Engineering, University of Antwerp, Antwerp, Belgium","Bogaerts, B., Faculty of Applied Engineering, University of Antwerp, Antwerp, Belgium; Sels, S., Faculty of Applied Engineering, University of Antwerp, Antwerp, Belgium; Vanlanduit, S., Faculty of Applied Engineering, University of Antwerp, Antwerp, Belgium; Penne, R., Faculty of Applied Engineering, University of Antwerp, Antwerp, Belgium","The CoppeliaSim VR Toolbox provides a set of tools to experience CoppeliaSim robot simulation software in Virtual Reality and to return user interactions. Its primary focus is to create a platform that enables the fast prototyping and verification of robotic systems. Moreover, the generality of the toolbox ensures that it can be valuable in other contexts like robotics education, human–robot interaction or reinforcement learning. The software is designed to have a low entry threshold for moderately complex use cases, but can be extended to perform very complex visualizations for more experienced users. © 2020 The Authors","Human–robot interaction; Interface; Prototyping; Robot simulation; Virtual reality","Computer software; Interfaces (materials); Reinforcement learning; Robotics; Software prototyping; Virtual reality; Fast prototyping; Robot interactions; Robot simulation software; Robot simulations; Robotic systems; Robotics education; User interaction; Human robot interaction",Article,"Final","",Scopus,2-s2.0-85080071825
"Ke Y., Liu P., An X., Song X., Ming D.","55760984800;57213603004;57214860474;55814078100;9745824400;","An online SSVEP-BCI system in an optical see-through augmented reality environment",2020,"Journal of Neural Engineering","17","1", 016066,"","",,5,"10.1088/1741-2552/ab4dc6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080070514&doi=10.1088%2f1741-2552%2fab4dc6&partnerID=40&md5=bd56e2fce8c2131522bac0a349d1c469","Academy of Medical Engineering and Translational Medicine, Tianjin International Joint Research Centre for Neural Engineering, Tianjin Key Laboratory of Brain Science and Neural Engineering, Tianjin University, Tianjin, 300072, China; Department of Biomedical Engineering, College of Precision Instrument and Optoelectronics Engineering, Tianjin University, Tianjin, 300072, China","Ke, Y., Academy of Medical Engineering and Translational Medicine, Tianjin International Joint Research Centre for Neural Engineering, Tianjin Key Laboratory of Brain Science and Neural Engineering, Tianjin University, Tianjin, 300072, China; Liu, P., Academy of Medical Engineering and Translational Medicine, Tianjin International Joint Research Centre for Neural Engineering, Tianjin Key Laboratory of Brain Science and Neural Engineering, Tianjin University, Tianjin, 300072, China; An, X., Academy of Medical Engineering and Translational Medicine, Tianjin International Joint Research Centre for Neural Engineering, Tianjin Key Laboratory of Brain Science and Neural Engineering, Tianjin University, Tianjin, 300072, China; Song, X., Academy of Medical Engineering and Translational Medicine, Tianjin International Joint Research Centre for Neural Engineering, Tianjin Key Laboratory of Brain Science and Neural Engineering, Tianjin University, Tianjin, 300072, China; Ming, D., Academy of Medical Engineering and Translational Medicine, Tianjin International Joint Research Centre for Neural Engineering, Tianjin Key Laboratory of Brain Science and Neural Engineering, Tianjin University, Tianjin, 300072, China, Department of Biomedical Engineering, College of Precision Instrument and Optoelectronics Engineering, Tianjin University, Tianjin, 300072, China","Objective. This study aimed to design and evaluate a high-speed online steady-state visually evoked potential (SSVEP)-based brain-computer interface (BCI) in an optical see-through (OST) augmented reality (AR) environment. Approach. An eight-class BCI was designed in an OST-AR headset which is wearable and allows users to see the user interface of the BCI and the device to be controlled in the same view field via the OST head-mounted display. The accuracies, information transfer rates (ITRs), and SSVEP signal characteristics of the AR-BCI were evaluated and compared with a computer screen-based BCI implemented with a laptop in offline and online cue-guided tasks. Then, the performance of the AR-BCI was evaluated in an online robotic arm control task. Main results. The offline results obtained during the cue-guided task performed with the AR-BCI showed maximum averaged ITRs of 65.50 ± 9.86 bits min-1 according to the extended canonical correlation analysis-based target identification method. The online cue-guided task achieved averaged ITRs of 65.03 ± 11.40 bits min-1. The online robotic arm control task achieved averaged ITRs of 45.57 ± 7.40 bits min-1. Compared with the screen-based BCI, some limitations of the AR environment impaired BCI performance and the quality of SSVEP signals. Significance. The results showed the potential for providing a high-performance brain-control interaction method by combining AR and BCI. This study could provide methodological guidelines for developing more wearable BCIs in OST-AR environments and will also encourage more interesting applications involving BCIs and AR techniques. © 2020 IOP Publishing Ltd.","augmented reality; brain-computer interface; electroencephalogram; optical see-through; steady-state visual evoked potential","Augmented reality; Electroencephalography; Helmet mounted displays; Interface states; Robotic arms; Robotics; User interfaces; Wearable computers; Canonical correlation analysis; Head mounted displays; Information transfer rate; Methodological guidelines; Optical see-through; Steady state visual evoked potentials; Steady state visually evoked potentials; Target identification; Brain computer interface; adult; augmented reality; Conference Paper; controlled study; correlation analysis; female; human; human experiment; male; normal human; online system; priority journal; robotics; signal transduction; task performance; visual evoked potential",Conference Paper,"Final","",Scopus,2-s2.0-85080070514
"Hoppe A.H., Marek F., De Camp F.V., Stiefelhagen R.","57195069885;57210910641;57194787505;6602180348;","Extending movable surfaces with touch interaction using the virtualtablet: An extended view",2020,"Advances in Science, Technology and Engineering Systems","5","2",,"328","337",,,"10.25046/AJ050243","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087525968&doi=10.25046%2fAJ050243&partnerID=40&md5=df0c63da1836cd541fada857bd9f6d7e","Karlsruhe Institute of Technology (KIT), Institute for Anthropomatics and Robotics (IAR), cv:hci Lab, Karlsruhe, 76131, Germany; Fraunhofer IOSB, Interactive Analysis and Diagnosis (IAD), Karlsruhe, 76131, Germany; Fraunhoferstr. 1, Karlsruhe, 76131, Germany","Hoppe, A.H., Karlsruhe Institute of Technology (KIT), Institute for Anthropomatics and Robotics (IAR), cv:hci Lab, Karlsruhe, 76131, Germany, Fraunhoferstr. 1, Karlsruhe, 76131, Germany; Marek, F., Karlsruhe Institute of Technology (KIT), Institute for Anthropomatics and Robotics (IAR), cv:hci Lab, Karlsruhe, 76131, Germany; De Camp, F.V., Fraunhofer IOSB, Interactive Analysis and Diagnosis (IAD), Karlsruhe, 76131, Germany; Stiefelhagen, R., Karlsruhe Institute of Technology (KIT), Institute for Anthropomatics and Robotics (IAR), cv:hci Lab, Karlsruhe, 76131, Germany","Immersive output and natural input are two core aspects of a virtual reality experience. Current systems are frequently operated by a controller or gesture-based approach. However, these techniques are either very accurate but require an effort to learn, or very natural but miss haptic feedback for optimal precision. We transfer ubiquitous touch interaction with haptic feedback into a virtual environment. To validate the performance of our implementation, we performed a user study with 28 participants. As the results show, the movable and cheap real world object supplies an accurate touch detection that is equal to a laserpointer-based interaction with a controller. Moreover, the virtual tablet can extend the functionality of a real world tablet. Additional information can be displayed in mid-air around the touchable area and the tablet can be turned over to interact with both sides. Therefore, touch interaction in virtual environments allows easy to learn and precise system interaction and can even augment the established touch metaphor with new paradigms. © 2020 ASTES Publishers. All rights reserved.","Haptic feedback; Touch interaction; Virtual environment; Virtual reality; VirtualTablet",,Article,"Final","",Scopus,2-s2.0-85087525968
"Huber B., Gajos K.Z.","57188807714;8375653300;","Conducting online virtual environment experiments with uncompensated, unsupervised samples",2020,"PLoS ONE","15","1", e0227629,"","",,3,"10.1371/journal.pone.0227629","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078713911&doi=10.1371%2fjournal.pone.0227629&partnerID=40&md5=f476cce779c79a329e6e1b8d1b27de70","School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, United States","Huber, B., School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, United States; Gajos, K.Z., School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, United States","Web-based experimentation with uncompensated and unsupervised samples allows for a larger and more diverse sample population, more generalizable results, and faster theory to experiment cycle. Given that participants are unsupervised, it is still unknown whether the data collected in such settings would be of sufficiently high quality to support robust conclusions. Therefore, we investigated the feasibility of conducting such experiments online using virtual environment technologies. We conducted a conceptual replication of two prior experiments that have been conducted in virtual environments. Our results replicate findings previously obtained in conventional laboratory settings. These results hold across different device types of participants (ranging from desktop, through mobile devices to immersive virtual reality headsets), suggesting that experiments can be conducted online with uncompensated samples in virtual environments. © 2020 Huber, Gajos. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"adolescent; adult; aged; Article; behavior assessment; child; community care; feasibility study; female; human; human experiment; laboratory; male; process design; replication study; unsupervised machine learning; virtual reality; web-based intervention; computer; interpersonal communication; middle aged; mobile phone; non-therapeutic research; online system; psychology; spatial orientation; young adult; Adolescent; Adult; Aged; Cell Phone; Child; Computers; Female; Humans; Male; Middle Aged; Negotiating; Nontherapeutic Human Experimentation; Online Systems; Spatial Navigation; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85078713911
"Rockstroh C., Blum J., Göritz A.S.","57209661689;57191752660;6603271342;","A mobile VR-based respiratory biofeedback game to foster diaphragmatic breathing",2020,"Virtual Reality",,,,"","",,,"10.1007/s10055-020-00471-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092085540&doi=10.1007%2fs10055-020-00471-5&partnerID=40&md5=1146e157b67d14795bff15e197391f71","Department of Occupational and Consumer Psychology, Albert-Ludwigs-Universität Freiburg, Engelbergerstr. 41, Freiburg, 79106, Germany","Rockstroh, C., Department of Occupational and Consumer Psychology, Albert-Ludwigs-Universität Freiburg, Engelbergerstr. 41, Freiburg, 79106, Germany; Blum, J., Department of Occupational and Consumer Psychology, Albert-Ludwigs-Universität Freiburg, Engelbergerstr. 41, Freiburg, 79106, Germany; Göritz, A.S., Department of Occupational and Consumer Psychology, Albert-Ludwigs-Universität Freiburg, Engelbergerstr. 41, Freiburg, 79106, Germany","Virtual reality (VR) has become popular in mental health research. Several studies have explored the use of VR in the context of biofeedback protocols. In the present paper, we report on the development and evaluation of a VR-based respiratory biofeedback game to foster diaphragmatic breathing. The game integrates respiratory biofeedback, restorative VR and gamification. The game is designed to run on a mobile, all-in-one VR headset. Notably, an integrated VR hand controller is utilized as a sensor to detect respiration-induced movements of the diaphragm. In a longitudinal within-subjects study, we explored the feasibility of the game and tested the effectiveness of six training sessions. Participants reported a pleasant user experience. Moreover, the results show that the brief VR-based breathing training increased perceived breath awareness, improved diaphragmatic breathing, increased relaxation, decreased perceived stress, reduced symptoms of burnout and boosted relaxation-related self-efficacy. Future studies need to address the generalizability and long-term stability of the results, compare the approach with existing treatments and fine-tune the training components. © 2020, The Author(s).","Diaphragmatic breathing; Respiratory biofeedback; Self-efficacy; Serious game; Stress reduction; Virtual reality","Biofeedback; User experience; Long term stability; Mental health; Self efficacy; Training sessions; Virtual reality",Article,"Article in Press","",Scopus,2-s2.0-85092085540
"Nuguri S.S., Calyam P., Oruche R., Gulhane A., Valluripally S., Stichter J., He Z.","57197736605;6507285722;57207993528;57207990715;57193485929;6602918053;7403885484;","vSocial: a cloud-based system for social virtual reality learning environment applications in special education",2020,"Multimedia Tools and Applications",,,,"","",,,"10.1007/s11042-020-09051-w","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085874226&doi=10.1007%2fs11042-020-09051-w&partnerID=40&md5=1dd676b2769f35d92da28167c6e0768d","University of Missouri, Columbia, MO, United States","Nuguri, S.S., University of Missouri, Columbia, MO, United States; Calyam, P., University of Missouri, Columbia, MO, United States; Oruche, R., University of Missouri, Columbia, MO, United States; Gulhane, A., University of Missouri, Columbia, MO, United States; Valluripally, S., University of Missouri, Columbia, MO, United States; Stichter, J., University of Missouri, Columbia, MO, United States; He, Z., University of Missouri, Columbia, MO, United States","Virtual Learning Environments (VLEs) are spaces designed to educate student groups remotely via online platforms. Although traditional VLEs have shown promise in educating students, they offer limited immersion that overall diminishes learning effectiveness. In this paper, we describe vSocial, a cloud-based virtual reality learning environment (VRLE) system that can be deployed over high-speed networks using the High Fidelity “social VR” platform. vSocial provides flexible control of group learning content and compliance with established VLE standards with improved immersive user experience for both instructor(s) and students. For our vSocial development, we build upon the use case of an existing special education VLE viz., iSocial that trains youth with Autism Spectrum Disorder by implementing the Social Competence Intervention (SCI) curriculum. The vSocial can be used to: (a) implement multiple learning modules using wearable VR technologies, (b) integrate cognitive state sensing devices, and (c) organize learning session data securely using web applications hosted on cloud resources. Our experiment results show that the VR mode of content delivery in vSocial better stimulates the generalization of lessons to the real world than non-VR lessons, and provides improved immersion when compared to an equivalent desktop version. Further, usability study results show that users can successfully use the web application features in vSocial for group learning activities with ease-of-use and consistency. © 2020, Springer Science+Business Media, LLC, part of Springer Nature.","Intelligent network services; Learning environments; Social virtual reality; Special education; Web applications","Compliance control; Computer aided instruction; HIgh speed networks; Learning systems; Regulatory compliance; Students; User experience; Virtual reality; Wearable technology; Autism spectrum disorders; Learning effectiveness; Learning sessions; Social competences; Special education; Usability studies; Virtual learning environments (VLEs); Virtual reality learning environments; E-learning",Article,"Article in Press","",Scopus,2-s2.0-85085874226
"Kandi V.R., Brittle P., Castronovo F., Gaedicke C.","57218765879;57218762256;55924007300;14007888200;","Application of a Virtual Reality Educational Game to Improve Design Review Skills",2020,"Construction Research Congress 2020: Project Management and Controls, Materials, and Contracts - Selected Papers from the Construction Research Congress 2020",,,,"545","554",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090229314&partnerID=40&md5=77556dfb26956aa5dbf78beb70671f9f","Construction Management Program, School of Engineering, California State Univ., Hayward, CA, United States","Kandi, V.R., Construction Management Program, School of Engineering, California State Univ., Hayward, CA, United States; Brittle, P., Construction Management Program, School of Engineering, California State Univ., Hayward, CA, United States; Castronovo, F., Construction Management Program, School of Engineering, California State Univ., Hayward, CA, United States; Gaedicke, C., Construction Management Program, School of Engineering, California State Univ., Hayward, CA, United States","Innovative software and technology solutions, such as building information modeling and virtual reality, are increasingly being adopted by the construction industry. One use of this technology is to utilize BIM models to perform design reviews in immersive virtual reality environments. Performing a design review, whether on paper drawings or in VR environments requires essential and strong problem-solving and evaluation skills. The objective of this paper is to support the development and education of such design review skills in undergraduate construction students using virtual reality simulation games. To achieve this objective, 32 undergraduate construction management students were asked to use the design review simulator, an educational virtual reality game designed with the learning objective of teaching design review skills. During the experiment the students were tasked with identifying noticeable design mistakes and writing down these mistakes as they were encountered. There were three basic research questions the authors were seeking to address in this experiment: 1) does playing the simulation game in VR encourage students to identify a higher number of design mistakes than evaluating the design on paper, 2) do design review skills gained from performing the design review in one mode transfer to the other alternate mode, 3) does the order in which the design review methods are implemented affect student improvements in design review skills? Based on the analysis of the results, the authors could conclude that the students gained design review skills. Through the use of the DRS the students found a significant higher number of design mistakes when performing design reviews in virtual reality, in comparison to performing design reviews using physical construction drawings. With study, the authors provide an example of how virtual reality simulation games can be leveraged in the classroom to gain design review skills. In future research, the authors will perform comparative experiments to test if the game supports higher gains in skills with knowledge tests. © 2020 American Society of Civil Engineers.",,"Architectural design; Computer aided software engineering; Construction industry; E-learning; Education computing; Project management; Virtual reality; Building Information Model - BIM; Comparative experiments; Construction drawings; Construction management; Immersive virtual reality; Learning objectives; Technology solutions; Virtual reality simulations; Students",Conference Paper,"Final","",Scopus,2-s2.0-85090229314
"Lyons K.D., Slaughenhaupt R.M., Mupparaju S.H., Lim J.S., Anderson A.A., Stankovic A.S., Cowan D.R., Fellows A.M., Binsted K.A., Buckey J.C.","57192428122;57221276743;57221276412;57221276972;57221275884;57197902798;57194430574;9939328400;8562364900;7003913960;","Autonomous Psychological Support for Isolation and Confinement",2020,"Aerospace Medicine and Human Performance","91","11",,"876","885",,,"10.3357/AMHP.5705.2020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098675681&doi=10.3357%2fAMHP.5705.2020&partnerID=40&md5=2b74ff07b83a33a189395fcdac791ada","Psychiatry Research, Dartmouth-Hitchcock Medical CenterNH, Lebanon; Space Medicine Innovations Laboratory, Geisel School of Medicine at DartmouthNH, Lebanon; Sidney Kimmel Medical College, Thomas Jefferson University, Philadelphia, PA, United States; Smead Aerospace Engineering Sciences, University of Colorado at Boulder, BoulderCO, United States; Department of Psychiatry, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Information and Computer Sciences University of Hawaii at Manoa, Honolulu, HI, United States","Lyons, K.D., Psychiatry Research, Dartmouth-Hitchcock Medical CenterNH, Lebanon; Slaughenhaupt, R.M., Space Medicine Innovations Laboratory, Geisel School of Medicine at DartmouthNH, Lebanon; Mupparaju, S.H., Sidney Kimmel Medical College, Thomas Jefferson University, Philadelphia, PA, United States; Lim, J.S., Space Medicine Innovations Laboratory, Geisel School of Medicine at DartmouthNH, Lebanon; Anderson, A.A., Smead Aerospace Engineering Sciences, University of Colorado at Boulder, BoulderCO, United States; Stankovic, A.S., Department of Psychiatry, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Cowan, D.R., Space Medicine Innovations Laboratory, Geisel School of Medicine at DartmouthNH, Lebanon; Fellows, A.M., Space Medicine Innovations Laboratory, Geisel School of Medicine at DartmouthNH, Lebanon; Binsted, K.A., Information and Computer Sciences University of Hawaii at Manoa, Honolulu, HI, United States; Buckey, J.C., Space Medicine Innovations Laboratory, Geisel School of Medicine at DartmouthNH, Lebanon","INTRODUCTION: Isolated and confined environments (ICEs), such as spaceflight, are challenging psychologically. We have been evaluating self-directed tools to sustain and improve psychological well-being in these settings. The Expedition Application for Peak Psychological Performance (Expedition-APPP) is an interactive media-based set of self-directed tools that address conflict resolution, stress management, and depression treatment. Virtual reality (VR) of nature scenes is a tool to improve attention and relieve stress by providing users with an immersive nature experience. We evaluated both Expedition-APPP and VR in an ICE. METHODS: The Expedition-APP was evaluated during three, and nature VR during two, deployments at the HI-SEAS habitat, where crews of six were isolated for 8–12 mo. Participants used both the Expedition-APPP and VR and shared their feedback and experiences after the deployments in semistructured interviews. These interviews were evaluated using qualitative analysis techniques to gather generalizable insights into implementing autonomous mental health programs for people living and working in ICEs. RESULTS: Expedition-APPP modules provided a shared culture, language, and tools for working through challenges. VR allowed for access to emotions and experiences that were unavailable in the habitat. Suggestions for improvement included making refresher training easily available and providing a wider range of content to address different individuals’ coping styles. DISCUSSION: Both the Expedition-APPP and VR were appreciated and used, although a wider range of content and experiences was desired by participants. © 2020. All Rights Reserved.","depression; mental health.; qualitative research; virtual reality","adult; article; attention; female; habitat; human; human experiment; language; male; mental health; qualitative analysis; semi structured interview; stress; virtual reality",Article,"Final","",Scopus,2-s2.0-85098675681
"Buatois A., Laroche L., Lafon G., Avarguès-Weber A., Giurfa M.","57190951756;57213609979;57215795678;35721565900;7003298526;","Higher-order discrimination learning by honeybees in a virtual environment",2020,"European Journal of Neuroscience","51","2",,"681","694",,3,"10.1111/ejn.14633","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077888991&doi=10.1111%2fejn.14633&partnerID=40&md5=931bd01a046412d41efdbd4bdf902e76","Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse Cedex 09, France; College of Animal Science (College of Bee Science), Fujian Agriculture and Forestry University, Fuzhou, China; Institut Universitaire de France (IUF), France","Buatois, A., Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse Cedex 09, France; Laroche, L., Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse Cedex 09, France; Lafon, G., Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse Cedex 09, France; Avarguès-Weber, A., Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse Cedex 09, France; Giurfa, M., Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse Cedex 09, France, College of Animal Science (College of Bee Science), Fujian Agriculture and Forestry University, Fuzhou, China, Institut Universitaire de France (IUF), France","Non-elemental learning constitutes a cognitive challenge because events to be learned are usually ambiguous in terms of reinforcement outcome, contrary to elemental learning, which relies on unambiguous associations. Negative patterning (NP) constitutes a paradigmatic case of non-elemental learning, as subjects have to learn that single elements are reinforced while their simultaneous presentation is not reinforced (A+, B+ vs. AB−). Solving NP requires treating AB as being different from the linear sum of its components in order to overcome the ambiguity of stimulus reinforcement (i.e. A and B are as often reinforced as not reinforced). The honeybee is currently the only insect mastering NP as shown by studies restricted mainly to the olfactory domain. Here, we tested the bees' capacity to solve a NP discrimination in the visual domain and used to this end a virtual reality (VR) environment in which a tethered bee walking stationary on a spherical treadmill faces visual stimuli projected on a semicircular screen. We show that bees learn a composite grating made of alternated green and blue bars in an elemental way, and generalize their response to both a blue and a green grating. Yet, after NP training, one-quarter of the bees inhibited elemental processing and responded significantly more to the single-coloured gratings than to the composite grating. Alternative strategies were used by the other bees, which achieved partial NP learning. These results offer attractive perspectives to study different forms of visual learning in a controlled VR environment, and dissect their underlying mechanisms. © 2019 Federation of European Neuroscience Societies and John Wiley & Sons Ltd","insect learning; negative patterning; non-elemental learning; virtual reality; visual cognition; visual learning","Article; controlled study; discrimination learning; evoked response; honeybee; negative patterning; nonhuman; priority journal; spatial summation; training; virtual reality; visual learning; visual stimulation; walking speed",Article,"Final","",Scopus,2-s2.0-85077888991
"Schwarze A., Kampling H., Niehaves B.","57217049797;57189869875;12139031400;","Advantages and propositions of learning emotion recognition in virtual reality for people with austism",2020,"27th European Conference on Information Systems - Information Systems for a Sharing Society, ECIS 2019",,,,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087108839&partnerID=40&md5=3f886071823c7f5052fd3f89580e1d9f","University of Siegen, Siegen, Germany","Schwarze, A., University of Siegen, Siegen, Germany; Kampling, H., University of Siegen, Siegen, Germany; Niehaves, B., University of Siegen, Siegen, Germany","People with an autism spectrum disorder face the daily challenge of social interactions - particularly in non-verbal communication. These difficulties make adequate interpersonal interactions “in real-time” a challenging obstacle to overcome in many cases and can lead to excessive demands, frustration and isolation (low level of Theory of Mind). Emotion cards are usually used in autism therapy to learn basic skills for recognizing emotions. Learning with autism is characterized by spontaneous - sometimes-extraordinary - mastery of complex contents. People with autism learn facts, details and routines well but have difficulties to transfer the learned contents to another context (Weak Central Coherence) or to react flexible to unpredicted events (low Executive Function). In addition, research has shown that autistics learn social competences while using a computer and performing practical exercises. Such systems provide the possibility to use an accepted computer simulated (virtual) environment in which autistic children can be taught social competences as emotion recognition. Consequently, we assume that learning emotion recognition in virtual learning environments can remove barriers and obstacles for autistics as they are more successful in solving social problems. Therefore, we are discussing in the paper at hand the potentials of how emotion recognition can be learned in virtual reality. © 27th European Conference on Information Systems - Information Systems for a Sharing Society, ECIS 2019. All rights reserved.","Autism; Case Study Research; Emotion Recognition Learning; Virtual Reality","Diseases; E-learning; Information systems; Information use; Speech recognition; Virtual reality; Autism spectrum disorders; Emotion recognition; Non-verbal communications; Recognizing emotions; Social competences; Social interactions; Virtual learning environments; Weak central coherences; Computer aided instruction",Conference Paper,"Final","",Scopus,2-s2.0-85087108839
"Stock S.C., Armengol-Urpi A., Kovács B., Maier H., Gerdes M., Stork W., Sarma S.E.","57205642330;57205652758;57216646432;57216648269;57216649677;7003711649;7102934487;","A system approach for closed-loop assessment of neuro-visual function based on convolutional neural network analysis of EEG signals",2020,"Proceedings of SPIE - The International Society for Optical Engineering","11360",, 1136008,"","",,2,"10.1117/12.2554417","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084177859&doi=10.1117%2f12.2554417&partnerID=40&md5=bde5b8fac5c55959dc092d5f6bc302a0","Karlsruhe Institute of Technology, Germany; Massachusetts Institute of Technology, United States","Stock, S.C., Karlsruhe Institute of Technology, Germany; Armengol-Urpi, A., Massachusetts Institute of Technology, United States; Kovács, B., Karlsruhe Institute of Technology, Germany; Maier, H., Karlsruhe Institute of Technology, Germany; Gerdes, M., Karlsruhe Institute of Technology, Germany; Stork, W., Karlsruhe Institute of Technology, Germany; Sarma, S.E., Massachusetts Institute of Technology, United States","We propose a generalized, modular, closed-loop system for objective assessment of human visual parameters. Our system presents periodical visual stimuli to the patient's field of view and analyses the consequent evoked brain potentials elicited in the occipital lobe and recorded through EEG. The analysis of the monitored EEG data is performed in an end-to-end fashion by a convolutional neural network (CNN). We propose a novel CNN architecture for EEG signal analysis that can be trained utilizing the benefits of multi-task learning. The closedloop attribute of our system allows for a real-time adaptation of the subsequent stimuli to further examine a potentially damaged area or increase the granularity of the exploration. Interchangeability is provided in terms of software modules, stimulus type, visual hardware, EEG acquisition device and EEG electrodes. Initially, the system is designed to monitor visual field loss originating from glaucoma or damage to the optic nerve using a virtual reality (VR) headset for the stimuli presentation. The modular architecture of our system paves the way for the assessment and monitoring of other neuro-visual functions. © 2020 SPIE.","Brain-computer-interface; Convolutional neural networks; Deep learning; EEG; Neuroscience; Ophthalmology; System design","Closed loop systems; Convolution; Eye protection; Multi-task learning; Network architecture; Signal analysis; Virtual reality; Assessment and monitoring; Eeg acquisitions; Modular architectures; Objective assessment; Real-time adaptation; Software modules; System approach; Visual functions; Convolutional neural networks",Conference Paper,"Final","",Scopus,2-s2.0-85084177859
"Panchenko L.F., Muzyka I.O.","57210124439;56768036800;","Analytical review of augmented reality MOOCs",2020,"CEUR Workshop Proceedings","2547",,,"168","180",,8,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079571403&partnerID=40&md5=a1a96532d1e6dec292a88b4cf89f9478","National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute”, 37, Peremohy Ave., Kyiv, 03056, Ukraine; Kryvyi Rih National University, 11, Vitaliy Matusevych Str., Kryvyi Rih, 50027, Ukraine","Panchenko, L.F., National Technical University of Ukraine “Igor Sikorsky Kyiv Polytechnic Institute”, 37, Peremohy Ave., Kyiv, 03056, Ukraine; Muzyka, I.O., Kryvyi Rih National University, 11, Vitaliy Matusevych Str., Kryvyi Rih, 50027, Ukraine","The aim of the article is to provide an analytical review of the content of massive open online courses about augmented reality and its use in education with the further intent to create a special course for the professional development system for the research and teaching personnel in postgraduate education. The object of research is massive open online courses. The subject of the study is the structure and content of augmented reality MOOCs which are offered by acclaimed providers of the world. The methods of research are: the analysis of publications on the problem; the analysis of MOOCs’ content, including observation; systematization and generalization of research information in order to design a special course about augmented reality for the system of professional training and retraining for educators in postgraduate education. The results of the research are the following: the content and program of specialized course “Augmented Reality as a Storytelling Tool” for the professional development of teachers. The purpose of the specialized course is to consider and discuss the possibilities of augmented reality as a new direction in the development of educational resources, to identify its benefits and constraints, as well as its components and the most appropriate tools for educators, to discuss the problems of teacher and student co-creation on the basis of the use of augmented reality, and to provide students with personal experience in designing their own stories and methodical tools in the form of augmented books and supplementary training aids with the help of modern digital services. Copyright © 2020 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).","Augmented books; Augmented reality; Massive open online courses; Professional training; Retraining","Augmented reality; E-learning; Information services; Personnel training; Professional aspects; Students; Teaching; Augmented book; Massive open online course; Methods of researches; Postgraduate education; Professional development; Professional development of teachers; Professional training; Retraining; Curricula",Conference Paper,"Final","",Scopus,2-s2.0-85079571403
"Coelho A., Cardoso P., Van Zeller M., Santos L., Raimundo J., Vaz R.","23089899600;57192416173;57217996598;57217605046;57216526950;57220402899;","Gamifying the museological experience",2020,"CEUR Workshop Proceedings","2618",,,"5","8",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087832942&partnerID=40&md5=e6609bfec2f83285b55a85e428879493","FEUP, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal; FBAUP, Faculty of Fine Arts, University of Porto, Avenida Rodrigues de Freitas, 265, Porto, 4049-021, Portugal; INESC TEC, Institute for Systems and Computer Engineering, Technology and Science, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal","Coelho, A., FEUP, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal, INESC TEC, Institute for Systems and Computer Engineering, Technology and Science, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal; Cardoso, P., FEUP, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal, FBAUP, Faculty of Fine Arts, University of Porto, Avenida Rodrigues de Freitas, 265, Porto, 4049-021, Portugal, INESC TEC, Institute for Systems and Computer Engineering, Technology and Science, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal; Van Zeller, M., FEUP, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal; Santos, L., FEUP, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal; Raimundo, J., FEUP, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal, INESC TEC, Institute for Systems and Computer Engineering, Technology and Science, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal; Vaz, R., FEUP, Faculty of Engineering, University of Porto, Rua Dr. Roberto Frias, Porto, 4200-465, Portugal","Museums continue to exert fascination in their visitors. However, the new generation of visitors expects museological experiences that promote their active participation. It is in this context that games and the gamification of such experiences capitalize on experiential learning by experimenting and enacting with in-game embedded artefact surrogates and know-how. In this article, we present four distinct projects that aim to enhance the visitors' experience in museums and green spaces, and also their effectiveness in informal learning. In the first project, gamification is used in combination with Augmented Reality to provide a more engaging experience in a boat museum. The drive of this experience is the metaphor of the stickers album collection to unleash the relevant information of the key-artefacts of the museum collection. The second and third projects focus on the use of pervasive games, more specifically location-based games, to enhance the visitors' experience and informal learning in a natural park and a botanical garden, respectively. The second project presents the concept of a mobile app for outdoor nature experiences. The drive for the experience in the third project is the narrative that intertwines specific locations in the botanic garden and a story inspired by the same place. Finally, in the fourth project, we focus on the potential of technology to provide accessibility in museums for people with special needs or disability, focusing more specifically on blind visitors. Copyright © 2020 for this paper by its authors.","Accessibility; Augmented Reality; Gamification; Location-based games; Pervasive games","Augmented reality; Gamification; Human computer interaction; Technology transfer; Botanical gardens; Experiential learning; Informal learning; Location based games; Museum collections; Pervasive game; Special needs; Specific location; Museums",Conference Paper,"Final","",Scopus,2-s2.0-85087832942
"Andersen S.A.W., Park Y.S., Sørensen M.Sø., Konge L.","56109501200;57216530811;35511725400;36704959000;","Reliable Assessment of Surgical Technical Skills Is Dependent on Context: An Exploration of Different Variables Using Generalizability Theory",2020,"Academic Medicine",,,,"1929","1936",,,"10.1097/ACM.0000000000003550","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096886868&doi=10.1097%2fACM.0000000000003550&partnerID=40&md5=8293270e2809800ce44c41468176f0a8","Copenhagen Academy for Medical Education and Simulation (CAMES), Center for HR and Education, Capital Region of Denmark, and Otorhinolaryngology Resident, Department of Otorhinolaryngology-Head and Neck Surgery, Rigshospitalet, Blegdamsvej 9, Copenhagen, DK-2100, Denmark; Department of Medical Education, University of Illinois, College of Medicine at Chicago, Chicago, IL, United States","Andersen, S.A.W., Copenhagen Academy for Medical Education and Simulation (CAMES), Center for HR and Education, Capital Region of Denmark, and Otorhinolaryngology Resident, Department of Otorhinolaryngology-Head and Neck Surgery, Rigshospitalet, Blegdamsvej 9, Copenhagen, DK-2100, Denmark; Park, Y.S., Department of Medical Education, University of Illinois, College of Medicine at Chicago, Chicago, IL, United States; Sørensen, M.Sø., Department of Medical Education, University of Illinois, College of Medicine at Chicago, Chicago, IL, United States; Konge, L., Copenhagen Academy for Medical Education and Simulation (CAMES), Center for HR and Education, Capital Region of Denmark, and Otorhinolaryngology Resident, Department of Otorhinolaryngology-Head and Neck Surgery, Rigshospitalet, Blegdamsvej 9, Copenhagen, DK-2100, Denmark","Purpose Reliable assessment of surgical skills is vital for competency-based medical training. Several factors influence not only the reliability of judgments but also the number of observations needed for making judgments of competency that are both consistent and reproducible. The aim of this study was to explore the role of various conditions-through the analysis of data from large-scale, simulation-based assessments of surgical technical skills-by examining the effects of those conditions on reliability using generalizability theory. Method Assessment data from large-scale, simulation-based temporal bone surgical training research studies in 2012-2018 were pooled, yielding collectively 3,574 assessments of 1,723 performances. The authors conducted generalizability analyses using an unbalanced random-effects design, and they performed decision studies to explore the effect of the different variables on projections of reliability. Results Overall, 5 observations were needed to achieve a generalizability coefficient > 0.8. Several variables modified the projections of reliability: Increased learner experience necessitated more observations (5 for medical students, 7 for residents, and 8 for experienced surgeons), the more complex cadaveric dissection required fewer observations than virtual reality simulation (2 vs 5 observations), and increased fidelity simulation graphics reduced the number of observations needed from 7 to 4. The training structure (either massed or distributed practice) and simulator-integrated tutoring had little effect on reliability. Finally, more observations were needed during initial training when the learning curve was steepest (6 observations) compared with the plateau phase (4 observations). Conclusions Reliability in surgical skills assessment seems less stable than it is often reported to be. Training context and conditions influence reliability. The findings from this study highlight that medical educators should exercise caution when using a specific simulation-based assessment in other contexts. © 2020 by the Association of American Medical Colleges.",,"clinical competence; education; human; learning curve; orthopedic surgery; reproducibility; simulation training; surgery; temporal bone; Clinical Competence; Humans; Learning Curve; Orthopedic Procedures; Reproducibility of Results; Simulation Training; Temporal Bone",Article,"Article in Press","",Scopus,2-s2.0-85096886868
"Papanastasiou G., Drigas A., Skianis C., Lytras M., Papanastasiou E.","56205162600;8662839500;15124619200;55830169000;57195954324;","Virtual and augmented reality effects on K-12, higher and tertiary education students’ twenty-first century skills",2019,"Virtual Reality","23","4",,"425","436",,21,"10.1007/s10055-018-0363-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053216727&doi=10.1007%2fs10055-018-0363-2&partnerID=40&md5=8c4e5953263f908e07bb10c44dfd8d19","NCSR Demokritos, Patr. Gregoriou E’ & 27, Neapoleos str., Agia Paraskevi, 15341, Greece; University of Aegean, Karlovassi, Samos, 83200, Greece; The American College of Greece, 6 Gravias str., Agia Paraskevi, 15342, Greece; King Abdulaziz University, Jeddah, Saudi Arabia; National Technical University of Athens, Zografou Campus 9, Iroon Polytechniou str., Athens, 15780, Greece","Papanastasiou, G., NCSR Demokritos, Patr. Gregoriou E’ & 27, Neapoleos str., Agia Paraskevi, 15341, Greece, University of Aegean, Karlovassi, Samos, 83200, Greece; Drigas, A., NCSR Demokritos, Patr. Gregoriou E’ & 27, Neapoleos str., Agia Paraskevi, 15341, Greece; Skianis, C., University of Aegean, Karlovassi, Samos, 83200, Greece; Lytras, M., The American College of Greece, 6 Gravias str., Agia Paraskevi, 15342, Greece, King Abdulaziz University, Jeddah, Saudi Arabia; Papanastasiou, E., National Technical University of Athens, Zografou Campus 9, Iroon Polytechniou str., Athens, 15780, Greece","The purpose of this review article is to present state-of-the-art approaches and examples of virtual reality/augmented reality (VR/AR) systems, applications and experiences which improve student learning and the generalization of skills to the real world. Thus, we provide a brief, representative and non-exhaustive review of the current research studies, in order to examine the effects, as well as the impact of VR/AR technologies on K-12, higher and tertiary education students’ twenty-first century skills and their overall learning. According to the literature, there are promising results indicating that VR/AR environments improve learning outcomes and present numerous advantages of investing time and financial resources in K-12, higher and tertiary educational settings. Technological tools such as VR/AR improve digital-age literacy, creative thinking, communication, collaboration and problem solving ability, which constitute the so-called twenty-first century skills, necessary to transform information rather than just receive it. VR/AR enhances traditional curricula in order to enable diverse learning needs of students. Research and development relative to VR/AR technology is focused on a whole ecosystem around smart phones, including applications and educational content, games and social networks, creating immersive three-dimensional spatial experiences addressing new ways of human–computer interaction. Raising the level of engagement, promoting self-learning, enabling multi-sensory learning, enhancing spatial ability, confidence and enjoyment, promoting student-centered technology, combination of virtual and real objects in a real setting and decreasing cognitive load are some of the pedagogical advantages discussed. Additionally, implications of a growing VR/AR industry investment in educational sector are provided. It can be concluded that despite the fact that there are various barriers and challenges in front of the adoption of virtual reality on educational practices, VR/AR applications provide an effective tool to enhance learning and memory, as they provide immersed multimodal environments enriched by multiple sensory features. © 2018, Springer-Verlag London Ltd., part of Springer Nature.","Higher education; K-12; Tertiary education; Twenty-first century skills; Virtual and augmented reality","Augmented reality; Computer games; E-learning; Human computer interaction; Problem solving; Smartphones; Social sciences computing; Virtual reality; Higher education; Multi-sensory learning; Problem-solving abilities; Research and development; State-of-the-art approach; Tertiary education; Twenty-first century skills; Virtual and augmented reality; Students",Article,"Final","",Scopus,2-s2.0-85053216727
"Makransky G., Borre-Gude S., Mayer R.E.","50361371800;57209681979;7403065717;","Motivational and cognitive benefits of training in immersive virtual reality based on multiple assessments",2019,"Journal of Computer Assisted Learning","35","6",,"691","707",,36,"10.1111/jcal.12375","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067604165&doi=10.1111%2fjcal.12375&partnerID=40&md5=4254d76dbce5eee871a9f331659adb0f","Department of Psychology, University of Copenhagen, Copenhagen, Denmark; School of Engineering, University of Aarhus, Aarhus, Denmark; Department of Psychological and Brain Sciences, University of California, Santa Barbara, Santa Barbara, CA, United States","Makransky, G., Department of Psychology, University of Copenhagen, Copenhagen, Denmark; Borre-Gude, S., School of Engineering, University of Aarhus, Aarhus, Denmark; Mayer, R.E., Department of Psychological and Brain Sciences, University of California, Santa Barbara, Santa Barbara, CA, United States","The main objective of this study was to examine the effectiveness of immersive virtual reality (VR) as a medium for delivering laboratory safety training. We specifically compare an immersive VR simulation, a desktop VR simulation, and a conventional safety manual. The sample included 105 first year undergraduate engineering students (56 females). We include five types of learning outcomes including post-test enjoyment ratings; pre- to post-test changes in intrinsic motivation and self-efficacy; a post-test multiple choice retention test; and two behavioral transfer tests. Results indicated that the groups did not differ on the immediate retention test, suggesting that all three media were equivalent in conveying the basic knowledge. However, significant differences were observed favoring the immersive VR group compared to the text group on the two transfer tests involving the solving problems in a physical lab setting (d = 0.54, d = 0.57), as well as enjoyment (d = 1.44) and increases in intrinsic motivation (d = 0.69) and self-efficacy (d = 0.60). The desktop VR group scored significantly higher than the text group on one transfer test (d = 0.63) but not the other (d= 0.11), as well as enjoyment (d =1.11) and intrinsic motivation (d =0.83). © 2019 John Wiley & Sons Ltd","delayed transfer test; multimedia learning; safety training; simulation; virtual reality",,Article,"Final","",Scopus,2-s2.0-85067604165
"Abidi M.H., Al-Ahmari A., Ahmad A., Ameen W., Alkhalefah H.","55582207400;6603483674;8244331200;56789986100;57203434201;","Assessment of virtual reality-based manufacturing assembly training system",2019,"International Journal of Advanced Manufacturing Technology","105","9",,"3743","3759",,12,"10.1007/s00170-019-03801-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066028866&doi=10.1007%2fs00170-019-03801-3&partnerID=40&md5=eb3341de426ddac10e671c4a1662aee4","Raytheon Chair for Systems Engineering (RCSE Chair), Advanced Manufacturing Institute, King Saud University, Riyadh, 11421, Saudi Arabia; Industrial Engineering Department, College of Engineering, King Saud University, Riyadh, 11421, Saudi Arabia; Louisiana Community and Technical College System-Manufacturing Extension Partnership, Baton Rouge, LA, United States; Advanced Manufacturing Institute, King Saud University, Riyadh, 11421, Saudi Arabia","Abidi, M.H., Raytheon Chair for Systems Engineering (RCSE Chair), Advanced Manufacturing Institute, King Saud University, Riyadh, 11421, Saudi Arabia, Industrial Engineering Department, College of Engineering, King Saud University, Riyadh, 11421, Saudi Arabia; Al-Ahmari, A., Raytheon Chair for Systems Engineering (RCSE Chair), Advanced Manufacturing Institute, King Saud University, Riyadh, 11421, Saudi Arabia, Industrial Engineering Department, College of Engineering, King Saud University, Riyadh, 11421, Saudi Arabia; Ahmad, A., Louisiana Community and Technical College System-Manufacturing Extension Partnership, Baton Rouge, LA, United States; Ameen, W., Raytheon Chair for Systems Engineering (RCSE Chair), Advanced Manufacturing Institute, King Saud University, Riyadh, 11421, Saudi Arabia; Alkhalefah, H., Advanced Manufacturing Institute, King Saud University, Riyadh, 11421, Saudi Arabia","Digital manufacturing concept is gaining a lot of attention and popularity due to its enormous benefits. It is considered as one of the pillars or component of Industry 4.0. With the advancements in technology, digital manufacturing is becoming a reality rather than a concept only. It is applied to various stages of the manufacturing process such as design, prototyping, and assembly training. Virtual reality (VR) is a cog in a wheel of digital manufacturing. It can be used in various phases of manufacturing. Planning and conducting assembly operations account for the majority of the cost of a product. It is difficult to design and train assembly operations during the early stages of product design. Assembly is a vital step in manufacturing, so firms provide training to their employees and it costs them time and money. Therefore, this research work extends VR applications in manufacturing by integrating concepts and studies from training simulations to the evaluation of assembly training effectiveness and transfer of training. VR provides a platform for “learning by doing” instead of learning by seeing, listening, or observing. A series of user-based evaluation studies are conducted to ensure that the virtual manufacturing assembly simulation provides an effective and efficient means for evaluating assembly operations and for training assembly personnel. Different feedback cues of VR are implemented to evaluate the system. Moreover, several case studies are used to assess the effectiveness of VR-based training. The results of the study reveal that participants trained by VR committed fewer errors and took lesser time in actual product assembly when compared against the participant from traditional or baseline training group. © 2019, Springer-Verlag London Ltd., part of Springer Nature.","Assembly training; Industry 4.0; Manufacturing assembly; Virtual Reality","Agile manufacturing systems; E-learning; Industrial research; Industry 4.0; Personnel training; Product design; Virtual reality; Assembly operations; Assembly trainings; Digital manufacturing; Manufacturing assembly; Manufacturing process; Transfer of trainings; User-based evaluations; Virtual manufacturing; Assembly",Article,"Final","",Scopus,2-s2.0-85066028866
"Shi Y., Du J.","57189999728;57219889677;","Simulation of Spatial Memory for Human Navigation Based on Visual Attention in Floorplan Review",2019,"Proceedings - Winter Simulation Conference","2019-December",, 9004783,"3031","3040",,1,"10.1109/WSC40007.2019.9004783","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081124854&doi=10.1109%2fWSC40007.2019.9004783&partnerID=40&md5=558fedad8dd7b812c1d9056972537659","University of Florida, Department of Civil and Coastal Engineering, Gainesville, FL  32611, United States","Shi, Y., University of Florida, Department of Civil and Coastal Engineering, Gainesville, FL  32611, United States; Du, J., University of Florida, Department of Civil and Coastal Engineering, Gainesville, FL  32611, United States","Human navigation simulation is critical to many civil engineering tasks and is of central interest to the simulation community. Most human navigation simulation approaches focus on the classic psychology evidence, or assumptions that still need further proofs. The overly simplified and generalized assumption of navigation behaviors does not highlight the need of capturing individual differences in spatial cognition and navigation decision-making, or the impacts of diverse ways of spatial information display. This study proposes the visual attention patterns in floorplan review to be a stronger predictor of human navigation behaviors. To set the theoretical foundation, a Virtual Reality (VR) experiment was performed to test if visual attention patterns during spatial information review can predict the quality of spatial memory, and how the relationship is affected by the diverse ways of information display, including 2D, 3D and VR. The results set a basis for future prediction model developments. © 2019 IEEE.",,"Decision making; Navigation; Virtual reality; Future predictions; Human navigation; Individual Differences; Information display; Navigation behavior; Spatial cognition; Spatial informations; Theoretical foundations; Behavioral research",Conference Paper,"Final","",Scopus,2-s2.0-85081124854
"Wdowik R., Ratnayake R.M.C.","56436715600;53881139600;","Collaborative Technological Process Planning with 5G Mobile Networks and Digital Tools: Manufacturing Environments' Perspective",2019,"IEEE International Conference on Industrial Engineering and Engineering Management",,, 8978721,"349","353",,2,"10.1109/IEEM44572.2019.8978721","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079694820&doi=10.1109%2fIEEM44572.2019.8978721&partnerID=40&md5=4e41a315c17e09bb84ce26b5408d05c0","Faculty of Mechanical Engineering and Aeronautics, Rzeszów University of Technology, Poland; University of Stavanger, Department of Mechanical and Structural Engineering and Materials Science, Norway","Wdowik, R., Faculty of Mechanical Engineering and Aeronautics, Rzeszów University of Technology, Poland; Ratnayake, R.M.C., University of Stavanger, Department of Mechanical and Structural Engineering and Materials Science, Norway","Technological process planning (TPP) requires an adaptation to the newest industrial trends, such as virtual reality (VR), mobile communication networks (e.g. Fifth Generation (5G) networks), Internet of Things (IoT), etc., to satisfy the frequently changing product demands in different manufacturing environments. TPP also uses the best practices, knowledge of experts and various digital tools (DTs), which have been implemented as software or hardware digital solutions, helping to achieve the anticipated production aims in the digital era. The DTs have been developed in parallel to the latest industrial trends. This paper presents the general notion of a collaborative technological process planning approach (CTPPA), taking into account the capabilities of the latest developments in mobile communication techniques such as 5G mobile networks. It also discusses the levels of communication within a manufacturing environment and several scenarios of the CTPPA, by considering TPP performance. Finally, it presents how the new 5G technology and new DTs can enhance TPP in the near future. It also demonstrates how faster data transfer can change the functionalities of existing DTs and redefine TPP methodologies. © 2019 IEEE.","5G networks; digital tools; digitalization; technological process planning","Data transfer; Digital devices; Internet of things; Manufacture; Mobile telecommunication systems; Process planning; Virtual reality; Wireless networks; Digital tools; digitalization; G-networks; Internet of Things (IOT); Manufacturing environments; Mobile communication networks; Mobile communications; Technological process; 5G mobile communication systems",Conference Paper,"Final","",Scopus,2-s2.0-85079694820
"Moriyama T., Asazu H., Takahashi A., Kajimoto H.","57202339848;6506297693;57195231000;6602141526;","Simple is vest: High-density tactile vest that realizes tactile transfer of fingers",2019,"SIGGRAPH Asia 2019 Emerging Technologies, SA 2019",,,,"42","43",,3,"10.1145/3355049.3360532","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076672766&doi=10.1145%2f3355049.3360532&partnerID=40&md5=4fb9058399b8282d250c118fdd67b102","University of Electro-Communications, Japan","Moriyama, T., University of Electro-Communications, Japan; Asazu, H., University of Electro-Communications, Japan; Takahashi, A., University of Electro-Communications, Japan; Kajimoto, H., University of Electro-Communications, Japan","We developed a high-density tactile vest that presents the haptic sensation of the five fingertips to the back rather than to the fingertip as a new haptic presentation method for objects in a virtual reality (VR) environment. The device adopts 144 eccentric mass vibration motors actuated individually and five Peltier elements. The voice coils present the contact points on the finger to the back and abdomen. When holding an object with fingers in VR scene, the sense of touch is presented to the wide area of the abdomen and back, so an accurate sense of which part of the finger is contacted can be comprehended. Compared with a fingertip-mounted display, it is possible to address issues of weight and size that hinder the free movement of fingers, while high-density distributed information can be presented. Furthermore, abdomen and back are totally free space in typical VR scenarios. © 2019 Copyright held by the owner/author(s).","Haptic devices; Vibrators","Vibrators; Virtual reality; Contact points; Distributed information; Eccentric mass; Haptic devices; Haptic sensation; Peltier elements; Sense of touch; Vibration motor; Interactive computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-85076672766
"Pietroszek K.","18037978700;","IRIS: Inter-reality intera",2019,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,, 3364731,"","",,1,"10.1145/3359996.3364731","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076146923&doi=10.1145%2f3359996.3364731&partnerID=40&md5=80b95c0fc86c12ee4478f0edc589963f","IDEAS Lab, American University, Washington, DC, United States","Pietroszek, K., IDEAS Lab, American University, Washington, DC, United States","While many metaphors were developed for interactions from a specific point at the reality-virtuality continuum, much less attention has been paid to designing metaphors that allow the users to cross the boundaries between the virtual, the augmented, and the real. We propose a use of an Inter-Reality Interactive Surface (IRIS) that enables users to collaborate across the reality-virtuality continuum within the same application. While we examine IRIS in the context of an immersive educational platform, UniVResity, the metaphor can be generalized to many other application domains. © 2019 Copyright held by the owner/author(s).","Augmented reality; Collaboration; Immersive learning; Interaction metaphor; Reality-virtuality continuum; Virtual reality","Augmented reality; Collaboration; Educational platforms; Immersive; Immersive learning; Interaction metaphors; Interactive surfaces; Virtuality continuum; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85076146923
"Pagé C., Bernier P.-M., Trempe M.","57209732350;9736834900;24176388500;","Using video simulations and virtual reality to improve decision-making skills in basketball",2019,"Journal of Sports Sciences","37","21",,"2403","2410",,8,"10.1080/02640414.2019.1638193","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068539753&doi=10.1080%2f02640414.2019.1638193&partnerID=40&md5=5a64e3c17e48958a6dbc864eb3fccefa","Département de kinanthropologie, Faculté des sciences de l’activité physique, Université de Sherbrooke, Sherbrooke, QC, Canada; Department of Sports Studies, Bishop’s University, Sherbrooke, QC, Canada","Pagé, C., Département de kinanthropologie, Faculté des sciences de l’activité physique, Université de Sherbrooke, Sherbrooke, QC, Canada; Bernier, P.-M., Département de kinanthropologie, Faculté des sciences de l’activité physique, Université de Sherbrooke, Sherbrooke, QC, Canada; Trempe, M., Département de kinanthropologie, Faculté des sciences de l’activité physique, Université de Sherbrooke, Sherbrooke, QC, Canada, Department of Sports Studies, Bishop’s University, Sherbrooke, QC, Canada","A large body of literature supports the effectiveness of using video simulations to improve decision-making skills in invasion sports. However, whether these improvements are transferable (from the laboratory to the court/field) and generalizable (from trained to untrained plays) remains unknown. In addition, it remains to be determined whether presenting the video simulations using virtual reality provides an added-value. To investigate these questions, varsity-level basketball players underwent four training sessions during which they observed video clips of basketball plays presented either on a computer screen (CS group) or using a virtual reality headset (VR group). A third group watched footage from NCAA playoff games on a computer screen (CTRL group). Decision-making was assessed on-court before and after the training sessions using two types of plays: “trained” plays (presented during the CS and VR training sessions) and “untrained” plays (presented only during the on-court tests). When facing the trained plays in the posttest, both VR and CS groups significantly outperformed the CTRL group. In contrast, when facing the untrained plays, the VR group outperformed both the CS and CTRL groups. Our results indicate that CS training leads to transferable but non-generalized decision-making gains while VR training leads to transferable and generalized gains. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","Decision-making; learning generalization; learning transfer; video simulation training; virtual reality","article; basketball player; court; decision making; human; simulation training; skill; transfer of learning; videorecording; virtual reality; adolescent; adult; basketball; female; male; motor performance; psychology; young adult; Adolescent; Adult; Basketball; Decision Making; Female; Generalization, Psychological; Humans; Male; Motor Skills; Transfer, Psychology; Video Recording; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85068539753
"Zou Y., Wang P., Tang Q., Sun Y.","57217006652;57217006341;57217400762;57217004882;","Implement Multi-Character Display in Virtual Reality Environment Based on Unet and Tracker",2019,"Proceedings - 2019 2nd International Conference on Safety Produce Informatization, IICSPI 2019",,, 9096025,"530","532",,,"10.1109/IICSPI48186.2019.9096025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085683784&doi=10.1109%2fIICSPI48186.2019.9096025&partnerID=40&md5=c77d19ebaa5c757cccf48ac7163524b2","Zunyi Power Supply Bureau, Safety Supervision Department, Zunyi, Guizhou, China","Zou, Y., Zunyi Power Supply Bureau, Safety Supervision Department, Zunyi, Guizhou, China; Wang, P., Zunyi Power Supply Bureau, Safety Supervision Department, Zunyi, Guizhou, China; Tang, Q., Zunyi Power Supply Bureau, Safety Supervision Department, Zunyi, Guizhou, China; Sun, Y., Zunyi Power Supply Bureau, Safety Supervision Department, Zunyi, Guizhou, China","Power grid operation is a very safe operation site, it is very important to be able to carry out related operations in accordance with the safe operation process, the existing traditional safe operation process, mainly in the traditional teaching mode or simulated real scene operation mode. In the links of management and training, operators lack intuitive experience and interaction, and they are not enough to show the serious consequences of illegal operation; As the head-mounted display becomes the most important interactive virtual reality display device, the 3d interactive display and the expressive force of the game engine are gradually improved, significantly improving participants' sense of immersion. Virtual reality technology can be used to build a simulation teaching platform for authentic visual experience, authentic representation of work flow and convincing interactive feedback. Virtual reality technology is used to establish a practical environment for grid operation in the virtual three-dimensional space of the computer that integrates class a illegal operation events. Users participating in the learning practice can operate in the virtual space according to the process. In this paper, based on unity built-in HAPI unet and third-party plug-in VRTK, the complex interaction of large-scale training business process is realized. Through VRTK, steam VR interface, the handle button state is obtained and information is transmitted on multiple instances, so as to determine the transfer and pickup state of interactive objects. © 2019 IEEE.","Inverse dynamics; Multiplayer networking technology; Multiplayer online interaction; Virtual reality technology","Crime; Electric power transmission networks; Helmet mounted displays; Interface states; Personnel training; Simulation platform; Head mounted displays; Interactive feedback; Interactive virtual reality; Power grid operations; Simulation teachings; Three dimensional space; Virtual reality technology; Virtual-reality environment; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85085683784
"Piccione J., Collett J., De Foe A.","57211538030;57206464821;55555885000;","Virtual skills training: the role of presence and agency",2019,"Heliyon","5","11", e02583,"","",,6,"10.1016/j.heliyon.2019.e02583","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074370179&doi=10.1016%2fj.heliyon.2019.e02583&partnerID=40&md5=41c139affc0f49a955d0d2674602e6aa","RMIT University, School of Health and Biomedical Sciences, Discipline of Psychology, Australia","Piccione, J., RMIT University, School of Health and Biomedical Sciences, Discipline of Psychology, Australia; Collett, J., RMIT University, School of Health and Biomedical Sciences, Discipline of Psychology, Australia; De Foe, A., RMIT University, School of Health and Biomedical Sciences, Discipline of Psychology, Australia","Virtual reality (VR) simulations provide increased feelings of presence and agency that could allow increased skill improvement during VR training. Direct relationships between active agency in VR and skill improvement have previously not been investigated. This study examined the relationship between (a) presence and agency, and (b) presence and skills improvement, via active and passive VR simulations and through measuring real-world golf-putting skill. Participants (n = 23) completed baseline putting skill assessment before using an Oculus Rift VR head-mounted display to complete active (putting with a virtual golf club) and passive (watching a game of golf) VR simulations. Measures of presence and agency were administered after each simulation, followed by a final putting skill assessment. The active simulation induced higher feelings of general presence and agency. However, no relationship was identified between presence and either agency or skill improvement. No skill improvement was evident in either the active or passive simulations, potentially due to the short training period applied, as well as a lack of realism in the VR simulations inhibiting a transfer of skills to a real environment. These findings reinforce previous literature that shows active VR to increase feelings of presence and agency. This study generates a number of fruitful research questions about the relationship between presence and skills training. © 2019 The AuthorsPsychology; Virtual reality; Presence; Human factors; Sport psychology © 2019 The Authors","Human factors; Presence; Psychology; Sport psychology; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85074370179
"Chew J.Y., Okayama K., Okuma T., Kawamoto M., Onda H., Kato N.","57189996822;57204778207;7004950282;56257346500;7006391806;57211832917;","Development of A Virtual Environment to Realize Human-Machine Interaction of Forklift Operation",2019,"2019 7th International Conference on Robot Intelligence Technology and Applications, RiTA 2019",,, 8932837,"112","118",,,"10.1109/RITAPP.2019.8932837","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078030425&doi=10.1109%2fRITAPP.2019.8932837&partnerID=40&md5=5c2a1a0ec9614f4b07ba4b3c1567ae88","National Institute of Advanced Industrial Science and Technology, Japan","Chew, J.Y., National Institute of Advanced Industrial Science and Technology, Japan; Okayama, K., National Institute of Advanced Industrial Science and Technology, Japan; Okuma, T., National Institute of Advanced Industrial Science and Technology, Japan; Kawamoto, M., National Institute of Advanced Industrial Science and Technology, Japan; Onda, H., National Institute of Advanced Industrial Science and Technology, Japan; Kato, N., National Institute of Advanced Industrial Science and Technology, Japan","This study presents an experimental concept to develop realistic Human-Machine Interaction (HMI) for a Virtual Environment (VE) and a novel evaluation methodology of such system. Such evaluation is motivated by the need to facilitate transfer of model/knowledge from VE to the Real Environment (RE), where it is crucial for the VE to trigger similar user behavior as in the RE. This paper discusses the application of such concept to evaluate interactions of forklift operation in the VE. First, a Virtual Reality (VR) forklift simulator is developed using motion capture and 3D reconstruction methods to mimic HMI of the real forklift operation. Then, the Dynamic Time Warping (DTW) algorithm is used for temporal evaluation of operation behaviors in VE and RE. Results of DTW (i.e. distance and correlation) are used as objective measures to evaluate fidelity of VE during forklift operations on the simulator. Results suggest the proposed forklift simulator triggers operation behavior which is similar (highly correlated) to that of real forklift operation. The contributions of this paper are (a) the novel VR forklift simulator system to realize interactions of real forklift in the VE, and (b) the proposed objective measures for temporal evaluation of the fidelity of VE. © 2019 IEEE.",,"Behavioral research; Intelligent robots; Man machine systems; Materials handling equipment; Simulators; Dynamic time warping algorithms; Evaluation methodologies; Highly-correlated; Human-machine interaction; Objective measure; Real environments; Simulator systems; Temporal evaluation; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85078030425
"Narciso D., Bessa M., Melo M., Vasconcelos-Raposo J.","57188767021;14031038800;7102354924;36070012200;","Virtual reality for training-the impact of smell on presence, cybersickness, fatigue, stress and knowledge transfer",2019,"ICGI 2019 - Proceedings of the International Conference on Graphics and Interaction",,, 8955071,"115","121",,1,"10.1109/ICGI47575.2019.8955071","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078949972&doi=10.1109%2fICGI47575.2019.8955071&partnerID=40&md5=eea844c1f887a3d220806d274c29acf7","UTAD, Engineering Department, Vila Real, Portugal; INESC TEC, Porto, Portugal; UTAD, Departament of Education and Psychology, Vila Real, Portugal","Narciso, D., UTAD, Engineering Department, Vila Real, Portugal; Bessa, M., UTAD, Engineering Department, Vila Real, Portugal; Melo, M., INESC TEC, Porto, Portugal; Vasconcelos-Raposo, J., UTAD, Departament of Education and Psychology, Vila Real, Portugal","The area of professional training using virtual reality technologies has received considerable investment due to the advantages that virtual reality provides over traditional training. In this paper, we present an experiment whose goal was to analyse the impact that an additional stimulus has on the effectiveness of a virtual environment designed to train firefighters. The additional stimulus is a smell, more specifically the smell of burnt wood, which is consistent with the audiovisual content presented, and the effectiveness of the VE is measured through participant's feeling of presence, cybersickness, fatigue, stress and transfer of knowledge. The results indicate that, although the VE was successful in transferring knowledge, the addition of smell did not influence any of the measured variables. In the discussion section, we present the various factors that we believe have influenced this result. As future work, more experiments will be performed, with other stimuli, to understand better which stimuli increase participant's feeling of presence in the VE. © 2019 IEEE.","Multisensory Stimulation; Olfactory Sense; Virtual Reality","Knowledge management; Virtual reality; Audio-visual content; Feeling of presences; Knowledge transfer; Multisensory stimulations; Olfactory sense; Professional training; Transfer of knowledge; Virtual reality technology; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85078949972
"Yu D., Liang H.-N., Lu X., Fan K., Ens B.","57203763734;8636386200;57210919536;57203767958;53867874600;","Modeling endpoint distribution of pointing selection tasks in virtual reality environments",2019,"ACM Transactions on Graphics","38","6", 3356544,"","",,7,"10.1145/3355089.3356544","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078889626&doi=10.1145%2f3355089.3356544&partnerID=40&md5=0e7c4cf924b43bed65cb3efc6fe21c3d","University of Melbourne, Melbourne, Australia; Xi'an Jiaotong-Liverpool University, China; Monash University, Australia","Yu, D., University of Melbourne, Melbourne, Australia, Xi'an Jiaotong-Liverpool University, China; Liang, H.-N., Xi'an Jiaotong-Liverpool University, China; Lu, X., Xi'an Jiaotong-Liverpool University, China; Fan, K., Xi'an Jiaotong-Liverpool University, China; Ens, B., Monash University, Australia","Understanding the endpoint distribution of pointing selection tasks can reveal the underlying patterns on how users tend to acquire a target, which is one of the most essential and pervasive tasks in interactive systems. It could further aid designers to create new graphical user interfaces and interaction techniques that are optimized for accuracy, efficiency, and ease of use. Previous research has explored the modeling of endpoint distribution outside of virtual reality (VR) systems that have shown to be useful in predicting selection accuracy and guide the design of new interactive techniques. This work aims at developing an endpoint distribution of selection tasks for VR systems which has resulted in EDModel, a novel model that can be used to predict endpoint distribution of pointing selection tasks in VR environments. The development of EDModel is based on two users studies that have explored how factors such as target size, movement amplitude, and target depth affect the endpoint distribution. The model is built from the collected data and its generalizability is subsequently tested in complex scenarios with more relaxed conditions. Three applications of EDModel inspired by previous research are evaluated to show the broad applicability and usefulness of the model: Correcting the bias in Fitts's law, predicting selection accuracy, and enhancing pointing selection techniques. Overall, EDModel can achieve high prediction accuracy and can be adapted to different types of applications in VR. © 2019 Association for Computing Machinery.","Endpoint distribution; Error prediction; Fitts's Law; Selection modeling; Target selection","Graphical user interfaces; Virtual reality; Endpoint distribution; Error prediction; Fitts's law; Selection model; Target selection; Forecasting",Article,"Final","",Scopus,2-s2.0-85078889626
"Rodriguez-Ramos A., Alvarez-Fernandez A., Bavle H., Campoy P., How J.P.","57190404560;57211628392;57190399962;23007441000;7006512768;","Vision-based multirotor following using synthetic learning techniques",2019,"Sensors (Switzerland)","19","21", 4794,"","",,2,"10.3390/s19214794","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074650087&doi=10.3390%2fs19214794&partnerID=40&md5=30bfbaaf3b880589c358ad49c0ae4d29","Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politécnica de Madrid (UPM-CSIC), Calle Jose Gutierrez Abascal 2, Madrid, 28006, Spain; Artificial Intelligence group, University of Groningen, Groningen, 9712, Netherlands; Aerospace Controls Laboratory, Massachusetts Institute of Technology (MIT), 77Mass. Ave, Cambridge, MA  02139, United States","Rodriguez-Ramos, A., Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politécnica de Madrid (UPM-CSIC), Calle Jose Gutierrez Abascal 2, Madrid, 28006, Spain; Alvarez-Fernandez, A., Artificial Intelligence group, University of Groningen, Groningen, 9712, Netherlands; Bavle, H., Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politécnica de Madrid (UPM-CSIC), Calle Jose Gutierrez Abascal 2, Madrid, 28006, Spain; Campoy, P., Computer Vision and Aerial Robotics group, Centre for Automation and Robotics, Universidad Politécnica de Madrid (UPM-CSIC), Calle Jose Gutierrez Abascal 2, Madrid, 28006, Spain; How, J.P., Aerospace Controls Laboratory, Massachusetts Institute of Technology (MIT), 77Mass. Ave, Cambridge, MA  02139, United States","Deep-and reinforcement-learning techniques have increasingly required large sets of real data to achieve stable convergence and generalization, in the context of image-recognition, object-detection or motion-control strategies. On this subject, the research community lacks robust approaches to overcome unavailable real-world extensive data by means of realistic synthetic-information and domain-adaptation techniques. In this work, synthetic-learning strategies have been used for the vision-based autonomous following of a noncooperative multirotor. The complete maneuver was learned with synthetic images and high-dimensional low-level continuous robot states, with deep-and reinforcement-learning techniques for object detection and motion control, respectively. A novel motion-control strategy for object following is introduced where the camera gimbal movement is coupled with the multirotor motion during the multirotor following. Results confirm that our present framework can be used to deploy a vision-based task in real flight using synthetic data. It was extensively validated in both simulated and real-flight scenarios, providing proper results (following a multirotor up to 1.3 m/s in simulation and 0.3 m/s in real flights). © 2019 by the authors. Licensee MDPI, Basel, Switzerland.","Deep learning; Following; Multirotor; Reinforcement learning; Synthetic learning; UAV","Deep learning; Flight simulators; Image recognition; Learning algorithms; Machine learning; Motion control; Object detection; Object recognition; Unmanned aerial vehicles (UAV); Visual servoing; Control strategies; Following; Learning techniques; Multirotor; Reinforcement learning techniques; Research communities; Stable convergence; Synthetic learning; Reinforcement learning; article; control strategy; deep learning; motion; reinforcement; robotics; simulation; vision",Article,"Final","",Scopus,2-s2.0-85074650087
"Forlim C.G., Bittner L., Mostajeran F., Steinicke F., Gallinat J., Kühn S.","56073571000;57211621650;57197835374;8883314100;7003503772;57203215366;","Stereoscopic Rendering via Goggles Elicits Higher Functional Connectivity During Virtual Reality Gaming",2019,"Frontiers in Human Neuroscience","13",, 365,"","",,5,"10.3389/fnhum.2019.00365","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074670363&doi=10.3389%2ffnhum.2019.00365&partnerID=40&md5=cf01b2c5f93edb1b14b4dbe531d24c96","Department of Psychiatry and Psychotherapy, University Medical Center Hamburg-Eppendorf (UKE), Hamburg, Germany; Department of Human-Computer-Interaction, University of Hamburg, Hamburg, Germany; Max Planck Institute for Human Development, Lise-Meitner Group for Environmental Neuroscience, Berlin, Germany","Forlim, C.G., Department of Psychiatry and Psychotherapy, University Medical Center Hamburg-Eppendorf (UKE), Hamburg, Germany; Bittner, L., Department of Psychiatry and Psychotherapy, University Medical Center Hamburg-Eppendorf (UKE), Hamburg, Germany; Mostajeran, F., Department of Human-Computer-Interaction, University of Hamburg, Hamburg, Germany; Steinicke, F., Department of Human-Computer-Interaction, University of Hamburg, Hamburg, Germany; Gallinat, J., Department of Psychiatry and Psychotherapy, University Medical Center Hamburg-Eppendorf (UKE), Hamburg, Germany; Kühn, S., Department of Psychiatry and Psychotherapy, University Medical Center Hamburg-Eppendorf (UKE), Hamburg, Germany, Max Planck Institute for Human Development, Lise-Meitner Group for Environmental Neuroscience, Berlin, Germany","Virtual reality (VR) simulates real-world scenarios by creating a sense of presence in its users. Such immersive scenarios lead to behavior that is more similar to that displayed in real world settings, which may facilitate the transfer of knowledge and skills acquired in VR to similar real world situations. VR has already been used in education, psychotherapy, rehabilitation and it comes as an appealing choice for training intervention purposes. The aim of the present study was to investigate to what extent VR technology for games presented via goggles can be used in a magnetic resonance imaging scanner (MRI), addressing the question of whether brain connectivity differs between VR stimulation via goggles and a presentation from a screen via mirror projection. Moreover, we wanted to investigate whether stereoscopic goggle stimulation, where both eyes receive different visual input, would elicit stronger brain connectivity than a stimulation in which both eyes receive the same visual input (monoscopic). To our knowledge, there is no previous research using games and functional connectivity (FC) in MRI to address this question. Multiple analyses approaches were taken so that different aspects of brain connectivity could be covered: fractional low-frequency fluctuation, independent component analysis (ICA), seed-based FC (SeedFC) and graph analysis. In goggle presentation (mono and stereoscopic) as contrasted to screen, we found differences in brain activation in left cerebellum and postcentral gyrus as well as differences in connectivity in the visual cortex and frontal inferior cortex [when focusing on the visual and default mode network (DMN)]. When considering connectivity in specific areas of interest, we found higher connectivity between bilateral superior frontal cortex and the temporal lobe, as well as bilateral inferior parietal cortex with right calcarine and right lingual cortex. Furthermore, we found superior frontal cortex and insula/putamen to be more strongly connected in goggle stereoscopic vs. goggle monoscopic, in line with our hypothesis. We assume that the condition that elicits higher brain connectivity values should be most suited for long-term brain training interventions given that, extended training under these conditions could permanently improve brain connectivity on a functional as well as on a structural level. © Copyright © 2019 Forlim, Bittner, Mostajeran, Steinicke, Gallinat and Kühn.","fMRI; fractional amplitude of low-frequency fluctuations; graph analysis; ICA; resting-state networks; seed-based functional connectivity; stereoscopic and monoscopic goggles; virtual reality","article; cerebellum; controlled study; default mode network; eye; frontal cortex; functional connectivity; functional magnetic resonance imaging; human; human experiment; independent component analysis; inferior parietal cortex; insula; plant seed; postcentral gyrus; putamen; temporal lobe; virtual reality; visual cortex",Article,"Final","",Scopus,2-s2.0-85074670363
"Xing J., Nagano K., Chen W., Xu H., Wei L.-Y., Zhao Y., Lu J., Kim B., Li H.","57221027161;55825559100;55570458100;57215128847;57220842683;57216268411;36022690300;57215125834;55082661800;","HairBrush for immersive data-driven hair modeling",2019,"UIST 2019 - Proceedings of the 32nd Annual ACM Symposium on User Interface Software and Technology",,,,"263","279",,2,"10.1145/3332165.3347876","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074836439&doi=10.1145%2f3332165.3347876&partnerID=40&md5=01e3e032a54c97c840c07e37da5bfd78","USC Institute for Creative Technologies; Pinscreen; Wayne State University, United States; Adobe Research","Xing, J., USC Institute for Creative Technologies; Nagano, K., Pinscreen; Chen, W., USC Institute for Creative Technologies; Xu, H., Wayne State University, United States; Wei, L.-Y., Adobe Research; Zhao, Y., USC Institute for Creative Technologies; Lu, J., Adobe Research; Kim, B., Adobe Research; Li, H., USC Institute for Creative Technologies, Pinscreen","While hair is an essential component of virtual humans, it is also one of the most challenging digital assets to create. Existing automatic techniques lack the generality and flexibility to create rich hair variations, while manual authoring interfaces often require considerable artistic skills and efforts, especially for intricate 3D hair structures that can be difficult to navigate. We propose an interactive hair modeling system that can help create complex hairstyles in minutes or hours that would otherwise take much longer with existing tools. Modelers, including novice users, can focus on the overall hairstyles and local hair deformations, as our system intelligently suggests the desired hair parts. Our method combines the flexibility of manual authoring and the convenience of data-driven automation. Since hair contains intricate 3D structures such as buns, knots, and strands, they are inherently challenging to create using traditional 2D interfaces. Our system provides a new 3D hair authoring interface for immersive interaction in virtual reality (VR). Users can draw high-level guide strips, from which our system predicts the most plausible hairstyles via a deep neural network trained from a professionally curated dataset. Each hairstyle in our dataset is composed of multiple variations, serving as blend-shapes to fit the user drawings via global blending and local deformation. The fitted hair models are visualized as interactive suggestions that the user can select, modify, or ignore. We conducted a user study to confirm that our system can significantly reduce manual labor while improve the output quality for modeling a variety of head and facial hairstyles that are challenging to create via existing techniques. © 2019 ACM.","Data-driven; Hair; Machine learning; Modeling; User interface; Virtual reality","Blending; Deep neural networks; Deformation; Learning systems; Models; Virtual reality; Automatic technique; Data driven; Digital assets; Hair; Hair structure; Local deformations; Output quality; Virtual humans; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-85074836439
"Krishna V., Ding Y., Xu A., Höllerer T.","57215827635;57211971230;57211501288;8358959700;","Multimodal Biometric Authentication for VR/AR using EEG and Eye Tracking",2019,"Adjunct of the 2019 International Conference on Multimodal Interaction, ICMI 2019",,, 3360655,"","",,2,"10.1145/3351529.3360655","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074216271&doi=10.1145%2f3351529.3360655&partnerID=40&md5=6f04e4e38b80684067b3eeba1dcceebd","Research Mentorship Program - UCSB National Public School - Indiranagar, Bangalore, Karnataka, India; University of California - Santa Barbara, Santa Barbara, CA, United States","Krishna, V., Research Mentorship Program - UCSB National Public School - Indiranagar, Bangalore, Karnataka, India; Ding, Y., University of California - Santa Barbara, Santa Barbara, CA, United States; Xu, A., University of California - Santa Barbara, Santa Barbara, CA, United States; Höllerer, T., University of California - Santa Barbara, Santa Barbara, CA, United States","Electroencephalogram (EEG) signals can enable an additional non-intrusive input modality especially when paired with a wearable headset (i.e. AR/VR). A great challenge in using EEG data for Brain-Computer Interface (BCI) algorithms is its poor generalization performance across users. Taking advantage of these inter-user differences, we investigate the potential in using this technology for user authentication – similar to facial recognition in smartphones. Additionally, we evaluate this in combination with eye tracking data which is also readily available in such headsets. We develop a biometric authentication systems for each of these systems and for their fusion. We formulate a novel evaluation paradigm using publicly available EEG motor imagery and eye tracking data and demonstrate strong feasibility towards using EEG and eye tracking for authentication. © 2019 Copyright held by the owner/author(s).","EEG; Eye Tracking; Machine Learning; Multimodal biometrics","Authentication; Biometrics; Brain computer interface; Electroencephalography; Face recognition; Interactive computer systems; Learning systems; Biometric authentication system; Electroencephalogram signals; Facial recognition; Generalization performance; Input modalities; Multi-modal biometrics; Multimodal biometric authentications; User authentication; Eye tracking",Conference Paper,"Final","",Scopus,2-s2.0-85074216271
"Meyer O.A., Omdahl M.K., Makransky G.","57209494578;57209393925;50361371800;","Investigating the effect of pre-training when learning through immersive virtual reality and video: A media and methods experiment",2019,"Computers and Education","140",, 103603,"","",,37,"10.1016/j.compedu.2019.103603","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067602710&doi=10.1016%2fj.compedu.2019.103603&partnerID=40&md5=d590ca910c0cb30b088c51f9fb6fb682","Department of Psychology, University of Copenhagen, Denmark; Department of Psychology, University of Southern Denmark, Denmark","Meyer, O.A., Department of Psychology, University of Copenhagen, Denmark; Omdahl, M.K., Department of Psychology, University of Southern Denmark, Denmark; Makransky, G., Department of Psychology, University of Copenhagen, Denmark","Immersive virtual reality (VR) is predicted to have a significant impact on education; but most studies investigating learning with immersive VR have reported mixed results when compared to low-immersion media. In this study, a sample of 118 participants was used to test whether a lesson presented in either immersive VR or as a video could benefit from the pre-training principle, as a means of reducing cognitive load. Participants were randomly assigned to one of two method conditions (with/without pre-training), and one of two media conditions (immersive VR/video). The results showed an interaction between media and method, indicating that pre-training had a positive effect on knowledge (d = 0.81), transfer (d = 0.62), and self-efficacy (d = 0.64) directly following the intervention; and on self-efficacy (d = 0.84) in a one-week delayed post-test in the immersive VR condition. No effect was found for any of these variables within the video condition. © 2019 The Author(s)","Cognitive theory of multimedia learning; Immersive virtual reality; Multimedia learning; Pre-training principle","Virtual reality; Cognitive loads; Cognitive theory of multimedia learning; Immersive virtual reality; Immersive VR; Multi-media learning; Post test; Pre-training; Self efficacy; E-learning",Article,"Final","",Scopus,2-s2.0-85067602710
"Wagner S., Joeres F., Gabele M., Hansen C., Preim B., Saalfeld P.","57209535826;57208648514;57208760476;55890379200;36744535200;56537022300;","Difficulty factors for VR cognitive rehabilitation training – Crossing a virtual road",2019,"Computers and Graphics (Pergamon)","83",,,"11","22",,2,"10.1016/j.cag.2019.06.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068072061&doi=10.1016%2fj.cag.2019.06.009&partnerID=40&md5=623e4c329cf5928dac5611ce3586ddc2","Department of Simulation and Graphics, University of Magdeburg, Germany","Wagner, S., Department of Simulation and Graphics, University of Magdeburg, Germany; Joeres, F., Department of Simulation and Graphics, University of Magdeburg, Germany; Gabele, M., Department of Simulation and Graphics, University of Magdeburg, Germany; Hansen, C., Department of Simulation and Graphics, University of Magdeburg, Germany; Preim, B., Department of Simulation and Graphics, University of Magdeburg, Germany; Saalfeld, P., Department of Simulation and Graphics, University of Magdeburg, Germany","Patients with cognitive or visual impairments have problems in dealing with complex situations. During the rehabilitation process, it is important to confront the patient with (everyday) tasks that have increasing degrees of difficulty to improve their performance. Immersive virtual reality training offers the potential to create a better transfer to daily life than non-immersive computer training. In cooperation with two neuropsychologists, an immersive virtual environment (VE) was developed in which cognitive training in the form of safe road crossing decisions can be performed. We present the experimental exploration and evaluation of difficulty factors within such a VR-based cognitive rehabilitation program. Four difficulty factors were identified and compared (number of relevant traffic lanes, speed of vehicles, distance between vehicles, and number of vehicles). The combination of these difficulty factors resulted in 36 training scenarios. The impact of the factors on participant performance and subjective perception of scenario difficulty were evaluated with 60 healthy participants to estimate the impact of the four factors to a situation's difficulty level. For the factors Relevant Lanes and Traffic Speed a clear influence on the perceived task difficulty could be determined. No clear influence could be found for the Gap Size. The Number of Vehicles had almost no effect on the perceived task difficulty. Finally, we asked two experienced neuropsychologists about the applicability of our developed system to patients, and they stated that the system is ready for a study on patients. © 2019 Elsevier Ltd","Cognitive rehabilitation; Disabilities; Virtual reality","E-learning; Roads and streets; Vehicles; Virtual reality; Cognitive rehabilitation; Cognitive training; Disabilities; Immersive virtual environments; Immersive virtual reality; Number of vehicles; Subjective perceptions; Visual impairment; Patient rehabilitation",Article,"Final","",Scopus,2-s2.0-85068072061
"Tarng S., Wang D., Hu Y.","57194037189;23480778300;57201840458;","Estimating cognitive processes related to haptic interaction within virtual environments",2019,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics","2019-October",, 8913853,"2823","2828",,,"10.1109/SMC.2019.8913853","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076757499&doi=10.1109%2fSMC.2019.8913853&partnerID=40&md5=844a96a2408eae30665e9308bfeda79e","University of Calgary, Department of Electrical and Computer Engineering, Calgary, AB, Canada","Tarng, S., University of Calgary, Department of Electrical and Computer Engineering, Calgary, AB, Canada; Wang, D., University of Calgary, Department of Electrical and Computer Engineering, Calgary, AB, Canada; Hu, Y., University of Calgary, Department of Electrical and Computer Engineering, Calgary, AB, Canada","Efforts exist to combine a brain-machine interface (BMI) into a 3D virtual environment (VE) for visual tasks. User interaction via haptic stimuli within the VE is still unexplored for developing the BMI however, due to little understanding of cognitive processes related to such haptic interaction. Hence, we investigated a feasibility of estimating cognitive processes related to haptic interaction. Involved in the investigation, human participants undertook a task via different haptic stimuli (e.g., force and vibration) within a 3D VE. Their brain activities evoked by the stimuli were acquired as electroencephalography signals. Patterns of event-related potential and power spectral density were extracted from the signals, indicating activation in certain brain areas. The estimation of connectivity among these areas used directed transfer function, emphasizing on the middle of the beta band (14 30) © 2019 IEEE.","Brain-machine interface (BMI); Electroencephalography (EEG); Haptic interaction; Virtual environment (VE)","Brain; Cognitive systems; Electroencephalography; Electrophysiology; Haptic interfaces; Spectral density; Virtual reality; Vision; 3-D virtual environment; Brain activity; Brain machine interface; Cognitive process; Directed transfer functions; Event related potentials; Haptic interactions; User interaction; Brain computer interface",Conference Paper,"Final","",Scopus,2-s2.0-85076757499
"Fernandes F., Werner C.","57202446568;7201754422;","Towards immersive learning in object-oriented paradigm: A preliminary study",2019,"Proceedings - 2019 21st Symposium on Virtual and Augmented Reality, SVR 2019",,, 8921030,"59","68",,,"10.1109/SVR.2019.00026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077235257&doi=10.1109%2fSVR.2019.00026&partnerID=40&md5=18c5e0ff98980061903b8ebf8218153d","Computer Science Department, IF Sudeste MG, Federal Institute Southeast of Minas Gerais, Manhuaçu, MG, Brazil; System Engineering and Computer Science Department, COPPE/UFRJ, Federal University of Rio de Janeiro, Rio de Janeiro, RJ, Brazil","Fernandes, F., Computer Science Department, IF Sudeste MG, Federal Institute Southeast of Minas Gerais, Manhuaçu, MG, Brazil; Werner, C., System Engineering and Computer Science Department, COPPE/UFRJ, Federal University of Rio de Janeiro, Rio de Janeiro, RJ, Brazil","Object-Oriented Paradigm Teaching is mandatory in the curriculum of the courses of the Computing area. Students are taught fundamental concepts about this paradigm, such as class, object, encapsulation, polymorphism, generalization and composition. One of the major challenges of Software Engineering is to teach complex and abstract concepts in a short time, with examples or simple projects done in academic environments. Virtual Reality has demonstrated advantages applied to Education, providing immersive experiences and new ways of visualization and interaction. However, this technology has not been extensively explored in Software Engineering. In this sense, this paper aims to present a disruptive method of teaching and learning support on fundamentals in object orientation paradigm based on Immersive Learning, called OO Game VR. In addition, an initial heuristic evaluation was performed with 6 subjects in order to identify usability problems. Despite problems found related to support learning, navigation and orientation, the natural expression of action and clear entry and exit points, the subjects were able to perform all the tasks, showing indications that the application has the potential to support teaching of OOP teaching through Immersive Learning. In future works, the usability problems will be fixed and specific methods will be applied for measuring influence immersion on learning outcomes. © 2019 IEEE.","Immersive learning; Object-oriented paradigm; Software engineering education; Virtual reality","Augmented reality; Engineering education; Learning systems; Software engineering; Teaching; Virtual reality; Academic environment; Fundamental concepts; Heuristic evaluation; Immersive learning; Object orientation; Object oriented paradigm; Teaching and learning; Usability problems; Object oriented programming",Conference Paper,"Final","",Scopus,2-s2.0-85077235257
"Tome D., Peluse P., Agapito L., Badino H.","57201376011;57215781039;12752515600;8981371600;","XR-EgoPose: Egocentric 3D human pose from an HMD camera",2019,"Proceedings of the IEEE International Conference on Computer Vision","2019-October",, 9010983,"7727","7737",,7,"10.1109/ICCV.2019.00782","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081916660&doi=10.1109%2fICCV.2019.00782&partnerID=40&md5=e9ba98391986b4166ef8f90ed97da3b2","University College London, United Kingdom; Facebook Reality Lab","Tome, D., University College London, United Kingdom, Facebook Reality Lab; Peluse, P., Facebook Reality Lab; Agapito, L., University College London, United Kingdom; Badino, H., Facebook Reality Lab","We present a new solution to egocentric 3D body pose estimation from monocular images captured from a downward looking fish-eye camera installed on the rim of a head mounted virtual reality device. This unusual viewpoint, just 2 cm.∼away from the user's face, leads to images with unique visual appearance, characterized by severe self-occlusions and strong perspective distortions that result in a drastic difference in resolution between lower and upper body. Our contribution is two-fold. Firstly, we propose a new encoder-decoder architecture with a novel dual branch decoder designed specifically to account for the varying uncertainty in the 2D joint locations. Our quantitative evaluation, both on synthetic and real-world datasets, shows that our strategy leads to substantial improvements in accuracy over state of the art egocentric pose estimation approaches. Our second contribution is a new large-scale photorealistic synthetic dataset - xR-EgoPose - offering 383K frames of high quality renderings of people with a diversity of skin tones, body shapes, clothing, in a variety of backgrounds and lighting conditions, performing a range of actions. Our experiments show that the high variability in our new synthetic training corpus leads to good generalization to real world footage and to state of the art results on real world datasets with ground truth. Moreover, an evaluation on the Human3.6M benchmark shows that the performance of our method is on par with top performing approaches on the more classic problem of 3D human pose from a third person viewpoint. © 2019 IEEE.",,"Benchmarking; Cameras; Decoding; Large dataset; Virtual reality; Body pose estimation; Encoder-decoder architecture; Head mounted virtual reality; Lighting conditions; Perspective distortion; Quantitative evaluation; Real-world datasets; Visual appearance; Computer vision",Conference Paper,"Final","",Scopus,2-s2.0-85081916660
"Gupta A., Cecil J., Tapia O., Sweet-Darter M.","57200825298;7005940561;57207105216;56719728800;","Design of cyber-human frameworks for immersive learning",2019,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics","2019-October",, 8914205,"1563","1568",,,"10.1109/SMC.2019.8914205","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076785558&doi=10.1109%2fSMC.2019.8914205&partnerID=40&md5=24f60e31ee08e1c61b6ac33241f99727","Oklahoma State University, Center for Cyber-Physical Systems, Stillwater, United States; Anselm Center, Edmond, OK, United States","Gupta, A., Oklahoma State University, Center for Cyber-Physical Systems, Stillwater, United States; Cecil, J., Oklahoma State University, Center for Cyber-Physical Systems, Stillwater, United States; Tapia, O., Oklahoma State University, Center for Cyber-Physical Systems, Stillwater, United States; Sweet-Darter, M., Anselm Center, Edmond, OK, United States","This paper focuses on the creation of information centric Cyber-Human Learning Frameworks involving Virtual Reality based mediums. A generalized framework is proposed, which is adapted for two educational domains: One to support education and training of residents in orthopedic surgery and the other focusing on science learning for children with autism. Users, experts and technology based mediums play a key role in the design of such a Cyber-Human framework. Virtual Reality based immersive and haptic mediums were two of the technologies explored in the implementation of the framework for these learning domains. The proposed framework emphasizes the importance of Information-Centric Systems Engineering (ICSE) principles which emphasizes a user centric approach along with formalizing understanding of target subjects or processes for which the learning environments are being created. © 2019 IEEE.","Human-Computer Interaction; Virtual Learning; Virtual Reality","Computer aided instruction; Human computer interaction; Virtual reality; Children with autisms; Education and training; Immersive learning; Information-centric; Learning environments; Orthopedic surgery; Technology-based; Virtual learning; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85076785558
"Boutros F., Damer N., Kirchbuchner F., Kuijper A.","57205379838;50861109400;57031859600;56131137100;","Eye-MMS: Miniature multi-scale segmentation network of key eye-regions in embedded applications",2019,"Proceedings - 2019 International Conference on Computer Vision Workshop, ICCVW 2019",,, 9022048,"3665","3670",,13,"10.1109/ICCVW.2019.00452","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082493607&doi=10.1109%2fICCVW.2019.00452&partnerID=40&md5=f767e071ce9f8f2e80f951c63200ac45","Fraunhofer Institute for Computer Graphics Research IGD, Germany; Technische Universität Darmstadt, Germany","Boutros, F., Fraunhofer Institute for Computer Graphics Research IGD, Germany, Technische Universität Darmstadt, Germany; Damer, N., Fraunhofer Institute for Computer Graphics Research IGD, Germany, Technische Universität Darmstadt, Germany; Kirchbuchner, F., Fraunhofer Institute for Computer Graphics Research IGD, Germany, Technische Universität Darmstadt, Germany; Kuijper, A., Fraunhofer Institute for Computer Graphics Research IGD, Germany, Technische Universität Darmstadt, Germany","Segmentation of the iris or sclera is an essential processing block in ocular biometric systems. However, human-computer interaction, as in VR/AR applications, requires multiple region segmentation to enable smoother interaction and eye-tracking. Such application does not only demand highly accurate and generalizable segmentation, it requires such segmentation model to be appropriate for the limited computational power of embedded systems. This puts strict limits on the size of the deployed deep learning models. This work presents a miniature multi-scale segmentation network consisting of inter-connected convolutional modules. We present a baseline multi-scale segmentation network and modify it to reduce its parameters by more than 80 times, while reducing its accuracy by less than 3%, resulting in our Eye-MMS model containing only 80k parameters. This work is developed on the OpenEDS database and is conducted in preparation for the OpenEDS Semantic Segmentation Challenge. © 2019 IEEE.","Biometrics; Embedded biometrics; Eye segmentation; Semantic segmentation","Biometrics; Computer vision; Deep learning; Embedded systems; Human computer interaction; Semantics; Biometric systems; Computational power; Embedded application; Embedded biometrics; Multiple regions; Multiscale segmentation; Segmentation models; Semantic segmentation; Eye tracking",Conference Paper,"Final","",Scopus,2-s2.0-85082493607
"Ip H.H.S., Li C., Leoni S., Chen Y., Ma K.-F., Wong C.H.-T., Li Q.","7005395690;56180363500;57192005943;57187275900;57192007385;57204512944;56190105400;","Design and Evaluate Immersive Learning Experience for Massive Open Online Courses (MOOCs)",2019,"IEEE Transactions on Learning Technologies","12","4", 8515107,"503","515",,3,"10.1109/TLT.2018.2878700","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055879387&doi=10.1109%2fTLT.2018.2878700&partnerID=40&md5=262dab079e4e3ad4edea8953a8886e91","Department of Computer Science, AIMtech Centre, City University of Hong Kong, Hong Kong; AIMtech Centre, City University of Hong Kong, Hong Kong; Department of Computer Science, City University of Hong Kong, Hong Kong; Department of Chinese and History, City University of Hong Kong, Kowloon Tong, Hong Kong","Ip, H.H.S., Department of Computer Science, AIMtech Centre, City University of Hong Kong, Hong Kong; Li, C., Department of Computer Science, AIMtech Centre, City University of Hong Kong, Hong Kong; Leoni, S., AIMtech Centre, City University of Hong Kong, Hong Kong; Chen, Y., Department of Computer Science, City University of Hong Kong, Hong Kong; Ma, K.-F., Department of Chinese and History, City University of Hong Kong, Kowloon Tong, Hong Kong; Wong, C.H.-T., Department of Chinese and History, City University of Hong Kong, Kowloon Tong, Hong Kong; Li, Q., Department of Computer Science, City University of Hong Kong, Hong Kong","Massive open online courses (MOOCs), a unique form of online education enabled by web-based learning technologies, allow learners from anywhere in the world with any level of educational background to enjoy online education experience provided by many top universities all around the world. Traditionally, MOOC learning contents are always delivered as text-based or video-based materials. Although introducing immersive learning experience for MOOCs may sound exciting and potentially significative, there are a number of challenges given this unique setting. In this paper, we present the design and evaluation methodologies for delivering immersive learning experience to MOOC learners via multiple media. Specifically, we have applied the techniques in the production of a MOOC entitled Virtual Hong Kong: New World, Old Traditions, led by AIMtech Centre, City University of Hong Kong, which is the first MOOC (as our knowledge) that delivers immersive learning content for distant learners to appreciate and experience how the traditional culture and folklore of Hong Kong impact upon the lives of its inhabitants in the 21st Century. The methodologies applied here can be further generalized as the fundamental framework of delivering immersive learning for future MOOCs. © 2008-2011 IEEE.","e-learning.; immersive learning; Massive open online course; virtual reality","Computer aided instruction; Curricula; Design; Education; Learning systems; Virtual reality; Google; Immersive learning; Information and Communication Technologies; Massive open online course; Solid model; Urban areas; E-learning",Article,"Final","",Scopus,2-s2.0-85055879387
"Škola F., Tinková S., Liarokapis F.","57189368470;57211272110;7801416785;","Progressive Training for Motor Imagery Brain-Computer Interfaces Using Gamification and Virtual Reality Embodiment",2019,"Frontiers in Human Neuroscience","13",, 329,"","",,9,"10.3389/fnhum.2019.00329","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073189702&doi=10.3389%2ffnhum.2019.00329&partnerID=40&md5=198ef3d60bdba1661c0d64955bfcdb1e","Faculty of Informatics, Masaryk University, Brno, Czech Republic","Škola, F., Faculty of Informatics, Masaryk University, Brno, Czech Republic; Tinková, S., Faculty of Informatics, Masaryk University, Brno, Czech Republic; Liarokapis, F., Faculty of Informatics, Masaryk University, Brno, Czech Republic","This paper presents a gamified motor imagery brain-computer interface (MI-BCI) training in immersive virtual reality. The aim of the proposed training method is to increase engagement, attention, and motivation in co-adaptive event-driven MI-BCI training. This was achieved using gamification, progressive increase of the training pace, and virtual reality design reinforcing body ownership transfer (embodiment) into the avatar. From the 20 healthy participants performing 6 runs of 2-class MI-BCI training (left/right hand), 19 were trained for a basic level of MI-BCI operation, with average peak accuracy in the session = 75.84%. This confirms the proposed training method succeeded in improvement of the MI-BCI skills; moreover, participants were leaving the session in high positive affect. Although the performance was not directly correlated to the degree of embodiment, subjective magnitude of the body ownership transfer illusion correlated with the ability to modulate the sensorimotor rhythm. © Copyright © 2019 Škola, Tinková and Liarokapis.","body ownership transfer; brain-computer interface; embodiment; gamification; motor imagery","accuracy; adaptation; adult; affect; Article; attention; body ownership transfer; brain computer interface; classification; clinical article; controlled study; electroencephalography; evidence based medicine; fatigue; female; gamified motor imagery brain computer interface; hand movement; human; illusion; machine learning; male; mathematical analysis; modulation transfer function; motivation; motor cortex; neuromodulation; online system; proprioceptive feedback; questionnaire; rating scale; robotics; self concept; sense of agency; sense of ownership; sensorimotor function; sensory evoked potential; sex difference; skill; tactile feedback; tactile stimulation; task performance; vibration; virtual reality; virtual reality embodiment; visual feedback",Article,"Final","",Scopus,2-s2.0-85073189702
"Kim A., Schweighofer N., Finley J.M.","57193429536;6701542947;24080097400;","Locomotor skill acquisition in virtual reality shows sustained transfer to the real world",2019,"Journal of NeuroEngineering and Rehabilitation","16","1", 113,"","",,12,"10.1186/s12984-019-0584-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072208527&doi=10.1186%2fs12984-019-0584-y&partnerID=40&md5=03fdeac9598efcc7ee28cf2ebcbf7be2","Division of Biokinesiology and Physical Therapy, University of Southern California, 1540 E. Alcazar St, CHP 155, Los Angeles, CA  90033, United States; Neuroscience Graduate Program, University of Southern California, Los Angeles, CA  90089, United States; Department of Biomedical Engineering, University of Southern California, Los Angeles, CA  90089, United States; Department of Computer Science, University of Southern California, Los Angeles, CA  90089, United States","Kim, A., Division of Biokinesiology and Physical Therapy, University of Southern California, 1540 E. Alcazar St, CHP 155, Los Angeles, CA  90033, United States; Schweighofer, N., Division of Biokinesiology and Physical Therapy, University of Southern California, 1540 E. Alcazar St, CHP 155, Los Angeles, CA  90033, United States, Neuroscience Graduate Program, University of Southern California, Los Angeles, CA  90089, United States, Department of Biomedical Engineering, University of Southern California, Los Angeles, CA  90089, United States, Department of Computer Science, University of Southern California, Los Angeles, CA  90089, United States; Finley, J.M., Division of Biokinesiology and Physical Therapy, University of Southern California, 1540 E. Alcazar St, CHP 155, Los Angeles, CA  90033, United States, Neuroscience Graduate Program, University of Southern California, Los Angeles, CA  90089, United States, Department of Biomedical Engineering, University of Southern California, Los Angeles, CA  90089, United States","Background: Virtual reality (VR) is a potentially promising tool for enhancing real-world locomotion in individuals with mobility impairment through its ability to provide personalized performance feedback and simulate real-world challenges. However, it is unknown whether novel locomotor skills learned in VR show sustained transfer to the real world. Here, as an initial step towards developing a VR-based clinical intervention, we study how young adults learn and transfer a treadmill-based virtual obstacle negotiation skill to the real world. Methods: On Day 1, participants crossed virtual obstacles while walking on a treadmill, with the instruction to minimize foot clearance during obstacle crossing. Gradual changes in performance during training were fit via non-linear mixed effect models. Immediate transfer was measured by foot clearance during physical obstacle crossing while walking over-ground. Retention of the obstacle negotiation skill in VR and retention of over-ground transfer were assessed after 24 h. Results: On Day 1, participants systematically reduced foot clearance throughout practice by an average of 5 cm (SD 4 cm) and transferred 3 cm (SD 1 cm) of this reduction to over-ground walking. The acquired reduction in foot clearance was also retained after 24 h in VR and over-ground. There was only a small, but significant 0.8 cm increase in foot clearance in VR and no significant increase in clearance over-ground on Day 2. Moreover, individual differences in final performance at the end of practice on Day 1 predicted retention both in VR and in the real environment. Conclusions: Overall, our results support the use of VR for locomotor training as skills learned in a virtual environment readily transfer to real-world locomotion. Future work is needed to determine if VR-based locomotor training leads to sustained transfer in clinical populations with mobility impairments, such as individuals with Parkinson's disease and stroke survivors. © 2019 The Author(s).","Motor learning; Obstacle negotiation; Retention; Transfer; Virtual reality","adult; Article; female; human; human experiment; locomotion; male; motor learning; normal human; Parkinson disease; population research; priority journal; skill retention; stroke survivor; task performance; transfer of learning; virtual reality; walking distance; walking speed; young adult; algorithm; biomechanics; foot; learning; motor performance; walking; walking difficulty; Adult; Algorithms; Biomechanical Phenomena; Female; Foot; Healthy Volunteers; Humans; Learning; Locomotion; Male; Mobility Limitation; Motor Skills; Transfer, Psychology; Virtual Reality; Walking; Young Adult",Article,"Final","",Scopus,2-s2.0-85072208527
"Nijman S.A., Veling W., Greaves-Lord K., Vermeer R.R., Vos M., Zandee C.E.R., Zandstra D.C., Geraets C.N.W., Pijnenborg G.H.M.","57205171580;19934411900;15925549000;57210891883;57210887069;57210897608;57210892122;57053538000;6507841579;","Dynamic Interactive Social Cognition Training in Virtual Reality (DiSCoVR) for social cognition and social functioning in people with a psychotic disorder: study protocol for a multicenter randomized controlled trial",2019,"BMC psychiatry","19","1", 272,"272","",,7,"10.1186/s12888-019-2250-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071753550&doi=10.1186%2fs12888-019-2250-0&partnerID=40&md5=41fa83c1682323ecbac6441ae1de7879","Department of Psychotic Disorders, GGZ Drenthe, LA, PO Box 30007, Assen, 9404, Netherlands; University Center of Psychiatry, University Medical Center Groningen, University of Groningen, RB, Hanzeplein 1 ,PO Box 30.001Groningen  9700, Netherlands; Department of Psychology, University of Groningen, Grote Kruisstraat 2/1Groningen  9712, Netherlands; Department of Child and Adolescent Psychiatry/Psychology, Erasmus MC-Sophia, CN, Wytemaweg 8, Rotterdam, 3015, Netherlands; Department of (Youth) Mental Health and Autism of Lentis Psychiatric Institute, JR, Laan Corpus den Hoorn 102-2Groningen  9728, Netherlands; Department of Yulius Autism, Dordrecht, Netherlands; Flexible Assertive Community Treatment Team, Outpatient Treatment Center, GGZ Delfland, Sint Jorisweg 2, Delft, 2612, Netherlands; Terneuzen, Netherlands","Nijman, S.A., Department of Psychotic Disorders, GGZ Drenthe, LA, PO Box 30007, Assen, 9404, Netherlands, University Center of Psychiatry, University Medical Center Groningen, University of Groningen, RB, Hanzeplein 1 ,PO Box 30.001Groningen  9700, Netherlands, Department of Psychology, University of Groningen, Grote Kruisstraat 2/1Groningen  9712, Netherlands; Veling, W., University Center of Psychiatry, University Medical Center Groningen, University of Groningen, RB, Hanzeplein 1 ,PO Box 30.001Groningen  9700, Netherlands; Greaves-Lord, K., Department of Child and Adolescent Psychiatry/Psychology, Erasmus MC-Sophia, CN, Wytemaweg 8, Rotterdam, 3015, Netherlands, Department of (Youth) Mental Health and Autism of Lentis Psychiatric Institute, JR, Laan Corpus den Hoorn 102-2Groningen  9728, Netherlands, Department of Yulius Autism, Dordrecht, Netherlands; Vermeer, R.R., Flexible Assertive Community Treatment Team, Outpatient Treatment Center, GGZ Delfland, Sint Jorisweg 2, Delft, 2612, Netherlands; Vos, M., University Center of Psychiatry, University Medical Center Groningen, University of Groningen, RB, Hanzeplein 1 ,PO Box 30.001Groningen  9700, Netherlands; Zandee, C.E.R., Flexible Assertive Community Treatment Team, Outpatient Treatment Center, GGZ Delfland, Sint Jorisweg 2, Delft, 2612, Netherlands; Zandstra, D.C., Terneuzen, Netherlands; Geraets, C.N.W., University Center of Psychiatry, University Medical Center Groningen, University of Groningen, RB, Hanzeplein 1 ,PO Box 30.001Groningen  9700, Netherlands; Pijnenborg, G.H.M., Department of Psychotic Disorders, GGZ Drenthe, LA, PO Box 30007, Assen, 9404, Netherlands, Department of Psychology, University of Groningen, Grote Kruisstraat 2/1Groningen  9712, Netherlands","BACKGROUND: Problems in social functioning (e.g., unemployment, social isolation), are common in people with a psychotic disorder. Social cognition is a treatment target to improve social functioning, as it is a proximal predictor of social functioning. Social Cognition Training (SCT) improves social cognition, but may not generalize (enduringly) to social functioning, perhaps due to insufficient opportunity to practice in daily-life social situations. Using virtual reality (VR) for SCT could address this problem, as VR is customizable, accessible, and interactive. We will test the effect of a VR SCT, 'DiSCoVR', on social cognition and social functioning in a randomized controlled trial (RCT). METHODS: In total 100 people with a psychotic disorder and deficits in social cognition will be recruited for this multicenter randomized controlled trial (RCT). Participants will be randomized to VR SCT (DiSCoVR) or VR relaxation training (VRelax; active control). DiSCoVR is a 16-session individual SCT, consisting of three modules: 1) emotion perception (recognizing facial emotions in a virtual shopping street); 2) social perception and theory of mind (observing social interactions between virtual characters and assessing their behavior, emotions and thoughts); and 3) application of higher-order social cognition in social interaction (role-playing personalized situations in VR). People receiving VRelax complete sixteen individual sessions, in which they receive psycho-education about stress, identify personal stressors, learn relaxation techniques, and explore relaxing immersive virtual environments. Assessments will be performed at baseline, post-treatment, and 3-month follow-up. Primary outcomes are emotion perception (Ekman 60 Faces), social perception and theory of mind (The Awareness of Social Inference Test). Secondary outcomes include social functioning (Personal and Social Performance Scale), experiences and social interactions in daily life (experience sampling of emotions, social participation and subjective experience of social situations), psychiatric symptoms (e.g., depression, perceived stress, anxiety, positive and negative symptoms) and self-esteem. DISCUSSION: To our knowledge, this will be the first RCT testing the efficacy of VR SCT. It will also investigate generalization to daily life social situations, the durability of treatment effects, and moderators and mediators of treatment success. TRIAL REGISTRATION: On December 5, 2017, this trial was registered prospectively in the Dutch Trial Register as NTR6863 .","Emotion perception; Psychotic disorder; Social cognition training; Social functioning; Theory of mind; Virtual reality","adolescent; adult; aged; clinical trial; cognition; cognitive behavioral therapy; female; human; human relation; male; middle aged; multicenter study; perception; procedures; psychology; psychosis; randomized controlled trial (topic); social behavior; social participation; theory of mind; treatment outcome; virtual reality exposure therapy; young adult; Adolescent; Adult; Aged; Cognition; Cognitive Behavioral Therapy; Female; Humans; Interpersonal Relations; Male; Middle Aged; Psychotic Disorders; Randomized Controlled Trials as Topic; Social Behavior; Social Participation; Social Perception; Theory of Mind; Treatment Outcome; Virtual Reality Exposure Therapy; Young Adult",Article,"Final","",Scopus,2-s2.0-85071753550
"Neumann E., Mayer J., Russo G.I., Amend B., Rausch S., Deininger S., Harland N., da Costa I.A., Hennenlotter J., Stenzl A., Kruck S., Bedke J.","57075873400;57202131941;57193081662;17134290500;54880045200;57196436400;56568103600;57201688571;15053231300;7005619547;23093995600;23970330900;","Transurethral Resection of Bladder Tumors: Next-generation Virtual Reality Training for Surgeons",2019,"European Urology Focus","5","5",,"906","911",,9,"10.1016/j.euf.2018.04.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047247435&doi=10.1016%2fj.euf.2018.04.011&partnerID=40&md5=e1555cd795e2e66da7938eb4be0aa4fb","University Tuebingen, Dept. of Urology, Tuebingen, Germany; University of Catania, Urology Section, Catania, Italy","Neumann, E., University Tuebingen, Dept. of Urology, Tuebingen, Germany; Mayer, J., University Tuebingen, Dept. of Urology, Tuebingen, Germany; Russo, G.I., University Tuebingen, Dept. of Urology, Tuebingen, Germany, University of Catania, Urology Section, Catania, Italy; Amend, B., University Tuebingen, Dept. of Urology, Tuebingen, Germany; Rausch, S., University Tuebingen, Dept. of Urology, Tuebingen, Germany; Deininger, S., University Tuebingen, Dept. of Urology, Tuebingen, Germany; Harland, N., University Tuebingen, Dept. of Urology, Tuebingen, Germany; da Costa, I.A., University Tuebingen, Dept. of Urology, Tuebingen, Germany; Hennenlotter, J., University Tuebingen, Dept. of Urology, Tuebingen, Germany; Stenzl, A., University Tuebingen, Dept. of Urology, Tuebingen, Germany; Kruck, S., University Tuebingen, Dept. of Urology, Tuebingen, Germany; Bedke, J., University Tuebingen, Dept. of Urology, Tuebingen, Germany","Background: The number of virtual reality (VR) simulators is increasing. The aim of this prospective trial was to determine the benefit of VR cystoscopy (UC) and transurethral bladder tumor resection (TURBT) training in students. Design, setting, and participants: Medical students without endoscopic experience (n = 51, median age = 25 yr, median 4th academic year) were prospectively randomized into groups A and B. After an initial VR-UC and VR-TURBT task, group A (n = 25) underwent a video-based tutorial by a skilled expert. Group B (n = 26) was trained using a VR training program (Uro-Trainer). Following the training, every participant performed a final VR-UC and VR-TURBT task. Performance indicators were recorded via the simulator. Data was analyzed by Mann-Whitney U test. Intervention: VR cystoscopy and TURBT. Results and limitations: No baseline and post-training differences were found for VR-UC between groups. During baseline, VR-TURBT group A showed higher inspected bladder surface than group B (56% vs 73%, p = 0.03). Subgroup analysis detected differences related to sex before training (male: 31.2% decreased procedure time; 38.1% decreased resectoscope movement; p = 0.02). After training, significant differences in procedure time (3.9 min vs 2.7 min, p = 0.007), resectoscope movement (857 mm vs 529 mm, p = 0.005), and accidental bladder injury (n = 3.0 vs n = 0.88, p = 0.003) were found. Male participants showed reduced blood loss (males: 3.92 ml vs females: 10.12 ml; p = 0.03) after training. Conclusions: Measuring endoscopic skills within a virtual environment can be done easily. Short training improved efficacy and safety of VR-TURBT. Nevertheless, transfer of improved VR performance into real world surgery needs further clarification. Patient summary: We investigated how students without endoscopic experience profit from simulation-based training. The safe environment and repeated simulations can improve the surgical training. It may be possible to enhance patient's safety and the training of surgeons in long term. © 2018 European Association of UrologySimulator training teaches endourological interventions under controlled conditions. Students without endoscopic experience profit from simulation-based training. In conclusion, a simulation-based training is very useful to push the surgical learning curve of future urologist 2.0. © 2018 European Association of Urology","Cystoscopy; Randomized controlled trial; Simulation; Training; Transurethral resection of bladder tumors; Uro-Trainer; Virtual reality","adult; Article; bladder injury; bladder tumor; bleeding; cohort analysis; controlled study; cystoscopy; female; human; male; medical student; operation duration; patient safety; prospective study; randomized controlled trial; sex difference; surgical training; transurethral resection; virtual reality; bladder tumor; education; medical education; procedures; simulation training; urethra; urologic surgery; urology; young adult; Adult; Female; Humans; Internship and Residency; Male; Prospective Studies; Simulation Training; Urethra; Urinary Bladder Neoplasms; Urologic Surgical Procedures; Urology; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85047247435
"Michalski S.C., Szpak A., Saredakis D., Ross T.J., Billinghurst M., Loetscher T.","57210961158;56544337100;57208775758;57208580953;7006142663;14422378000;","Getting your game on: Using virtual reality to improve real table tennis skills",2019,"PLoS ONE","14","9", e0222351,"","",,9,"10.1371/journal.pone.0222351","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072012518&doi=10.1371%2fjournal.pone.0222351&partnerID=40&md5=ff27cc648e975d990d1ddedb0226ded6","Cognitive Ageing and Impairment Neurosciences Laboratory, School of Psychology, University of South Australia, Adelaide, SA, Australia; Empathic Computing Lab, School of Information Technology and Mathematical Sciences, University of South Australia, Adelaide, SA, Australia","Michalski, S.C., Cognitive Ageing and Impairment Neurosciences Laboratory, School of Psychology, University of South Australia, Adelaide, SA, Australia; Szpak, A., Cognitive Ageing and Impairment Neurosciences Laboratory, School of Psychology, University of South Australia, Adelaide, SA, Australia; Saredakis, D., Cognitive Ageing and Impairment Neurosciences Laboratory, School of Psychology, University of South Australia, Adelaide, SA, Australia; Ross, T.J., Cognitive Ageing and Impairment Neurosciences Laboratory, School of Psychology, University of South Australia, Adelaide, SA, Australia; Billinghurst, M., Empathic Computing Lab, School of Information Technology and Mathematical Sciences, University of South Australia, Adelaide, SA, Australia; Loetscher, T., Cognitive Ageing and Impairment Neurosciences Laboratory, School of Psychology, University of South Australia, Adelaide, SA, Australia","Objective The present study investigates skill transfer from Virtual Reality (VR) sports training to the real world, using the fast-paced sport of table tennis. Background A key assumption of VR training is that the learned skills and experiences transfer to the real world. Yet, in certain application areas, such as VR sports training, the research testing this assumption is sparse. Design Real-world table tennis performance was assessed using a mixed-model analysis of variance. The analysis comprised a between-subjects (VR training group vs control group) and a within-subjects (pre- and post-training) factor. Method Fifty-seven participants (23 females) were either assigned to a VR training group (n = 29) or no-training control group (n = 28). During VR training, participants were immersed in competitive table tennis matches against an artificial intelligence opponent. An expert table tennis coach evaluated participants on real-world table tennis playing before and after the training phase. Blinded regarding participant's group assignment, the expert assessed participants' backhand, forehand and serving on quantitative aspects (e.g. count of rallies without errors) and quality of skill aspects (e.g. technique and consistency). Results VR training significantly improved participants' real-world table tennis performance compared to a no-training control group in both quantitative (p < .001, Cohen's d = 1.08) and quality of skill assessments (p < .001, Cohen's d = 1.10). Conclusions This study adds to a sparse yet expanding literature, demonstrating real-world skill transfer from Virtual Reality in an athletic task. © 2019 Public Library of Science. All rights reserved.",,"adult; analysis of variance; article; artificial intelligence; controlled study; female; human; human experiment; major clinical study; male; quantitative analysis; skill; tennis; virtual reality; adolescent; athletic performance; clinical trial; young adult; Adolescent; Adult; Athletic Performance; Female; Humans; Male; Tennis; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85072012518
"Palmas F., Labode D., Plecher D.A., Klinker G.","57208681848;57211522317;55923283100;6603530980;","Comparison of a gamified and non-gamified virtual reality training assembly task",2019,"2019 11th International Conference on Virtual Worlds and Games for Serious Applications, VS-Games 2019 - Proceedings",,, 8864583,"1DUUMY","",,5,"10.1109/VS-Games.2019.8864583","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074257749&doi=10.1109%2fVS-Games.2019.8864583&partnerID=40&md5=c74c3636133e6da9ac1e76ca8a13f78c","Research Group Augmented Reality, Technical University of Munich, Munich, Germany","Palmas, F., Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Labode, D., Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Plecher, D.A., Research Group Augmented Reality, Technical University of Munich, Munich, Germany; Klinker, G., Research Group Augmented Reality, Technical University of Munich, Munich, Germany","By using simulations in virtual reality (VR), people have the chance to train without supervision in a safe and controlled environment. VR simulation training allows users to gain new skills and apply them to real-life situations. However, the learning curve of this technology from a novice level could influence the expected learning results of a training session. A training approach based on the combination of VR and gamification could speed up this overall learning process and not just for a novice. In this paper we evaluate how gamification in a VR training session can improve the efficiency of the training and the accuracy of the task execution in a real-world practical test. In the training scenario of this study, 50 randomly assigned participants were divided into two groups. The groups were assigned to a gamified and a non-gamified version of the same VR training and were then guided through a step-by-step tutorial outlining how to solve an assembly task. Performance differences were evaluated based on time taken and specific errors made during the training session. The results of this study show, in general, that beneficial effects can be attributed to the use of gamification in the conducted VR training simulation, particularly for the VR novice participants. © 2019 IEEE.","Assembly task; Gamification; Learning transfer; Training; Virtual reality; Virtual training","Personnel training; Virtual reality; Assembly tasks; Beneficial effects; Controlled environment; Gamification; Learning Transfer; Training simulation; Virtual reality training; Virtual training; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85074257749
"Alfalah S.F.M., Falah J.F.M., Alfalah T., Elfalah M., Muhaidat N., Falah O.","55583479900;55350011200;56410895700;57203174172;57203165392;53879792700;","A comparative study between a virtual reality heart anatomy system and traditional medical teaching modalities",2019,"Virtual Reality","23","3",,"229","234",,7,"10.1007/s10055-018-0359-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050790522&doi=10.1007%2fs10055-018-0359-y&partnerID=40&md5=09f0d586cab75a4b324d47e1476bdefb","Department of Computer Information Systems, The University of Jordan, Amman, Jordan; Department of Computer Science, Al-Balqa` Applied University, Amman, Jordan; Department of Business Administration, Applied Science University, Amman, Jordan; Department of Ophthalmology, Faculty of Medicine, The University of Jordan, Amman, Jordan; Department of Obstetrics and Gynaecology, Faculty of Medicine, The University of Jordan, Amman, Jordan; Department of Vascular Surgery, The University of Edinburgh, Edinburgh, United Kingdom","Alfalah, S.F.M., Department of Computer Information Systems, The University of Jordan, Amman, Jordan; Falah, J.F.M., Department of Computer Science, Al-Balqa` Applied University, Amman, Jordan; Alfalah, T., Department of Business Administration, Applied Science University, Amman, Jordan; Elfalah, M., Department of Ophthalmology, Faculty of Medicine, The University of Jordan, Amman, Jordan; Muhaidat, N., Department of Obstetrics and Gynaecology, Faculty of Medicine, The University of Jordan, Amman, Jordan; Falah, O., Department of Vascular Surgery, The University of Edinburgh, Edinburgh, United Kingdom","The aim of using virtual reality (VR) as a medical training tool is to offer additional means to teach students and to improve the quality of medical skills. A novel system was developed to fulfil the requirements of modern medical education and overcome the challenges faced by both students and lecturers in the process of knowledge transfer. A heart three-dimensional model presented in a virtual reality (VR) environment has been implemented in order to facilitate a new educational modality. This paper reports the outcome of a comparative study between traditional medical teaching modalities and virtual reality technology. This study was conducted in the Faculty of Medicine in the University of Jordan. The participants were asked to perform system trials and experiment with the system by navigating through the system interfaces, as well as being exposed to the traditional physical model of the human heart that is currently used in the faculty during practical anatomy sessions. Afterwards, they were asked to provide feedback via a comparative questionnaire. The participants’ replies to the questions regarding the Physical Heart Model and VR heart anatomy system were assessed for reliability using Cronbach’s alpha. The first group’s (Physical Heart Model questions) α value was 0.689. The second group’s (VR heart anatomy system questions) α value was 0.791. Comparing students’ experience results between the traditional method (Physical Heart Model) and the VR heart anatomy system, the mean scores showed a distinct increase in the values. This indicates that the developed system enhanced their experience in anatomy learning and the provided tools improved their understanding of heart anatomy. Results demonstrated the usefulness of the system by showing a higher satisfaction rate for the provided tools regarding structure and visualisation. © 2018, Springer-Verlag London Ltd., part of Springer Nature.","Anatomy; Comparative study; Heart; Medical education; Virtual reality","Education computing; Heart; Knowledge management; Medical education; Students; Teaching; Virtual reality; Anatomy; Comparative studies; Knowledge transfer; Medical training; Satisfaction rates; System interfaces; Three-dimensional model; Virtual reality technology; E-learning",Article,"Final","",Scopus,2-s2.0-85050790522
"Asghar I., Egaji O.A., Dando L., Griffiths M., Jenkins P.","56039492700;56009964300;57211524192;57211516910;57211514047;","A virtual reality based gas assessment application for training gas engineers",2019,"ACM International Conference Proceeding Series",,,,"57","61",,2,"10.1145/3357419.3357443","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074298411&doi=10.1145%2f3357419.3357443&partnerID=40&md5=cbe33b5c39e2a5f3ab6972a69ebd3552","Centre of Excellence in Mobile and Emerging Technologies, University of South Wales, Pontypridd, United Kingdom; GATC, 14A Taff Business Centre, Treforest, United Kingdom","Asghar, I., Centre of Excellence in Mobile and Emerging Technologies, University of South Wales, Pontypridd, United Kingdom; Egaji, O.A., Centre of Excellence in Mobile and Emerging Technologies, University of South Wales, Pontypridd, United Kingdom; Dando, L., Centre of Excellence in Mobile and Emerging Technologies, University of South Wales, Pontypridd, United Kingdom; Griffiths, M., Centre of Excellence in Mobile and Emerging Technologies, University of South Wales, Pontypridd, United Kingdom; Jenkins, P., GATC, 14A Taff Business Centre, Treforest, United Kingdom","Once a gas leak is reported, the rescue operation usually requires safe and precise identification of a leak source and stopping it. However, it is risky to train new gas engineers in a real gas leak situation. This paper aims to address this challenge by proposing a virtual reality (VR) based Gas Assessments and Training (GAT) Application (App) that helps gas engineers gain practical experience on correct gas safety procedures. The GAT App will also train gas engineers to make timely decisions and practice relevant safety measures when dealing with an actual gas leak. Sixteen gas engineers evaluated the GAT App. All the participants carried out several tasks with the GAT App and completed System Usability Scale (SUS) questionnaires afterwards. The data revealed an average SUS score of 84.06, which indicates that the gas engineers enjoyed using the GAT App and will recommend it to their colleagues. However, there is a need for more user testing for result generalisation. © 2019 Association for Computing Machinery.","Gas Assessments; Questionnaire; Safety; Training; Usability; Virtual Reality","Accident prevention; E-learning; Engineers; Personnel training; Surveys; Virtual addresses; Virtual reality; Generalisation; Practical experience; Questionnaire; Rescue operations; Safety measures; System Usability Scale (SUS); Usability; User testing; Gases",Conference Paper,"Final","",Scopus,2-s2.0-85074298411
"Xu X., Shen L., Li S., Wang S.","57212107701;57212102274;57212108732;57212110295;","Research on 10kV line breaker check training system based on virtual reality",2019,"Proceedings - 2019 International Conference on Smart Grid and Electrical Automation, ICSGEA 2019",,, 8901373,"18","21",,,"10.1109/ICSGEA.2019.00013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075940419&doi=10.1109%2fICSGEA.2019.00013&partnerID=40&md5=cc1e8b915dcc9b8d2d27cdc93f2f99be","Shibei Power Supply Company of SIVIEPC, Shanghai, 200072, China","Xu, X., Shibei Power Supply Company of SIVIEPC, Shanghai, 200072, China; Shen, L., Shibei Power Supply Company of SIVIEPC, Shanghai, 200072, China; Li, S., Shibei Power Supply Company of SIVIEPC, Shanghai, 200072, China; Wang, S., Shibei Power Supply Company of SIVIEPC, Shanghai, 200072, China","The training is the important means to improve power system operators' quality and ensure the safe, stable and reliable operation of power system. The job of 10kV line breaker check is one of the most important tasks of relay protection, and the training effect of this job is directly related to the work efficiency and quality of relay protection employees. However, in the training for relay protection trainees, it is impossible to carry out the actual operation in the substation considering the safety factor, and the construction of simulated substation costs a lot. To solve this problem, this paper uses Unity to develop a 10kV line breaker check training system based on virtual reality (VR). The training system development tools, 10kV line breaker check project, the training system structure and function design are introduced in the paper. Practical application shows that the training system is simple to use, easy to learn, can timely and quickly transfer data and results, which has achieved a good training effect. © 2019 IEEE.","10kV line breaker check; Relay protection; Virtual reality","E-learning; Electric power system protection; Electric power transmission networks; Relay protection; Safety factor; Smart power grids; Virtual reality; Actual operation; Function designs; Line breakers; Power system operators; Quality of relays; Reliable operation; Training effects; Training Systems; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-85075940419
"Miranda C.S., Oliveira T.D.P., Gouvêa J.X.M., Perez D.B., Marques A.P., Piemonte M.E.P.","55904702000;55340229200;57210340768;57143700400;9043065700;24081312100;","Balance Training in Virtual Reality Promotes Performance Improvement but Not Transfer to Postural Control in People with Chronic Stroke",2019,"Games for Health Journal","8","4",,"294","300",,1,"10.1089/g4h.2018.0075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068605388&doi=10.1089%2fg4h.2018.0075&partnerID=40&md5=f2c9cc4bcffbbbefc54112f349fe72b6","Department of Physical Therapy Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Rua Cipotânea, 51. Cid Universitária, São Paulo-SP, 05360-000, Brazil; Institute of Psychology, University of São Paulo, São Paulo, Brazil","Miranda, C.S., Department of Physical Therapy Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Rua Cipotânea, 51. Cid Universitária, São Paulo-SP, 05360-000, Brazil; Oliveira, T.D.P., Department of Physical Therapy Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Rua Cipotânea, 51. Cid Universitária, São Paulo-SP, 05360-000, Brazil; Gouvêa, J.X.M., Institute of Psychology, University of São Paulo, São Paulo, Brazil; Perez, D.B., Institute of Psychology, University of São Paulo, São Paulo, Brazil; Marques, A.P., Department of Physical Therapy Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Rua Cipotânea, 51. Cid Universitária, São Paulo-SP, 05360-000, Brazil; Piemonte, M.E.P., Institute of Psychology, University of São Paulo, São Paulo, Brazil","Objective: In people with chronic stroke, we investigated the transfer of gains obtained after balance training with virtual reality (VR) to an untrained task with similar balance demands. Materials and Methods: This study included 29 people with chronic stroke randomized into two groups: experimental (EG, n = 16) and control (CG, n = 13). The EG performed three sessions of balance training with VR using a platform-based videogame (Nintendo Wii Fit system™) for 1 week. The CG received no intervention. Transfer was evaluated through balance tests on the force platform Balance Master™, performed before and after the intervention period, for both groups. Results: The analysis of variance for repeated measures for game performance in the EG showed statistically significant improvement in scores in all five games after training (AT). In contrast, similar analysis for balance tests for the EG and CG showed no significant differences in performance index scores derived from the Balance Master tests after the intervention period for both groups. Conclusion: People with chronic stroke showed performance improvement AT with VR, but there was no transfer of the gains obtained to an untrained task with similar balance demands. © 2019, Mary Ann Liebert, Inc.","Learning; Paresis; Postural balance; Rehabilitation; Stroke; Virtual reality exposure therapy","adult; body equilibrium; cerebrovascular accident; complication; devices; female; human; male; middle aged; procedures; psychology; stroke rehabilitation; virtual reality; Adult; Female; Humans; Male; Middle Aged; Physical Functional Performance; Postural Balance; Stroke; Stroke Rehabilitation; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85068605388
"Freeman D., Yu L.-M., Kabir T., Martin J., Craven M., Leal J., Lambe S., Brown S., Morrison A., Chapman K., Dudley R., O'Regan E., Rovira A., Goodsell A., Rosebrock L., Bergin A., Cryer T.L., Robotham D., Andleeb H., Geddes J.R., Hollis C., Clark D.M., Waite F.","57202665457;7404164174;8306023400;57207800864;56768273300;16316414400;56062305400;57197845312;7402258312;57193302351;7102777269;35364796300;36168782400;57210820949;55599839200;57220371600;57209103191;16246148900;57210820762;56883972800;7006624553;7404789162;56602675700;","Automated virtual reality (VR) cognitive therapy for patients with psychosis: Study protocol for a single-blind parallel group randomised controlled trial (gameChange)",2019,"BMJ Open","9","8", e031606,"","",,6,"10.1136/bmjopen-2019-031606","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071540567&doi=10.1136%2fbmjopen-2019-031606&partnerID=40&md5=48d536baa2fc52f9fa303f730a726d5d","Department of Psychiatry, University of Oxford, Oxford, United Kingdom; Oxford Health NHS Foundation Trust, Oxford, United Kingdom; NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom; Primary Care Clinical Trials Unit, Nuffield Department of Primary Care Health Sciences, University of Oxford, Oxford, United Kingdom; McPin Foundation, London, United Kingdom; NIHR MindTech, Institute of Mental Health, Division of Psychiatry and Applied Psychology, University of Nottingham, Nottingham, United Kingdom; Health Economics Research Centre, Nuffield Department of Population Health, University of Oxford, Oxford, United Kingdom; Greater Manchester Mental Health Foundation Trust, Manchester, United Kingdom; Division of Psychology and Mental Health, University of Manchester, Manchester, United Kingdom; Avon and Wiltshire Mental Health Partnership (AWP) NHS Trust, Bath, United Kingdom; Northumberland, Tyne and Wear NHS Foundation Trust, Newcastle upon Tyne, United Kingdom; University of Newcastle, Newcastle upon Tyne, United Kingdom; Nottinghamshire Healthcare NHS Foundation Trust, Nottingham, United Kingdom; Department of Experimental Psychology, University of Oxford, Oxford, United Kingdom","Freeman, D., Department of Psychiatry, University of Oxford, Oxford, United Kingdom, Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom; Yu, L.-M., Primary Care Clinical Trials Unit, Nuffield Department of Primary Care Health Sciences, University of Oxford, Oxford, United Kingdom; Kabir, T., McPin Foundation, London, United Kingdom; Martin, J., NIHR MindTech, Institute of Mental Health, Division of Psychiatry and Applied Psychology, University of Nottingham, Nottingham, United Kingdom; Craven, M., NIHR MindTech, Institute of Mental Health, Division of Psychiatry and Applied Psychology, University of Nottingham, Nottingham, United Kingdom; Leal, J., Health Economics Research Centre, Nuffield Department of Population Health, University of Oxford, Oxford, United Kingdom; Lambe, S., Department of Psychiatry, University of Oxford, Oxford, United Kingdom, Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom; Brown, S., NIHR MindTech, Institute of Mental Health, Division of Psychiatry and Applied Psychology, University of Nottingham, Nottingham, United Kingdom; Morrison, A., Greater Manchester Mental Health Foundation Trust, Manchester, United Kingdom, Division of Psychology and Mental Health, University of Manchester, Manchester, United Kingdom; Chapman, K., Avon and Wiltshire Mental Health Partnership (AWP) NHS Trust, Bath, United Kingdom; Dudley, R., Northumberland, Tyne and Wear NHS Foundation Trust, Newcastle upon Tyne, United Kingdom, University of Newcastle, Newcastle upon Tyne, United Kingdom; O'Regan, E., Nottinghamshire Healthcare NHS Foundation Trust, Nottingham, United Kingdom; Rovira, A., Department of Psychiatry, University of Oxford, Oxford, United Kingdom, Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom; Goodsell, A., Department of Psychiatry, University of Oxford, Oxford, United Kingdom, Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom; Rosebrock, L., Department of Psychiatry, University of Oxford, Oxford, United Kingdom, Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom; Bergin, A., NIHR MindTech, Institute of Mental Health, Division of Psychiatry and Applied Psychology, University of Nottingham, Nottingham, United Kingdom; Cryer, T.L., McPin Foundation, London, United Kingdom; Robotham, D., McPin Foundation, London, United Kingdom; Andleeb, H., McPin Foundation, London, United Kingdom; Geddes, J.R., Department of Psychiatry, University of Oxford, Oxford, United Kingdom, Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom; Hollis, C., NIHR MindTech, Institute of Mental Health, Division of Psychiatry and Applied Psychology, University of Nottingham, Nottingham, United Kingdom; Clark, D.M., Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom, Department of Experimental Psychology, University of Oxford, Oxford, United Kingdom; Waite, F., Department of Psychiatry, University of Oxford, Oxford, United Kingdom, Oxford Health NHS Foundation Trust, Oxford, United Kingdom, NIHR Oxford Health Biomedical Research Centre, Oxford, United Kingdom","Introduction Many patients with psychosis experience everyday social situations as anxiety-provoking. The fears can arise, for example, from paranoia, hallucinations, social anxiety or negative-self beliefs. The fears lead patients to withdraw from activities, and this isolation leads to a cycle of worsening physical and mental health. Breaking this cycle requires highly active treatment directly in the troubling situations so that patients learn that they can safely and confidently enter them. However patients with psychosis seldom receive such life-changing interventions. To solve this problem we have developed an automated psychological treatment delivered in virtual reality (VR). It allows patients to experience computer simulations of the situations that they find anxiety-provoking. A virtual coach guides patients, using cognitive techniques, in how to overcome their fears. Patients are willing to enter VR simulations of anxiety-provoking situations because they know the simulations are not real, but the learning made transfers to the real world. Methods and analysis 432 patients with psychosis and anxious avoidance of social situations will be recruited from National Health Service (NHS) secondary care services. In the gameChange trial, they will be randomised (1:1) to the six-session VR cognitive treatment added to treatment as usual or treatment as usual alone. Assessments will be conducted at 0, 6 (post-treatment) and 26 weeks by a researcher blind to allocation. The primary outcome is avoidance and distress in real-life situations, using a behavioural assessment task, at 6 weeks. The secondary outcomes are psychiatric symptoms, activity levels and quality of life. All main analyses will be intention-to-treat. Moderation and mediation will be tested. An economic evaluation will be conducted. Ethics and dissemination The trial has received ethical approval from the NHS South Central - Oxford B Research Ethics Committee (19/SC/0075). A key output will be a high-quality automated VR treatment for patients to overcome anxious avoidance of social situations. Trial registration number ISRCTN17308399. © Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY. Published by BMJ.","Cognitive therapy; Psychosis; Schizophrenia; Treatment; Virtual reality","adult; anxiety; Article; avoidance behavior; behavior assessment; clinical outcome; clinical trial protocol; cognitive therapy; computer simulation; controlled study; cost effectiveness analysis; distress syndrome; economic evaluation; fear; human; intention to treat analysis; major clinical study; multicenter study; psychosis; psychotherapy; quality of life; randomized controlled trial; single blind procedure; virtual reality; cognitive behavioral therapy; computer assisted therapy; England; multicenter study (topic); procedures; psychology; psychosis; randomized controlled trial (topic); time factor; treatment outcome; virtual reality exposure therapy; Cognitive Behavioral Therapy; England; Humans; Multicenter Studies as Topic; Psychotic Disorders; Quality of Life; Randomized Controlled Trials as Topic; Single-Blind Method; Therapy, Computer-Assisted; Time Factors; Treatment Outcome; Virtual Reality Exposure Therapy",Article,"Final","",Scopus,2-s2.0-85071540567
"Schmidt M.W., Kowalewski K.-F., Schmidt M.L., Wennberg E., Garrow C.R., Paik S., Benner L., Schijven M.P., Müller-Stich B.P., Nickel F.","57191077022;56909719800;57213155163;57200621341;57038854800;57204429364;57195478316;6602492995;14322034300;35603936500;","The Heidelberg VR Score: development and validation of a composite score for laparoscopic virtual reality training",2019,"Surgical Endoscopy","33","7",,"2093","2103",,7,"10.1007/s00464-018-6480-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055471799&doi=10.1007%2fs00464-018-6480-x&partnerID=40&md5=b9aca13315c47a6d89707907660fdcf4","Department of General, Visceral, and Transplantation Surgery, Heidelberg University Hospital, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Karlsruhe, Germany; Department of Medical Biometry and Informatics, University of Heidelberg, Im Neuenheimer Feld 130.3, Heidelberg, 69120, Germany; Deparment of Surgery, Amsterdam Gastroenterology and Metabolism, Amsterdam UMC, University of Amsterdam, PO Box 22660, Amsterdam, 1100 DD, Netherlands","Schmidt, M.W., Department of General, Visceral, and Transplantation Surgery, Heidelberg University Hospital, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Kowalewski, K.-F., Department of General, Visceral, and Transplantation Surgery, Heidelberg University Hospital, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Schmidt, M.L., Karlsruhe, Germany; Wennberg, E., Department of General, Visceral, and Transplantation Surgery, Heidelberg University Hospital, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Garrow, C.R., Department of General, Visceral, and Transplantation Surgery, Heidelberg University Hospital, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Paik, S., Department of General, Visceral, and Transplantation Surgery, Heidelberg University Hospital, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Benner, L., Department of Medical Biometry and Informatics, University of Heidelberg, Im Neuenheimer Feld 130.3, Heidelberg, 69120, Germany; Schijven, M.P., Deparment of Surgery, Amsterdam Gastroenterology and Metabolism, Amsterdam UMC, University of Amsterdam, PO Box 22660, Amsterdam, 1100 DD, Netherlands; Müller-Stich, B.P., Department of General, Visceral, and Transplantation Surgery, Heidelberg University Hospital, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Nickel, F., Department of General, Visceral, and Transplantation Surgery, Heidelberg University Hospital, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany","Introduction: Virtual reality (VR-)trainers are well integrated in laparoscopic surgical training. However, objective feedback is often provided in the form of single parameters, e.g., time or number of movements, making comparisons and evaluation of trainees’ overall performance difficult. Therefore, a new standard for reporting outcome data is highly needed. The aim of this study was to create a weighted, expert-based composite score, to offer simple and direct evaluation of laparoscopic performance on common VR-trainers. Materials and methods: An integrated analytic hierarchy process-Delphi survey was conducted with 14 international experts to achieve a consensus on the importance of different skill categories and parameters in evaluation of laparoscopic performance. A scoring algorithm was established to allow comparability between tasks and VR-trainers. A weighted composite score was calculated for basic skills tasks and peg transfer on the LapMentor™ II and III and validated for both VR-trainers. Results: Five major skill categories (time, efficiency, safety, dexterity, and outcome) were identified and weighted in two Delphi rounds. Safety, with a weight of 67%, was determined the most important category, followed by efficiency with 17%. The LapMentor™-specific score was validated using 15 (14) novices and 9 experts; the score was able to differentiate between both groups for basic skills tasks and peg transfer (LapMentor™ II: Exp: 86.5 ± 12.7, Nov. 52.8 ± 18.3; p < 0.001; LapMentor™ III: Exp: 80.8 ± 7.1, Nov: 50.6 ± 16.9; p < 0.001). Conclusion: An effective and simple performance measurement was established to propose a new standard in analyzing and reporting VR outcome data—the Heidelberg virtual reality (VR) score. The scoring algorithm and the consensus results on the importance of different skill aspects in laparoscopic surgery are universally applicable and can be transferred to any simulator or task. By incorporating specific expert baseline data for the respective task, comparability between tasks, studies, and simulators can be achieved. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Analytic hierarchy process; Delphi; Minimally invasive surgery; Score; Skill assessment; Virtual reality trainer","Article; Delphi study; evaluation study; Heidelberg vr score; human; laparoscopic surgery; mathematical computing; priority journal; safety; scoring system; surgical training; validation study; virtual reality; clinical competence; computer simulation; education; laparoscopy; male; medical education; procedures; questionnaire; reproducibility; Clinical Competence; Computer Simulation; Education, Medical, Graduate; Humans; Laparoscopy; Male; Reproducibility of Results; Surveys and Questionnaires; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85055471799
"Neueder D., Andreatta M., Pauli P.","55877547500;23967624100;7003473881;","Contextual fear conditioning and fear generalization in individuals with panic attacks",2019,"Frontiers in Behavioral Neuroscience","13",, 152,"","",,3,"10.3389/fnbeh.2019.00152","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069528852&doi=10.3389%2ffnbeh.2019.00152&partnerID=40&md5=9aa8d7ab670badde1b8617f15ae9cbef","Department of Psychology (Biological Psychology Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany; Center for Mental Health, Medical Faculty, University of Würzburg, Würzburg, Germany","Neueder, D., Department of Psychology (Biological Psychology Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany; Andreatta, M., Department of Psychology (Biological Psychology Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany; Pauli, P., Department of Psychology (Biological Psychology Clinical Psychology and Psychotherapy), University of Würzburg, Würzburg, Germany, Center for Mental Health, Medical Faculty, University of Würzburg, Würzburg, Germany","Context conditioning is characterized by unpredictable threat and its generalization may constitute risk factors for panic disorder (PD). Therefore, we examined differences between individuals with panic attacks (PA; N = 21) and healthy controls (HC, N = 22) in contextual learning and context generalization using a virtual reality (VR) paradigm. Successful context conditioning was indicated in both groups by higher arousal, anxiety and contingency ratings, and increased startle responses and skin conductance levels (SCLs) in an anxiety context (CTX+) where an aversive unconditioned stimulus (US) occurred unpredictably vs. a safety context (CTX−). PA compared to HC exhibited increased differential responding to CTX+ vs. CTX− and overgeneralization of contextual anxiety on an evaluative verbal level, but not on a physiological level. We conclude that increased contextual conditioning and contextual generalization may constitute risk factors for PD or agoraphobia contributing to the characteristic avoidance of anxiety contexts and withdrawal to safety contexts and that evaluative cognitive process may play a major role. © 2019 Neueder, Andreatta and Pauli.","Anxiety generalization; Contextual fear conditioning; Panic disorder; Startle response; Virtual reality","adult; agoraphobia; anxiety; arousal; Article; clinical article; cognition; conditioning; context generalization; contextual learning; controlled study; female; human; male; neuropsychological test; panic; physiological process; risk assessment; risk factor; skin conductance; startle reflex; virtual reality",Article,"Final","",Scopus,2-s2.0-85069528852
"Steffen J.H., Gaskin J.E., Meservy T.O., Jenkins J.L., Wolman I.","57200579874;36006215900;8965919200;36713489900;57210317891;","Framework of Affordances for Virtual Reality and Augmented Reality",2019,"Journal of Management Information Systems","36","3",,"683","729",,10,"10.1080/07421222.2019.1628877","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070323987&doi=10.1080%2f07421222.2019.1628877&partnerID=40&md5=4cc7e578379bb372fe5452b489db6237","Terry College of Business, University of Georgia, United States; Management Information Systems, Brigham Young University, United States; Information Systems, Brigham Young University, United States; Information Systems, Brigham Young University, United States; Master of Information Systems Management program, Brigham Young University, United States","Steffen, J.H., Terry College of Business, University of Georgia, United States; Gaskin, J.E., Management Information Systems, Brigham Young University, United States; Meservy, T.O., Information Systems, Brigham Young University, United States; Jenkins, J.L., Information Systems, Brigham Young University, United States; Wolman, I., Master of Information Systems Management program, Brigham Young University, United States","Virtual reality (VR) and augmented reality (AR) technologies continue to grow and present possibilities to change the ways we learn, accomplish tasks, and interact with the world. However, widespread adoption has continually languished below purported potential. We suggest that a more complete understanding of the underlying motives driving users to take advantage of VR and AR would aid researchers by consolidating fragmented knowledge across domains and by identifying paths for additional inquiry. Additionally, practitioners could identify areas of unmet motives for using VR and AR. To examine the motives for virtualization, we draw upon Gibson’s seminal work on affordances to create a framework of generalized affordances for virtually assisted activities relative to the affordances of physical reality. This framework facilitates comparison of virtualized activities to non-virtualized activities, comparison of similar activities across VR and AR, and delineates areas of inquiry for future research. The validity of the framework was explored through two quantitative studies and one qualitative study of a wide variety of professionals. We found that participants perceive a significant difference between physical reality and both VR and AR for all proposed affordances, and that for many affordances, users perceive a difference in the ability of AR and VR to enact them. The qualitative study confirmed the general structure of the framework, while also revealing additional sub-affordances to explore. Theoretically, this suggests that examining the affordances that differentiate these technologies from physical reality may be a valid approach to understanding why users adopt these technologies. Practitioners may find success by focusing development on the specific affordances that VR or AR is best equipped to enact. ©, Copyright © Taylor & Francis Group, LLC.","adoption motivations; augmented reality; technology adoption; technology affordances; theoretical framework; virtual reality; virtually assisted activities","Augmented reality; Virtual reality; Adoption motivations; Technology adoption; Technology affordances; Theoretical framework; virtually assisted activities; Engineering education",Article,"Final","",Scopus,2-s2.0-85070323987
"Wu H., Wang Y., Qiu J., Liu J., Zhang X.L.","14030737900;57204950159;57203815608;57203815337;55715154500;","User-defined gesture interaction for immersive VR shopping applications",2019,"Behaviour and Information Technology","38","7",,"726","741",,7,"10.1080/0144929X.2018.1552313","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058093939&doi=10.1080%2f0144929X.2018.1552313&partnerID=40&md5=658f7a33df4427d9da8503cc19cb20a1","The School of Communication and Design, Sun Yat-sen University, Guangzhou, China; Department of Medical Oncology, Sun Yat-sen University Cancer Center, State Key Laboratory of Oncology, South China, Collaborative Innovation Center for Cancer Medicine, Guangzhou, China; College of Information Sciences and Technology, Pennsylvania State University, University Park, PA, United States","Wu, H., The School of Communication and Design, Sun Yat-sen University, Guangzhou, China; Wang, Y., Department of Medical Oncology, Sun Yat-sen University Cancer Center, State Key Laboratory of Oncology, South China, Collaborative Innovation Center for Cancer Medicine, Guangzhou, China; Qiu, J., The School of Communication and Design, Sun Yat-sen University, Guangzhou, China; Liu, J., The School of Communication and Design, Sun Yat-sen University, Guangzhou, China; Zhang, X.L., College of Information Sciences and Technology, Pennsylvania State University, University Park, PA, United States","Gesture elicitation studies, which are a popular technology for collecting requirements and expectations by involving real users in gesture design processes, often suffer from gesture disagreement and legacy bias and may not generate optimal gestures for a target system in practice. This paper reports a research project on user-defined gestures for interacting with immersive VR shopping applications. The main contribution of this work is the proposal of a more practical method for deriving more reliable gestures than traditional gesture elicitation studies. We applied this method to a VR shopping application and obtained empirical evidence for the benefits of deriving two gestures in the a priori stage and selecting the top-two gestures in the a posteriori stage of traditional elicitation studies for each referent. We hope that this research can help lay a theoretical foundation for freehand-gesture-based user interface design and be generalised to all freehand-gesture-based applications. © 2018, © 2018 Informa UK Limited, trading as Taylor & Francis Group.","elicitation study; Gestural interaction; online shopping; user-centered design; virtual reality","Human computer interaction; Software design; User centered design; Virtual reality; Design process; elicitation study; Gestural interaction; Online shopping; Practical method; Theoretical foundations; User interface designs; User-defined gestures; User interfaces",Article,"Final","",Scopus,2-s2.0-85058093939
"Juliano J.M., Saldana D., Schmiesing A., Liew S.-L.","57209396794;57194044260;57194041188;36992162200;","Experience with head-mounted virtual reality (HMD-VR) predicts transfer of HMD-VR motor skills",2019,"International Conference on Virtual Rehabilitation, ICVR","2019-July",, 8994345,"","",,,"10.1109/ICVR46560.2019.8994345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080146106&doi=10.1109%2fICVR46560.2019.8994345&partnerID=40&md5=e52cf9a653b976ff6d3a6891f629dc26","University of Southern California (USC), Neuroscience Graduate Program, Los Angeles, CA, United States; University of Southern California, Chan Division of Occupational, Los Angeles, CA, United States","Juliano, J.M., University of Southern California (USC), Neuroscience Graduate Program, Los Angeles, CA, United States; Saldana, D., University of Southern California, Chan Division of Occupational, Los Angeles, CA, United States; Schmiesing, A., University of Southern California, Chan Division of Occupational, Los Angeles, CA, United States; Liew, S.-L., University of Southern California, Chan Division of Occupational, Los Angeles, CA, United States","Immersive, head-mounted virtual reality (HMD-VR) has the potential to be a useful tool for motor rehabilitation. However, when developing tools for rehabilitation, it is essential to design interventions that will be most effective for generalizing to the real world. Therefore, it is important to understand what factors facilitate transfer from HMD-VR to non-HMD-VR environments. Here we used a well-established test of skilled motor learning, the Sequential Visual Isometric Pinch Task (SVIPT), to train healthy individuals in an HMD-VR environment. We examined whether learned motor skills transferred to a more conventional (non-HMD-VR) environment and what factors facilitated transfer. Our results suggest that on average, learned motor skills from this task transfer from an immersive virtual environment to a conventional environment; however, some individuals did not transfer the learned motor skills. We then examined individual differences between those that did show transfer and those that did not. We found that individuals who had previous exposure to HMD-VR were more likely to transfer their learned motor skills than those who did not. Individual differences in previous exposure to HMD-VR environments prior to training may serve as a predictor to whether learned motor skills will transfer out of HMD-VR. © 2019 IEEE.","head-mounted virtual reality; skilled motor learning; transfer","Helmet mounted displays; Virtual reality; Head mounted virtual reality; Healthy individuals; Immersive virtual environments; Individual Differences; Motor learning; Motor rehabilitation; Task transfer; transfer; Transfer learning",Conference Paper,"Final","",Scopus,2-s2.0-85080146106
"Wei S.-E., Saragih J., Simon T., Harley A.W., Lombardi S., Perdoch M., Hypes A., Wang D., Badino H., Sheikh Y.","55485702800;16178291100;36444916900;56115289800;57204687314;24822136000;57189798081;57211427209;8981371600;9437184000;","VR facial animation via multiview image translation",2019,"ACM Transactions on Graphics","38","4", 67,"","",,16,"10.1145/3306346.3323030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073888466&doi=10.1145%2f3306346.3323030&partnerID=40&md5=f6eae33b4d0ae00f03aadbb5bba01c86","Carnegie Mellon University, Facebook Reality Labs, United States; Facebook Reality Labs, Pittsburgh, PA, United States","Wei, S.-E., Facebook Reality Labs, Pittsburgh, PA, United States; Saragih, J., Facebook Reality Labs, Pittsburgh, PA, United States; Simon, T., Facebook Reality Labs, Pittsburgh, PA, United States; Harley, A.W., Carnegie Mellon University, Facebook Reality Labs, United States, Facebook Reality Labs, Pittsburgh, PA, United States; Lombardi, S., Facebook Reality Labs, Pittsburgh, PA, United States; Perdoch, M., Facebook Reality Labs, Pittsburgh, PA, United States; Hypes, A., Facebook Reality Labs, Pittsburgh, PA, United States; Wang, D., Facebook Reality Labs, Pittsburgh, PA, United States; Badino, H., Facebook Reality Labs, Pittsburgh, PA, United States; Sheikh, Y., Facebook Reality Labs, Pittsburgh, PA, United States","A key promise of Virtual Reality (VR) is the possibility of remote social interaction that is more immersive than any prior telecommunication media. However, existing social VR experiences are mediated by inauthentic digital representations of the user (i.e., stylized avatars). These stylized representations have limited the adoption of social VR applications in precisely those cases where immersion is most necessary (e.g., professional interactions and intimate conversations). In this work, we present a bidirectional system that can animate avatar heads of both users’ full likeness using consumer-friendly headset mounted cameras (HMC). There are two main challenges in doing this: unaccommodating camera views and the image-to-avatar domain gap. We address both challenges by leveraging constraints imposed by multiview geometry to establish precise image-to-avatar correspondence, which are then used to learn an end-to-end model for real-time tracking. We present designs for a training HMC, aimed at data-collection and model building, and a tracking HMC for use during interactions in VR. Correspondence between the avatar and the HMC-acquired images are automatically found through self-supervised multiview image translation, which does not require manual annotation or one-to-one correspondence between domains. We evaluate the system on a variety of users and demonstrate significant improvements over prior work. © 2019 Copyright held by the owner/author(s).","And Phrases: Face Tracking; Differentiable Rendering; Unsupervised Image Style Transfer","Virtual reality; Bidirectional system; Differentiable Rendering; Digital representations; Face Tracking; Multi-view geometry; Professional interactions; Social interactions; Unsupervised Image Style Transfer; Cameras",Article,"Final","",Scopus,2-s2.0-85073888466
"Levac D.E., Glegg S., Pradhan S., Fox E.J., Espy D., Chicklis E., Deutsch J.E.","25937323900;36871721200;35146628200;7202093916;34876570500;57209688091;7201985389;","A comparison of virtual reality and active video game usage, attitudes and learning needs among therapists in Canada and the US",2019,"International Conference on Virtual Rehabilitation, ICVR","2019-July",, 8994624,"","",,,"10.1109/ICVR46560.2019.8994624","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080126548&doi=10.1109%2fICVR46560.2019.8994624&partnerID=40&md5=76dbcb4ce339178f44905371c7592a26","Northeastern University, Dept. of Physical Therapy, Boston, United States; Sunny Hill Health Centre for Children, Therapy Department, Vancouver, Canada; University of Washington, Div. of Physical Therapy, Seattle, United States; University of Florida, Dept. of Physical Therapy, Gainesville, FL, United States; Cleveland State University, Dept. of Health Sciences, Cleveland, United States; Northeastern University, Rehabilitation Games and Virtual Reality Lab, Boston, MA, United States; Rutgers University, Dept. of Rehab and Movement Sciences, Newark, United States","Levac, D.E., Northeastern University, Dept. of Physical Therapy, Boston, United States; Glegg, S., Sunny Hill Health Centre for Children, Therapy Department, Vancouver, Canada; Pradhan, S., University of Washington, Div. of Physical Therapy, Seattle, United States; Fox, E.J., University of Florida, Dept. of Physical Therapy, Gainesville, FL, United States; Espy, D., Cleveland State University, Dept. of Health Sciences, Cleveland, United States; Chicklis, E., Northeastern University, Rehabilitation Games and Virtual Reality Lab, Boston, MA, United States; Deutsch, J.E., Rutgers University, Dept. of Rehab and Movement Sciences, Newark, United States","Differences in health care funding and policies between the United States and Canada may influence uptake of and attitudes towards virtual reality (VR) and active video gaming (AVG) systems by physical (PTs) and occupational therapists (OTs) in each country. The purpose of this study was to undertake a cross-country comparison of VR/AVG uptake to inform the content of educational interventions designed to promote implementation of these technologies into practice. A cross-sectional online survey that included the Assessing Determinants of Prospective Take-up of Virtual Reality (version 2; ADOPT-VR2) Instrument was conducted in 2014-2015 (Canada) and replicated in 2017-2018 (US). Recruitment took place via convenience and snowball sampling, using email, social media and newsletter postings. Therapists in the US reported greater past experience with, current use of, and intention to use VR/AVGs than did those in Canada. They also rated facilitators more positively and barriers less negatively. Use of customized VR systems was low, with specific system prevalence differing between countries. The most frequently used AVG systems, populations and settings of use, functional goals, predictors of use, learning needs and preferred forms of support were similar between countries. These similarities support the generalizability of educational interventions for both countries. Materials to be developed will focus on non-customized AVG systems. Subsequent work will examine how uptake relates to country-specific health care funding and policies, probe differences in learning needs between therapists with experience using customized versus non-customized VR/AVG systems, and extend the survey to other countries where VR/AVG use is prevalent. © 2019 IEEE.","active video games; knowledge translation; rehabilitation; survey; virtual reality","E-learning; Health care; Interactive computer graphics; Patient rehabilitation; Surveying; Surveys; User experience; Virtual reality; Canada and the US; Country comparisons; Educational intervention; Intention to use; Knowledge translation; Online surveys; Video game; Video gaming; Learning systems",Conference Paper,"Final","",Scopus,2-s2.0-85080126548
"Martschinke J., Hartnagel S., Keinert B., Engel K., Stamminger M.","56537046200;57210255427;55370532400;56744888500;55906526700;","Adaptive Temporal Sampling for Volumetric Path Tracing of Medical Data",2019,"Computer Graphics Forum","38","4",,"67","76",,1,"10.1111/cgf.13771","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070074954&doi=10.1111%2fcgf.13771&partnerID=40&md5=5c230129b7621a2b1f6a743a720ce9e4","University of Erlangen-Nuremberg, Germany; Siemens Healthineers, Germany","Martschinke, J., University of Erlangen-Nuremberg, Germany; Hartnagel, S., University of Erlangen-Nuremberg, Germany; Keinert, B., University of Erlangen-Nuremberg, Germany; Engel, K., Siemens Healthineers, Germany; Stamminger, M., University of Erlangen-Nuremberg, Germany","Monte-Carlo path tracing techniques can generate stunning visualizations of medical volumetric data. In a clinical context, such renderings turned out to be valuable for communication, education, and diagnosis. Because a large number of computationally expensive lighting samples is required to converge to a smooth result, progressive rendering is the only option for interactive settings: Low-sampled, noisy images are shown while the user explores the data, and as soon as the camera is at rest the view is progressively refined. During interaction, the visual quality is low, which strongly impedes the user's experience. Even worse, when a data set is explored in virtual reality, the camera is never at rest, leading to constantly low image quality and strong flickering. In this work we present an approach to bring volumetric Monte-Carlo path tracing to the interactive domain by reusing samples over time. To this end, we transfer the idea of temporal antialiasing from surface rendering to volume rendering. We show how to reproject volumetric ray samples even though they cannot be pinned to a particular 3D position, present an improved weighting scheme that makes longer history trails possible, and define an error accumulation method that downweights less appropriate older samples. Furthermore, we exploit reprojection information to adaptively determine the number of newly generated path tracing samples for each individual pixel. Our approach is designed for static, medical data with both volumetric and surface-like structures. It achieves good-quality volumetric Monte-Carlo renderings with only little noise, and is also usable in a VR context. © 2019 The Author(s) Computer Graphics Forum © 2019 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd.","Applied computing → Health informatics; CCS Concepts; • Computing methodologies → Ray tracing; • Human-centered computing → Scientific visualization","Cameras; Diagnosis; Interactive computer systems; Medical informatics; Virtual reality; Visualization; Volume rendering; Volumetric analysis; Applied computing; CCS Concepts; Computing methodologies; Human-centered computing; Interactive domains; Monte Carlo path tracing; Monte-Carlo rendering; Progressive rendering; Monte Carlo methods",Article,"Final","",Scopus,2-s2.0-85070074954
"Wang H., Wang Q., Hu F.","57214057788;57145088700;57205211655;","Are you afraid of heights and suitable for working at height?",2019,"Biomedical Signal Processing and Control","52",,,"23","31",,4,"10.1016/j.bspc.2019.03.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063350700&doi=10.1016%2fj.bspc.2019.03.011&partnerID=40&md5=aa4056a7eff76371071e3dc5157f14a2","NO. 3-11, Wenhua Road, Heping District, Shenyang, 110819, China","Wang, H., NO. 3-11, Wenhua Road, Heping District, Shenyang, 110819, China; Wang, Q., NO. 3-11, Wenhua Road, Heping District, Shenyang, 110819, China; Hu, F., NO. 3-11, Wenhua Road, Heping District, Shenyang, 110819, China","Fear of highs is one of the most common phobias all around world. It could affect people's life, work and health. Standing on high-altitude can lead to fear, anxiety or even panic to some people. In this paper, EEG method is creatively combined with VR technology to assess the severity of fear of heights. By doing time-frequency analysis, we found that alpha band (8–13 Hz) and high beta (20–30 Hz) are sensitive to fear of heights and frontal and parietotemporal areas are the regions of interests for fear of heights. Then using cross mutual information we built up a functional brain networks of every subject. And we extracted EEG features from the brain networks. Statistical analysis was performed to select the features based on significance of difference. Finally, we implemented classification. The performance of classifiers (the average accuracy could reach 94.44%) based on the proposed method was compared to the performance of classifiers based on the traditional physiological features. As a result, the proposed method was verified to be reliable and superior on estimating the severity of fear of heights. In addition, the system was tested on elderly people and came out with good performance. It turns out that the proposed system has good generalization capability and adaptability. © 2019","EEG; Fear of heights; Functional brain network; VR","Biomedical engineering; Control engineering; Electroencephalography; Brain networks; Fear of heights; Generalization capability; Mutual informations; Performance of classifier; Physiological features; Regions of interest; Time frequency analysis; Signal processing; acrophobia; adult; agitation; anxiety; Article; brain function; controlled study; electroencephalogram; electrooculogram; entropy; fear; female; human; male; muscle tone; nerve cell network; normal human; priority journal; supervised machine learning; virtual reality; work environment",Article,"Final","",Scopus,2-s2.0-85063350700
"Forjan M., David V., Wagner M., Dolesch L., Lechner M., Sauermann S.","54899324700;55907047600;57190175055;57213606780;57213603313;6602179283;","Conceptualization of an ICU Infrastructure for Simulation Based Education in Medical Engineering eHealth",2019,"Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS",,, 8856949,"4186","4189",,,"10.1109/EMBC.2019.8856949","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077881460&doi=10.1109%2fEMBC.2019.8856949&partnerID=40&md5=df91b734ff025cff1a48f66ac01dd9b9","Department Life Sciences, University of Applied Sciences Technikum Wien, Vienna, Austria; Division of Neonatology, Pediatric Intensive Care and Neuropediatrics, Medical University of Vienna, Vienna, Austria; Gsm Gesellschaft für Sicherheit in der Medizintechnik GmbH, Vienna, Austria","Forjan, M., Department Life Sciences, University of Applied Sciences Technikum Wien, Vienna, Austria; David, V., Department Life Sciences, University of Applied Sciences Technikum Wien, Vienna, Austria; Wagner, M., Division of Neonatology, Pediatric Intensive Care and Neuropediatrics, Medical University of Vienna, Vienna, Austria; Dolesch, L., Gsm Gesellschaft für Sicherheit in der Medizintechnik GmbH, Vienna, Austria; Lechner, M., Gsm Gesellschaft für Sicherheit in der Medizintechnik GmbH, Vienna, Austria; Sauermann, S., Department Life Sciences, University of Applied Sciences Technikum Wien, Vienna, Austria","The use of simulation-based training is gaining importance in medical as well as engineering related education. The complex environment of an intensive care unit is characterized by a high need of interaction between clinical as well as technical components and views. These diverse interactions and the connected requirements are the focus for the presented simulation infrastructure, enabling research, education and training. The presented concept of a modular and flexible intensive care environment provides a high degree of interoperability and flexibility for individual research questions and full support of connectivity for typical clinical workflows. The presented simulation and testing bed will allow both, education for engineering and medical students using patient simulation and simultaneous data transfer as well as research on medical workflows, infrastructural demands and connectivity conformance questions. © 2019 IEEE.",,"Biomedical engineering; Clinical research; Data transfer; Well testing; Complex environments; Education and training; Intensive care environments; Medical engineering; Patient simulations; Research questions; Simulation and testing; Simulation-based training; Intensive care units; adult; article; biomedical engineering; case report; clinical article; female; human; intensive care unit; male; medical student; patient simulation; telehealth; workflow",Conference Paper,"Final","",Scopus,2-s2.0-85077881460
"Katrychuk D., Griffith H.K., Komogortsev O.V.","57210105027;57189386560;6506328653;","Power-efficient and shift-robust eye-tracking sensor for portable VR headsets",2019,"Eye Tracking Research and Applications Symposium (ETRA)",,, a19,"","",,7,"10.1145/3314111.3319821","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069483095&doi=10.1145%2f3314111.3319821&partnerID=40&md5=457b404170995b342473d55c75de6d33","Department of Computer Science, Texas State University, San Marcos, TX, United States","Katrychuk, D., Department of Computer Science, Texas State University, San Marcos, TX, United States; Griffith, H.K., Department of Computer Science, Texas State University, San Marcos, TX, United States; Komogortsev, O.V., Department of Computer Science, Texas State University, San Marcos, TX, United States","Photosensor oculography (PSOG) is a promising solution for reducing the computational requirements of eye tracking sensors in wireless virtual and augmented reality platforms. This paper proposes a novel machine learning-based solution for addressing the known performance degradation of PSOG devices in the presence of sensor shifts. Namely, we introduce a convolutional neural network model capable of providing shift-robust end-to-end gaze estimates from the PSOG array output. Moreover, we propose a transfer-learning strategy for reducing model training time. Using a simulated workflow with improved realism, we show that the proposed convolutional model offers improved accuracy over a previously considered multilayer perceptron approach. In addition, we demonstrate that the transfer of initialization weights from pre-trained models can substantially reduce training time for new users. In the end, we provide the discussion regarding the design trade-offs between accuracy, training time, and power consumption among the considered models. © 2019 Association for Computing Machinery.","Eye-tracking; Machine learning; ML; Photo-sensor oculography; PSOG; Virtual reality; VR","Augmented reality; Convolution; Economic and social effects; Learning systems; Machine learning; Neural networks; Optical sensors; Virtual reality; Computational requirements; Convolutional model; Convolutional neural network; Eye-tracking sensors; Performance degradation; Photo-sensors; PSOG; Virtual and augmented reality; Eye tracking",Conference Paper,"Final","",Scopus,2-s2.0-85069483095
"Lopez C.E., Ashour O., Tucker C.","57193163382;36080456300;15833577900;","An introduction to the CLICK approach: Leveraging virtual reality to integrate the industrial engineering curriculum",2019,"ASEE Annual Conference and Exposition, Conference Proceedings",,,,"","",,3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076433701&partnerID=40&md5=0b9ee7dc3d5e083d23ad59a1d87115c6","Pennsylvania State University, University Park, United States; Penn State Erie, Behrend College, United States","Lopez, C.E., Pennsylvania State University, University Park, United States; Ashour, O., Penn State Erie, Behrend College, United States; Tucker, C., Pennsylvania State University, University Park, United States","This work introduces a new approach called Connected Learning and Integrated Course Knowledge (CLICK). CLICK is intended to provide an integrative learning experience by leveraging Virtual Reality (VR) technology to help provide a theme to connect and transfer the knowledge of engendering concepts. Integrative learning is described as the process of creating connections between concepts (i.e., skill and knowledge) from different resources and experiences, linking theory and practice, and using a variation of platforms to help students' understanding. In the CLICK approach, the integration is achieved by VR learning modules that serve as a platform for a common theme and include various challenges and exercises from multiple courses across the IE curriculum. Moreover, the modules will provide an immersive and realistic experience, which the authors hypothesize, will improve how the students relate what they learn in a classroom, to real-life experiences. The goals of the CLICK approach are to (i) provide the needed connection between courses and improve students' learning, and (ii) provide the needed linkage between theory and practice through a realistic representation of systems using VR. This work presents the results from an initial usability test performed on one of the VR modules. The results from the usability test indicate that participants liked the realism of the VR module. However, there are still some areas for improvement, and future work will focus on assessing the impact of the CLICK approach on students' learning, motivation, and preparation to be successful engineers, areas which could translate to a STEM pipeline for the future workforce. © American Society for Engineering Education, 2019",,"Curricula; Engineering education; Knowledge management; Virtual reality; Integrated course; Integrative learning; Learning modules; Life experiences; Multiple course; New approaches; Theory and practice; Usability tests; Students",Conference Paper,"Final","",Scopus,2-s2.0-85076433701
"ElZomor M., Youssef O.","57190814645;57184009100;","Coupling haptic learning with technology to advance informal sTEM pedagogies",2019,"ASEE Annual Conference and Exposition, Conference Proceedings",,,,"","",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078724961&partnerID=40&md5=a7c4d937977639c351f36f40db141b2e","Florida International University, United States; University of Arizona, United States","ElZomor, M., Florida International University, United States; Youssef, O., University of Arizona, United States","Research in the field of engineering education highlights the ineffectiveness of one-way, lecture-based teaching and strongly advocates that faculty adopt new pedagogies that integrate technological tools. Such strategies actively engage learners and support their understanding. To revolutionize the traditional haptic learning pedagogy, Virtual Reality (VR) can be incorporated to support science, technology, engineering, and mathematics (STEM) students' level of learning, advance their communication skills and enhance problem-solving skills. VR is a technological tool that immerses students in the real built environment and utilizes different parts of the brain to access auditory and visual data. This ongoing, work in progress, research study describes the process of interweaving between engineering, technology, architecture and building sciences, through integration of VR. VR was used to leverage a seamless virtual application thus complementing theories with unlimited interactive pedagogies, which kept learners engaged, interested and ultimately fosters retention particularly in haptic courses. Specifically, this study integrates the VR technology into an Environmental Science Laboratory to support teaching, enhance students' understanding, and increase retention as well as triggering an interactive educational environment. This paper focuses on the method of advancing haptic learning with VR through introducing and analyzing five modules taught in a building sciences laboratory course in addition to sharing limitations and some lessons learned of this pedagogy. Consequently advancing an unorthodox pedagogical approach that not only provides students with a unique educational experience but also equips them with know-how and knowledge to utilize emerging technologies. © American Society for Engineering Education, 2019",,"Engineering research; Environmental technology; Students; Teaching; Technical presentations; Technology transfer; Architecture and buildings; Communication skills; Educational environment; Educational experiences; Emerging technologies; Environmental science; Problem solving skills; Science , technology , engineering , and mathematics; Engineering education",Conference Paper,"Final","",Scopus,2-s2.0-85078724961
"Vertemati M., Cassin S., Rizzetto F., Vanzulli A., Elli M., Sampogna G., Gallieni M.","6602085318;57205576019;57205575796;16026541900;7003507564;57193081915;7004243711;","A Virtual Reality Environment to Visualize Three-Dimensional Patient-Specific Models by a Mobile Head-Mounted Display",2019,"Surgical Innovation","26","3",,"359","370",,7,"10.1177/1553350618822860","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060629868&doi=10.1177%2f1553350618822860&partnerID=40&md5=e7b6cc98e1f592ddf43393f6e8f6d519","Università degli Studi di Milano, Milan, Italy","Vertemati, M., Università degli Studi di Milano, Milan, Italy; Cassin, S., Università degli Studi di Milano, Milan, Italy; Rizzetto, F., Università degli Studi di Milano, Milan, Italy; Vanzulli, A., Università degli Studi di Milano, Milan, Italy; Elli, M., Università degli Studi di Milano, Milan, Italy; Sampogna, G., Università degli Studi di Milano, Milan, Italy; Gallieni, M., Università degli Studi di Milano, Milan, Italy","Introduction. With the availability of low-cost head-mounted displays (HMDs), virtual reality environments (VREs) are increasingly being used in medicine for teaching and clinical purposes. Our aim was to develop an interactive, user-friendly VRE for tridimensional visualization of patient-specific organs, establishing a workflow to transfer 3-dimensional (3D) models from imaging datasets to our immersive VRE. Materials and Methods. This original VRE model was built using open-source software and a mobile HMD, Samsung Gear VR. For its validation, we enrolled 33 volunteers: morphologists (n = 11), trainee surgeons (n = 15), and expert surgeons (n = 7). They tried our VRE and then filled in an original 5-point Likert-type scale 6-item questionnaire, considering the following parameters: ease of use, anatomy comprehension compared with 2D radiological imaging, explanation of anatomical variations, explanation of surgical procedures, preoperative planning, and experience of gastrointestinal/neurological disorders. Results in the 3 groups were statistically compared using analysis of variance. Results. Using cross-sectional medical imaging, the developed VRE allowed to visualize a 3D patient-specific abdominal scene in 1 hour. Overall, the 6 items were evaluated positively by all groups; only anatomy comprehension was statistically significant different among the 3 groups. Conclusions. Our approach, based on open-source software and mobile hardware, proved to be a valid and well-appreciated system to visualize 3D patient-specific models, paving the way for a potential new tool for teaching and preoperative planning. © The Author(s) 2019.","anatomy; head-mounted display; mobile; training; virtual reality","anatomy; Article; clinical practice; computer assisted tomography; human; image segmentation; medical education; nuclear magnetic resonance imaging; partial nephrectomy; questionnaire; radiography; surgeon; surgical technique; surgical training; three-dimensional imaging; training; treatment planning; virtual reality; computer assisted surgery; computer interface; devices; equipment design; software; three dimensional imaging; x-ray computed tomography; Equipment Design; Humans; Imaging, Three-Dimensional; Magnetic Resonance Imaging; Software; Surgery, Computer-Assisted; Surveys and Questionnaires; Tomography, X-Ray Computed; User-Computer Interface; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85060629868
"Chen M., Saad W., Yin C., Debbah M.","57113807700;57203259001;7201995655;35588784300;","Data Correlation-Aware Resource Management in Wireless Virtual Reality (VR): An Echo State Transfer Learning Approach",2019,"IEEE Transactions on Communications","67","6", 8648419,"4267","4280",,16,"10.1109/TCOMM.2019.2900624","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067570259&doi=10.1109%2fTCOMM.2019.2900624&partnerID=40&md5=a5394beb4157a6063a3abd74b6a89eb1","Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA  24061, United States; Mathematical and Algorithmic Sciences Lab, Huawei France RD, Paris, 92100, France","Chen, M., Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Saad, W., Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA  24061, United States; Yin, C., Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Debbah, M., Mathematical and Algorithmic Sciences Lab, Huawei France RD, Paris, 92100, France","Providing seamless connectivity for wireless virtual reality (VR) users has emerged as a key challenge for future cloud-enabled cellular networks. In this paper, the problem of wireless VR resource management is investigated for a wireless VR network in which VR contents are sent by a cloud to cellular small base stations (SBSs). The SBSs will collect tracking data from the VR users, over the uplink, in order to generate the VR content and transmit it to the end-users using downlink cellular links. For this model, the data requested or transmitted by the users can exhibit correlation, since the VR users may engage in the same immersive virtual environment with different locations and orientations. As such, the proposed resource management framework can factor in such spatial data correlation, so as to better manage uplink and downlink traffic. This potential spatial data correlation can be factored into the resource allocation problem to reduce the traffic load in both the uplink and downlink. In the downlink, the cloud can transmit 360° contents or specific visible contents (e.g., user field of view) that are extracted from the original 360° contents to the users according to the users' data correlation so as to reduce the backhaul traffic load. In the uplink, each SBS can associate with the users that have similar tracking information so as to reduce the tracking data size. This data correlation-aware resource management problem is formulated as an optimization problem whose goal is to maximize the users' successful transmission probability, defined as the probability that the content transmission delay of each user satisfies an instantaneous VR delay target. To solve this problem, a machine learning algorithm that uses echo state networks (ESNs) with transfer learning is introduced. By smartly transferring information on the SBS's utility, the proposed transfer-based ESN algorithm can quickly cope with changes in the wireless networking environment due to users' content requests and content request distributions. Simulation results demonstrate that the developed algorithm achieves up to 15.8% and 29.4% gains in terms of successful transmission probability compared to Q-learning with data correlation and Q-learning without data correlation, respectively. © 1972-2012 IEEE.","echo state networks; resource allocation; transfer learning; Virtual reality","E-learning; Information management; Learning algorithms; Machine learning; Natural resources management; Probability; Problem solving; Resource allocation; Virtual reality; Echo state networks; Immersive virtual environments; Resource allocation problem; Resource management framework; Resource management problems; Transfer learning; Transmission probabilities; Wireless networking environment; Data reduction",Conference Paper,"Final","",Scopus,2-s2.0-85067570259
"van Ginkel S., Gulikers J., Biemans H., Noroozi O., Roozen M., Bos T., van Tilborg R., van Halteren M., Mulder M.","56543234400;55886508300;6603110521;57207851921;57206788460;57206775089;57206775011;57206781899;15136874400;","Fostering oral presentation competence through a virtual reality-based task for delivering feedback",2019,"Computers and Education","134",,,"78","97",,16,"10.1016/j.compedu.2019.02.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061989143&doi=10.1016%2fj.compedu.2019.02.006&partnerID=40&md5=ff9494b02443b0098dadc0d406cbdf81","VR Lab of the Archimedes Institute, Hogeschool Utrecht, University of Applied Sciences, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands; Department of Education and Learning Sciences, Social Sciences Group, Wageningen University & Research, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands; Groningen Institute for Evolutionary Life Sciences, Department of Behavioural Neuroscience, University of Groningen, P.O. Box 11103, Groningen, CC  9700, Netherlands; NCOI Education Management, Box 447, Hilversum, NL 1200 AK, Netherlands; CoVince, Adventurous Learning, Reyer Anslostraat 28, Utrecht, DJ  3522, Netherlands","van Ginkel, S., VR Lab of the Archimedes Institute, Hogeschool Utrecht, University of Applied Sciences, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands, Department of Education and Learning Sciences, Social Sciences Group, Wageningen University & Research, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands; Gulikers, J., Department of Education and Learning Sciences, Social Sciences Group, Wageningen University & Research, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands; Biemans, H., Department of Education and Learning Sciences, Social Sciences Group, Wageningen University & Research, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands; Noroozi, O., Department of Education and Learning Sciences, Social Sciences Group, Wageningen University & Research, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands; Roozen, M., Groningen Institute for Evolutionary Life Sciences, Department of Behavioural Neuroscience, University of Groningen, P.O. Box 11103, Groningen, CC  9700, Netherlands; Bos, T., NCOI Education Management, Box 447, Hilversum, NL 1200 AK, Netherlands; van Tilborg, R., CoVince, Adventurous Learning, Reyer Anslostraat 28, Utrecht, DJ  3522, Netherlands; van Halteren, M., CoVince, Adventurous Learning, Reyer Anslostraat 28, Utrecht, DJ  3522, Netherlands; Mulder, M., Department of Education and Learning Sciences, Social Sciences Group, Wageningen University & Research, bode 68, P.O. Box 8130, Wageningen, NL 6700 EW, Netherlands","While previous studies have stressed the importance of feedback delivered by experts, it is unclear whether students’ oral presentation competence can be fostered through innovative technology for delivering feedback. This experimental study examined the effectiveness of a virtual reality-based task, in which first-year undergraduate students practiced their presentation in a virtual environment and received feedback produced by the system, on their presentation competence components (i.e. cognition, behaviour and attitudes towards presenting). The effects were compared with a control condition, which was a face-to-face presentation task with expert feedback. The students’ performance was measured using pre- and post-test multiple-choice tests, validated rubrics, and self-evaluation instruments. Results revealed significant improvements from pre-test to post-test in all three presentation competence components, without a difference between the conditions. Furthermore, the self-evaluation tests showed that students who presented in virtual reality were appreciative of the detailed and analytical feedback they received. Because of sample size limitations, the effects found could not be generalised. Therefore, future research on a larger sample is needed to examine population effects. Follow-up studies should focus on the extent to which virtual reality-based tasks can encourage self-regulation skills for the effective and efficient integration of these tasks in presentation courses. © 2019 Elsevier Ltd","Formative assessment; Higher education; Oral presentation competence; Virtual reality","Feedback; Technical presentations; Testing; Virtual reality; Follow-up Studies; Formative assessment; Higher education; Innovative technology; Oral presentations; Presentation tasks; Self regulation; Undergraduate students; Students",Article,"Final","",Scopus,2-s2.0-85061989143
"De La Garza J.R., Schmidt M.W., Kowalewski K.-F., Benner L., Müller P.C., Kenngott H.G., Fischer L., Müller-Stich B.P., Nickel F.","57193726976;57191077022;56909719800;57195478316;56252356700;23097654000;24179145000;14322034300;35603936500;","Does rating with a checklist improve the effect of E-learning for cognitive and practical skills in bariatric surgery? A rater-blinded, randomized-controlled trial",2019,"Surgical Endoscopy","33","5",,"1532","1543",,3,"10.1007/s00464-018-6441-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053388053&doi=10.1007%2fs00464-018-6441-4&partnerID=40&md5=ef98f398a8a856c53616c14c805c11b3","Department of General, Visceral, and Transplantation Surgery, University of Heidelberg, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Institute for Medical Biometry and Informatics, University of Heidelberg, Im Neuenheimer Feld 130.3, Heidelberg, 69120, Germany","De La Garza, J.R., Department of General, Visceral, and Transplantation Surgery, University of Heidelberg, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Schmidt, M.W., Department of General, Visceral, and Transplantation Surgery, University of Heidelberg, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Kowalewski, K.-F., Department of General, Visceral, and Transplantation Surgery, University of Heidelberg, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Benner, L., Institute for Medical Biometry and Informatics, University of Heidelberg, Im Neuenheimer Feld 130.3, Heidelberg, 69120, Germany; Müller, P.C., Department of General, Visceral, and Transplantation Surgery, University of Heidelberg, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Kenngott, H.G., Department of General, Visceral, and Transplantation Surgery, University of Heidelberg, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Fischer, L., Department of General, Visceral, and Transplantation Surgery, University of Heidelberg, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Müller-Stich, B.P., Department of General, Visceral, and Transplantation Surgery, University of Heidelberg, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Nickel, F., Department of General, Visceral, and Transplantation Surgery, University of Heidelberg, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany","Background: Mental training of laparoscopic procedures with E-learning has been shown to translate to the operating room. The present study aims to explore whether the use of checklists during E-learning improves transfer of skills to the simulated OR on a Virtual Reality (VR) trainer for Roux-en-Y gastric bypass (RYGB). Methods: Laparoscopy naive medical students (n = 80) were randomized in two groups. After an E-learning introduction to RYGB, checklist group rated RYGB videos using the validated Bariatric Objective Structured Assessment of Technical Skills (BOSATS) checklist while group without checklist only observed the videos. Participants then performed RYGB on a VR-trainer twice and were evaluated by a blinded expert rater using BOSATS. A multiple choice (MC) knowledge test on RYGB was performed. Suturing on a cadaveric porcine small bowel was evaluated using objective structured assessment of technical skill (OSATS). Results: Checklist group was better in the knowledge test (A 8.3 ± 1.1 vs. B 7.1 ± 1.3; p ≤ 0.001) and there was a trend towards better VR RYGB performance (BOSATS) on the first try (85.9 ± 10.2 vs. 81.1 ± 11.5; p = 0.058), but not on the second try (92.0 ± 9.7 vs. 89.3 ± 10.5; p = 0.251). Suturing as measured by OSATS was not different (29.5 ± 3.0 vs. 29.0 ± 3.5; p = 0.472). Conclusion: This study presents evidence that the use of a BOSATS checklist during E-learning helps trainees to improve their knowledge acquisition with E-learning. The transfer from mental training to the simulated OR environment seems to be partially enhanced by use of the BOSATS checklist. However, more research is required to investigate potential benefits. © 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Checklist; Minimally invasive surgery; Multiple choice test; Obesity; Training; Virtual reality","adult; article; bariatric surgery; checklist; controlled study; female; human; human experiment; laparoscopy; learning; major clinical study; male; medical student; minimally invasive surgery; multiple choice test; nonhuman; pig; randomized controlled trial; Roux-en-Y gastric bypass; simulation; single blind procedure; skill; small intestine; virtual reality; clinical competence; education; gastric bypass surgery; Germany; procedures; prospective study; simulation training; young adult; Checklist; Clinical Competence; Female; Gastric Bypass; Germany; Humans; Male; Prospective Studies; Simulation Training; Students, Medical; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85053388053
"Rogers J.M., Duckworth J., Middleton S., Steenbergen B., Wilson P.H.","57205393446;36460871400;7102867349;6701413521;7404348396;","Elements virtual rehabilitation improves motor, cognitive, and functional outcomes in adult stroke: Evidence from a randomized controlled pilot study",2019,"Journal of NeuroEngineering and Rehabilitation","16","1", 56,"","",,11,"10.1186/s12984-019-0531-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066015714&doi=10.1186%2fs12984-019-0531-y&partnerID=40&md5=05d2f102a4b02f5b33162a9028b41868","University of Sydney, Faculty of Health Sciences, Sydney, NSW, Australia; School of Design, RMIT, Melbourne, VIC, Australia; Nursing Research Institute, St Vincent's Health Australia and Australian Catholic University, Sydney, NSW, Australia; Behavioural Science Institute, Radboud University, Nijmegen, Netherlands; Centre for Disability and Development Research (CeDDR) and School of Behavioural and Health Science, Australian Catholic University, Melbourne, VIC, Australia","Rogers, J.M., University of Sydney, Faculty of Health Sciences, Sydney, NSW, Australia; Duckworth, J., School of Design, RMIT, Melbourne, VIC, Australia; Middleton, S., Nursing Research Institute, St Vincent's Health Australia and Australian Catholic University, Sydney, NSW, Australia; Steenbergen, B., Behavioural Science Institute, Radboud University, Nijmegen, Netherlands; Wilson, P.H., Centre for Disability and Development Research (CeDDR) and School of Behavioural and Health Science, Australian Catholic University, Melbourne, VIC, Australia","Background: Virtual reality technologies show potential as effective rehabilitation tools following neuro-trauma. In particular, the Elements system, involving customized surface computing and tangible interfaces, produces strong treatment effects for upper-limb and cognitive function following traumatic brain injury. The present study evaluated the efficacy of Elements as a virtual rehabilitation approach for stroke survivors. Methods: Twenty-one adults (42-94 years old) with sub-acute stroke were randomized to four weeks of Elements virtual rehabilitation (three weekly 30-40 min sessions) combined with treatment as usual (conventional occupational and physiotherapy) or to treatment as usual alone. Upper-limb skill (Box and Blocks Test), cognition (Montreal Cognitive Assessment and selected CogState subtests), and everyday participation (Neurobehavioral Functioning Inventory) were examined before and after inpatient training, and one-month later. Results: Effect sizes for the experimental group (d = 1.05-2.51) were larger compared with controls (d = 0.11-0.86), with Elements training showing statistically greater improvements in motor function of the most affected hand (p = 0.008), and general intellectual status and executive function (p ≤ 0.001). Proportional recovery was two- to three-fold greater than control participants, with superior transfer to everyday motor, cognitive, and communication behaviors. All gains were maintained at follow-up. Conclusion: A course of Elements virtual rehabilitation using goal-directed and exploratory upper-limb movement tasks facilitates both motor and cognitive recovery after stroke. The magnitude of training effects, maintenance of gains at follow-up, and generalization to daily activities provide compelling preliminary evidence of the power of virtual rehabilitation when applied in a targeted and principled manner. Trial registration: this pilot study was not registered. © 2019 The Author(s).","Cognition; Motor activity; Rehabilitation; Stroke; Upper extremity; Virtual reality","adult; aged; Article; Box and Blocks Test; cerebrovascular accident; clinical article; clinical effectiveness; cognition; CogState subtest; controlled study; effect size; Elements virtual rehabilitation; executive function; female; follow up; human; male; Montreal cognitive assessment; motor performance; Neurobehavioral Functioning Inventory; neurologic examination; occupational therapy; outcome assessment; physiotherapy; pilot study; priority journal; randomized controlled trial (topic); telerehabilitation; very elderly; cerebrovascular accident; convalescence; devices; middle aged; motor activity; pathophysiology; physiology; procedures; randomized controlled trial; stroke rehabilitation; virtual reality; Adult; Aged; Aged, 80 and over; Cognition; Female; Humans; Male; Middle Aged; Motor Activity; Physical Therapy Modalities; Pilot Projects; Recovery of Function; Stroke; Stroke Rehabilitation; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85066015714
"Hurst W., Shone N., Tully D.","7006028554;56026608500;56896990700;","Investigations into the Development of a Knowledge Transfer Platform for Business Productivity",2019,"5th International Conference on Information Management, ICIM 2019",,, 8714702,"159","164",,,"10.1109/INFOMAN.2019.8714702","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066620998&doi=10.1109%2fINFOMAN.2019.8714702&partnerID=40&md5=9e32b8a3193a303d6e9ce0b797c6ee67","Department of Computer Science, Liverpool John Moores University, Liverpool, L3 3AF, United Kingdom","Hurst, W., Department of Computer Science, Liverpool John Moores University, Liverpool, L3 3AF, United Kingdom; Shone, N., Department of Computer Science, Liverpool John Moores University, Liverpool, L3 3AF, United Kingdom; Tully, D., Department of Computer Science, Liverpool John Moores University, Liverpool, L3 3AF, United Kingdom","There is a lack of access to training tools., best practice guides and knowledge repositories to help with the digital switch to Industry 4.0. Consequently., in this paper., the ProAccel (Productivity Accelerator) platform design is outlined. The system is a modular cloud-based multimedia platform that employs advanced data analytics and gamification techniques., such as Virtual Reality (VR)., to revolutionise the way productivity information is shared to support businesses in their uptake of digital technologies in the Industry 4.0 environment. We present our findings from a 4 month case study., involving over 100 UK-based companies. The resulting research was used to construct a prototype of the ProAccel platform. As an evaluation., a simulated user evaluation of the platform using a guestimate model derived from a KLM analysis is conducted as an analysis of the platform's functionality. © 2019 IEEE.","Education; Industry 4.0; Internet of things; Knowledge management; Productivity; Smart homes; Virtual reality","Advanced Analytics; Automation; Data Analytics; Education; Industry 4.0; Intelligent buildings; Internet of things; Knowledge management; Virtual reality; Best Practice Guide; Business productivity; Digital technologies; Knowledge repository; Knowledge transfer; Multimedia platforms; Smart homes; User evaluations; Productivity",Conference Paper,"Final","",Scopus,2-s2.0-85066620998
"Li J., Kong Y., Röggla T., De Simone F., Ananthanarayan S., De Ridder H., El Ali A., Cesar P.","57203114304;57209395670;57188760937;25822067800;36170274900;35387764300;36701307500;16237880000;","Measuring and understanding photo sharing experiences in social virtual reality",2019,"Conference on Human Factors in Computing Systems - Proceedings",,,,"","",,8,"10.1145/3290605.3300897","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067595707&doi=10.1145%2f3290605.3300897&partnerID=40&md5=cab8f7ecc1cca5e5950db66af176998d","Centrum Wiskunde and Informatica, Amsterdam, Netherlands; University of Oldenburg, Oldenburg, Germany; Delft University of Technology, Delft, Netherlands; Centrum Wiskunde and Informatica, Delft University of Technology, Amsterdam, Netherlands","Li, J., Centrum Wiskunde and Informatica, Amsterdam, Netherlands; Kong, Y., Centrum Wiskunde and Informatica, Amsterdam, Netherlands; Röggla, T., Centrum Wiskunde and Informatica, Amsterdam, Netherlands; De Simone, F., Centrum Wiskunde and Informatica, Amsterdam, Netherlands; Ananthanarayan, S., University of Oldenburg, Oldenburg, Germany; De Ridder, H., Delft University of Technology, Delft, Netherlands; El Ali, A., Centrum Wiskunde and Informatica, Amsterdam, Netherlands; Cesar, P., Centrum Wiskunde and Informatica, Delft University of Technology, Amsterdam, Netherlands","Millions of photos are shared online daily, but the richness of interaction compared with face-to-face (F2F) sharing is still missing. While this may change with social Virtual Reality (socialVR), we still lack tools to measure such immersive and interactive experiences. In this paper, we investigate photo sharing experiences in immersive environments, focusing on socialVR. Running context mapping (N=10), an expert creative session (N=6), and an online experience clustering questionnaire (N=20), we develop and statistically evaluate a questionnaire to measure photo sharing experiences. We then ran a controlled, within-subject study (N=26 pairs) to compare photo sharing under F2F, Skype, and Facebook Spaces. Using interviews, audio analysis, and our questionnaire, we found that socialVR can closely approximate F2F sharing. We contribute empirical findings on the immersiveness differences between digital communication media, and propose a socialVR questionnaire that can in the future generalize beyond photo sharing. © 2019 Copyright held by the owner/author(s).","Immersion; Photo sharing; Presence; Questionnaire; Social; Virtual reality","Digital communication systems; Human computer interaction; Human engineering; Virtual reality; Immersion; Photo sharing; Presence; Questionnaire; Social; Surveys",Conference Paper,"Final","",Scopus,2-s2.0-85067595707
"Chen M., Saad W., Yin C.","57113807700;57203259001;7201995655;","Liquid State Based Transfer Learning for 360° Image Transmission in Wireless VR Networks",2019,"IEEE International Conference on Communications","2019-May",, 8761494,"","",,2,"10.1109/ICC.2019.8761494","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070234616&doi=10.1109%2fICC.2019.8761494&partnerID=40&md5=f2882dac4d905d889b9c8f4018e9a94e","Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Wireless at VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, United States","Chen, M., Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Saad, W., Wireless at VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, United States; Yin, C., Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China","In this paper, the problem of 360° image transmission is studied for a wireless network of virtual reality (VR) users that communicate with cellular base stations (BSs). The VR users will send their uplink tracking information to the BS and receive the VR images in the downlink. To satisfy VR users' delay target, the BSs can change the image transmission format for each image requested by users so as to reduce the downlink traffic load. Meanwhile, the VR users can directly rotate the already received VR image and use the rotated VR images at a later time to further reduce the downlink traffic load. This 360° image transmission and image rotation problem is then formulated as an optimization problem whose goal is to maximize the users' successful transmission probability which is defined as the probability that the delay of tracking information and image transmission for each VR user satisfies the VR delay requirement. A liquid state machine (LSM) based transfer learning algorithm is proposed to solve this optimization problem. The proposed LSM-based transfer learning algorithm enables each BS to transfer the already learned successful transmission to the new successful transmission that must be learned so as to increase the convergence speed. Simulation results show that the proposed algorithm achieves 14.9% gain in terms of successful transmission probability compared to Q-learning. © 2019 IEEE.",,"Imaging systems; Optimization; Probability; Reinforcement learning; Virtual reality; Cellular base stations; Convergence speed; Downlink traffics; Liquid state machines; Optimization problems; Transfer learning; Transmission formats; Transmission probabilities; Learning algorithms",Conference Paper,"Final","",Scopus,2-s2.0-85070234616
"Çakiroğlu Ü., Gökoğlu S.","26656621800;57192837084;","Development of fire safety behavioral skills via virtual reality",2019,"Computers and Education","133",,,"56","68",,28,"10.1016/j.compedu.2019.01.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060856945&doi=10.1016%2fj.compedu.2019.01.014&partnerID=40&md5=9e0b2c837029344bc6f9ecd3a9e473a9","Trabzon University, Fatih Faculty of Education, Department of Computer and Instructional Technology Education, Trabzon, Turkey; Kastamonu University, Cide Rıfat Ilgaz Vocational School, Department of Computer Technologies, Kastamonu, Turkey","Çakiroğlu, Ü., Trabzon University, Fatih Faculty of Education, Department of Computer and Instructional Technology Education, Trabzon, Turkey; Gökoğlu, S., Kastamonu University, Cide Rıfat Ilgaz Vocational School, Department of Computer Technologies, Kastamonu, Turkey","In recent years, virtual reality has become prevalent in many educational settings. In this study, virtual reality-based behavioral skills training (VR-BST) approach is proposed to teach basic behavioral skills for fire safety. A virtual reality-based environment was designed and implemented in the context of the design-based research. A group of ten primary school students received a basic fire safety training package through this environment and in situ training was implemented when needed. The results indicated that students’ fire safety behavioral skills significantly improved with the use of virtual reality based training and the majority of the students could transfer their behavioral skills to real environments. The way of modelling the behaviors in this study and integrating in situ training into the learning environment positively contributed to the development of behavioral skills. The study concludes with suggestions for practitioners and researchers in the field of virtual reality for behavioral skills training. © 2019 Elsevier Ltd","Fire safety training; Virtual reality; Virtual reality-based behavioral skills training (VR-BST)","Computer aided instruction; Fires; Students; Virtual reality; Design-based research; Educational settings; Fire safety; Learning environments; Primary schools; Real environments; Skills training; E-learning",Article,"Final","",Scopus,2-s2.0-85060856945
"Zhao P., Zhang Y., Bian K., Tuo H., Song L.","57206728251;57193653970;55339892600;57203371516;55585880400;","LadderNet: Knowledge Transfer Based Viewpoint Prediction in 360° Video",2019,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings","2019-May",, 8682776,"1657","1661",,2,"10.1109/ICASSP.2019.8682776","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068956621&doi=10.1109%2fICASSP.2019.8682776&partnerID=40&md5=0ab85daff85f6c55cf234042883c1abe","Peking University, Beijing, China; IQIYI Co. Ltd., Beijing, China","Zhao, P., Peking University, Beijing, China; Zhang, Y., Peking University, Beijing, China; Bian, K., Peking University, Beijing, China; Tuo, H., IQIYI Co. Ltd., Beijing, China; Song, L., Peking University, Beijing, China","In the past few years, virtual reality (VR) has become an enabling technique, not only for enriching our visual experience but also for providing new channels for businesses. Untethered mobile devices are the main players for watching 360-degree content, thereby the precision of predicting the future viewpoints is one key challenge to improve the quality of the playbacks. In this paper, we investigate the image features of the 360-degree videos and the contextual information of the viewpoint trajectories. Specifically, we design ladder convolution to adapt for the distorted image, and propose LadderNet to transfer the knowledge from the pre-trained model and retrieve the features from the distorted image. We then combine the image features and the contextual viewpoints as the inputs for long short-term memory (LSTM) to predict the future viewpoints. Our approach is compared with several state-of-the-art viewpoint prediction algorithms over two 360-degree video datasets. Results show that our approach can improve the Intersection over Union (IoU) by at least 5% and meeting the requirements of the playback of 360-degree video on mobile devices. © 2019 IEEE.","image distortion; Untethered virtual reality; viewpoint prediction","Audio signal processing; Forecasting; Knowledge management; Speech communication; Virtual reality; Contextual information; Distorted images; Enabling techniques; Image distortions; Knowledge transfer; Prediction algorithms; State of the art; Visual experiences; Long short-term memory",Conference Paper,"Final","",Scopus,2-s2.0-85068956621
"Zaragoza-Siqueiros J., Medellin-Castillo H.I., de la Garza-Camargo H., Lim T., Ritchie J.M.","56582397300;8579367300;57205670877;24923001300;7403187395;","An integrated haptic-enabled virtual reality system for orthognathic surgery planning",2019,"Computer Methods in Biomechanics and Biomedical Engineering","22","5",,"499","517",,4,"10.1080/10255842.2019.1566817","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061031514&doi=10.1080%2f10255842.2019.1566817&partnerID=40&md5=001900041eb9709390d157631314cea6","Facultad de Ingeniería, Universidad Autónoma de San Luis Potosí, San Luis Potosí, Mexico; Facultad de Estomatología, Universidad Autónoma de San Luis Potosí, San Luis Potosí, Mexico; Institute of Mechanical, Process and Energy Engineering, School of Engineering and Physical Sciences, Heriot-Watt University, Riccarton, Edinburgh, United Kingdom","Zaragoza-Siqueiros, J., Facultad de Ingeniería, Universidad Autónoma de San Luis Potosí, San Luis Potosí, Mexico; Medellin-Castillo, H.I., Facultad de Ingeniería, Universidad Autónoma de San Luis Potosí, San Luis Potosí, Mexico; de la Garza-Camargo, H., Facultad de Estomatología, Universidad Autónoma de San Luis Potosí, San Luis Potosí, Mexico; Lim, T., Institute of Mechanical, Process and Energy Engineering, School of Engineering and Physical Sciences, Heriot-Watt University, Riccarton, Edinburgh, United Kingdom; Ritchie, J.M., Institute of Mechanical, Process and Energy Engineering, School of Engineering and Physical Sciences, Heriot-Watt University, Riccarton, Edinburgh, United Kingdom","Conventional Orthognathic surgery (OGS) planning involves cephalometric analyses and dental casts to be mounted on an articulator. Dental segments are subsequently identified, cut and repositioned to allow the fabrication of intraoral wafers that guide the positioning of the osteotomy bone segments. This conventional planning introduces many inaccuracies that affect the post-surgery outcomes. Although computer technologies have advanced computational tools for OGS planning, they have failed in providing a practical solution. Many focuses only on some specific stages of the planning process, and their ability to transfer preoperative planning data to the operating room is limited. This paper proposes a new integrated haptic-enabled virtual reality (VR) system for OGS planning. The system incorporates CAD tools and haptics to facilitate a complete planning process and is able to automatically generate preoperative plans. A clinical pre-diagnosis is also provided automatically by the system based on the patient’s digital data. A functional evaluation based on a real patient case study demonstrates that the proposed virtual OGS planning method is feasible and more effective than the traditional approach at increasing the intuitiveness and reducing errors and planning times. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.","computer-aided surgery; haptic technologies; Orthognathic surgery (OGS); surgery planning; virtual reality (VR)","Virtual reality; Cephalometric analysis; Computer aided surgery; Haptic technology; Orthognathic surgeries; Pre-operative planning; Surgery planning; Traditional approaches; Virtual reality system; Surgery; acrylic acid resin; hydroxyapatite; nerve cell adhesion molecule; adult; Article; case report; clinical article; computer aided design; cone beam computed tomography; daily life activity; human; male; mastoidectomy; maxillofacial surgery; middle aged; nuclear magnetic resonance imaging; osteotomy; panoramic radiography; priority journal; three dimensional imaging; training; treadmill exercise; virtual reality; cephalometry; computer assisted surgery; computer simulation; face; orthognathic surgery; patient care planning; physiology; procedures; time factor; touch; Adult; Cephalometry; Computer Simulation; Computer-Aided Design; Face; Humans; Imaging, Three-Dimensional; Male; Orthognathic Surgery; Patient Care Planning; Surgery, Computer-Assisted; Time Factors; Touch; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85061031514
"Makransky G., Terkildsen T.S., Mayer R.E.","50361371800;57205338475;7403065717;","Adding immersive virtual reality to a science lab simulation causes more presence but less learning",2019,"Learning and Instruction","60",,,"225","236",,159,"10.1016/j.learninstruc.2017.12.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85039065813&doi=10.1016%2fj.learninstruc.2017.12.007&partnerID=40&md5=bec8f76c5a5c407cea29ee47829f155c","Department of Psychology, University of Copenhagen, Copenhagen, Denmark; Psychological and Brain Sciences, University of California Santa BarbaraCA, United States","Makransky, G., Department of Psychology, University of Copenhagen, Copenhagen, Denmark; Terkildsen, T.S., Department of Psychology, University of Copenhagen, Copenhagen, Denmark; Mayer, R.E., Psychological and Brain Sciences, University of California Santa BarbaraCA, United States","Virtual reality (VR) is predicted to create a paradigm shift in education and training, but there is little empirical evidence of its educational value. The main objectives of this study were to determine the consequences of adding immersive VR to virtual learning simulations, and to investigate whether the principles of multimedia learning generalize to immersive VR. Furthermore, electroencephalogram (EEG) was used to obtain a direct measure of cognitive processing during learning. A sample of 52 university students participated in a 2 × 2 experimental cross-panel design wherein students learned from a science simulation via a desktop display (PC) or a head-mounted display (VR); and the simulations contained on-screen text or on-screen text with narration. Across both text versions, students reported being more present in the VR condition (d = 1.30); but they learned less (d = 0.80), and had significantly higher cognitive load based on the EEG measure (d = 0.59). In spite of its motivating properties (as reflected in presence ratings), learning science in VR may overload and distract the learner (as reflected in EEG measures of cognitive load), resulting in less opportunity to build learning outcomes (as reflected in poorer learning outcome test performance). © 2017 Elsevier Ltd","Cognitive load; EEG; Presence; Redundancy principle; Simulation; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85039065813
"Baxter G., Hainey T.","7202105776;16238485400;","Student perceptions of virtual reality use in higher education",2019,"Journal of Applied Research in Higher Education","12","3",,"413","424",,5,"10.1108/JARHE-06-2018-0106","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064012439&doi=10.1108%2fJARHE-06-2018-0106&partnerID=40&md5=0dda0a11d1aef1b0a553cca74f01eefc","Department of Computing, University of the West of Scotland, Paisley, United Kingdom","Baxter, G., Department of Computing, University of the West of Scotland, Paisley, United Kingdom; Hainey, T., Department of Computing, University of the West of Scotland, Paisley, United Kingdom","Purpose: This paper provides an analysis and insight into undergraduate student views concerning the use of virtual reality technology towards whether it has the potential to support and provide novel pedagogical avenues towards teaching and learning in higher education. The purpose of this paper is to ascertain student views about the application of VR technology within their degree programmes from a pedagogical perspective in addition to identifying potential challenges to VR adoption. Design/methodology/approach: The research design adopted a mixed methods approach through the use of a questionnaire that was disseminated to undergraduate students studying in the discipline area of the creative industries. Through a series of open and closed questions, student views on VR adoption in higher education were analysed both quantitatively and qualitatively. The results were analysed statistically through a series of Mann–Whitney and Kruskal–Wallis tests. The qualitative statements were contextualised in the overall perspective of the research with the more relevant viewpoints identified to coincide with aspects of VR discovered in the literature. Findings: The predominant findings of the research indicated that the majority of the students considered the use of VR to have useful pedagogical implications though not all findings were positive. The findings provided a sound overview of the benefits and potential drawbacks of VR use in general with a more specific focus in an educational context. Research limitations/implications: Limitations of the research include the lack of overall generalisations that can be formed from the study due to the sample size and the fact that the results were based from one specific academic institution. Practical implications: The findings of the research will provide educators with an insight into various perceptions of VR adoption within higher education. This will aid towards allowing them to reflect on whether VR is an appropriate tool to integrate within their curriculum and pedagogical approaches towards course delivery. Originality/value: Though several studies have explored the use of VR in multiple contexts and subject areas, there still needs to be more research towards its potential drawbacks in a teaching and learning scenario and how to resolve these issues. © 2019, Emerald Publishing Limited.","Engagement; Higher education; Immersion; Presence; Virtual reality; VR technology",,Article,"Final","",Scopus,2-s2.0-85064012439
"Pennington E., Hafer R., Nistler E., Seech T., Tossell C.","57209737760;57209735754;57209738148;55502164700;36025854100;","Integration of advanced technology in initial flight training",2019,"2019 Systems and Information Engineering Design Symposium, SIEDS 2019",,, 8735628,"","",,2,"10.1109/SIEDS.2019.8735628","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068579778&doi=10.1109%2fSIEDS.2019.8735628&partnerID=40&md5=bf3b9b2ac5bb2b48d57afefef6182328","United States Air Force Academy (USAFA), United States","Pennington, E., United States Air Force Academy (USAFA), United States; Hafer, R., United States Air Force Academy (USAFA), United States; Nistler, E., United States Air Force Academy (USAFA), United States; Seech, T., United States Air Force Academy (USAFA), United States; Tossell, C., United States Air Force Academy (USAFA), United States","As virtual reality and artificial intelligence technologies continue to advance, the United States Military is quickly integrating these capabilities into initial flight training through efforts like the Air Force's Pilot Training Next (PTN) program. A persistent issue, however, has been a lack of data guiding (1) the ideal degree of integration into traditional pilot training and (2) the optimal amount of structure for student pilots' training experience. The goal of this study was to evaluate the aforementioned PTN model when applied to the U.S. Air Force Academy's flight training program with special emphasis on the ideal degree of structure for airmanship success. To this end, a quasi-experimental approach was utilized, which included 60 USAFA cadets enrolled in the Powered Flight Program who were pseudo-randomly assigned to three independent groups with varying degrees of structure. The groups (i.e., High Structured, Scaffolded, and Low Structured Groups) represented a spectrum of VR-training curriculum structure ranging from a rigid, lineal objective-completion model (akin to traditional flight training) to an unguided, Montessori-like model. With group assignment as the independent variable, live-flight performance was used as the dependent variable, which was quantified using flight grade cards, number of 'landing tabs' (i.e., modified solos) awarded, and a subjective Instructor Pilot rating. Subjective feedback was also obtained from students in each condition. Initial effectiveness data indicated an increased level of perceived self-efficacy in coordination with increased virtual reality simulator time as well as an accelerated rate of positive transfer to real aircraft from the strictly structured and scaffolded groups. The results of this study allow for initial recommendations for forthcoming airmanship training and undergraduate pilot training augmentation efforts across the Department of Defense. © 2019 IEEE.",,"Curricula; Military aviation; Structural optimization; Virtual reality; Artificial intelligence technologies; Department of Defense; Experimental approaches; Independent variables; Perceived self-efficacy; Training experiences; U.s. air force academies; Virtual reality simulator; Training aircraft",Conference Paper,"Final","",Scopus,2-s2.0-85068579778
"Farra S., Hodgson E., Miller E.T., Timm N., Brady W., Gneuhs M., Ying J., Hausfeld J., Cosgrove E., Simon A., Bottomley M.","54921506600;14053915200;7404491434;16311140300;57189643415;54882273500;57213118440;25947532900;57189640346;57194346781;57190347218;","Effects of Virtual Reality Simulation on Worker Emergency Evacuation of Neonates",2019,"Disaster Medicine and Public Health Preparedness","13","2",,"301","308",,5,"10.1017/dmp.2018.58","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055001091&doi=10.1017%2fdmp.2018.58&partnerID=40&md5=9e0b02a8fa6048c76fb01b477e2eadde","Wright State University, 3640 Colonel Glenn Hwy, Dayton, OH, United States; Miami University, Miami, FL, United States; University of Cincinnati, Cincinnati, OH, United States; Cincinnati Children's Hospital and Medical Center, Cincinnati, OH, United States","Farra, S., Wright State University, 3640 Colonel Glenn Hwy, Dayton, OH, United States; Hodgson, E., Miami University, Miami, FL, United States; Miller, E.T., University of Cincinnati, Cincinnati, OH, United States; Timm, N., Cincinnati Children's Hospital and Medical Center, Cincinnati, OH, United States; Brady, W., Cincinnati Children's Hospital and Medical Center, Cincinnati, OH, United States; Gneuhs, M., Cincinnati Children's Hospital and Medical Center, Cincinnati, OH, United States; Ying, J., University of Cincinnati, Cincinnati, OH, United States; Hausfeld, J., Cincinnati Children's Hospital and Medical Center, Cincinnati, OH, United States; Cosgrove, E., Cincinnati Children's Hospital and Medical Center, Cincinnati, OH, United States; Simon, A., Cincinnati Children's Hospital and Medical Center, Cincinnati, OH, United States; Bottomley, M., Wright State University, 3640 Colonel Glenn Hwy, Dayton, OH, United States","Objective: This study examined differences in learning outcomes among newborn intensive care unit (NICU) workers who underwent virtual reality simulation (VRS) emergency evacuation training versus those who received web-based clinical updates (CU). Learning outcomes included a) knowledge gained, b) confidence with evacuation, and c) performance in a live evacuation exercise. Methods: A longitudinal, mixed-method, quasi-experimental design was implemented utilizing a sample of NICU workers randomly assigned to VRS training or CUs. Four VRS scenarios were created that augmented neonate evacuation training materials. Learning was measured using cognitive assessments, self-efficacy questionnaire (baseline, 0, 4, 8, 12 months), and performance in a live drill (baseline, 12 months). Data were collected following training and analyzed using mixed model analysis. Focus groups captured VRS participant experiences. Results: The VRS and CU groups did not statistically differ based upon the scores on the Cognitive Assessment or perceived self-efficacy. The virtual reality group performance in the live exercise was statistically (P<.0001) and clinically (effect size of 1.71) better than that of the CU group. Conclusions: Training using VRS is effective in promoting positive performance outcomes and should be included as a method for disaster training. VRS can allow an organization to train, test, and identify gaps in current emergency operation plans. In the unique case of disasters, which are low-volume and high-risk events, the participant can have access to an environment without endangering themselves or clients. © Copyright 2018 Society for Disaster Medicine and Public Health, Inc.","disaster; evacuation; virtual reality","article; controlled study; disaster; effect size; emergency surgery; exercise; female; human; human experiment; learning; male; newborn; questionnaire; self concept; simulation; virtual reality; worker; adult; computer simulation; disaster medicine; education; longitudinal study; neonatal intensive care unit; organization and management; patient transport; procedures; Adult; Computer Simulation; Disaster Medicine; Female; Humans; Infant, Newborn; Intensive Care Units, Neonatal; Longitudinal Studies; Male; Patient Transfer; Surveys and Questionnaires; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85055001091
"Sportillo D., Paljic A., Ojeda L.","56912310500;34873176200;57194572140;","On-Road Evaluation of Autonomous Driving Training",2019,"ACM/IEEE International Conference on Human-Robot Interaction","2019-March",, 8673277,"182","190",,9,"10.1109/HRI.2019.8673277","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063979607&doi=10.1109%2fHRI.2019.8673277&partnerID=40&md5=bd03eba8222bcb01343450cc3fe89a9d","PSL Research University, Center for Robotics, MINES ParisTech Groupe PSA, Paris, France; Groupe PSA, Velizy-Villacoublay, France","Sportillo, D., PSL Research University, Center for Robotics, MINES ParisTech Groupe PSA, Paris, France; Paljic, A., PSL Research University, Center for Robotics, MINES ParisTech Groupe PSA, Paris, France; Ojeda, L., Groupe PSA, Velizy-Villacoublay, France","Driver interaction with increasingly automated vehicles requires prior knowledge of system capabilities, operational know-how to use novel car equipment and responsiveness to unpredictable situations. With the purpose of getting drivers ready for autonomous driving, in a between-subject study sixty inexperienced participants were trained with an on-board video tutorial, an Augmented Reality (AR) program and a Virtual Reality (VR) simulator. To evaluate the transfer of training to real driving scenarios, a test drive on public roads was conducted implementing, for the first time in these conditions, the Wizard of Oz (WoZ) protocol. Results suggest that VR and AR training can foster knowledge acquisition and improve reaction time performance in take-over requests. Moreover, participants' behavior during the test drive highlights the ecological validity of the experiment thanks to the effective implementation of the WoZ methodology. © 2019 IEEE.","Augmented Reality; Automated Vehicles; Human-Vehicle Interaction; TOR; Transfer of Training; Virtual Reality; Wizard of Oz","Augmented reality; Human reaction time; Man machine systems; Network security; Technology transfer; Vehicles; Virtual reality; Automated vehicles; Autonomous driving; Driver interaction; Ecological validity; Human vehicle interactions; System capabilities; Transfer of trainings; Wizard of Oz; Human robot interaction",Conference Paper,"Final","",Scopus,2-s2.0-85063979607
"Jones J.A., Luckett E., Key T., Newsome N.","57196738064;57210912806;57210910865;57063160100;","Latency measurement in head-mounted virtual environments",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8798361,"1000","1001",,4,"10.1109/VR.2019.8798361","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071842820&doi=10.1109%2fVR.2019.8798361&partnerID=40&md5=36a303749d045ab3bbdd3f0e38908c11","University of Mississippi, United States; Rust College, United States; Clemson University, United States","Jones, J.A., University of Mississippi, United States; Luckett, E., University of Mississippi, United States; Key, T., Rust College, United States; Newsome, N., Clemson University, United States","In this paper, we discuss a generalizable method to measure end-to-end latency. This is the length of time that elapses between when a real-world movement occurs and when the pixels within a head-mounted display are updated to reflect this movement. The method described here utilizes components commonly available at electronics and hobby shops. We demonstrate this measurement method using an HTC Vive and discuss the influence of its low-persistence display on latency measurement. © 2019 IEEE.","Centered computing; Centered computing; Human; Interaction paradigms; Virtual reality Human; VisualizationVisualization design and evaluation methods","Helmet mounted displays; User interfaces; Centered computing; Design and evaluation methods; End to end latencies; Head mounted displays; Human; Interaction paradigm; Latency measurements; Measurement methods; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85071842820
"Andreasen N.K., Baceviciute S., Pande P., Makransky G.","57210913825;55441702500;56534799500;50361371800;","Virtual reality instruction followed by enactment can increase procedural knowledge in a science lesson",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8797755,"840","841",,2,"10.1109/VR.2019.8797755","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071855895&doi=10.1109%2fVR.2019.8797755&partnerID=40&md5=33eb6d9b3fc921873229350ee2e8f972","Aalborg University, Denmark; University of Copenhagen, Denmark; Roskilde University, Denmark","Andreasen, N.K., Aalborg University, Denmark; Baceviciute, S., University of Copenhagen, Denmark; Pande, P., Roskilde University, Denmark; Makransky, G., Aalborg University, Denmark","A 2×2 between-subjects experiment (a) investigated and compared the instructional effectiveness of immersive virtual reality (VR) versus video as media for teaching scientific procedural knowledge, and (b) examined the efficacy of enactment as a generative learning strategy in combination with the respective instructional media. A total of 117 high school students (74 females) were randomly distributed across four instructional groups - VR and enactment, video and enactment, only VR, and only video. Outcome measures included declarative knowledge, procedural knowledge, knowledge transfer, and subjective ratings of perceived enjoyment. Results indicated that there were no main effects or interactions for the outcomes of declarative knowledge or transfer. However, there was a significant interaction between media and method for the outcome of procedural knowledge with the VR and enactment group having the highest performance. Furthermore, media also seemed to have a significant effect on student perceived enjoyment, indicating that the groups enjoyed the VR simulation significantly more than the video. The results deepen our understanding of how we learn with immersive technology, as well as suggest important implications for implementing VR in schools. © 2019 IEEE.","Enactment; Generative learning strategy; Learning; Procedural knowledge; Virtual reality","E-learning; Knowledge management; Learning systems; Virtual reality; Declarative knowledge; Enactment; Immersive technologies; Immersive virtual reality; Learning; Learning strategy; Procedural knowledge; Randomly distributed; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-85071855895
"Hoppe A.H., Marek F., Van De Camp F., Stietelhaqen R.","57195069885;57210910641;22235493700;57210914556;","VirtualTablet: Extending movable surfaces with touch interaction",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8797993,"980","981",,3,"10.1109/VR.2019.8797993","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071844187&doi=10.1109%2fVR.2019.8797993&partnerID=40&md5=e1432398a595971e51b267c0541e2f1a","Karlsruhe Institute of Technology (KIT) - IAR, Germany; Fraunhofer IOS8, Germany","Hoppe, A.H., Karlsruhe Institute of Technology (KIT) - IAR, Germany; Marek, F., Karlsruhe Institute of Technology (KIT) - IAR, Germany; Van De Camp, F., Fraunhofer IOS8, Germany; Stietelhaqen, R., Karlsruhe Institute of Technology (KIT) - IAR, Germany","Immersive output and effortless input are two core aspects of a virtual reality (VR) experience. We transfer ubiquitous touch interaction with haptic feedback into a virtual environment (VE). The movable and cheap real world object supplies an accurate touch detection equal to a ray-casting interaction with a controller. Moreover, the virtual tablet extends the functionality of a real world tablet. Additional information is displayed in mid-air around the touchable area and the tablet can be turned over to interact with both sides. It allows easy to learn and precise system interaction and can even augment the established touch metaphor with new paradigms. © 2019 IEEE.","Centered computing; Human; Human computer interaction (HCI); Interaction paradigms; Virtual reality","Rendering (computer graphics); User interfaces; Virtual reality; Centered computing; Haptic feedbacks; Human; Human computer interaction (HCI); Interaction paradigm; Real-world objects; System interactions; Touch interaction; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-85071844187
"Luckett E., Key T., Newsome N., Jones J.A.","57210912806;57210910865;57063160100;57196738064;","Metrics for the evaluation of tracking systems for virtual environments",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8798374,"1711","1716",,3,"10.1109/VR.2019.8798374","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071885907&doi=10.1109%2fVR.2019.8798374&partnerID=40&md5=824eae960a63410e877e08f03bc6c6dd","University of Mississippi, United States; Rust College, United States; Clemson University, United States","Luckett, E., University of Mississippi, United States; Key, T., Rust College, United States; Newsome, N., Clemson University, United States; Jones, J.A., University of Mississippi, United States","In this paper, we present three generalizable metrics by which tracking systems for virtual environments can be evaluated. These metrics include positional accuracy, rotational accuracy, and tracking resolution. Additionally, we present methods for acquiring these measurements using components commonly available at hardware and hobby shops. The methods are tested using a consumer-grade virtual reality system but are widely generalizable to most tracking systems, both professional-and consumer-grade. © 2019 IEEE.","Centered computing; Human; Interaction paradigms; Virtual reality","Tracking (position); User interfaces; Centered computing; Human; Interaction paradigm; Positional accuracy; Rotational accuracy; Tracking system; Virtual reality system; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85071885907
"Huynh B., Orlosky J., Hollerer T.","57192544046;55641218100;8358959700;","In-situ labeling for augmented reality language learning",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8798358,"1606","1611",,2,"10.1109/VR.2019.8798358","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071876610&doi=10.1109%2fVR.2019.8798358&partnerID=40&md5=85211cef84f8fbe0b5cffddb75bffc83","University of California, Santa Barbara, United States; Osaka University, Japan","Huynh, B., University of California, Santa Barbara, United States; Orlosky, J., Osaka University, Japan; Hollerer, T., University of California, Santa Barbara, United States","Augmented Reality is a promising interaction paradigm for learning applications. It has the potential to improve learning outcomes by merging educational content with spatial cues and semantically relevant objects within a learner's everyday environment. The impact of such an interface could be comparable to the method of loci, a well known memory enhancement technique used by memory champions and polyglots. However, using Augmented Reality in this manner is still impractical for a number of reasons. Scalable object recognition and consistent labeling of objects is a significant challenge, and interaction with arbitrary (unmodeled) physical objects in AR scenes has consequently not been well explored. To help address these challenges, we present a framework for in-situ object labeling and selection in Augmented Reality, with a particular focus on language learning applications. Our framework uses a generalized object recognition model to identify objects in the world in real time, integrates eye tracking to facilitate selection and interaction within the interface, and incorporates a personalized learning model that dynamically adapts to student's growth. We show our current progress in the development of this system, including preliminary tests and benchmarks. We explore challenges with using such a system in practice, and discuss our vision for the future of AR language learning applications. © 2019 IEEE.","Centered computing; Human; Mixed and augmented reality; Semi; Supervised learning; Theory and algorithms for application domains","Augmented reality; Computation theory; Eye tracking; Genetic algorithms; Object recognition; Supervised learning; User interfaces; Virtual reality; Centered computing; Educational contents; Human; Interaction paradigm; Memory enhancement; Mixed and augmented realities; Personalized learning; Semi; Learning systems",Conference Paper,"Final","",Scopus,2-s2.0-85071876610
"Hurnmukainen O.S., Schlecht S.J., Robotham T., Plinge A., Habets E.A.P.","57210918036;55546914800;57190864032;47061909300;13608885900;","Perceptual study of near-field binaural audio rendering in six-degrees-of-freedom virtual reality",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8798177,"448","454",,,"10.1109/VR.2019.8798177","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071839312&doi=10.1109%2fVR.2019.8798177&partnerID=40&md5=f77a479b511db471c45be8f0778503e7","International Audio Laboratories Erlangen, A Joint Institution of the Friedrich-Alexander-University Erlangen-Nürnberg (FAU), Fraunhofer Institute for Integrated Circuits (IIS), Germany","Hurnmukainen, O.S., International Audio Laboratories Erlangen, A Joint Institution of the Friedrich-Alexander-University Erlangen-Nürnberg (FAU), Fraunhofer Institute for Integrated Circuits (IIS), Germany; Schlecht, S.J., International Audio Laboratories Erlangen, A Joint Institution of the Friedrich-Alexander-University Erlangen-Nürnberg (FAU), Fraunhofer Institute for Integrated Circuits (IIS), Germany; Robotham, T., International Audio Laboratories Erlangen, A Joint Institution of the Friedrich-Alexander-University Erlangen-Nürnberg (FAU), Fraunhofer Institute for Integrated Circuits (IIS), Germany; Plinge, A., International Audio Laboratories Erlangen, A Joint Institution of the Friedrich-Alexander-University Erlangen-Nürnberg (FAU), Fraunhofer Institute for Integrated Circuits (IIS), Germany; Habets, E.A.P., International Audio Laboratories Erlangen, A Joint Institution of the Friedrich-Alexander-University Erlangen-Nürnberg (FAU), Fraunhofer Institute for Integrated Circuits (IIS), Germany","Auditory localization cues in the near-field ( 1.0\ \mathrm{m}) are significantly different than in the far-field. The near-field region is within an arm's length of the listener allowing to integrate proprioceptive cues to determine the location of an object in space. This perceptual study compares three non-individualized methods to apply head-related transfer functions (HRTFs) in six-degrees-of-freedom near-field audio rendering, namely, far-field measured HRTFs, multi-distance measured HRTFs, and spherical-model-based HRTFs with near-field extrapolation. To set our findings in context, we provide a real-world hand-held audio source for comparison along with a distance-invariant condition. Two modes of interaction are compared in an audio-visual virtual reality: One allowing the participant to move the audio object dynamically and the other with a stationary audio object but a freely moving listener. © 2019 IEEE.","Centered computing; Centered computing; Centered computing; Human; Human; Human; Human computer interaction (hci); Human computer interaction (hci); Human computer interaction (hci)hci design and evaluation methods; Interaction paradigms; Interaction paradigmsmixed / augmented reality; User studies; Virtual reality","Degrees of freedom (mechanics); Electric arc welding; Sound reproduction; Transfer functions; User interfaces; Virtual reality; Centered computing; HCI design; Human; Human computer interaction (HCI); Interaction paradigm; Interaction paradigmsmixed/augmented reality; User study; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-85071839312
"Shen S., Chen H.-T., Leong T.W.","56157229100;7501615750;55234419400;","Training transfer of bimanual assembly tasks in cost-differentiated virtual reality systems",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8797917,"1152","1153",,1,"10.1109/VR.2019.8797917","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071837898&doi=10.1109%2fVR.2019.8797917&partnerID=40&md5=13e8c93f7df6294c0c8067b89ed781b6","School of Software University of Technology, Sydney, Australia","Shen, S., School of Software University of Technology, Sydney, Australia; Chen, H.-T., School of Software University of Technology, Sydney, Australia; Leong, T.W., School of Software University of Technology, Sydney, Australia","Recent advances of the affordable virtual reality headsets make virtual reality training an economical choice when compared to traditional training. However, these virtual reality devices present a range of different levels of virtual reality fidelity and interactions. Few works have evaluated their validity against the traditional training formats. This paper presents a study that compares the learning efficiency of a bimanual gearbox assembly task among traditional training, virtual reality training with direct 3D inputs (HTC VIVE), and virtual reality training without 3D inputs (Google Cardboard). A pilot study was conducted and the result shows that HTC VIVE brings the best learning outcomes. © 2019 IEEE.","Assistive systems; Head; Learning transfer; Mounted display; Virtual reality","User interfaces; Virtual reality; Assistive system; Head; Learning efficiency; Learning Transfer; Virtual reality devices; Virtual reality system; Virtual reality training; Virtual-reality headsets; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85071837898
"Day B., Ebrahimi E., Hartman L.S., Pagano C.C., Robb A.C., Babu S.V.","55578106200;55868302600;56369773000;7005950745;55211963300;9039004700;","Examining the effects of altered avatars on perception-action in virtual reality",2019,"Journal of Experimental Psychology: Applied","25","1",,"1","24",,10,"10.1037/xap0000192","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055081790&doi=10.1037%2fxap0000192&partnerID=40&md5=d74d5faae21781732add1aad9ad044df","Department of Psychology, Butler University, United States; Department of Computer Science, University of North Carolina-Wilmington, United States; Department of Psychology, Clemson University, United States; School of Computing, Clemson University, United States","Day, B., Department of Psychology, Butler University, United States; Ebrahimi, E., Department of Computer Science, University of North Carolina-Wilmington, United States; Hartman, L.S., Department of Psychology, Clemson University, United States; Pagano, C.C., Department of Psychology, Clemson University, United States; Robb, A.C., School of Computing, Clemson University, United States; Babu, S.V., School of Computing, Clemson University, United States","In virtual reality (VR), avatars are graphical representations of people. Previous research highlights benefits of having a self-avatar when perceiving-acting while embedded in a virtual environment. We studied the effect that an altered avatar had on the perception of one's action capabilities. In Experiment 1, some participants acted with a normal, or faithful, avatar whereas another group of participants used an avatar with an extended arm, all in virtual reality. Experiment 2 utilized the same methodology and procedure as Experiment 1, except that only a calibration phase occurred in VR, whereas other phases were completed in the real world. All participants performed reaches to various distances presented visually. Results showed that calibration to altered dimensions of avatars is possible after receiving feedback while acting with the altered avatar. Calibration occurred more quickly when feedback was used to transition from a normal avatar to an altered avatar than when transitioning from the altered avatar back to the normal avatar without feedback. The implications of these findings for training in virtual reality simulations and for transfer to the real world are discussed, along with the implications for the concept of an embodied action schema. © 2018 American Psychological Association.","Action capabilities; Avatar; Calibration; Perception-action; Virtual reality","adolescent; computer interface; feedback system; female; human; male; movement (physiology); perception; physiology; virtual reality; Adolescent; Feedback; Female; Humans; Male; Movement; Perception; User-Computer Interface; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85055081790
"Bialkova S., Dickhoff B.","36247103900;57210915943;","Encouraging rehabilitation trials: The potential of 360° immersive instruction videos",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8797805,"1443","1447",,,"10.1109/VR.2019.8797805","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071832880&doi=10.1109%2fVR.2019.8797805&partnerID=40&md5=d7ce467e61a2a59195ec7197703c62de","Utrecht University, Netherlands; Saxion University of Applied Sciences, Netherlands","Bialkova, S., Utrecht University, Netherlands; Dickhoff, B., Saxion University of Applied Sciences, Netherlands","Despite the rapid growth of the VR/AR/ XR applications in the health-care sector, enhancing health and well-being with innovative technologies often is a challenge. Part of the challenge is the limited knowledge transfer between the healthcare, technology, the patients demands, and how these demands could be appropriately met. The current study addressed this challenge when exploring the potential of 360° immersive instruction videos in encouraging rehabilitation trials. A professional VR/ video maker studio created the video for the purpose of the current research. A rehabilitation therapist was recorded while performing rehabilitation exercise as it is done in the real life practice. Patients currently in various rehabilitation trials (motor vs. cardiovascular) were exposed to the 360° immersive instruction video. Their experience was compared with the control group, i.e. healthy people. The VR experience and the rehabilitation exercise experience were evaluated as measures of the Virtual Reality Rehabilitation (VRR) impact. Results showed that 360° immersive videos engaged patients well, irrespective of the rehabilitation trial they are currently in. Regression modelling further demonstrated that the more people liked the VR experience, the more they enjoyed the rehabilitation activity. The more the rehabilitation activity was enjoyed, the more people were satisfied with the VRR. Current outcomes are discussed in the framework of a model of VRR impact, which is a solid base for long-term exercise adherence. The model could be implemented to successfully develop immersive instructional videos as efficient tools in the course of physical rehabilitation trials, and thus, to enhance health and well-being. © 2019 IEEE.","360 videos; Patients engagement; Virtual reality rehabilitation","Health care; Knowledge management; User interfaces; Virtual reality; 360 videos; Innovative technology; Instructional videos; Patients engagement; Physical rehabilitation; Regression modelling; Rehabilitation activities; Rehabilitation exercise; Patient rehabilitation",Conference Paper,"Final","",Scopus,2-s2.0-85071832880
"Khokhar A., Yoshimura A., Borst C.W.","57210910170;57210910262;9736479200;","Pedagogical agent responsive to eye tracking in educational VR",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8797896,"1018","1019",,4,"10.1109/VR.2019.8797896","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071837894&doi=10.1109%2fVR.2019.8797896&partnerID=40&md5=a6aae3f1e474862d8622f95935957398","University of Louisiana at Lafayette, United States","Khokhar, A., University of Louisiana at Lafayette, United States; Yoshimura, A., University of Louisiana at Lafayette, United States; Borst, C.W., University of Louisiana at Lafayette, United States","We present an architecture to make a VR pedagogical agent responsive to shifts in user attention monitored by eye tracking. The behavior-based AI includes low-level sensor elements, sensor combiners that compute attention metrics for higher-level sensors called generalized hotspots, an annotation system for arranging scene elements and responses, and its response selection system. We show that the techniques can control the playback of teacher avatar clips that point out and explain objects in a VR oil rig for training. © 2019 IEEE.","Centered computing; Human; Visualization","Flow visualization; Personnel training; User interfaces; Virtual reality; Annotation systems; Behavior-based; Centered computing; Human; Level sensors; Pedagogical agents; Response selection; User attention; Eye tracking",Conference Paper,"Final","",Scopus,2-s2.0-85071837894
"Schirm J.","57210919413;","Case-studies of contemporary presence theory: Towards more objective and reliable measures of presence",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8798203,"1363","1364",,1,"10.1109/VR.2019.8798203","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071868739&doi=10.1109%2fVR.2019.8798203&partnerID=40&md5=de4e40fcdbef031db14d738b4716aa0a","Sheffield Hallam University, United Kingdom; Reutlingen University, Germany","Schirm, J., Sheffield Hallam University, United Kingdom, Reutlingen University, Germany","A large body of literature is concerned with models of presence-The sensory illusion of being part of a virtual scene-but there is still no general agreement on how to measure it in an objective and reliable way. When it comes to virtual reality, presence is often considered as one of the main factors contributing to quality of experience, yet existing methods either rely on subjective assessments of users or on specifics of the virtual environment they are applied in, making it difficult for experimental procedures to be generalized. This paper presents ideas for research into promising measures of presence, based on first experiments with novel behavioral measures inside a rich environment which users can feel present in more naturally. © 2019 IEEE.","Centered computing; Centered computing; HCI design and evaluation methods; Human; Human; Human computer interaction (HCI); Human computer interaction (HCI); Interaction paradigms; User studies; Virtual reality","Computation theory; Human computer interaction; Quality of service; User interfaces; Centered computing; HCI design; Human; Human computer interaction (HCI); Interaction paradigm; User study; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85071868739
"Danieau F., Gubins I., Olivier N., Dumas O., Denis B., Lopez T., Mollet N., Frager B., Avril Q.","37057062300;57210915853;57210919806;57163193100;57210918555;7103065998;24481532200;57210914421;38662147000;","Automatic generation and stylization of 3d facial rigs",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8798208,"784","792",,1,"10.1109/VR.2019.8798208","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071882939&doi=10.1109%2fVR.2019.8798208&partnerID=40&md5=f362bc829724f056f31ddb2b21e43cad","Technicolor, France; Utrecht University, Netherlands; ESIR, France; Technicolor Experience Center, United States","Danieau, F., Technicolor, France; Gubins, I., Utrecht University, Netherlands; Olivier, N., ESIR, France; Dumas, O., Technicolor, France; Denis, B., Technicolor, France; Lopez, T., Technicolor, France; Mollet, N., Technicolor, France; Frager, B., Technicolor Experience Center, United States; Avril, Q., Technicolor, France","In this paper, we present a fully automatic pipeline for generating and stylizing high geometric and textural quality facial rigs. They are automatically rigged with facial blendshapes for animation, and can be used across platforms for applications including virtual reality, augmented reality, remote collaboration, gaming and more. From a set of input facial photos, our approach is to be able to create a photorealistic, fully rigged character in less than seven minutes. The facial mesh reconstruction is based on state-of-The art photogrammetry approaches. Automatic landmarking coupled with ICP registration with regularization provide direct correspondence and registration from a given generic mesh to the acquired facial mesh. Then, using deformation transfer, existing blendshapes are transferred from the generic to the reconstructed facial mesh. The reconstructed face is then fit to the full body generic mesh. Extra geometry such as jaws, teeth and nostrils are retargeted and transferred to the character. An automatic iris color extraction algorithm is performed to colorize a separate eye texture, animated with dynamic UVs. Finally, an extra step applies a style to the photorealis-tic face to enable blending of personalized facial features into any other character. The user's face can then be adapted to any human or non-human generic mesh. A pilot user study was performed to evaluate the utility of our approach. Up to 65% of the participants were successfully able to discern the presence of one's unique facial features when the style was not too far from a humanoid shape. © 2019 IEEE.","Animation; Character; Pipeline; Virtual reality","Animation; Augmented reality; Blending; Mesh generation; Pipelines; Textures; Virtual reality; Automatic Generation; Automatic landmarking; Character; Color extraction; Deformation transfer; Mesh reconstruction; Remote collaboration; Textural quality; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-85071882939
"Voong T.M., Oehler M.","57205547907;57195979767;","Auditory spatial perception using bone conduction headphones along with fitted head related transfer functions",2019,"26th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2019 - Proceedings",,, 8798218,"1211","1212",,4,"10.1109/VR.2019.8798218","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071835642&doi=10.1109%2fVR.2019.8798218&partnerID=40&md5=eb449f8b26f4ed7c2691a7f6797b017e","Osnabrück University, Germany","Voong, T.M., Osnabrück University, Germany; Oehler, M., Osnabrück University, Germany","An approach is presented how to practically determine which head-related transfer function (HRTF) profiles fit best for individuals wearing a bone conduction headphone. Such headphones may be particularly useful for visually impaired people (e.g., for navigation applications) as they do not obstruct the outer ear. Hence, it is still possible to perceive environmental sounds without restraints while wearing such headphones. For a fast and user-friendly identification of fitting HRTF profiles, an adapted tournament system is proposed. It could be shown that the results of the tournament method, where participants had to rate overall preference, externalization and envelopment, correlated well with the results of the localization task. The correlation was higher for the conventional headphones condition than for the bone conduction headphones condition. Analyses of the transmission characteristics show an uneven frequency response of bone conduction headphones compared to conventional headphones or speakers. In future research it will be investigated whether these findings are relevant for the auditory spatial perception at all and to what extent best fitting HRTFs may compensate for these phenomena. © 2019 IEEE.","Bone; Conductionheadphone; Functions; Head; Related; Tournament methods; Transfer","Bone; Frequency response; Functions; Headphones; Loudspeakers; User interfaces; Virtual reality; Wear of materials; Conductionheadphone; Head; Related; Tournament method; Transfer; Transfer functions",Conference Paper,"Final","",Scopus,2-s2.0-85071835642
"Smith M.J., Smith J.D., Fleming M.F., Jordan N., Oulvey E.A., Bell M.D., Mueser K.T., McGurk S.R., Spencer E.-S., Mailey K., Razzano L.A.","57193378295;32267597900;7201853421;35740601600;8688364200;35519035000;7005767113;7003914169;57205214823;57205214441;6602896099;","Enhancing individual placement and support (IPS) - Supported employment: A Type 1 hybrid design randomized controlled trial to evaluate virtual reality job interview training among adults with severe mental illness",2019,"Contemporary Clinical Trials","77",,,"86","97",,5,"10.1016/j.cct.2018.12.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059144829&doi=10.1016%2fj.cct.2018.12.008&partnerID=40&md5=591b3d8a82ca73632d29e4371876ca3b","School of Social Work, University of Michigan, United States; Department of Psychiatry and Behavioral Sciences, Northwestern University, United States; Department of Preventive Medicine, Northwestern University Feinberg School of Medicine, United States; Department of Pediatrics, Northwestern University Feinberg School of Medicine, United States; Illinois Department of Human Services, Division of Rehabilitation Services, United States; Department of Psychiatry, Yale School of Medicine, United States; Boston University, United States; Adams and Associates, Inc., United States; Thresholds Inc, United States; Chicago Department of Psychiatry, University of Illinois, United States","Smith, M.J., School of Social Work, University of Michigan, United States; Smith, J.D., Department of Psychiatry and Behavioral Sciences, Northwestern University, United States, Department of Preventive Medicine, Northwestern University Feinberg School of Medicine, United States, Department of Pediatrics, Northwestern University Feinberg School of Medicine, United States; Fleming, M.F., Department of Psychiatry and Behavioral Sciences, Northwestern University, United States; Jordan, N., Department of Psychiatry and Behavioral Sciences, Northwestern University, United States; Oulvey, E.A., Illinois Department of Human Services, Division of Rehabilitation Services, United States; Bell, M.D., Department of Psychiatry, Yale School of Medicine, United States; Mueser, K.T., Boston University, United States; McGurk, S.R., Boston University, United States; Spencer, E.-S., Adams and Associates, Inc., United States; Mailey, K., Thresholds Inc, United States; Razzano, L.A., Thresholds Inc, United States, Chicago Department of Psychiatry, University of Illinois, United States","Individual Placement and Support (IPS) is the evidence-based model of supported employment that increases employment rates in adults with severe mental illness (SMI). Although IPS is largely successful, over 80% of adults with SMI remain unemployed. An enhancement to high fidelity IPS could be an evidence-based job interview training component. To meet this training need, our group recently completed a series of randomized controlled efficacy trials funded by the National Institute of Mental Health to develop and test virtual reality job interview training (VR-JIT) in a lab setting. The results demonstrated that the intervention was efficacious at helping trainees improve their job interview skills and receive job offers within six months of completing VR-JIT compared to non-trainees. The overarching goal of this study is to evaluate the effectiveness of VR-JIT as an enhancement to IPS when delivered in a large community-based mental health service provider via a randomized controlled trial and initial process evaluation. Our aims are to: evaluate whether IPS services-as-usual in combination with VR-JIT, compared to IPS services-as-usual alone, enhances IPS outcomes for adults with SMI; evaluate mechanisms of employment outcomes and psychological distress; and conduct a multilevel, multidisciplinary, and mixed-method process evaluation of VR-JIT adoption and implementation to assess the acceptability, scalability, generalizability, and affordability of VR-JIT. © 2018 Elsevier Inc.",,"adult; Article; clinical effectiveness; controlled study; disease severity; distress syndrome; evaluation study; evidence based practice; human; individual placement and support; intervention study; job interview; major clinical study; mental disease; national health organization; randomized controlled trial; supported employment; training; unemployment; virtual reality; adolescent; employment; interview; mental disease; mental health service; middle aged; organization and management; procedures; psychology; severity of illness index; supported employment; young adult; Adolescent; Adult; Community Mental Health Services; Employment; Employment, Supported; Humans; Interviews as Topic; Mental Disorders; Middle Aged; Psychological Distress; Severity of Illness Index; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85059144829
"Mertens G., Wagensveld P., Engelhard I.M.","56642504800;57204568011;6701593489;","Cue conditioning using a virtual spider discriminates between high and low spider fearful individuals",2019,"Computers in Human Behavior","91",,,"192","200",,4,"10.1016/j.chb.2018.10.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056172525&doi=10.1016%2fj.chb.2018.10.006&partnerID=40&md5=01119daeb39d2e59e0cf4f30d5d0e9d1","Department of Clinical Psychology, Utrecht University, Utrecht, Netherlands","Mertens, G., Department of Clinical Psychology, Utrecht University, Utrecht, Netherlands; Wagensveld, P., Department of Clinical Psychology, Utrecht University, Utrecht, Netherlands; Engelhard, I.M., Department of Clinical Psychology, Utrecht University, Utrecht, Netherlands","The fear conditioning paradigm is one of the most commonly used procedures to examine the etiology and treatment of anxiety disorders in laboratories. However, findings with this procedure often do not generalize to clinical settings. Virtual reality (VR) is a promising tool for improving the ecological and predictive validity of fear conditioning. The current study explored whether a classical differential cue conditioning paradigm with spider-fearful participants can be conducted in a VR-environment. Specifically, 25 spider-fearful and 25 non-fearful female students participated in a fear-conditioning experiment with a virtual spider as an unconditioned stimulus (US). The experiment took place in a virtual office in which participants viewed an avatar of themselves sitting at a desk. Conditioned stimuli (CS) were a blue (CS+; 100% reinforcement) and a green (CS-) light emitted by a desk lamp. Fear reactions were measured by fear ratings, skin conductance responses (SCR), and fear potentiated startle responses (FPS). Our results indicated stronger differential fear conditioning for spider-fearful participants than for non-fearful participants. Furthermore, we demonstrate that these results relate specifically to spider-fear, and not to general trait anxiety. We conclude that fear conditioning in VR is a promising tool to improve the validity of classical fear conditioning procedures. © 2018 Elsevier Ltd","Acquisition; Extinction; Fear conditioning; Spider-related fear; Virtual reality","Light extinction; Mobile computing; Acquisition; Clinical settings; Female students; Skin conductance response; Spider-related fear; Virtual office; Virtual reality; adult; anxiety; article; clinical article; controlled study; electrodermal response; fear conditioning test; female; human; nonhuman; reinforcement; spider; startle reflex; stimulus; student; validity; virtual reality",Article,"Final","",Scopus,2-s2.0-85056172525
"Navarro-Haro M.V., Modrego-Alarcón M., Hoffman H.G., López-Montoyo A., Navarro-Gil M., Montero-Marin J., García-Palacios A., Borao L., García-Campayo J.","56955636800;57193067497;7201677607;57195236598;55551872600;35292920200;55917735200;57197792593;7007024687;","Evaluation of a mindfulness-based intervention with and without virtual reality dialectical behavior therapy® mindfulness skills training for the treatment of generalized anxiety disorder in primary care: A pilot study",2019,"Frontiers in Psychology","10","JAN", 55,"","",,10,"10.3389/fpsyg.2019.00055","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061030144&doi=10.3389%2ffpsyg.2019.00055&partnerID=40&md5=83bf01ccefec8eb7cb74f152d567c160","Personality Disorders Unit, General University Hospital of Catalonia, University of Barcelona, Barcelona, Spain; Instituto de Investigación Sanitaria Aragón, Zaragoza, Spain; Virtual Reality Research Center at the Human Photonics Lab, Mechanical Engineering, University of Washington, Seattle, WA, United States; Edificio Investigación II, Universitat Jaume I, Castellón de la Plana, Spain; Primary Care Prevention and Health Promotion Network, RedIAPP, Zaragoza, Spain; Hospital Universitario Miguel Servet, Zaragoza, Spain","Navarro-Haro, M.V., Personality Disorders Unit, General University Hospital of Catalonia, University of Barcelona, Barcelona, Spain; Modrego-Alarcón, M., Instituto de Investigación Sanitaria Aragón, Zaragoza, Spain; Hoffman, H.G., Virtual Reality Research Center at the Human Photonics Lab, Mechanical Engineering, University of Washington, Seattle, WA, United States; López-Montoyo, A., Edificio Investigación II, Universitat Jaume I, Castellón de la Plana, Spain; Navarro-Gil, M., Instituto de Investigación Sanitaria Aragón, Zaragoza, Spain; Montero-Marin, J., Primary Care Prevention and Health Promotion Network, RedIAPP, Zaragoza, Spain; García-Palacios, A., Edificio Investigación II, Universitat Jaume I, Castellón de la Plana, Spain; Borao, L., Instituto de Investigación Sanitaria Aragón, Zaragoza, Spain; García-Campayo, J., Instituto de Investigación Sanitaria Aragón, Zaragoza, Spain, Primary Care Prevention and Health Promotion Network, RedIAPP, Zaragoza, Spain, Hospital Universitario Miguel Servet, Zaragoza, Spain","Generalized Anxiety Disorder (GAD) is a very prevalent disorder in primary care (PC). Most patients with GAD never seek treatment, and those who do seek treatment often drop out before completing treatment. Although it is an understudied treatment, Mindfulness-Based Interventions (MBIs) indicate preliminary efficacy for the treatment of GAD symptoms, but many patients with GAD present other associated symptoms (e.g., attention deficits) that complicate the treatment. Virtual Reality DBT® Mindfulness Skills learning has recently been developed to make learning mindfulness easier for patients with emotion dysregulation who have trouble concentrating. Virtual Reality (VR) might serve as a visual guide for practicing mindfulness as it gives patients the illusion of ""being there"" in the 3D computer generated world. The main goal of this study was to evaluate the effect of two MBIs (a MBI in a group setting alone and the same MBI plus 10 min VR DBT® Mindfulness skills training) to reduce GAD symptoms. A secondary aim was to explore the effect in depression, emotion regulation, mindfulness, and interoceptive awareness. Other exploratory aims regarding the use of VR DBT® Mindfulness skills were also carried out. The sample was composed of 42 patients (roughly half in each group) with GAD attending PC visits. After treatment, both groups of patients showed significant improvements in General Anxiety Disorder measured by the GAD-7 using mixed regression models [MBI alone (B = -5.70; p < 0.001; d = -1.36), MBI+VR DBT® Mindfulness skills (B = -4.38; p < 0.001; d = -1.33)]. Both groups also showed significant improvements in anxiety, depression, difficulties of emotion regulation and several aspects of mindfulness and interoceptive awareness. Patients in the group that received additional 10 min VR DBT Mindfulness Skills training were significantly more adherent to the treatment than those receiving only standard MBI (100% completion rate in MBI + VR vs. 70% completion rate in MBI alone; Fisher = 0.020). Although randomized controlled studies with larger samples are needed, this pilot study shows preliminary effectiveness of MBI to treat GAD, and preliminary evidence that adjunctive VR DBT® Mindfulness Skills may reduce dropouts. © 2019 Navarro-Haro, Modrego-Alarcón, Hoffman, López-Montoyo, Navarro-Gil, Montero-Marin, García-Palacios, Borao and García-Campayo.","Dialectical behavior therapy; Generalized anxiety disorder; Mindfulness; Virtual reality; Virtual reality mindfulness",,Article,"Final","",Scopus,2-s2.0-85061030144
"Trejo F., Hu Y.","56027819200;57201840458;","User Performance of VR-Based Dissection: Direct Mapping and Motion Coupling of a Surgical Tool",2019,"Proceedings - 2018 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2018",,, 8616512,"3039","3044",,,"10.1109/SMC.2018.00516","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062237775&doi=10.1109%2fSMC.2018.00516&partnerID=40&md5=a1e52e6b433c2e3e8f287c9d83c61585","Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, Canada","Trejo, F., Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, Canada; Hu, Y., Department of Electrical and Computer Engineering, University of Calgary, Calgary, AB, Canada","Robot-assisted surgical systems aim at enhancing surgeon's skills. Nonetheless, the learning curve for mastering such systems is very slow due to the motion-coupling mode that is usually presented in these systems for manipulating a surgical tool. This mode has limitations compared to the direct mapping mode used in open surgery for manipulating a tool. Virtual reality (VR) surgical simulators may reduce the learning time for transferring the surgeon's skills from direct mapping to motion coupling of tool manipulation. This may be accomplished by adding two features to the simulator. First, force models of tool-tissue interaction can be implemented in the haptic interface of the simulator. Second, VR-based surgical tasks can be designed to recreate directmapping mode and motion coupling mode of tool manipulation, as in open and robot-assisted surgeries, respectively. This may permit to transfer the surgeon's skills from open surgery to robotassisted surgery in a timely manner. This work presents a preliminary study on the effect of direct mapping mode and motion coupling mode of tool manipulation on the performance of naïve participants for VR-based brain tissue dissection. An Analytic force model of soft-tissue dissection was implemented in the simulator along with visual feedback of a predefined tool speed of 1 mm/s, which is observed in neurosurgery. The outcomes indicated that the motion quality of the tool via direct mapping was significantly better than with motion coupling. Thus, the study might serve as a first step toward the assessment of user's skills for VR-based robot-assisted dissection. © 2018 IEEE.","direct mapping; motion coupling; robot-assisted surgery; soft-tissue dissection; VR-based surgical simulation","Brain mapping; Cybernetics; Dissection; Haptic interfaces; Mapping; Neurosurgery; Robotic surgery; Robots; Simulators; Tissue; Transplantation (surgical); Virtual reality; Visual communication; Visual servoing; Direct mapping; Motion Coupling; Robot-assisted surgery; Soft tissue; Surgical simulation; Surgical equipment",Conference Paper,"Final","",Scopus,2-s2.0-85062237775
"Geronazzo M., Sikstrom E., Kleimola J., Avanzini F., De Gotzen A., Serafin S.","36720522500;55354784700;24829233900;7005300654;24724148200;6603367536;","The Impact of an Accurate Vertical Localization with HRTFs on Short Explorations of Immersive Virtual Reality Scenarios",2019,"Proceedings of the 2018 IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2018",,, 8613754,"90","97",,8,"10.1109/ISMAR.2018.00034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062179431&doi=10.1109%2fISMAR.2018.00034&partnerID=40&md5=5a0b7c6c5270986682096e1aad3ed439","Dept. of Architecture, Design and Media Technology, Aalborg University, Denmark; Virsabi ApS, Denmark; Hefio Ltd, Denmark; Dept. of Computer Science, University of Milano, Italy","Geronazzo, M., Dept. of Architecture, Design and Media Technology, Aalborg University, Denmark; Sikstrom, E., Virsabi ApS, Denmark; Kleimola, J., Hefio Ltd, Denmark; Avanzini, F., Dept. of Computer Science, University of Milano, Italy; De Gotzen, A., Dept. of Architecture, Design and Media Technology, Aalborg University, Denmark; Serafin, S., Dept. of Architecture, Design and Media Technology, Aalborg University, Denmark","Achieving a full 3D auditory experience with head-related transfer functions (HRTFs) is still one of the main challenges of spatial audio rendering. HRTFs capture the listener's acoustic effects and personal perception, allowing immersion in virtual reality (VR) applications. This paper aims to investigate the connection between listener sensitivity in vertical localization cues and experienced presence, spatial audio quality, and attention. Two VR experiments with head-mounted display (HMD) and animated visual avatar are proposed: (i) a screening test aiming to evaluate the participants' localization performance with HRTFs for a non-visible spatialized audio source, and (ii) a 2 minute free exploration of a VR scene with five audiovisual sources in a both non-spatialized (2D stereo panning) and spatialized (free-field HRTF rendering) listening conditions. The screening test allows a distinction between good and bad localizers. The second one shows that no biases are introduced in the quality of the experience (QoE) due to different audio rendering methods; more interestingly, good localizers perceive a lower audio latency and they are less involved in the visual aspects. © 2018 IEEE.","Auditory feedback; Human-centered computing; Interaction devices; Interaction paradigms; Interaction techniques; Sound-based input / output Human-centered computing; Virtual reality; Human-centered computing","Augmented reality; Helmet mounted displays; Three dimensional computer graphics; Transfer functions; Virtual reality; Auditory feedback; Human-centered computing; Input/output; Interaction devices; Interaction paradigm; Interaction techniques; Sound reproduction",Conference Paper,"Final","",Scopus,2-s2.0-85062179431
"Hofmann S.M., Klotzsche F., Mariola A., Nikulin V.V., Villringer A., Gaebler M.","57203966872;57203973247;57203969187;7007084310;7007157177;55551073400;","Decoding subjective emotional arousal during a naturalistic VR experience from EEG using LSTMs",2019,"Proceedings - 2018 IEEE International Conference on Artificial Intelligence and Virtual Reality, AIVR 2018",,, 8613645,"128","131",,5,"10.1109/AIVR.2018.00026","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062183906&doi=10.1109%2fAIVR.2018.00026&partnerID=40&md5=1ac742f01e79eb17010913730181993a","Amsterdam Brain and Cognition, University of Amsterdam, Amsterdam, Netherlands; Berlin School of Mind and Brain, Humboldt Universität zu Berlin, Berlin, Germany; Sussex Neuroscience, University of Sussex, Sussex, United Kingdom; Neurology, MPI Hum. Cog. and Brain Sci., Leipzig, Germany","Hofmann, S.M., Amsterdam Brain and Cognition, University of Amsterdam, Amsterdam, Netherlands; Klotzsche, F., Berlin School of Mind and Brain, Humboldt Universität zu Berlin, Berlin, Germany; Mariola, A., Sussex Neuroscience, University of Sussex, Sussex, United Kingdom; Nikulin, V.V., Neurology, MPI Hum. Cog. and Brain Sci., Leipzig, Germany; Villringer, A., Neurology, MPI Hum. Cog. and Brain Sci., Leipzig, Germany; Gaebler, M., Neurology, MPI Hum. Cog. and Brain Sci., Leipzig, Germany","Emotional arousal (EA) denotes a heightened state of activation that has both subjective and physiological aspects. The neurophysiology of subjective EA, among other mind-brain-body phenomena, can best be tested when subjects are stimulated in a natural fashion. Immersive virtual reality (VR) enables naturalistic experimental stimulation and thus promises to increase the ecological validity of research findings i.e., how well they generalize to real-life settings. In this study, 45 participants experienced virtual rollercoaster rides while their brain activity was recorded using electroencephalography (EEG). A Long Short-Term Memory (LSTM) recurrent neural network (RNN) was then trained on the alpha-frequency (8-12 Hz) component of the EEG signal (input) and the retrospectively acquired continuous reports of subjective EA (target). With the LSTM-based model, subjective EA could be predicted significantly above chance level. This demonstrates a novel EEG-based decoding approach for subjective states of experience in naturalistic research designs using VR. © 2018 IEEE.","Continuous time series; Emotional arousal; Naturalistic research designs; Neural decoding; Subjective experience","Brain; Continuous time systems; Decoding; Electrophysiology; Long short-term memory; Neurophysiology; Virtual reality; Well stimulation; Continuous-time; Emotional arousal; Neural decoding; Research designs; Subjective experiences; Electroencephalography",Conference Paper,"Final","",Scopus,2-s2.0-85062183906
"Barbosa Monforte P.H., Matos Araujo G., Azevedo De Lima A.","57207112505;57207105241;24733621100;","Evaluation of a New Kernel-Based Classifier in Eye Pupil Detection",2019,"Proceedings - 17th IEEE International Conference on Machine Learning and Applications, ICMLA 2018",,, 8614088,"380","385",,1,"10.1109/ICMLA.2018.00063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062230155&doi=10.1109%2fICMLA.2018.00063&partnerID=40&md5=a0859b6c189a69687c57b4b66cd46877","Centro Federal de Educação Tecnolgica Celso Suckow da Fonseca, Estrada de Adrianópolis, 1.317, Nova Iguaçu - RJ, CEP: 26041-271, Brazil","Barbosa Monforte, P.H., Centro Federal de Educação Tecnolgica Celso Suckow da Fonseca, Estrada de Adrianópolis, 1.317, Nova Iguaçu - RJ, CEP: 26041-271, Brazil; Matos Araujo, G., Centro Federal de Educação Tecnolgica Celso Suckow da Fonseca, Estrada de Adrianópolis, 1.317, Nova Iguaçu - RJ, CEP: 26041-271, Brazil; Azevedo De Lima, A., Centro Federal de Educação Tecnolgica Celso Suckow da Fonseca, Estrada de Adrianópolis, 1.317, Nova Iguaçu - RJ, CEP: 26041-271, Brazil","Accurate pupil location is paramount to applications such as gaze estimation, assistive technologies and several man-machine interfaces as the ones found in smartphones and VR applications. We introduce a new classifier stemmed from the Inner Product Detector and investigate its features on the challenging task of pupil localization. IPD (Inner Product Detector) is a classifier with high potential in facial landmarks detection. It is robust to variations in the desired pattern while maintaining good generalization and computational efficiency. However, one possible limitation is its linear behavior, which could be overcome by aggregating non-linear techniques, such as kernel methods. Although kernel classifiers have been exhaustively studied in the past two decades, it was not analyzed or applied with IPD, yet. The proposed KIPD achieves in the worst case an accuracy of 97.41% on the BioID dataset and 93.71% in LFPW dataset both at 10% of the interocular distance. In this paper the KIPD is compared to the state of the art methods, including the ones using deep learning, being competitive in terms of accuracy as well as computational complexity. © 2018 IEEE.","Correlation filtes; Kernel machines; Machine learning","Computational efficiency; Learning systems; Machine learning; Assistive technology; Eye pupil detections; Kernel based classifiers; Kernel classifiers; Kernel machine; Man machine interface; Nonlinear techniques; State-of-the-art methods; Deep learning",Conference Paper,"Final","",Scopus,2-s2.0-85062230155
"Mochizuki S., Imamura K., Mori K., Matsuda Y., Matsumura T.","15082726700;7202591831;56390797300;7402705505;57216116814;","Ultra-low-latency video coding method for autonomous vehicles and virtual reality devices",2019,"Proceedings - 2018 IEEE International Conference on Internet of Things and Intelligence System, IOTAIS 2018",,, 8600851,"155","161",,1,"10.1109/IOTAIS.2018.8600851","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061708079&doi=10.1109%2fIOTAIS.2018.8600851&partnerID=40&md5=8edd7b8f9b62586cf1bdb570953a5711","College of Engineering, Nihon University, Koriyama, Japan; College of Science and Engineering, Kanazawa University, Kanazawa, Japan","Mochizuki, S., College of Engineering, Nihon University, Koriyama, Japan; Imamura, K., College of Science and Engineering, Kanazawa University, Kanazawa, Japan; Mori, K., College of Engineering, Nihon University, Koriyama, Japan; Matsuda, Y., College of Science and Engineering, Kanazawa University, Kanazawa, Japan; Matsumura, T., College of Engineering, Nihon University, Koriyama, Japan","Applications such as autonomous driving and virtual reality (VR) require low-latency transfer of high definition (HD) video. The proposed ultra-low-latency video coding method, which adopts line-based processing, has 0.44μs latency at minimum for Full-HD video. With multiple line-based image-prediction methods, image-adaptive quantization, and optimized entropy coding, the proposed method achieves compression to 39.0% data size and image quality of 45.4dB. The proposed basic algorithm and the optional 1D-DCT mode achieve compression to 33% and 20%, respectively, without significant visual degradation. These results are comparable to those for H.264 Intra despite one-thousandth ultra-low-latency of the proposed method. With the proposed video coding, the autonomous vehicles and VR devices can transfer HD video using 20% of the bandwidth of the source video without significant latency or visual degradation. © 2018 IEEE.","autonomous driving; low latency; video coding; virtual reality (VR)","Autonomous vehicles; Codes (symbols); Digital television; Image coding; Image compression; Internet of things; Virtual reality; Adaptive quantization; Autonomous driving; Entropy coding; High-definition videos; Image prediction; Low latency; Virtual reality devices; Visual degradations; Video signal processing",Conference Paper,"Final","",Scopus,2-s2.0-85061708079
"Qin Z., Tai Y., Xia C., Peng J., Huang X., Chen Z., Li Q., Shi J.","57197755201;36984437500;57205556936;57214109873;18436902100;36633870500;55911980700;8640031700;","Towards Virtual VATS, Face, and Construct Evaluation for Peg Transfer Training of Box, VR, AR, and MR Trainer",2019,"Journal of Healthcare Engineering","2019",, 6813719,"","",,4,"10.1155/2019/6813719","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060519204&doi=10.1155%2f2019%2f6813719&partnerID=40&md5=3f4666c758e681e13ee471dd0a467665","Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China; Department of Thoracic Surgery, Yunnan First People's Hospital, Kunming, 650000, China","Qin, Z., Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China; Tai, Y., Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China; Xia, C., Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China; Peng, J., Department of Thoracic Surgery, Yunnan First People's Hospital, Kunming, 650000, China; Huang, X., Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China; Chen, Z., Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China; Li, Q., Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China; Shi, J., Yunnan Key Laboratory of Opto-Electronic Information Technology, Yunnan Normal University, Kunming, 650000, China","The aim of this study is to develop and assess the peg transfer training module face, content and construct validation use of the box, virtual reality (VR), cognitive virtual reality (CVR), augmented reality (AR), and mixed reality (MR) trainer, thereby to compare advantages and disadvantages of these simulators. Training system (VatsSim-XR) design includes customized haptic-enabled thoracoscopic instruments, virtual reality helmet set, endoscope kit with navigation, and the patient-specific corresponding training environment. A cohort of 32 trainees comprising 24 novices and 8 experts underwent the real and virtual simulators that were conducted in the department of thoracic surgery of Yunnan First People's Hospital. Both subjective and objective evaluations have been developed to explore the visual and haptic potential promotions in peg transfer education. Experiments and evaluation results conducted by both professional and novice thoracic surgeons show that the surgery skills from experts are better than novices overall, AR trainer is able to provide a more balanced training environments on visuohaptic fidelity and accuracy, box trainer and MR trainer demonstrated the best realism 3D perception and surgical immersive performance, respectively, and CVR trainer shows a better clinic effect that the traditional VR trainer. Combining these in a systematic approach, tuned with specific fidelity requirements, medical simulation systems would be able to provide a more immersive and effective training environment. © 2019 Zhibao Qin et al.",,"Augmented reality; E-learning; Mixed reality; Transplantation (surgical); Evaluation results; Medical simulations; Patient specific; Subjective and objective evaluations; Thoracic surgery; Training modules; Training Systems; Virtual simulators; Surgical equipment; adult; Article; augmented reality; construct validity; facial recognition; female; human; intermethod comparison; male; medical education; mixed reality; postgraduate student; simulation training; skill; thoracic surgeon; video assisted thoracoscopic surgery; virtual reality; clinical competence; comparative study; computer interface; computer simulation; education; lung tumor; middle aged; procedures; software; teaching; video assisted thoracoscopic surgery; virtual reality; young adult; Adult; Augmented Reality; Clinical Competence; Computer Simulation; Computer-Assisted Instruction; Female; Humans; Lung Neoplasms; Male; Middle Aged; Software; Thoracic Surgery, Video-Assisted; User-Computer Interface; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85060519204
"Schiavon M., Keber M., Cossutta A., Zini A., Jez M., Ambrosio L.","57211568046;23008588000;57211567113;55332827800;56081909900;56865597700;","Virtual reality in shipbuilding: Three use cases in a cruise ship design process",2019,"RINA, Royal Institution of Naval Architects - 19th International Conference on Computer Applications in Shipbuilding, ICCAS 2019","1",,,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074450034&partnerID=40&md5=842897b25714bc524d05ebe39d5ae178","Fincantieri S.p.A, Italy; Fincantieri Oil and Gas S.p.A., Italy; CETENA S.p.A., Italy; Arsenal S.r.l., Italy","Schiavon, M., Fincantieri S.p.A, Italy; Keber, M., Fincantieri Oil and Gas S.p.A., Italy; Cossutta, A., Fincantieri S.p.A, Italy; Zini, A., CETENA S.p.A., Italy; Jez, M., Arsenal S.r.l., Italy; Ambrosio, L., Fincantieri S.p.A, Italy","Due to the complexity of modern cruise ships, efficient management of information is in many cases possible only by introducing suitable advanced technological solutions. In this paper we discuss the implications of using a virtual reality (VR) system in a cruise ship design process. At the initial stages, most of the information about a vessel is included in its design in the form of 3D CAD models, which are normally not accessible to stakeholders with insufficient CAD skills. By transferring the models to an immersive environment, the understanding of the project normally improves for expert as well as non-expert stakeholders. However, the potential of the technology is dependent on the quality of pre-processing of CAD models for VR and on the set-up of the VR scenes. As described, the workflow in the design process must therefore be carefully adjusted to allow seamless transfer of files between CAD and VR environments. © 2019: The Royal Institution of Naval Architects.",,"Shipbuilding; Ships; Shipyards; Virtual reality; 3d cad models; Cruise ships; Design process; Efficient managements; Immersive environment; Pre-processing; Seamless transfer; Technological solution; Computer aided design",Conference Paper,"Final","",Scopus,2-s2.0-85074450034
"Kalarat K., Koomhin P.","16319061300;55619841400;","Real-time volume rendering interaction in Virtual Reality",2019,"International Journal of Technology","10","7",,"1307","1314",,,"10.14716/ijtech.v10i7.3259","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076044621&doi=10.14716%2fijtech.v10i7.3259&partnerID=40&md5=005226cee497ef28d0d76d480aa41a00","School of Informatics, Walailak University, 222 Thaiburi, Thasala District, Nakhon Si Thammarat, 80161, Thailand; School of Medicine, Walailak University, 222 Thaiburi, Thasala District, Nakhon Si Thammarat, 80161, Thailand","Kalarat, K., School of Informatics, Walailak University, 222 Thaiburi, Thasala District, Nakhon Si Thammarat, 80161, Thailand; Koomhin, P., School of Medicine, Walailak University, 222 Thaiburi, Thasala District, Nakhon Si Thammarat, 80161, Thailand","Volume visualization using Direct Volume Rendering (DVR) techniques is used to view information inside 3D volumetric data. Data is classified using a transfer function to emphasize or filter some parts of volumetric information, such as that from Computed Tomography (CT) or Magnetic Resonance Imaging (MRI). In this paper, we introduced an application for real-time volume rendering interaction with 1D transfer functions using Virtual Reality (VR) technology based on the Oculus Rift headset and Oculus Touch controllers. Resulting images were visualized stereoscopically at 60 frames per second using a ray-casting shader, which works based on Graphics Processing Unit (GPU). To evaluate the system, 20 participants interacted with the application to complete three tasks, including a free viewpoint scan, clipping planes renderer, and an editable transfer function in the virtual environment. Then, a survey was carried out using a questionnaire to gather data. Findings showed that the average usability score for the application was 87.54, which suggested that it was highly usable. © IJTech 2019.","Direct volume rendering; Ray casting; Virtual environment; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85076044621
"Moore H.F., Eiris R., Gheisari M., Esmaeili B.","57209801285;57196006104;36459705300;35388139800;","Hazard Identification Training Using 360-Degree Panorama vs. Virtual Reality Techniques: A Pilot Study",2019,"Computing in Civil Engineering 2019: Visualization, Information Modeling, and Simulation - Selected Papers from the ASCE International Conference on Computing in Civil Engineering 2019",,,,"55","62",,5,"10.1061/9780784482421.008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068793185&doi=10.1061%2f9780784482421.008&partnerID=40&md5=50941e5e91da0bb940956a73a319410c","Healthcare Division, Haskell Company, 111 Riverside Ave., Jacksonville, FL  32202, United States; Human-Centered Technology in Construction (HCTC) Research Group, Rinker School of Construction Management, Univ. of Florida, PO Box 115703, Gainesville, FL  32611-5701, United States; Safety, Risk Management, and Decision-Making (SARMAD) Research Group, Sid and Reva Dewberry Dept. of Civil, Environmental, and Infrastructure Engineering, George Mason Univ., PO Box 115703, Fairfax, VA  22030, United States","Moore, H.F., Healthcare Division, Haskell Company, 111 Riverside Ave., Jacksonville, FL  32202, United States; Eiris, R., Human-Centered Technology in Construction (HCTC) Research Group, Rinker School of Construction Management, Univ. of Florida, PO Box 115703, Gainesville, FL  32611-5701, United States; Gheisari, M., Human-Centered Technology in Construction (HCTC) Research Group, Rinker School of Construction Management, Univ. of Florida, PO Box 115703, Gainesville, FL  32611-5701, United States; Esmaeili, B., Safety, Risk Management, and Decision-Making (SARMAD) Research Group, Sid and Reva Dewberry Dept. of Civil, Environmental, and Infrastructure Engineering, George Mason Univ., PO Box 115703, Fairfax, VA  22030, United States","Virtual reality (VR)-based approaches have been used to facilitate safety knowledge transfer and increase hazard awareness by providing safe and controlled experiences of unsafe scenarios for construction safety training applications. However, high computational costs, long development times, and the limited sense of presence and realism associated with existing VR methods have posed significant challenges for using such VR-based safety training platforms. Unlike the VR environments that provide computer-generated simulations of the environment, 360-degree panoramas create true-to-reality simulations of environments while maintaining a high sense of presence. The purpose of this research is to develop and compare hazard identification training scenarios using 360-degree panorama and VR techniques. A pilot study, based on OSHA's focus-four hazards, was conducted to assess the effectiveness of safety hazard identification training using these techniques. The results of this preliminary research indicate that hazard identification index scores were slightly higher on average in the VR condition comparing to the ""messier"" or ""dirtier"" as-build representation of the 360-degree panorama. © 2019 American Society of Civil Engineers.",,"E-learning; Hazardous materials; Information theory; Knowledge management; Virtual reality; Visualization; Computational costs; Computer generated; Construction safety; Hazard awareness; Hazard identification; Sense of presences; Training scenario; Virtual reality techniques; Hazards",Conference Paper,"Final","",Scopus,2-s2.0-85068793185
"Riva G., Wiederhold B.K., Mantovani F.","56962750600;7003634518;7006190897;","Neuroscience of Virtual Reality: From Virtual Exposure to Embodied Medicine",2019,"Cyberpsychology, Behavior, and Social Networking","22","1",,"82","96",,74,"10.1089/cyber.2017.29099.gri","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055999466&doi=10.1089%2fcyber.2017.29099.gri&partnerID=40&md5=cd9711ea83953e848a8ad11e7c485d1c","Applied Technology for Neuro-Psychology Lab, IRCCS Istituto Auxologico Italiano, Milan, Italy; Department of Psychology, Università Cattolica Del Sacro Cuore, Largo Gemelli 1, Milan, 20123, Italy; Virtual Reality Medical Center, San Diego, CA, United States; Virtual Reality Medical Institute, Brussels, Belgium; Department of Human Sciences for Education, Università degli Studi di Milano-Bicocca, Milan, Italy","Riva, G., Applied Technology for Neuro-Psychology Lab, IRCCS Istituto Auxologico Italiano, Milan, Italy, Department of Psychology, Università Cattolica Del Sacro Cuore, Largo Gemelli 1, Milan, 20123, Italy; Wiederhold, B.K., Virtual Reality Medical Center, San Diego, CA, United States, Virtual Reality Medical Institute, Brussels, Belgium; Mantovani, F., Department of Human Sciences for Education, Università degli Studi di Milano-Bicocca, Milan, Italy","Is virtual reality (VR) already a reality in behavioral health? To answer this question, a meta-review was conducted to assess the meta-analyses and systematic and narrative reviews published in this field in the last twenty-two months. Twenty-five different articles demonstrated the clinical potential of this technology in both the diagnosis and the treatment of mental health disorders: VR compares favorably to existing treatments in anxiety disorders, eating and weight disorders, and pain management, with long-term effects that generalize to the real world. But why is VR so effective? Here, the following answer is suggested: VR shares with the brain the same basic mechanism: embodied simulations. According to neuroscience, to regulate and control the body in the world effectively, the brain creates an embodied simulation of the body in the world used to represent and predict actions, concepts, and emotions. VR works in a similar way: the VR experience tries to predict the sensory consequences of an individual's movements, providing to him/her the same scene he/she will see in the real world. To achieve this, the VR system, like the brain, maintains a model (simulation) of the body and the space around it. If the presence in the body is the outcome of different embodied simulations, concepts are embodied simulations, and VR is an embodied technology, this suggests a new clinical approach discussed in this article: the possibility of altering the experience of the body and facilitating cognitive modeling/change by designing targeted virtual environments able to simulate both the external and the internal world/body. © Giuseppe Riva et al. 2019; Published by Mary Ann Liebert, Inc.",,"analgesia; anxiety disorder; cognitive neuroscience; human; mental disease; meta analysis; virtual reality; virtual reality exposure therapy; Anxiety Disorders; Cognitive Neuroscience; Humans; Mental Disorders; Pain Management; Virtual Reality; Virtual Reality Exposure Therapy",Article,"Final","",Scopus,2-s2.0-85055999466
"Eiler T.J., Grünewald A., Brück R.","57209602482;55320081200;9639255900;","Fighting substance dependency combining AAT therapy and virtual reality with game design elements",2019,"VISIGRAPP 2019 - Proceedings of the 14th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications","2",,,"28","37",,2,"10.5220/0007362100280037","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068205164&doi=10.5220%2f0007362100280037&partnerID=40&md5=4f227b31e734c7f5ac635d8330c0a3a1","Medical Informatics and Microsystems Engineering, University of Siegen, Hölderlinstraße 3, Siegen, 57076, Germany","Eiler, T.J., Medical Informatics and Microsystems Engineering, University of Siegen, Hölderlinstraße 3, Siegen, 57076, Germany; Grünewald, A., Medical Informatics and Microsystems Engineering, University of Siegen, Hölderlinstraße 3, Siegen, 57076, Germany; Brück, R., Medical Informatics and Microsystems Engineering, University of Siegen, Hölderlinstraße 3, Siegen, 57076, Germany","Smoking poses a significant health risk and is still the main cause of premature mortality today. The Approach Avoidance Task (AAT) developed by Rinck and Becker aims to develop a substance dependence therapy that can reach the digital society. In this paper, a demonstrator that transfers the AAT procedure into virtual reality (VR) is presented. This demonstrator was used to carry out an evaluation with twenty participants who were asked to use the program and evaluate it by means of questionnaires and interviews. In addition, the reaction times (RTs) of the test persons were recorded and evaluated. The results show that the transfer of the AAT procedure to VR is possible and promising. Above all, the use of three-dimensional scenarios and objects, with which one interacts during the training, were well received and increased the immersion as well as the felt embodiment. The use of game design elements has also proved helpful and has had a positive influence on user motivation. Copyright © 2019 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved","Approach Avoidance Task; Approach Bias; Cognitive Bias Modification; Digital Medicine; Game Design; Substance Dependency; Therapy; Virtual Reality; VR Applications","Design; Health risks; Human computer interaction; Surveys; Virtual reality; Approach Avoidance Task; Approach Bias; Cognitive bias; Game design; Substance Dependency; Therapy; VR applications; Computer vision",Conference Paper,"Final","",Scopus,2-s2.0-85068205164
"Oberdörfer S., Latoschik M.E.","57192160404;6602976914;","Knowledge encoding in game mechanics: Transfer-oriented knowledge learning in desktop-3D and VR",2019,"International Journal of Computer Games Technology","2019",, 7626349,"","",,4,"10.1155/2019/7626349","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065769392&doi=10.1155%2f2019%2f7626349&partnerID=40&md5=0741462efb8e93e61183958445a8371b","Human-Computer Interaction, University of Würzburg, Würzburg, Germany","Oberdörfer, S., Human-Computer Interaction, University of Würzburg, Würzburg, Germany; Latoschik, M.E., Human-Computer Interaction, University of Würzburg, Würzburg, Germany","Affine Transformations (ATs) are a complex and abstract learning content. Encoding the AT knowledge in Game Mechanics (GMs) achieves a repetitive knowledge application and audiovisual demonstration. Playing a serious game providing these GMs leads to motivating and effective knowledge learning. Using immersive Virtual Reality (VR) has the potential to even further increase the serious game's learning outcome and learning quality. This paper compares the effectiveness and efficiency of desktop-3D and VR in respect to the achieved learning outcome. Also, the present study analyzes the effectiveness of an enhanced audiovisual knowledge encoding and the provision of a debriefing system. The results validate the effectiveness of the knowledge encoding in GMs to achieve knowledge learning. The study also indicates that VR is beneficial for the overall learning quality and that an enhanced audiovisual encoding has only a limited effect on the learning outcome. © 2019 Sebastian Oberdörfer and Marc Erich Latoschik.",,"Encoding (symbols); Knowledge management; Signal encoding; Virtual reality; Affine transformations; Effectiveness and efficiencies; Immersive virtual reality; Knowledge application; Knowledge learning; Learning contents; Learning outcome; Learning quality; Serious games",Article,"Final","",Scopus,2-s2.0-85065769392
"Chang C.-H., Lin C.-Y., Wang R.-G., Chou C.-C.","57203374856;46062172900;57203964800;55710381200;","Applying Deep Learning and Building Information Modeling to Indoor Positioning Based on Sound",2019,"Computing in Civil Engineering 2019: Visualization, Information Modeling, and Simulation - Selected Papers from the ASCE International Conference on Computing in Civil Engineering 2019",,,,"193","199",,1,"10.1061/9780784482421.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068750871&doi=10.1061%2f9780784482421.025&partnerID=40&md5=4715e36373be40eb5a8db12c0c7eabc7","Information Technology for Disaster Prevention Program, Dept. of Civil Engineering, National Central Univ., 300 Jhongda Rd., Jhongli Dist., Taoyuan City, 32001, Taiwan; National Science and Technology Center for Disaster Reduction (NCDR), 9F, No. 200, Sec. 3, Beisin Rd., Xindian Dist., New Taipei City, 23143, Taiwan","Chang, C.-H., Information Technology for Disaster Prevention Program, Dept. of Civil Engineering, National Central Univ., 300 Jhongda Rd., Jhongli Dist., Taoyuan City, 32001, Taiwan; Lin, C.-Y., National Science and Technology Center for Disaster Reduction (NCDR), 9F, No. 200, Sec. 3, Beisin Rd., Xindian Dist., New Taipei City, 23143, Taiwan; Wang, R.-G., Information Technology for Disaster Prevention Program, Dept. of Civil Engineering, National Central Univ., 300 Jhongda Rd., Jhongli Dist., Taoyuan City, 32001, Taiwan; Chou, C.-C., Information Technology for Disaster Prevention Program, Dept. of Civil Engineering, National Central Univ., 300 Jhongda Rd., Jhongli Dist., Taoyuan City, 32001, Taiwan","At present, indoor positioning has great potential for disaster mitigation, such as guiding evacuees to safe places. This research aims at developing such a sound-based method using artificial intelligence (AI) and building information modeling (BIM). Amid a disaster, first responders can quickly set up the proposed system to help indoor positioning, which relies on BIM, virtual reality (VR), and head related transfer functions (HRTF) techniques to simulate virtual sound fields. Then, a deep learning model is trained so as to be able to predict the current zone within a room based on the sound received. Unity, a serious game platform, and Steam Audio, a Unity plugin designed for adding 3D audio to VR experience, are employed to generate input data sets. The overall accuracy of the output results is about 90% though the training time is long, which can be reduced if more powerful computing resources are utilized. © 2019 American Society of Civil Engineers.",,"Acoustic fields; Architectural design; Disasters; Indoor positioning systems; Information theory; Serious games; Sound reproduction; Virtual reality; Visualization; Building Information Model - BIM; Computing resource; Disaster mitigation; First responders; Head related transfer function; Indoor positioning; Learning models; Overall accuracies; Deep learning",Conference Paper,"Final","",Scopus,2-s2.0-85068750871
"Riva G., Wiederhold B.K., Di Lernia D., Chirico A., Riva E.F.M., Mantovani F., Cipresso P., Gaggioli A.","56962750600;7003634518;57189076325;56755080200;57200803512;7006190897;36717478000;6603138127;","Virtual reality meets artificial intelligence: The emergence of advanced digital therapeutics and digital biomarkers",2019,"Annual Review of CyberTherapy and Telemedicine","17",,,"3","7",,4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085609366&partnerID=40&md5=96fce33c0e8b3450c84334fd77801a83","Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy; Applied Technology for Neuro-Psychology Lab. Istituto Auxologico Italiano, Milan, Italy; Interactive Media Institute, San Diego, CA, United States; Department of Cultural Heritage and Environment, Università degli Studi di Milano, Milano, Italy; Department of Human Sciences for Education, Università degli Studi di Milano-Bicocca, Milan, Italy","Riva, G., Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy, Applied Technology for Neuro-Psychology Lab. Istituto Auxologico Italiano, Milan, Italy; Wiederhold, B.K., Interactive Media Institute, San Diego, CA, United States; Di Lernia, D., Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy; Chirico, A., Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy; Riva, E.F.M., Department of Cultural Heritage and Environment, Università degli Studi di Milano, Milano, Italy; Mantovani, F., Department of Human Sciences for Education, Università degli Studi di Milano-Bicocca, Milan, Italy; Cipresso, P., Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy, Applied Technology for Neuro-Psychology Lab. Istituto Auxologico Italiano, Milan, Italy; Gaggioli, A., Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy, Applied Technology for Neuro-Psychology Lab. Istituto Auxologico Italiano, Milan, Italy","In the past 25 years, researchers have discovered that Virtual Reality (VR) is an effective tool for mental health treatment and assessment in anxiety disorders, eating and weight disorders, and pain management with long-term effects that generalize to the real world. Moreover, VR is also an effective assessment tool with practical applications that range from social and cognitive deficits to addiction. Nevertheless, despite progress, evidence-based psychological treatments still need improvement. In this paper we suggest that the integration of VR with another emerging technology – Artificial Intelligence (AI) – will provide clinicians with two new powerful tools for improving evidence-based psychological treatments: advanced digital therapeutics and digital biomarkers. The term “Digital Therapeutics” indicates the use of digital/online health technologies to treat a medical or psychological condition. Following this definition, any VR clinical application can be defined as a form of digital therapeutics. However, the integration between VR al AI allows a critical feature for any digital therapeutic: personalization. On one side, VR allows the collection of “Digital Biomarkers”-physiological, and behavioral data that are collected by means of digital technologies and used as an indicator of biologic processes or biological responses to therapeutic interventions – that are directly connected to the brain functioning and can be altered to correct the specific dysfunctions of the predictive coding mechanisms in the individual’s brain. On the other side AI, by applying machine learning techniques to the individual's digital biomarkers, allows the optimization the individual treatment strategy facilitating the transition to a personalized, effective and engaging medicine. © 2019, Interactive Media Institute. All rights reserved.","Behavioral health; Digital biomarkers; Digital therapeutics; Embodied medicine; Neuroscience; Virtual Reality","biological marker; analgesia; anxiety disorder; Article; artificial intelligence; body weight disorder; digital therapeutics; eating disorder; human; machine learning; mental health; neuroscience; telemedicine; virtual reality",Article,"Final","",Scopus,2-s2.0-85085609366
"Liang Z., Zhou K., Gao K.","57219563458;14326511900;57202081500;","Development of Virtual Reality Serious Game for Underground Rock-Related Hazards Safety Training",2019,"IEEE Access","7",, 8795446,"118639","118649",,5,"10.1109/ACCESS.2019.2934990","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096356867&doi=10.1109%2fACCESS.2019.2934990&partnerID=40&md5=6f76e226cf1620939d4a0a5c67da7438","School of Resources and Safety Engineering, Central South University, Changsha, China","Liang, Z., School of Resources and Safety Engineering, Central South University, Changsha, China; Zhou, K., School of Resources and Safety Engineering, Central South University, Changsha, China; Gao, K., School of Resources and Safety Engineering, Central South University, Changsha, China","Traditional safety training media to transfer safety knowledge specific to the rock-related hazards in underground mines are mainly video or manuals, which are inefficient and bring a poor training experience. In this paper, we designed and developed a serious game based on virtual reality (VR) technology in order to efficiently transfer safety knowledge and enable enhanced interactive safety training. For different training purposes and users, we designed two modes, one for professional scaling training suitable for novice scalers, the other for rock-related hazards perception training suitable for other miners. Our game is built based on game engine-Unity3D and equipped with HTC VIVE to improve immersion. The game pipeline is to have trainees basically understand safety knowledge through guided interaction and then make a self-adaptive practice to fully master it. We evaluated the effectiveness of our game, and the results of the comparative experiment show that our game is more efficient than the instructional video in both training modes. The application of our game is proven to have the potential to change the safety situation of underground mines and evaluate the level of safety awareness and risk aversion of the miners in the future. © 2013 IEEE.","rock-related hazards; Safety training; serious game; underground mining; virtual reality","E-learning; Education computing; Hazards; Miners; Virtual reality; Comparative experiments; Instructional videos; Level of safeties; Safety knowledge; Safety training; Training experiences; Training purpose; Underground mine; Serious games",Article,"Final","",Scopus,2-s2.0-85096356867
"Tayeh R., Bademosi F.M., Issa R.R.A.","57190000479;57202742349;35587852800;","Interactive Holograms for Better Construction Information Communication",2019,"Computing in Civil Engineering 2019: Visualization, Information Modeling, and Simulation - Selected Papers from the ASCE International Conference on Computing in Civil Engineering 2019",,,,"112","119",,2,"10.1061/9780784482421.015","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068736374&doi=10.1061%2f9780784482421.015&partnerID=40&md5=fe1f62c82c74ceab7f1b674f2ef38188","Rinker School of Construction Management, Univ. of Florida, Gainesville, FL  32603, United States","Tayeh, R., Rinker School of Construction Management, Univ. of Florida, Gainesville, FL  32603, United States; Bademosi, F.M., Rinker School of Construction Management, Univ. of Florida, Gainesville, FL  32603, United States; Issa, R.R.A., Rinker School of Construction Management, Univ. of Florida, Gainesville, FL  32603, United States","Over the last few decades, the investments in more complex construction projects have increased the need for better communication means. Effective means of communications should be employed on construction projects to help aggregate dispersed information between project stakeholders. Advancements in information technology have resulted in new construction visualization techniques aiming at enhancing communication between project stakeholders. Some of these technologies include virtual reality, augmented reality, and holography. The aim of this paper is to further investigate the use of holography in the architecture, engineering, construction, and operations (AECO) industry. The holographic technology used in this research was previously developed by the authors through a game engine and an add-in for Revit. The add-in allows an easy transfer of information from a building information model in Revit to be used in the game engine. In addition, the developed hologram allows the user to interact with the hologram using voice commands and/or hand gestures. Both the game and the add-in were the subject of an experimental study conducted to evaluate their ease of use and effectiveness. The results proved that the developed add-in is easier to use and more effective than traditional methods used to export building models from modeling platforms into a gaming environment. Moreover, the interactive hologram was able to enhance the human-human interaction between multiple users. Future research will focus on further developing the software and on investigating the use of the holographic experience on job sites. © 2019 American Society of Civil Engineers.",,"Augmented reality; Information theory; Lithography; Virtual reality; Visualization; Building Information Model - BIM; Complex construction project; Construction information; Construction projects; Holographic technology; Human-human interactions; Project stakeholders; Transfer of information; Holograms",Conference Paper,"Final","",Scopus,2-s2.0-85068736374
"Hsieh C.-C., Lin P.-S., Hsu W.-C., Wang J.-S., Huang Y.-C., Lim A.-Y., Hsu Y.-C.","57188729505;57188726149;7402002805;7701334279;57205147495;57195630796;57205143063;","The effectiveness of a virtual reality-based tai chi exercise on cognitive and physical function in older adults with cognitive impairment",2019,"Dementia and Geriatric Cognitive Disorders","46","5-6",,"358","370",,13,"10.1159/000494659","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058824325&doi=10.1159%2f000494659&partnerID=40&md5=4168ce7d2bd29870738e44a9c66c697c","Department of Physical Therapy, Graduate Institute of Rehabilitation Science, College of Medicine, Chang Gung University, No. 259, Wenhua 1st Rd., Kweishan District, Taoyuan City, 33302, Taiwan; Health Aging Research Center, Chang Gung University, Chang Gung Memorial Hospital, Taoyuan, Taiwan; Dementia Center, Chang Gung Memorial Hospital, Taoyuan, Taiwan; Department of Neurology, Chang Gung Memorial Hospital, Linkou, Taiwan","Hsieh, C.-C., Department of Physical Therapy, Graduate Institute of Rehabilitation Science, College of Medicine, Chang Gung University, No. 259, Wenhua 1st Rd., Kweishan District, Taoyuan City, 33302, Taiwan; Lin, P.-S., Department of Physical Therapy, Graduate Institute of Rehabilitation Science, College of Medicine, Chang Gung University, No. 259, Wenhua 1st Rd., Kweishan District, Taoyuan City, 33302, Taiwan, Health Aging Research Center, Chang Gung University, Chang Gung Memorial Hospital, Taoyuan, Taiwan; Hsu, W.-C., Dementia Center, Chang Gung Memorial Hospital, Taoyuan, Taiwan, Department of Neurology, Chang Gung Memorial Hospital, Linkou, Taiwan; Wang, J.-S., Department of Physical Therapy, Graduate Institute of Rehabilitation Science, College of Medicine, Chang Gung University, No. 259, Wenhua 1st Rd., Kweishan District, Taoyuan City, 33302, Taiwan, Health Aging Research Center, Chang Gung University, Chang Gung Memorial Hospital, Taoyuan, Taiwan; Huang, Y.-C., Department of Physical Therapy, Graduate Institute of Rehabilitation Science, College of Medicine, Chang Gung University, No. 259, Wenhua 1st Rd., Kweishan District, Taoyuan City, 33302, Taiwan; Lim, A.-Y., Department of Physical Therapy, Graduate Institute of Rehabilitation Science, College of Medicine, Chang Gung University, No. 259, Wenhua 1st Rd., Kweishan District, Taoyuan City, 33302, Taiwan; Hsu, Y.-C., Department of Physical Therapy, Graduate Institute of Rehabilitation Science, College of Medicine, Chang Gung University, No. 259, Wenhua 1st Rd., Kweishan District, Taoyuan City, 33302, Taiwan","Background: Tai Chi (TC) is a Chinese mind-body exercise with proven physical and psychological benefits. A modified TC via virtual reality (VR) may be suitable for the elderly owing to the immediate guidance and feedback regarding movement accuracy. This study explored the cognitive and physical effects of a VR-based TC (VRTC) exercise program on older adults with cognitive impairment (CI). Methods: Sixty older adults with CI were cluster-assigned to either the VRTC or the control group; the intervention was conducted twice weekly for 6 months. Outcomes included cognitive and physical functions. The movement accuracy score and attendance were recorded. Generalized estimating equation (GEE) and multiple regression analyses were performed. Results: Adjusted GEE analysis showed significant interaction effects in the 6-min walk test, 30-s sit-to-stand test, functional reach, 5-m gait speed, and abstract thinking and judgment. Overall, medium to large effect sizes (d = 0.50-0.82) were found in favor of the VRTC group. The average movement accuracy score in the first 3 months significantly predicted improvement in cognitive performance (p = 0.011). Conclusions: The VRTC exercise posed a protective effect for some cognitive and physical functions in older adults with CI. The more engaging the program, the greater the improvement in the cognitive performance. © 2018 S. Karger AG, Basel.","Cognitive function; Cognitive impairment; Dementia; Exergame; Nonpharmacological therapy; Physical function; Tai Chi; Virtual reality","adult; aged; Article; clinical effectiveness; clinical trial; cognition; cognitive defect; controlled study; decision making; effect size; exercise test; female; health program; human; major clinical study; male; movement accuracy score; multiple regression; outcome assessment; patient attendance; patient compliance; physical performance; priority journal; scoring system; sit to stand test; six minute walk test; Tai Chi; thinking; treatment duration; virtual reality; virtual reality based tai chi exercise; walking speed; cognition; cognitive defect; exercise; pathophysiology; physiology; procedures; psychology; Taiwan; treatment outcome; Aged; Cognition; Cognitive Dysfunction; Exercise; Female; Humans; Male; Physical Functional Performance; Tai Ji; Taiwan; Treatment Outcome; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85058824325
"Monaco F., Del Mastro A.","50262604500;55845537900;","Deep space learning - Disrupting tolerant networking (DTN) for interplanetary communities of practices",2019,"Proceedings of the International Astronautical Congress, IAC","2019-October",, IAC-19_D5_2_5_x52937,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079158665&partnerID=40&md5=655da7a761fe39df5f0c1fface664a66","University of Parma, Italy; Mars Planet, Italy","Monaco, F., University of Parma, Italy, Mars Planet, Italy; Del Mastro, A., Mars Planet, Italy","Distance and asynchronicity are relevant issues and reverse salients in space communication performances as much for humans as for technological systems. A beknown space program about Delay & Disruption Tolerant Networking (DTN) is under development. In considering the feasibility and design of a deep space internet for Earth, Moon, Mars and beyond, space lag may be overcome with point-to-point data transfer by a different internet protocol not based on the instantaneous connection of two points. Although, given communication interruption and data disruption, such different protocol will guarantee data packet delivery only every time the next communication path will open. Given the need for a scientific approach to learning, possibly researched by quantitative and qualitative methods, Deep Space Learning (DSP) might be taken into consideration as a field of research on simulation in designing and delivering teaching, learning and collaboration for space and off-world exploration. An Italian association for the exploration of Mars -Marsplanet- has been active in research in the field of communities in extreme environments and virtual reality. The next step is a learning program to increase fidelity in simulation and analog missions, where knowledge management and information sharing can make the difference for the success of the missions and survival of astronauts. The goal is a program of virtual and asynchronous learning for remote communities based on simulating long-distance communication and Disruption Tolerant Networking. It involves experts and volunteers at many levels: vision, design, test and the benchmarking of the current earthlings virtual learning systems and networking solutions. The program includes the development of VR treadmills which are designed to offer new technological opportunities to investigate the human exploration of space. Space studies about the reaction time to new pieces of information and scaffolding knowledge should be given proper attention in designing successful strategies for the innovation of learning in future missions. Copyright © 2019 by the International Astronautical Federation (IAF). All rights reserved.","Distance Learning; DTN; Multiuser platform; Space Mission Simulation; Virtual Reality","Data transfer; Deep learning; Distance education; E-learning; Earth (planet); Interplanetary flight; Knowledge management; Learning systems; Manned space flight; Moon; Scaffolds; Virtual reality; Asynchronous learning; Communities of Practice; Disruption tolerant networking; Long distance communication; Multi-user; Quantitative and qualitative methods; Space missions; Technological opportunity; Delay tolerant networks",Conference Paper,"Final","",Scopus,2-s2.0-85079158665
"Lu C.Y., Kao C., Kang S.C., Lai J.S., Lee T.H.","57210197618;57201400350;23090862400;57210195557;7501439901;","A generalized procedure to develop a virtual environment for the conducting of hydraulics laboratory experiments",2019,"EG-ICE 2010 - 17th International Workshop on Intelligent Computing in Engineering",,,,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083946596&partnerID=40&md5=222e4af45d29d05541703d58db385d57","National Taiwan University, Taiwan","Lu, C.Y., National Taiwan University, Taiwan; Kao, C., National Taiwan University, Taiwan; Kang, S.C., National Taiwan University, Taiwan; Lai, J.S., National Taiwan University, Taiwan; Lee, T.H., National Taiwan University, Taiwan","In many engineering fields, laboratory experiment courses are a core aspect of engineering classes. Students can learn basic theories through manipulating the equipment and observing the phenomena in the experiments, cultivating an engineer's keen sense of observation. However, due to high costs and limited numbers of experimental equipment, students must be divided into groups having to take turns to do the experiment, causing a lot of difficulty and inconvenience in conducting this kind of laboratory course. Maneuverable virtual equipment is an ideal approach for providing a feasible alternative to using physical laboratory equipment in courses. Yet such an alternative is not without its challenges. Developing virtual equipment requires mapping experimental procedures from the physical world onto virtual environments. The system developers need to deal with constraints unique to virtual environments, such as limitations in user interfaces and computer calculation speed. It requires effective integration of the expertise between experienced teachers and the 3D system programmers. To achieve this purpose, our research has proposed a generalized procedure for developing virtual equipment and instruments for procedure-based experiments. The procedure has four main phases: (1) observation, (2) storyboard, (3) implementation, and (4) user test; or OSIT in short. To validate the OSIT, it was used to develop and implement virtual equipment for a standard hydraulic experiment, called the Force Vortex Experiment, at National Taiwan University. We found that using OSIT significantly reduced the total elapsed time of communication between instructors and 3D programmers. OSIT also delivered software that better matched users' needs. © Nottingham University Press","Engineering education; Hydraulic experiment; User centered design; Virtual equipment","Computation theory; Curricula; Engineering education; Intelligent computing; Laboratories; Software design; User centered design; User interfaces; Virtual reality; Computer calculation; Experimental equipments; Experimental procedure; Feasible alternatives; Laboratory experiments; National Taiwan University; Physical laboratory; Virtual equipments; Hydraulic machinery",Conference Paper,"Final","",Scopus,2-s2.0-85083946596
"Zhu D., Zhou Q., Han T., Chen Y.","57213510302;35096857600;57195952219;57221457399;","360 Degree Panorama Synthesis from Sequential Views Based on Improved FC-Densenets",2019,"IEEE Access","7",, 8926406,"180503","180511",,1,"10.1109/ACCESS.2019.2958111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077180697&doi=10.1109%2fACCESS.2019.2958111&partnerID=40&md5=fbd2a5bd98ad8ca7fcca16c8373f3968","Artificial Intelligence Institute, Shanghai Jiao Tong University, Shanghai, 200240, China; School of Information and Computer, Shanghai Business School, Shanghai, 201400, China; Department of Computer Science, Stevens Institute of Technology, Hoboken, NJ  07030, United States; Hainan Air Traffic Management Sub-Bureau, Haikou, 570000, China","Zhu, D., Artificial Intelligence Institute, Shanghai Jiao Tong University, Shanghai, 200240, China; Zhou, Q., School of Information and Computer, Shanghai Business School, Shanghai, 201400, China; Han, T., Department of Computer Science, Stevens Institute of Technology, Hoboken, NJ  07030, United States; Chen, Y., Hainan Air Traffic Management Sub-Bureau, Haikou, 570000, China","Inspired by the effectiveness of deep learning model, many panorama saliency prediction models based on deep learning began to emerge and achieved significant performance improvement. However, this kind of model requires a large number of labeled ground-truth data, and the existing panorama datasets are small-scale and difficult to train the deep learning models. To address this problem, we propose a novel panorama generative model for synthesizing realistic and sharp-looking panorama. In particular, our proposed panorama generative model consists of two sub-networks of generator and discriminator. At first, in order to make the synthesized panorama more realistic, we employ the improved Fully-Convolutional Densely Connected Convolutional Networks (FC-DenseNets) as the generator network. Secondly, we design a new correlation layer in the discriminator network, which can calculate the similarity between the generated image and the ground-truth image, and achieve the pixel level accuracy. The experimental results show that our proposed method outperforms other baseline work and has superior generalization ability to synthesize real-world data. © 2013 IEEE.","correlation layer; generative model; panorama; saliency prediction; Virtual reality","Convolution; Discriminators; Large dataset; Virtual reality; Convolutional networks; Generalization ability; Generative model; Ground truth data; Learning models; New correlations; panorama; Prediction model; Deep learning",Article,"Final","",Scopus,2-s2.0-85077180697
"Jaruszewska K., Baranski F., Piotrowska M., Melon M., Dazel O., Vorländer M., Aspöck L., Horvat M., Jambrošic K., Rychtáriková M., Kritly L., Herweg A.","55353653500;52863220200;57221514377;6602498019;16425154800;6602187261;56196314900;26660715200;26662090200;25822861400;57200092210;56337132300;","ACOUCOU platform to acquire professional skills and knowledge in the field of acoustics",2019,"Proceedings of the International Congress on Acoustics","2019-September",,,"4348","4355",,,"10.18154/RWTH-CONV-239454","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099331649&doi=10.18154%2fRWTH-CONV-239454&partnerID=40&md5=2276f4fbda17e121807e49ebb76fc396","KFB Acoustics, Poland; EdTech and SCIENCE, Poland; LAUM, UMR, CNRS 6613, Le Mans Université, France; Institute of Technical Acoustics, RWTH Aachen University, Germany; University Zagreb, Faculty of Electrical Engineering and Computing, Zagreb, Croatia; KU Leuven, Belgium; Head Acoustics, Germany","Jaruszewska, K., KFB Acoustics, Poland; Baranski, F., KFB Acoustics, Poland; Piotrowska, M., EdTech and SCIENCE, Poland; Melon, M., LAUM, UMR, CNRS 6613, Le Mans Université, France; Dazel, O., LAUM, UMR, CNRS 6613, Le Mans Université, France; Vorländer, M., Institute of Technical Acoustics, RWTH Aachen University, Germany; Aspöck, L., Institute of Technical Acoustics, RWTH Aachen University, Germany; Horvat, M., University Zagreb, Faculty of Electrical Engineering and Computing, Zagreb, Croatia; Jambrošic, K., University Zagreb, Faculty of Electrical Engineering and Computing, Zagreb, Croatia; Rychtáriková, M., KU Leuven, Belgium; Kritly, L., KU Leuven, Belgium; Herweg, A., Head Acoustics, Germany","Today, in the digital era, education must meet the needs and adapt to modern forms of knowledge transfer. While this is often implemented in higher education programs (distance learning, OpenCourseWare platforms), vocational education and training seems to be the most traditional branch of education, especially in the field of specialized courses for engineers. Our goal is to create space for new, innovative and multidisciplinary approaches for teaching and e-learning acoustics (e.g., based on gamification, VR, or web simulators). The ACOUCOU Platform (http://acoucou.org/) _is a part of a strategy aimed at expanding and strengthening acoustic knowledge, supporting the development of innovative teaching methods based on attractive and effective delivery of content, services, teaching methodologies and practices at national and international levels. The form of materials and courses published on the Acoustic Courseware Platform are suitable to be used for self-learning as well as in blended learning, where an educator uses materials from platform to carry out training among employees/students. Technical, professional knowledge is usually presented as text including equations and technical drawings. Presenting it in a visually attractive form is more appealing and increases the motivation of the users. The visualization of phenomena simplifies the understanding of problems and makes it easy to acquire knowledge in similar, practical situations of an engineer's work. © 2019 Proceedings of the International Congress on Acoustics. All rights reserved.","Acoustical Engineering; Education; Industrial Acoustics; Noise Awareness; Room Acoustics",,Conference Paper,"Final","",Scopus,2-s2.0-85099331649
"Alfred M.C., Neyens D.M., Gramopadhye A.K.","56901101700;15045355400;7005569103;","Learning in simulated environments: An assessment of 4-week retention outcomes",2019,"Applied Ergonomics","74",,,"107","117",,,"10.1016/j.apergo.2018.08.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051812375&doi=10.1016%2fj.apergo.2018.08.002&partnerID=40&md5=b4e609452a72f07a4e7535936423420b","Department of Industrial Engineering, Clemson University, Clemson, SC  29634, United States","Alfred, M.C., Department of Industrial Engineering, Clemson University, Clemson, SC  29634, United States; Neyens, D.M., Department of Industrial Engineering, Clemson University, Clemson, SC  29634, United States; Gramopadhye, A.K., Department of Industrial Engineering, Clemson University, Clemson, SC  29634, United States","Simulations offer the benefits of a safer and more accessible learning environment, where learners can practice until the point of proficiency. While research into the effectiveness of simulations as learning tools has found tangible benefits, fewer studies have examined retention and differences between high and low fidelity simulations. This research sought to supplement the literature in this domain by investigating whether participants who learned to construct an electrical circuit using a 2D or 3D breadboard simulation could achieve comparable learning, transfer, and retention outcomes to those who learned using a physical breadboard. The influence of learner characteristics - cognitive ability and goal orientation - were also evaluated. This study had two parts: a cross-sectional portion that examined learning and transfer outcomes and a longitudinal portion that examined retention outcomes after a 2 and 4-week period. The cross-sectional analysis included 70 participants and the longitudinal analysis included 40 participants. The results found that the physical fidelity of the learning environment significantly impacted several transfer outcomes (construction and construction time) but not retention outcomes. Cognitive ability was a significant predictor of learning (gain score, circuit design score) and retention (posttest scores, construction time) outcomes. Learning goal orientation significantly predicted circuit construction over time and measurement occasion significantly predicted posttest scores and interacted with fidelity to predict circuit design score. The study demonstrated that simulated environments can lead to comparable, or better, proficiency than physical environments. These findings have implications for the design and implementation of simulated environments, specifically for courses delivered in an online setting. © 2018 Elsevier Ltd","Fidelity; Learning; Simulation","Curricula; Integrated circuit manufacture; Cross sectional analysis; Design and implementations; Fidelity; Learning; Longitudinal analysis; Physical environments; Simulated environment; Simulation; Computer aided instruction; adult; article; cross-sectional study; female; human; human experiment; learning environment; major clinical study; male; outcome assessment; simulation; transfer of learning; cognition; learning; long term memory; longitudinal study; procedures; simulation training; time factor; young adult; Cognition; Cross-Sectional Studies; Female; Humans; Learning; Longitudinal Studies; Male; Retention (Psychology); Simulation Training; Time Factors; Transfer (Psychology); Young Adult",Article,"Final","",Scopus,2-s2.0-85051812375
"Barumerli R., Geronazzo M., Avanzini F.","57205380408;36720522500;7005300654;","Round robin comparison of inter-laboratory HRTF Measurements - Assessment with an auditory model for elevation",2018,"2018 IEEE 4th VR Workshop on Sonic Interactions for Virtual Environments, SIVE 2018",,, 8577091,"","",,5,"10.1109/SIVE.2018.8577091","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046153385&doi=10.1109%2fSIVE.2018.8577091&partnerID=40&md5=616a6454e992dad30718c275e6d71646","Department of Information Engineering, University of Padova, Italy; Dept. of Architecture, Design and Media Technology, Aalborg University, Denmark; Dept. of Computer Science, Univeristy of Milano, Italy","Barumerli, R., Department of Information Engineering, University of Padova, Italy; Geronazzo, M., Dept. of Architecture, Design and Media Technology, Aalborg University, Denmark; Avanzini, F., Dept. of Computer Science, Univeristy of Milano, Italy","Repeatability of head-related transfer function (HRTF) measurements is a critical issue in intra- and inter- laboratory setups. In this paper, simulated perceptual variabilities of HRTFs are computed as an attempt to understand if different acquisition methods achieve similar results in terms of psychoacoustic features. We consider 12 HRTF independent measurement sets of a Neumann KU-100 dummy head from the international round-robin study Club Fritz. Our analysis of HRTF variabilities focuses on localization performance in elevation within the mid-sagittal plane. A round robin evaluation is performed by means of an auditory model which is able to predict elevation errors and front-back confusion for a given pair of target and template HRTF sets. Results report comparable localization performances between four HRTF databases, suggesting that these acquisition methods led to similar performances in providing elevation cues. Such findings further emphasize the intrinsic complexity and the sensitivity of the HRTF measurement process. The final aim of this study is to certify the quality and repeatability of a measurement process at perceptual level; this findings could be extended to the acquisition of human head acoustics. © 2018 IEEE.","Human-centered computing; Treemaps; Visualization; Visualization design and evaluation methods; Visualization techniques","Acoustics; Flow visualization; Mergers and acquisitions; Virtual reality; Visualization; Front-back confusion; Head related transfer function; Human-centered computing; Independent measurement; Localization performance; Tree-maps; Visualization designs; Visualization technique; Transfer functions",Conference Paper,"Final","",Scopus,2-s2.0-85046153385
"Boton C.","37017251600;","Supporting constructability analysis meetings with Immersive Virtual Reality-based collaborative BIM 4D simulation",2018,"Automation in Construction","96",,,"1","15",,30,"10.1016/j.autcon.2018.08.020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052856267&doi=10.1016%2fj.autcon.2018.08.020&partnerID=40&md5=3d990781587b82ec708ca7ac60851335","Department of Construction Engineering, Ecole de Technologie Supérieure, 1100, rue Notre-Dame Ouest, Montréal, Québec  H3C 1K3, Canada","Boton, C., Department of Construction Engineering, Ecole de Technologie Supérieure, 1100, rue Notre-Dame Ouest, Montréal, Québec  H3C 1K3, Canada","Immersive Virtual Reality-based collaborative BIM 4D simulation can offer a unique, supportive environment for conducting constructability analysis meetings in the construction industry. While many research works have addressed various aspects of VR-based 4D simulation, there is still no comprehensive and neutral framework to help both practitioners and experts to identify the main challenges to address. This paper proposes four main complementary steps with which to define the VR environment, to develop the 4D model, to prepare and transfer the model in the VR system and to conduct constructability analysis meeting. In the current state of the framework, the 4D-based constructability analysis is more about the collaborative use of 4D rather than the collaborative generation and interaction with the 4D model. Each step of the framework is supported by appropriate methods and tools. A collaborative personas-based case study helps to evaluate the framework and to show how it can be used. Compared to recent related works, the proposed framework is more structured and comprehensive, providing a structured approach using concepts from multiple scientific areas. © 2018 Elsevier B.V.",,"Architectural design; Construction industry; 4d simulations; Constructability analysis; Immersive virtual reality; Neutral framework; Related works; Structured approach; VR systems; Virtual reality",Article,"Final","",Scopus,2-s2.0-85052856267
"Misak J.","57203751752;","A (Virtual) Bridge Not Too Far: Teaching Narrative Sense of Place with Virtual Reality",2018,"Computers and Composition","50",,,"39","52",,,"10.1016/j.compcom.2018.07.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052820547&doi=10.1016%2fj.compcom.2018.07.007&partnerID=40&md5=c9dca853d7762f7c4db6d9944099fc06","New York Institute of Technology, Northern Boulevard, Balding House Room 103, Old Westbury, New York, 11568, United States","Misak, J., New York Institute of Technology, Northern Boulevard, Balding House Room 103, Old Westbury, New York, 11568, United States","Teaching narrative sense of place to student writers can be difficult with traditional texts. Virtual reality (VR) games can help students realize the importance of this by illustrating it. This article outlines a VR exercise for students to experience immersion as a parallel to how written works transport readers to their environments. The exercise offers a visual example of narrative sense of place and serves as a guide for the students’ writing. As personal narratives often suffer from a lack of sensory details, a visual reminder can help these writers reflect on how to immerse their readers. For students to fully grasp the purpose of the exercise, metacognitive practices are used to prepare them. Meta-strategic knowledge (MSK) makes students aware of what to look for in the VR game before they play it. I present an argument for the transfer of the skill of identifying the importance of sense of place to student writing through the familiar practice of playing games and the use of MSK. Wearable technologies serve as new frontiers for learning, and I believe exercises like this one using VR can reach more students, specifically visual learners and video game players. © 2018 Elsevier Inc.","Composition; Metacognition; Narrative; Presence; Telepresence; Virtual reality; Writing",,Article,"Final","",Scopus,2-s2.0-85052820547
"Lee H.T., Kim Y.S.","55346611300;55602218400;","The effect of sports VR training for improving human body composition",2018,"Eurasip Journal on Image and Video Processing","2018","1", 148,"","",,1,"10.1186/s13640-018-0387-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058840704&doi=10.1186%2fs13640-018-0387-2&partnerID=40&md5=243b0f1a30859f14137c423a4b46dac9","BioComputing Lab, Institute for Bio-engineering Application Technology, Departent of Computer Science and Engineering, KOREATECH, Cheonan, South Korea","Lee, H.T., BioComputing Lab, Institute for Bio-engineering Application Technology, Departent of Computer Science and Engineering, KOREATECH, Cheonan, South Korea; Kim, Y.S., BioComputing Lab, Institute for Bio-engineering Application Technology, Departent of Computer Science and Engineering, KOREATECH, Cheonan, South Korea","The purpose of this study is to find out the effect of sports virtual training with applied sports science and information and communication technology (ICT) for adults. We have developed a 4-week workout program that focuses on improving basic endurance, strength, and function. The experiment is to derive the kinematic data for ergonomic evaluation of indoor sports device combined with a virtual image and to compare and evaluate the pre- and post-body composition. Twenty-one participants were selected, and each training program was conducted considering individual differences and levels. Results showed that 4-week sports virtual reality (VR) training program developed in this study turned out to be appropriate as a sport VR training one to improve body composition and health. Although it is difficult to generalize the effect to all human, it is meaningful to study some ways of reducing the heterogeneity and improving the training efficiency in the situation where the sports VR system is gradually being applied to the exercise. © 2018, The Author(s).","Body composition; Sports biomechanics; Sports VR training","Biochemistry; Curricula; Sports medicine; Virtual reality; Body composition; Ergonomic evaluation; Individual Differences; Information and Communication Technologies; Kinematic data; Training efficiency; Training program; Virtual training; Sports",Article,"Final","",Scopus,2-s2.0-85058840704
"Tarr B., Slater M., Cohen E.","56364689400;7202932472;23968508000;","Synchrony and social connection in immersive Virtual Reality",2018,"Scientific Reports","8","1", 3693,"","",,20,"10.1038/s41598-018-21765-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042744157&doi=10.1038%2fs41598-018-21765-4&partnerID=40&md5=253be66f64014d213e892baff3bf0d41","Institute of Cognitive and Evolutionary Anthropology, University of Oxford, 64 Banbury Rd, Oxford, OX2 6PN, United Kingdom; Department of Experimental Psychology, University of Oxford, South Parks Rd, Oxford, OX 1 3UD, United Kingdom; Institució Catalana de Recerca i Estudis Avançats (ICREA), 23 Passeig de Lluís Companys, Barcelona, 08010, Spain; Faculty of Psychology, University of Barcelona, 171 Passeig de la Vall d'Hebron, Barcelona, 08035, Spain; Department of Computer Science, University College London, Gower Street, London, WC1E 6BT, United Kingdom; Wadham College, Parks Rd, Oxford, OX1 3PN, United Kingdom","Tarr, B., Institute of Cognitive and Evolutionary Anthropology, University of Oxford, 64 Banbury Rd, Oxford, OX2 6PN, United Kingdom, Department of Experimental Psychology, University of Oxford, South Parks Rd, Oxford, OX 1 3UD, United Kingdom; Slater, M., Institució Catalana de Recerca i Estudis Avançats (ICREA), 23 Passeig de Lluís Companys, Barcelona, 08010, Spain, Faculty of Psychology, University of Barcelona, 171 Passeig de la Vall d'Hebron, Barcelona, 08035, Spain, Department of Computer Science, University College London, Gower Street, London, WC1E 6BT, United Kingdom; Cohen, E., Institute of Cognitive and Evolutionary Anthropology, University of Oxford, 64 Banbury Rd, Oxford, OX2 6PN, United Kingdom, Wadham College, Parks Rd, Oxford, OX1 3PN, United Kingdom","Synchronising movements in time with others can have significant positive effects on affiliative attitudes and behaviors. To explore the generalizability of synchrony effects, and to eliminate confounds of suggestion, competence and shared intention typical of standard laboratory and field experiments, we used an Immersive Virtual Reality (VR) environment. Participants, represented as virtual humans, took part in a joint movement activity with two other programmed virtual humans. The timings of the co-participant characters' movements were covertly manipulated to achieve synchrony or non-synchrony with the focal participant. Participants in the synchrony condition reported significantly greater social closeness to their virtual co-participants than those in the non-synchrony condition. Results indicate that synchrony in joint action causes positive social effects and that these effects are robust in a VR setting. The research can potentially inform the development of VR interventions for social and psychological wellbeing. © The Author(s)2018.",,"adult; article; field experiment; human; intimacy; joint function; psychological well-being; virtual reality; adolescent; female; male; questionnaire; social behavior; young adult; Adolescent; Adult; Female; Humans; Male; Social Behavior; Surveys and Questionnaires; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85042744157
"Babaians E., Tamiz M., Sarti Y., Mogoei A., Mehrabi E.","57188707391;55746759800;57211075801;57211074600;55569573500;","ROS2Unity3D; High-performance plugin to interface ROS with unity3d engine",2018,"2018 9th Conference on Artificial Intelligence and Robotics and 2nd Asia-Pacific International Symposium, AIAR 2018",,, 8769798,"59","64",,3,"10.1109/AIAR.2018.8769798","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072559001&doi=10.1109%2fAIAR.2018.8769798&partnerID=40&md5=f2cda416efc765297cb2be81c4c277ae","Tehran Polytechnic, Arsamrobotics Co. LTD., Amirkabir University of Technology, No.424, Hafez AVE, Tehran, Iran","Babaians, E., Tehran Polytechnic, Arsamrobotics Co. LTD., Amirkabir University of Technology, No.424, Hafez AVE, Tehran, Iran; Tamiz, M., Tehran Polytechnic, Arsamrobotics Co. LTD., Amirkabir University of Technology, No.424, Hafez AVE, Tehran, Iran; Sarti, Y., Tehran Polytechnic, Arsamrobotics Co. LTD., Amirkabir University of Technology, No.424, Hafez AVE, Tehran, Iran; Mogoei, A., Tehran Polytechnic, Arsamrobotics Co. LTD., Amirkabir University of Technology, No.424, Hafez AVE, Tehran, Iran; Mehrabi, E., Tehran Polytechnic, Arsamrobotics Co. LTD., Amirkabir University of Technology, No.424, Hafez AVE, Tehran, Iran","In this paper, we propose a novel highperformance method to interface ROS (Robot Operating System) from the Unity3d engine. In this regard, we introduce a message passing middleware to perform decentralized and efficient data transfer. We utilize the ZeroMQ; Google Protobuf and GStreamer libraries to achieve these aims. For evaluation, we compare our approach with state of the art Siemens ROS# U nity3D plugin. On the other hand, we simulate various essential robotic sensors such as LIDAR, RGBD, and Monocular cameras in Unity3D to experiment our solution in complex enough robotic scenarios. As Unity3D support a variety of devices and VR (Virtual Reality) capabilities, this solution may help researchers to perform better human-computer interaction using ROS and Unity3d engine. Besides, for developers who are not familiar with URDF and programming side of ROS Gazebo Sim, this will be a more natural way to exporting their 3D meshes to the Unity3D engine and simulate robotic experiments with ROS. © 2018 IEEE.","Google Protobuf; GStreamer; Robotic Simulation; ROS; Unity3d; ZeroMQ","Data transfer; Engines; Human computer interaction; Message passing; Middleware; Robotics; Virtual reality; Google Protobuf; Gstreamer; Robotic simulation; Unity3d; ZeroMQ; Robot programming",Conference Paper,"Final","",Scopus,2-s2.0-85072559001
"Bourgeois A., Badier E., Baron N., Carruzzo F., Vuilleumier P.","54942986700;57204930250;56258963900;57204933522;57200075380;","Influence of reward learning on visual attention and eye movements in a naturalistic environment: A virtual reality study",2018,"PLoS ONE","13","12", e0207990,"","",,2,"10.1371/journal.pone.0207990","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058002614&doi=10.1371%2fjournal.pone.0207990&partnerID=40&md5=a09fc135a143b758a457603057d5533b","Neuroscience Department, Laboratory for Behavioral Neurology and Imaging of Cognition, University of Geneva, Geneva, Switzerland; Swiss Center for Affective Sciences, University of Geneva-CISA, Geneva, Switzerland","Bourgeois, A., Neuroscience Department, Laboratory for Behavioral Neurology and Imaging of Cognition, University of Geneva, Geneva, Switzerland; Badier, E., Swiss Center for Affective Sciences, University of Geneva-CISA, Geneva, Switzerland; Baron, N., Swiss Center for Affective Sciences, University of Geneva-CISA, Geneva, Switzerland; Carruzzo, F., Neuroscience Department, Laboratory for Behavioral Neurology and Imaging of Cognition, University of Geneva, Geneva, Switzerland; Vuilleumier, P., Neuroscience Department, Laboratory for Behavioral Neurology and Imaging of Cognition, University of Geneva, Geneva, Switzerland","Rewards constitute crucial signals that motivate approach behavior and facilitate the perceptual processing of objects associated with favorable outcomes in past encounters. Reward-related influences on perception and attention have been reliably observed in studies where a reward is paired with a unidimensional low-level visual feature, such as the color or orientation of a line in visual search tasks. However, our environment is drastically different and composed of multidimensional and changing visual features, encountered in complex and dynamic scenes. Here, we designed an immersive virtual reality (VR) experiment using a 4-frame CAVE system to investigate the impact of rewards on attentional orienting and gaze patterns in a naturalistic and ecological environment. Forty-one healthy participants explored a virtual forest and responded to targets appearing on either the left or right side of their path. To test for reward-induced biases in spatial orienting, targets on one side were associated with high reward, whereas those on the opposite side were paired with a low reward. Eye-movements recording showed that left-side high rewards led to subsequent increase of eye gaze fixations towards this side of the path, but no such asymmetry was found after exposure to right-sided high rewards. A milder spatial bias was also observed after left-side high rewards during subsequent exploration of a virtual castle yard, but not during route turn choices along the forest path. Our results indicate that reward-related influences on attention and behavior may be better learned in left than right space, in line with a right hemisphere dominance, and could generalize to another environment to some extent, but not to spatial choices in another decision task, suggesting some domain- or context-specificity. This proof-of-concept study also outlines the advantages and the possible drawbacks of the use of the 3D CAVE immersive platform for VR in neuroscience. © 2018 Bourgeois et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"adult; article; clinical article; controlled study; eye movement; female; forest; gaze; hemispheric dominance; human; human experiment; learning; male; neuroscience; proof of concept; reward; right hemisphere; virtual reality; visual attention; adolescent; anatomy and histology; attention; depth perception; eye fixation; learning; physiology; spatial orientation; Adolescent; Adult; Attention; Cerebrum; Female; Fixation, Ocular; Functional Laterality; Humans; Learning; Male; Orientation, Spatial; Reward; Space Perception; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85058002614
"Deherkar K., Martin G., George N., Maurya V.","55575267000;57206929971;57205293919;57205293847;","Gesture Controlled Virtual Reality Based Conferencing",2018,"2018 International Conference on Smart City and Emerging Technology, ICSCET 2018",,, 8537334,"","",,,"10.1109/ICSCET.2018.8537334","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059411790&doi=10.1109%2fICSCET.2018.8537334&partnerID=40&md5=6aa4b5f07daebc5b4567fca9b157c741","Computer Engineering Department, Don Bosco Institute of Technology, Mumbai, India","Deherkar, K., Computer Engineering Department, Don Bosco Institute of Technology, Mumbai, India; Martin, G., Computer Engineering Department, Don Bosco Institute of Technology, Mumbai, India; George, N., Computer Engineering Department, Don Bosco Institute of Technology, Mumbai, India; Maurya, V., Computer Engineering Department, Don Bosco Institute of Technology, Mumbai, India","The technology available today for interacting with a virtual environment involves wired or wireless hand controls with limited buttons or a large setup involving a camera and/or a sensor to capture movements. The cost of such a setup is such that it makes it inaccessible to most. The project aims at providing a cost effective VR solution which can produce the same effect with precision and flexibility, which is accessible to all. The proposed idea is to provide a hardware device that provides the user with an immersive VR experience and uses hand gestures captured via a camera placed on the device to control and interact with the VR environment. As an application of the project, an interactive workspace environment would be simulated, using a single hardware component that provides the user the viewing interface as well as can be controlled by simple hand gestures eliminating the need for additional hand-held devices controls. The project will also delve into the field of supervised learning to make possible the implementation of gesture recognition. © 2018 IEEE.","File transfer; Gesture Recognition; Hand Gesture Controls; Sensor; Supervised learning; Virtual Reality; VOIP; VR","Cameras; Cost effectiveness; Hardware; Sensors; Smart city; Supervised learning; Virtual reality; Cost effective; File transfers; Hand gesture control; Hand held device; Hardware components; Hardware devices; Interactive workspace; VOIP; Gesture recognition",Conference Paper,"Final","",Scopus,2-s2.0-85059411790
"Van Leeuwen J.P., Hermans K., Jylhä A., Quanjer A.J., Nijman H.","7101943103;57205245949;34881770200;57207729757;57205248742;","Effectiveness of virtual reality in participatory urban planning",2018,"ACM International Conference Proceeding Series",,,,"128","136",,2,"10.1145/3284389.3284491","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062789034&doi=10.1145%2f3284389.3284491&partnerID=40&md5=66845dda78c73dc95036872de2752b7b","Hague University of Applied Sciences, The Hague, Netherlands; Municipality of The Hague, Netherlands; Twynstra and Gudde, Utrecht, Netherlands","Van Leeuwen, J.P., Hague University of Applied Sciences, The Hague, Netherlands; Hermans, K., Municipality of The Hague, Netherlands; Jylhä, A., Hague University of Applied Sciences, The Hague, Netherlands; Quanjer, A.J., Hague University of Applied Sciences, The Hague, Netherlands; Nijman, H., Twynstra and Gudde, Utrecht, Netherlands","In urban planning, 3D modeling and virtual reality (VR) provide new means for involving citizens in the planning process. For municipal government, it is essential to know how effective these means are, to justify investments. In this study, we present a case of using VR in a municipal process of civic participation concerning the redesign of a public park. The process included co-design activities and involved citizens in decision-making through a ballot, using 3D-rendered versions of competing designs. In co-design, 3D-modeling tools were instrumental in empowering citizens to negotiate design decisions, to discuss the quality of designs with experts, and to collectively take decisions. This paper demonstrates that, in a ballot on competing designs with 1302 citizens, VR headsets proved to be equally effective compared to other display technologies in informing citizens during decision making. The results of an additional, controlled experiment indicate that VR headsets provide higher engagement and more vivid memories than viewing the designs on non-immersive displays. By integrating research into a municipal process, we contribute evidence of cognitive and engagement effects of using 3D modeling and immersive VR technologies to empower citizens in participatory urban planning. The case described in the paper concerns a public park; a similar approach could be applied to the design of public installations including media architecture. © 2018 Association for Computing Machinery.","Civic engagement; Participatory design; Urban planning; Virtual reality","Architecture; Decision making; Technology transfer; Urban planning; Virtual reality; 3D modeling tools; Civic engagement; Competing designs; Controlled experiment; Display technologies; Integrating research; Municipal government; Participatory design; 3D modeling",Conference Paper,"Final","",Scopus,2-s2.0-85062789034
"Visoottiviseth V., Phungphat A., Puttawong N., Chantaraumporn P., Haga J.","8549374100;57204967354;57202817892;57204965579;7003936129;","Lord of secure: The virtual reality game for Educating Network security",2018,"Proceeding of 2018 7th ICT International Student Project Conference, ICT-ISPC 2018",,, 8523947,"","",,5,"10.1109/ICT-ISPC.2018.8523947","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058172937&doi=10.1109%2fICT-ISPC.2018.8523947&partnerID=40&md5=c1d7f6be5cecab63a5412ff60eaf0f5a","Faculty of Information and Communication Technology, Mahidol University, Nakhon Pathom, Thailand; Information Technology Research Institute, National Institute of Advanced Industrial Science and Technology, Tsukuba, Japan","Visoottiviseth, V., Faculty of Information and Communication Technology, Mahidol University, Nakhon Pathom, Thailand; Phungphat, A., Faculty of Information and Communication Technology, Mahidol University, Nakhon Pathom, Thailand; Puttawong, N., Faculty of Information and Communication Technology, Mahidol University, Nakhon Pathom, Thailand; Chantaraumporn, P., Faculty of Information and Communication Technology, Mahidol University, Nakhon Pathom, Thailand; Haga, J., Information Technology Research Institute, National Institute of Advanced Industrial Science and Technology, Tsukuba, Japan","At the present, the security on the Internet is very sensitive and important. Most of the computer science curricula in universities and institutes of higher education provides this knowledge in term of computer and network security. Therefore, students studying in the information technology area need to have some basic knowledge about the security in order to prevent the potential attacks and protect themselves from hackers or intruders. Unfortunately, the network security concept is moderately abstract when students learn in the traditional lecture-based class. In this paper, to motivate and help students to perceive better than in the traditional classroom, we propose a security game called 'Lord of Secure', which is a virtual reality (VR) game on Android for education. It is an alternative learning materials for learners to gain the knowledge about the network security effectively. The game composes of main topics of the network security such as Firewall, IDS, IPS, and Honey pot. Moreover, the game will give the players knowledge about network security through the virtual world. The game also contains several quizzes including pretest and posttest, so players will know how much they gain more knowledge about network security by comparing scores before and after playing the game. © 2018 IEEE.","education game; edutainment; network security; virtual reality","Computer system firewalls; Education computing; Personal computing; Students; Technology transfer; Virtual reality; Computer and network security; Computer science curricula; Education game; Edutainment; Higher education; Learning materials; Potential attack; Security on the internets; Network security",Conference Paper,"Final","",Scopus,2-s2.0-85058172937
"Ginsburg E.S., Jellerette-Nolan T., Daftary G., Du Y., Silverberg K.M.","7006749458;56183619000;6701382947;57204511514;6603787477;","Patient experience in a randomized trial of a weekly progesterone vaginal ring versus a daily progesterone gel for luteal support after in vitro fertilization",2018,"Fertility and Sterility","110","6",,"1101","1108.e3",,2,"10.1016/j.fertnstert.2018.07.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055873634&doi=10.1016%2fj.fertnstert.2018.07.014&partnerID=40&md5=fb1828eb4951a951ce1704d82d9bc9a3","Department of Obstetrics, Gynecology and Reproductive Biology, Harvard Medical School, Boston, MA, United States; Ferring Pharmaceuticals, Inc., Parsippany, NJ, United States; Ferring International Pharmascience Center US, Parsippany, NJ, United States; Texas Fertility Center, Austin, TX, United States","Ginsburg, E.S., Department of Obstetrics, Gynecology and Reproductive Biology, Harvard Medical School, Boston, MA, United States; Jellerette-Nolan, T., Ferring Pharmaceuticals, Inc., Parsippany, NJ, United States; Daftary, G., Ferring Pharmaceuticals, Inc., Parsippany, NJ, United States; Du, Y., Ferring International Pharmascience Center US, Parsippany, NJ, United States; Silverberg, K.M., Texas Fertility Center, Austin, TX, United States","Objective: To assess patient experience and convenience of using progesterone vaginal ring (VR) versus vaginal gel for women requiring luteal phase support during in vitro fertilization (IVF). Design: Post hoc analysis of a prospective, randomized, single-blind, multicenter, phase 3 clinical trial. Setting: Twenty-two U.S. IVF centers. Patient(s): Women undergoing IVF (N = 1,297). Intervention(s): Randomization to weekly VR or daily gel the day after egg retrieval for up to 10 weeks, with fresh embryo transfer IVF per site-specific procedures. Main Outcome Measure(s): Patient satisfaction questionnaire completed at final study visit. Result(s): In the women who were taking ≥1 dose of either VR (n = 647) or gel (n = 650), >97% reported that learning to use the formulation, remembering to take it at the correct time, and using it as prescribed was “easy” or “somewhat easy.” More VR than gel users reported noninterference with daily activity (93.3% vs. 74.7%, P<.001), sexual comfort (80.3% vs. 67.8%, P<.001), and sexual desire (73.8% vs. 61.8%, P<.001), as well as not being bothered during sexual intercourse (66.9% vs. 39.2%, P<.001). More gel than VR users reported no difficulty with application (97.4% vs. 80.9%, P<.001). Among women who had previously used progesterone during IVF, more VR users than gel users preferred their currently assigned treatment to their previous treatment (91.4% vs. 83.0%, P=.03). Conclusion(s): Weekly progesterone VR and daily progesterone gel were easy to use, with limited impact on quality of life. Overall, the VR appeared to interfere less with daily life, social activities, and sexual activity although the gel was less difficult or stressful to apply. Clinical Trial Registration Number: NCT00615251. © 2018 The Authors","In vitro fertilization; luteal phase support; progesterone; vaginal gel; vaginal ring","progesterone; agents used intravaginally; gestagen; progesterone; adult; Article; comparative study; controlled study; dosage schedule comparison; embryo transfer; female; gel; human; in vitro fertilization; luteal phase; major clinical study; multicenter study; oocyte retrieval; patient satisfaction; phase 3 clinical trial; priority journal; prospective study; quality of life; questionnaire; randomized controlled trial; sexual behavior; sexual intercourse; single blind procedure; supplementation; adolescent; clinical trial; drug administration; drug effect; female contraceptive device; female infertility; in vitro fertilization; intravaginal drug administration; luteal phase; metabolism; pregnancy; trends; young adult; Administration, Intravaginal; Adolescent; Adult; Contraceptive Devices, Female; Drug Administration Schedule; Female; Fertilization in Vitro; Humans; Infertility, Female; Luteal Phase; Pregnancy; Progesterone; Progestins; Prospective Studies; Single-Blind Method; Surveys and Questionnaires; Vaginal Creams, Foams, and Jellies; Young Adult",Article,"Final","",Scopus,2-s2.0-85055873634
"Szczurowski K., Smith M.","57202899868;57196078717;","'Woodlands'-A Virtual Reality Serious Game Supporting Learning of Practical Road Safety Skills",2018,"2018 IEEE Games, Entertainment, Media Conference, GEM 2018",,, 8516493,"427","435",,6,"10.1109/GEM.2018.8516493","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057030782&doi=10.1109%2fGEM.2018.8516493&partnerID=40&md5=ad57ac1f8e24833e90e1f57db49254f1","Department of Informatics, Institute of Technology Blanchardstown, Dublin, Ireland","Szczurowski, K., Department of Informatics, Institute of Technology Blanchardstown, Dublin, Ireland; Smith, M., Department of Informatics, Institute of Technology Blanchardstown, Dublin, Ireland","In developed societies road safety skills are taught early and often practiced under the supervision of a parent, providing children with a combination of theoretical and practical knowledge. At some point children will attempt to cross a road unsupervised, at that point in time their safety depends on the effectiveness of their road safety education. To date, various attempts to supplement road safety education with technology were made. Most common approach focus on addressing declarative knowledge, by delivering road safety theory in an engaging fashion. Apart from expanding on text based resources to include instructional videos and animations, some stakeholders (e.g.: Irish Road Safety Authority) attempt to take advantage of game-based learning [1]. However, despite the high capacity for interaction being common in Virtual Environments, available game-based solutions to road safety education are currently limited to delivering and assessing declarative knowledge. With recent advancements in the field of Virtual Reality (VR) Head Mounted Displays, procedural knowledge might also be addressed in Virtual Environments. This paper describes the design and development process of a computer-supported learning system that attempts to address psycho-motor skills involved in crossing a road safely, changing learners' attitude towards road safety best practices, and enabling independent practice of transferable skills. By implementing game-based learning principles and following best practice for serious game design (such as making educational components essential to successful game-play, or instructional scaffolding) we hope to make it not only more effective, but also engaging, allowing us to rely on learners' intrinsic motivation [2], to increase their independent practice time and provide them with feedback that will help to condition safe behaviour and increase retention. Presence in Virtual Reality might evoke responses to Virtual Environment as if it was real (RAIR) [3] and enable learners to truly experience learning scenarios. In consequence leading to formation of autobiographical memories constructed from multisensory input, which should result in an increased knowledge retention and transfer [4]. © 2018 IEEE.","Experiential Learning; Game-Based Learning; Road Safety; Serious Game; Virtual Environment; Virtual Reality; VR","Accident prevention; Animation; E-learning; Education computing; Helmet mounted displays; Learning systems; Motor transportation; Roads and streets; Scaffolds; Virtual reality; Autobiographical memory; Computer supported learning systems; Declarative knowledge; Design and development process; Experiential learning; Game-based Learning; Head mounted displays; Road safety; Serious games",Conference Paper,"Final","",Scopus,2-s2.0-85057030782
"Hashimura S., Shimakawa H., Kajiwara Y.","57204808489;8529351700;54681995100;","Automatic assessment of student understanding level using virtual reality",2018,"Proceedings of the 2018 Federated Conference on Computer Science and Information Systems, FedCSIS 2018",,, 8511187,"39","45",,3,"10.15439/2018F268","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057246476&doi=10.15439%2f2018F268&partnerID=40&md5=a59e0c25c33e6d1afd52c0b77ddee4d7","Ritsumeikan University, Graduate School of Information Science and Engineering, Shiga, Japan; College of Information Science and Engineering, Ritsumeikan University, Shiga, Japan","Hashimura, S., Ritsumeikan University, Graduate School of Information Science and Engineering, Shiga, Japan; Shimakawa, H., College of Information Science and Engineering, Ritsumeikan University, Shiga, Japan; Kajiwara, Y., College of Information Science and Engineering, Ritsumeikan University, Shiga, Japan","The improvement of the efficiency in teaching requires knowing the understanding level of each student. However, it is difficult due to limited time in a class. We propose a Virtual Reality (VR) space imposing assignments on students, to know their understanding level from their behavior which comes from cognitive loads during their answering. The VR space presents a student an assignment and a working space to answer it. In general, students solve assignments, using elements on their short term memory. When students solve same kind of assignments many times, they build generalized solution methods in their long term memory. When they engage in such assignments, their cognitive load is low enough to make them watch only the working spaces, keeping their hands working. On the other hand, when students have no solution pattern, their short term memory works hard. Their high cognitive load often stop their hands, because of confusion. They also look assignments and the working space many times, to reconsider solutions. Since answering behavior of students exposes their cognitive load, a VR space is ideal to estimate cognitive load. We conducted an experiment to evaluate the ability of the method to estimate the cognitive load. We examined the movement of the hand and the edit distance of student's answer from the correct sentence during their answering. We confirmed a fair correlation of the hands' stagnation with the confidence in students of good scores. We also found a relationship of eye movement with the change of the edit distance. The experiment result implies the possibility to estimate the cognitive load. The estimation would enable teachers to know students' understanding faults, which leads to education according to the understanding level. © 2018 Polish Information Processing Society.",,"Brain; Eye movements; Information systems; Information use; Virtual reality; Automatic assessment; Cognitive loads; Edit distance; Generalized solution; Long term memory; Short term memory; Solution patterns; Understanding level; Students",Conference Paper,"Final","",Scopus,2-s2.0-85057246476
"Krekhov A., Krüger J., Cmentowski S.","41761856000;42761557200;57197770288;","VR animals: Surreal body ownership in virtual reality games",2018,"CHI PLAY 2018 - Proceedings of the 2018 Annual Symposium on Computer-Human Interaction in Play Companion Extended Abstracts",,,,"503","511",,7,"10.1145/3270316.3271531","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058482003&doi=10.1145%2f3270316.3271531&partnerID=40&md5=ad8f33934d960d9672b9af89e5fd61db","University of Duisburg-Essen, Duisburg, 47057, Germany","Krekhov, A., University of Duisburg-Essen, Duisburg, 47057, Germany; Krüger, J., University of Duisburg-Essen, Duisburg, 47057, Germany; Cmentowski, S., University of Duisburg-Essen, Duisburg, 47057, Germany","The illusion of being someone else and to perceive a virtual body as our own is one of the strengths of virtual reality setups. Past research explored that phenomenon regarding human-like virtual representations. In contrast, our ongoing work focuses on playing VR games in the role of an animal. We present five ways to control three different animals in a VR environment. The controls range from third person companion mode to first person full-body tracking. Our exploratory study indicates that virtual body ownership is also applicable to animals, which paves the way to a number of novel, animal-centered game mechanics. Based on interview outcomes, we also discuss possible directions for further research regarding non-humanoid VR experiences in digital games. © 2018 Copyright is held by the owner/author(s).","Animal avatar control; Animal embodiment; Body transfer illusion; Virtual body ownership; Virtual reality games","Animals; Human computer interaction; Interactive computer graphics; Interactive computer systems; Body transfer illusion; Digital games; Exploratory studies; First person; Full-body tracking; Human like; Virtual bodies; Virtual representations; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85058482003
"Brouwer A.-M., van der Waa J., Stokking H.","7102575587;57193858656;25032071700;","BCI to potentially enhance streaming images to a VR headset by predicting head rotation",2018,"Frontiers in Human Neuroscience","12",, 420,"","",,1,"10.3389/fnhum.2018.00420","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056811876&doi=10.3389%2ffnhum.2018.00420&partnerID=40&md5=51b5275784df9bd4315f22469dfaa8f4","Department of Perceptual and Cognitive Systems, Netherlands Organization for Applied Scientific Research (TNO), Soesterberg, Netherlands; Department of Media Networking, Netherlands Organization for Applied Scientific Research (TNO), Den Haag, Netherlands","Brouwer, A.-M., Department of Perceptual and Cognitive Systems, Netherlands Organization for Applied Scientific Research (TNO), Soesterberg, Netherlands; van der Waa, J., Department of Perceptual and Cognitive Systems, Netherlands Organization for Applied Scientific Research (TNO), Soesterberg, Netherlands; Stokking, H., Department of Media Networking, Netherlands Organization for Applied Scientific Research (TNO), Den Haag, Netherlands","While numerous studies show that brain signals contain information about an individual’s current state that are potentially valuable for smoothing man–machine interfaces, this has not yet lead to the use of brain computer interfaces (BCI) in daily life. One of the main challenges is the common requirement of personal data that is correctly labeled concerning the state of interest in order to train a model, where this trained model is not guaranteed to generalize across time and context. Another challenge is the requirement to wear electrodes on the head. We here propose a BCI that can tackle these issues and may be a promising case for BCI research and application in everyday life. The BCI uses EEG signals to predict head rotation in order to improve images presented in a virtual reality (VR) headset. When presenting a 360° video to a headset, field-of-view approaches only stream the content that is in the current field of view and leave out the rest. When the user rotates the head, other content parts need to be made available soon enough to go unnoticed by the user, which is problematic given the available bandwidth. By predicting head rotation, the content parts adjacent to the currently viewed part could be retrieved in time for display when the rotation actually takes place. We here studied whether head rotations can be predicted on the basis of EEG sensor data and if so, whether application of such predictions could be applied to improve display of streaming images. Eleven participants generated left- and rightward head rotations while head movements were recorded using the headsets motion sensing system and EEG. We trained neural network models to distinguish EEG epochs preceding rightward, leftward, and no rotation. Applying these models to streaming EEG data that was withheld from the training showed that 400 ms before rotation onset, the probability “no rotation” started to decrease and the probabilities of an upcoming right- or leftward rotation started to diverge in the correct direction. In the proposed BCI scenario, users already wear a device on their head allowing for integrated EEG sensors. Moreover, it is possible to acquire accurately labeled training data on the fly, and continuously monitor and improve the model’s performance. The BCI can be harnessed if it will improve imagery and therewith enhance immersive experience. © 2018 Brouwer, van der Waa and Stokking.","Applied neuroscience; Brain computer interface; EEG; Head mounted display; Head rotation; Movement prediction; Neuroadaptive technology; Virtual reality","adult; Article; artificial neural network; brain computer interface; electroencephalography; head movement; human; human experiment; image display; image processing; imagery; normal human; prediction; probability; signal transduction; videorecording; virtual reality",Article,"Final","",Scopus,2-s2.0-85056811876
"Oberdorfer S., Latoschik M.E.","57192160404;6602976914;","Effectivity of affine transformation knowledge training using game mechanics",2018,"2018 10th International Conference on Virtual Worlds and Games for Serious Applications, VS-Games 2018 - Proceedings",,, 8493418,"","",,3,"10.1109/VS-Games.2018.8493418","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057303697&doi=10.1109%2fVS-Games.2018.8493418&partnerID=40&md5=e0057463f0e6fa4359dd06754d24d153","Human-Computer Interaction, University of Wurzburg, Wurzburg, Germany","Oberdorfer, S., Human-Computer Interaction, University of Wurzburg, Wurzburg, Germany; Latoschik, M.E., Human-Computer Interaction, University of Wurzburg, Wurzburg, Germany","The Gamified Training Environment for Affine Transformation (GEtiT) was developed as a demonstrator for the Gamified Knowledge Encoding model (GKE). The GKE is a novel framework that defines knowledge training using game mechanics (GMs). It describes the process of directly encoding learning contents in GMs to allow for an engaging and effective transfer-oriented knowledge training. Overall, GEtiT is developed to facilitate the training process of the complex and abstract Affine Transformation (AT) knowledge. The complexity of the AT makes it hard to demonstrate this learning content thus learners frequently experience issues when trying to develop an understanding for its application. During the gameplay, the application of the AT's mathematical grounded aspects is required and information about the underlying principles are provided. In this article, a short overview over GEtiT's structure and the knowledge encoding process is given. Also, this article presents the results of a study measuring the training effectivity and motivational aspects of GEtiT. The results indicate a training outcome similar to a traditional paper-based training method but a higher motivation of the GEtiT players. Hence, GEtiT yields a higher learning quality. © 2018 IEEE.",,"Encoding (symbols); Interactive computer graphics; Signal encoding; Virtual reality; Affine transformations; Encoding process; ITS applications; Knowledge training; Learning contents; Training methods; Training process; Underlying principles; Abstracting",Conference Paper,"Final","",Scopus,2-s2.0-85057303697
"Škola F., Liarokapis F.","57189368470;7801416785;","Embodied VR environment facilitates motor imagery brain–computer interface training",2018,"Computers and Graphics (Pergamon)","75",,,"59","71",,12,"10.1016/j.cag.2018.05.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049323107&doi=10.1016%2fj.cag.2018.05.024&partnerID=40&md5=561e34077968d8ba1953764e02e33b25","Faculty of Informatics, Masaryk University, Botanická 68a, Brno, Czech Republic","Škola, F., Faculty of Informatics, Masaryk University, Botanická 68a, Brno, Czech Republic; Liarokapis, F., Faculty of Informatics, Masaryk University, Botanická 68a, Brno, Czech Republic","Motor imagery (MI) is the predominant control paradigm for brain–computer interfaces (BCIs). After sufficient effort is invested to the training, the accuracy of commands mediated by mental imagery of bodily movements grows to a satisfactory level. However, many issues with the MI-BCIs persist; e.g., low bit transfer rate, BCI illiteracy, sub-optimal training procedure. Especially the training process for the MI-BCIs requires improvements. Currently, the training has an inappropriate form, resulting in a high mental and temporal demand on the users (weeks of training are required for the control). This study aims at addressing the issues with the MI-BCI training. To support the learning process, an embodied training environment was created. Participants were placed into a virtual reality environment observed from a first-person view of a human-like avatar, and their rehearsal of MI actions was reflected by the corresponding movements performed by the avatar. Leveraging extension of the sense of ownership, agency, and self-location towards a non-body object (principles known from the rubber hand illusion and the body transfer illusions) has already been proven to help in producing stronger EEG correlates of MI. These principles were used to facilitate the MI-BCI training process for the first time. Performance of 30 healthy participants after two sessions of training was measured using an on-line BCI scenario. The group trained using our embodied VR environment gained significantly higher average accuracy for BCI actions (58.3%) than the control group, trained with a standard MI-BCI training protocol (52.9%). © 2018 Elsevier Ltd","Body transfer illusion; Brain–Computer interfaces; Embodiment; Motor imagery; Rubber hand illusion; Virtual reality","Interfaces (computer); Rubber; Virtual reality; Bit transfer rates; Body transfer illusion; Embodiment; Learning process; Motor imagery; Optimal training; Predominant control; Virtual-reality environment; Brain computer interface",Article,"Final","",Scopus,2-s2.0-85049323107
"Keith K., Hansen D.M., Johannessen M.A.","57203975337;57203988133;26648593600;","Perceived value of a skills laboratory with virtual reality simulator training in arthroscopy: A survey of orthopedic surgery residents",2018,"Journal of the American Osteopathic Association","118","10",,"667","672",,2,"10.7556/jaoa.2018.146","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053913559&doi=10.7556%2fjaoa.2018.146&partnerID=40&md5=9bab93536f4b3f4d19b062350f4086da","Lake Erie College of Osteopathic Medicine, Erie, PA, United States","Keith, K., Lake Erie College of Osteopathic Medicine, Erie, PA, United States; Hansen, D.M., Lake Erie College of Osteopathic Medicine, Erie, PA, United States; Johannessen, M.A., Lake Erie College of Osteopathic Medicine, Erie, PA, United States","Background: Arthroscopy is one of the most common procedures performed by orthopedic surgeons. Virtual reality (VR) simulation in general surgery residency training has been increasing over the past decade, but it has seen little use in the field of orthopedic surgery. Objective: To determine osteopathic orthopedic surgery residents’ perceived value of having access to a VR simulator before performing an arthroscopic procedure on a live patient. Methods: A survey was developed and sent to all US osteopathic orthopedic surgery residency programs to be disseminated to all of their current residents. The survey consisted of 12 questions, which included Likert-type scale responses and yes or no responses. Results: Fifty-eight residents out of approximately 507 responded. Forty-one of 57 respondents (72%) were in year 1 of residency when they performed their first arthroscopy, and 53 of 57 (93%) were not very comfortable when they performed their first arthroscopy. With respect to VR simulator exposure, approximately 31of 51 (61%) reported no exposure to a VR simulator, and 40 of 50 (80%) reported that their program did not provide a skills laboratory where they could practice arthroscopy. Of 50 respondents, 37 (74%) believed that a skills laboratory was important, 28 (56%) believed that a resident should perform 1 to 10 arthroscopies in a skills laboratory before performing one in the operating room, 34 (60%) believed that skills acquired in a skills laboratory would transfer to the operating room, and 33 (66%) agreed that every residency program should provide a skills laboratory. However, 29 (58%) believed that a skills laboratory would not improve patient safety. Conclusion: Osteopathic orthopedic surgery residents indicated that they would benefit from the addition of an arthroscopic skills laboratory with a VR simulator. Furthermore, they believed that the skills learned in the skills laboratory would transfer to the operating room and would increase their comfort level with the procedure. © 2018 American Osteopathic Association.","Arthroscopic surgery; Competency-based education; Virtual reality","arthroscopy; clinical competence; education; health personnel attitude; human; medical education; orthopedics; questionnaire; simulation training; virtual reality; Arthroscopy; Attitude of Health Personnel; Clinical Competence; Humans; Internship and Residency; Orthopedics; Simulation Training; Surveys and Questionnaires; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85053913559
"Panerai S., Catania V., Rundo F., Ferri R.","6506285735;57159156400;9633894700;8759218700;","Remote home-based virtual training of functional living skills for adolescents and young adults with intellectual disability: Feasibility and preliminary results",2018,"Frontiers in Psychology","9","SEP", 1730,"","",,3,"10.3389/fpsyg.2018.01730","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053467322&doi=10.3389%2ffpsyg.2018.01730&partnerID=40&md5=62167ff72b289c53805c7d984d6a547e","Unit of Psychology, Oasi Research Institute - IRCCS, Troina, Italy; Unit of Neurology, Oasi Research Institute - IRCCS, Troina, Italy","Panerai, S., Unit of Psychology, Oasi Research Institute - IRCCS, Troina, Italy; Catania, V., Unit of Psychology, Oasi Research Institute - IRCCS, Troina, Italy; Rundo, F., Unit of Neurology, Oasi Research Institute - IRCCS, Troina, Italy; Ferri, R., Unit of Neurology, Oasi Research Institute - IRCCS, Troina, Italy","Background: Virtual Reality (VR) is acquiring increasing credibility as a tool for teaching independent living skills to people with Intellectual Disability (ID). Generalization of skills acquired during VR training into real environment seems to be feasible. Objective: To assess feasibility and verify effectiveness of a remote home-based rehabilitation, focused on functional living skills, for adolescents and young adults with ID, by using virtual apps installed on tablets. In particular, to assess if this tool can be managed independently, if it is enjoyable and simple to be used, and if the acquired skills can be generalized to the real environment of everyday life. Subjects and method: A single group, pre- and post-test research design was used. Sixteen participants with ID were included. A digital system was arranged, with a server managing communication between the database and the apps installed on tablets. In vivo tests were performed before and after the eleven sessions of VR training. Satisfaction questionnaires were also administered. Results: Statistically significant improvements were found between the pre- and post-in vivo tests, as well as between the VR training sessions, in almost all the parameters taken into account, for each app. Final questionnaires showed a good satisfaction level for both the participants and their families. Conclusion: The highly technological system was managed independently by participants with ID, who found it simple to be used, useful and even fun; generalization across settings was obtained. Results obtained require to be confirmed by future controlled studies, with larger samples. © 2018 Panerai, Catania, Rundo and Ferri.","Functional living skills; Home-based rehabilitation; Intellectual disability; Remote rehabilitation; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85053467322
"Narbutt M., Allen A., Skoglund J., Chinen M., Hines A.","14830442200;57195237656;7004049754;56556720800;35179621200;","AMBIQUAL-A full reference objective quality metric for ambisonic spatial audio",2018,"2018 10th International Conference on Quality of Multimedia Experience, QoMEX 2018",,, 8463408,"","",,12,"10.1109/QoMEX.2018.8463408","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054367108&doi=10.1109%2fQoMEX.2018.8463408&partnerID=40&md5=3b3e686e001f1dd456d15a0af3758001","School of Computing, Dublin Institute of Technology, Dublin, Ireland; Google Inc., San Francisco, CA, United States; School of Computer Science, University College Dublin, Dublin, Ireland","Narbutt, M., School of Computing, Dublin Institute of Technology, Dublin, Ireland; Allen, A., Google Inc., San Francisco, CA, United States; Skoglund, J., Google Inc., San Francisco, CA, United States; Chinen, M., Google Inc., San Francisco, CA, United States; Hines, A., School of Computer Science, University College Dublin, Dublin, Ireland","Streaming spatial audio over networks requires efficient encoding techniques that compress the raw audio content without compromising quality of experience. Streaming service providers such as YouTube need a perceptually relevant objective audio quality metric to monitor users' perceived quality and spatial localization accuracy. In this paper we introduce a full reference objective spatial audio quality metric, AMBIQUAL, which assesses both Listening Quality and Localization Accuracy. In our solution both metrics are derived directly from the B-format Ambisonic audio. The metric extends and adapts the algorithm used in ViSQOLAudio, a full reference objective metric designed for assessing speech and audio quality. In particular, Listening Quality is derived from the omnidirectional channel and Localization Accuracy is derived from a weighted sum of similarity from B-format directional channels. This paper evaluates whether the proposed AMBIQUAL objective spatial audio quality metric can predict two factors: Listening Quality and Localization Accuracy by comparing its predictions with results from MUSHRA subjective listening tests. In particular, we evaluated the Listening Quality and Localization Accuracy of First and Third-Order Ambisonic audio compressed with the OPUS 1.2 codec at various bitrates (i.e. 32, 128 and 256, 512kbps respectively). The sample set for the tests comprised both recorded and synthetic audio clips with a wide range of time-frequency characteristics. To evaluate Localization Accuracy of compressed audio a number of fixed and dynamic (moving vertically and horizontally) source positions were selected for the test samples. Results showed a strong correlation (PCC=0.919; Spearman=0.882 regarding Listening Quality and PCC=0.854; Spearman=0.842 regarding Localization Accuracy) between objective quality scores derived from the B-format Ambisonic audio using AMBIQUAL and subjective scores obtained during listening MUSHRA tests. AMBIQUAL displays very promising quality assessment predictions for spatial audio. Future work will optimise the algorithm to generalise and validate it for any Higher Order Ambisonic formats. © 2018 IEEE.","ambisonics; audio coding; audio compression; MUSHRA; opus codec; spatial audio; virtual reality",,Conference Paper,"Final","",Scopus,2-s2.0-85054367108
"Lin J.-H.T., Wu D.-Y., Tao C.-C.","54781539900;57201859887;17436193200;","So scary, yet so fun: The role of self-efficacy in enjoyment of a virtual reality horror game",2018,"New Media and Society","20","9",,"3223","3242",,8,"10.1177/1461444817744850","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041421935&doi=10.1177%2f1461444817744850&partnerID=40&md5=dc0e6f8a7b9637dec5bac7ba92ff514f","National Chengchi University, Taiwan; National Chiao Tung University, Taiwan","Lin, J.-H.T., National Chengchi University, Taiwan; Wu, D.-Y., National Chengchi University, Taiwan; Tao, C.-C., National Chiao Tung University, Taiwan","Enjoyment of frightening content is a paradoxical issue in communication research. Revising Zillmann’s model of suspense, we propose a three-factor model examining the audience appeal of horror content in a virtual reality (VR) survival horror game. In a laboratory study, participants played a VR horror game. The results show significant effects of the three-way interaction among horror self-efficacy, physiological arousal, and fear on enjoyment and future intentions to play similar games. Horror self-efficacy interacts with fear to affect enjoyment only among high-arousal participants. Among high-fear participants, higher horror self-efficacy leads to significantly greater enjoyment than lower horror self-efficacy. We measured enjoyment through self-reported ratings, future intentions to play similar games, and the behavioral choice of subsequent games to demonstrate the appeal of horror content. Horror self-efficacy in coping with mediated fright is the key to explaining the conditional positive association of fear and enjoyment in the gaming context. © The Author(s) 2017.","Arousal; enjoyment; excitation transfer; fear; horror game; self-efficacy; virtual reality",,Article,"Final","",Scopus,2-s2.0-85041421935
"Grubert J., Witzani L., Ofek E., Pahud M., Kranz M., Kristensson P.O.","35114754100;56024891600;10139546600;6602493330;12239425600;6507412583;","Text Entry in Immersive Head-Mounted Display-Based Virtual Reality Using Standard Keyboards",2018,"25th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2018 - Proceedings",,, 8446059,"159","166",,41,"10.1109/VR.2018.8446059","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053830754&doi=10.1109%2fVR.2018.8446059&partnerID=40&md5=751e12a3f39023107cd2837e1c6effd0","Coburg University of Applied Sciences and Arts, Germany; University of Passau, Germany; Microsoft Research, Germany; University of Cambridge, United Kingdom","Grubert, J., Coburg University of Applied Sciences and Arts, Germany; Witzani, L., University of Passau, Germany; Ofek, E., Microsoft Research, Germany; Pahud, M., Coburg University of Applied Sciences and Arts, Germany; Kranz, M., Coburg University of Applied Sciences and Arts, Germany; Kristensson, P.O., University of Cambridge, United Kingdom","We study the performance and user experience of two popular mainstream text entry devices, desktop keyboards and touchscreen keyboards, for use in Virtual Reality (VR) applications. We discuss the limitations arising from limited visual feedback, and examine the efficiency of different strategies of use. We analyze a total of 24 hours of typing data in VR from 24 participants and find that novice users are able to retain about 60% of their typing speed on a desktop keyboard and about 40-45% of their typing speed on a touchscreen keyboard. We also find no significant learning effects, indicating that users can transfer their typing skills fast into VR. Besides investigating baseline performances, we study the position in which keyboards and hands are rendered in space. We find that this does not adversely affect performance for desktop keyboard typing and results in a performance trade-off for touchscreen keyboard typing. © 2018 IEEE.","H.5.2: [User Interfaces-Input devices and strategies.]","Economic and social effects; Helmet mounted displays; Typewriter keyboards; Virtual reality; Visual communication; Base-line performance; Head mounted displays; Input devices and strategies; Learning effects; Performance trade-off; Touch-screen keyboards; User experience; Visual feedback; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-85053830754
"Caluya N.R., Plopski A., Ty J.F., Sandor C., Taketomi T., Kato H.","57190392364;56023098100;56534116200;15061666200;25422748800;7406497359;","Transferability of Spatial Maps: Augmented Versus Virtual Reality Training",2018,"25th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2018 - Proceedings",,, 8447561,"387","393",,2,"10.1109/VR.2018.8447561","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053846424&doi=10.1109%2fVR.2018.8447561&partnerID=40&md5=0c9b1b8fb3541286613ed87d95c21344","Nara Institute of Science and Technology, Interactive Media Design Laboratory, Japan","Caluya, N.R., Nara Institute of Science and Technology, Interactive Media Design Laboratory, Japan; Plopski, A., Nara Institute of Science and Technology, Interactive Media Design Laboratory, Japan; Ty, J.F., Nara Institute of Science and Technology, Interactive Media Design Laboratory, Japan; Sandor, C., Nara Institute of Science and Technology, Interactive Media Design Laboratory, Japan; Taketomi, T., Nara Institute of Science and Technology, Interactive Media Design Laboratory, Japan; Kato, H., Nara Institute of Science and Technology, Interactive Media Design Laboratory, Japan","Work space simulations help trainees acquire skills necessary to perform their tasks efficiently without disrupting the workflow, forgetting important steps during a procedure, or the location of important information. This training can be conducted in Augmented and Virtual Reality (AR, VR) to enhance its effectiveness and speed. When the skills are transferred to the actual application, it is referred to as positive training transfer. However, thus far, it is unclear which training, AR or VR, achieves better results in terms of positive training transfer. We compare the effectiveness of AR and VR for spatial memory training in a control-room scenario, where users have to memorize the location of buttons and information displays in their surroundings. We conducted a within-subject study with 16 participants and evaluated the impact the training had on short-Term and long-Term memory. Results of our study show that VR outperformed AR when tested in the same medium after the training. In a memory transfer test conducted two days later AR outperformed VR. Our findings have implications on the design of future training scenarios and applications. © 2018 IEEE.","and virtual realities; augmented; Evaluation/methodology; H.5.1-Information Interfaces and Presentation: Multimedia Information Systems-Artificial; H.5.2-Information Interfaces and Presentation: Multimedia Information Systems-Ergonomics; Theory and methods","E-learning; Ergonomics; Information systems; Information use; Virtual reality; augmented; Evaluation/methodology; MultiMedia Information Systems; Multimedia information systems-artificial; Theory and methods; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-85053846424
"Krum D.M., Kang S.-H., Phan T.","6701630874;22835064900;55869140500;","Influences on the Elicitation of Interpersonal Space with Virtual Humans",2018,"25th IEEE Conference on Virtual Reality and 3D User Interfaces, VR 2018 - Proceedings",,, 8446235,"223","229",,1,"10.1109/VR.2018.8446235","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053822218&doi=10.1109%2fVR.2018.8446235&partnerID=40&md5=efee792ec391075882d1fad42a20ac03","University of Southern California, Institute for Creative Technologies, United States","Krum, D.M., University of Southern California, Institute for Creative Technologies, United States; Kang, S.-H., University of Southern California, Institute for Creative Technologies, United States; Phan, T., University of Southern California, Institute for Creative Technologies, United States","The emergence of low cost virtual and augmented reality systems has encouraged the development of immersive training applications for medical, military, and many other fields. Many of the training scenarios for these various fields may require the presentation of realistic interactions with virtual humans. It is thus vital to determine the critical factors of fidelity required in those interactions to elicit naturalistic behavior on the part of trainees. Negative training may occur if trainees are inadvertently influenced to react in ways that are unexpected and unnatural, hindering proper learning and transfer of skills and knowledge back into real world contexts. In this research, we examined whether haptic priming (presenting an illusion of virtual human touch at the beginning of the virtual experience) and different locomotion techniques (either joystick or physical walking) might affect proxemic behavior in human users. The results of our study suggest that locomotion techniques can alter proxemic behavior in significant ways. Haptic priming did not appear to impact proxemic behavior, but did increase rapport and other subjective social measures. The results suggest that designers and developers of immersive training systems should carefully consider the impact of even simple design and fidelity choices on trainee reactions in social interactions. © 2018 IEEE.","fidelity; haptic priming; immersive training; locomotion techniques; proxemics; Virtual humans; virtual reality","Augmented reality; Behavioral research; Biocommunications; Human computer interaction; Military applications; User interfaces; fidelity; haptic priming; Immersive; Locomotion technique; proxemics; Virtual humans; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85053822218
"Bothén S., Font J., Nilsson P.","57204435557;56344008800;57204432176;","An analysis and comparative user study on interactions in mobile virtual reality games",2018,"ACM International Conference Proceeding Series",,, 4,"","",,2,"10.1145/3235765.3235772","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055561057&doi=10.1145%2f3235765.3235772&partnerID=40&md5=bceeeb8cb311e53abe43c92aa24f856e","Malmö University, Malmö, Sweden","Bothén, S., Malmö University, Malmö, Sweden; Font, J., Malmö University, Malmö, Sweden; Nilsson, P., Malmö University, Malmö, Sweden","Mobile Virtual Reality (MVR) makes Virtual Reality games more accessible to a broader audience. Interaction design guidelines and best practices for MVR experiences are available for developers. In this paper, we specifically explore interactions in MVR games, a particular subset of MVR experiences that is becoming popular. A set of MVR games is analyzed with a special focus on head gaze, categorizing and isolating their mechanics implemented with this common MVR technique. This analysis is the basis of a test application in the MVR interactions are implemented and later compared to a traditional game pad controller in three different challenges. A comparative user study has been carried out from the perspective of both gamers and non-gamers facing these challenges. Results show the preferences and performances of the players using all the interactions, highlighting an interesting generalized preference for MVR interactions over the traditional controller in some of the analyzed cases. © 2018 ACM.","Head gaze; Mobile virtual reality; Video games","Computer games; Interactive computer graphics; Virtual reality; Best practices; Head gaze; Interaction design; Test applications; User study; Video game; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-85055561057
"Ahn S., Gorlatova M., Naghizadeh P., Chiang M., Mittal P.","57203146162;24775927000;56176019100;7102873398;24825217800;","Adaptive fog-based output security for augmented reality",2018,"VR/AR Network 2018 - Proceedings of the 2018 Morning Workshop on Virtual Reality and Augmented Reality Network, Part of SIGCOMM 2018",,,,"1","6",,13,"10.1145/3229625.3229626","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056428916&doi=10.1145%2f3229625.3229626&partnerID=40&md5=74ed627af7deca908b65e7738a0b4b72","Department of Electrical Engineering, Princeton University, Princeton, NJ, United States; Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, United States","Ahn, S., Department of Electrical Engineering, Princeton University, Princeton, NJ, United States; Gorlatova, M., Department of Electrical Engineering, Princeton University, Princeton, NJ, United States; Naghizadeh, P., Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, United States; Chiang, M., Department of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, United States; Mittal, P., Department of Electrical Engineering, Princeton University, Princeton, NJ, United States","Augmented reality (AR) technologies are rapidly being adopted across multiple sectors, but little work has been done to ensure the security of such systems against potentially harmful or distracting visual output produced by malicious or bug-ridden applications. Past research has proposed to incorporate manually specified policies into AR devices to constrain their visual output. However, these policies can be cumbersome to specify and implement, and may not generalize well to complex and unpredictable environmental conditions. We propose a method for generating adaptive policies to secure visual output in AR systems using deep reinforcement learning. This approach utilizes a local fog computing node, which runs training simulations to automatically learn an appropriate policy for filtering potentially malicious or distracting content produced by an application. Through empirical evaluations, we show that these policies are able to intelligently displace AR content to reduce obstruction of real-world objects, while maintaining a favorable user experience. © 2018 Copyright held by the owner/author(s).","Augmented reality; Edge computing; Fog computing; Policy optimization; Reinforcement learning; Visual output security","Augmented reality; Deep learning; Edge computing; Fog; Reinforcement learning; Virtual reality; Adaptive policy; Empirical evaluations; Environmental conditions; Policy optimization; Real-world objects; Training simulation; User experience; Visual outputs; Fog computing",Conference Paper,"Final","",Scopus,2-s2.0-85056428916
"Abernethy M., Sinnen O., Adams J., De Ruvo G., Giacaman N.","57201299216;57203063083;7404782866;56948173700;24528603500;","ParallelAR: An augmented reality app and instructional approach for learning parallel programming scheduling concepts",2018,"Proceedings - 2018 IEEE 32nd International Parallel and Distributed Processing Symposium Workshops, IPDPSW 2018",,, 8425430,"324","331",,2,"10.1109/IPDPSW.2018.00063","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052244534&doi=10.1109%2fIPDPSW.2018.00063&partnerID=40&md5=a616f759cdca09547c42dd74e95fb3a2","Parallel and Reconfigurable Computing Lab, Department of Electrical and Computer Engineering, Auckland, New Zealand; Department of Computer Science, Calvin College, Grand Rapids, United States","Abernethy, M., Parallel and Reconfigurable Computing Lab, Department of Electrical and Computer Engineering, Auckland, New Zealand; Sinnen, O., Parallel and Reconfigurable Computing Lab, Department of Electrical and Computer Engineering, Auckland, New Zealand; Adams, J., Department of Computer Science, Calvin College, Grand Rapids, United States; De Ruvo, G., Parallel and Reconfigurable Computing Lab, Department of Electrical and Computer Engineering, Auckland, New Zealand; Giacaman, N., Parallel and Reconfigurable Computing Lab, Department of Electrical and Computer Engineering, Auckland, New Zealand","Parallel programming has rapidly moved from a special-purpose technique to standard practice. This newfound ubiquity needs to be matched by improved parallel programming education. As parallel programming involves higher level concepts, students tend to struggle with turning the abstract information into concrete mental models. Analogies are known to aid in this knowledge transfer, by providing an existing schema as the basis for the formation of a new schema. Additionally, technology has been proven to increase motivation and engagement in students, which ultimately improves learning. Combining these ideas, this paper presents several contributions that enhance aspects of parallel programming education. These contributions include a set of collaborative learning activities to target fundamental scheduling concepts, a detailed analogy to assist in the understanding of the scheduling concepts, and an augmented reality application to facilitate the collaborative learning activity by bringing the analogy to life. © 2018 IEEE.","Analogies; Augmented reality; Collaborative learning; Scheduling policies","Augmented reality; Distributed computer systems; Education computing; Knowledge management; Scheduling; Students; Analogies; Augmented reality applications; Collaborative learning; Collaborative learning activities; Knowledge transfer; Motivation and engagements; Programming education; Scheduling policies; Parallel programming",Conference Paper,"Final","",Scopus,2-s2.0-85052244534
"Agus M., Boges D., Gagnon N., Magistretti P.J., Hadwiger M., Calí C.","57195623616;56780189200;57202248458;7007046209;14021127100;24337622600;","GLAM: Glycogen-derived Lactate Absorption Map for visual analysis of dense and sparse surface reconstructions of rodent brain structures on desktop systems and virtual environments",2018,"Computers and Graphics (Pergamon)","74",,,"85","98",,12,"10.1016/j.cag.2018.04.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047628319&doi=10.1016%2fj.cag.2018.04.007&partnerID=40&md5=a276e314d27f8e5d009691c6386a7ce3","Visual Computing Center, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia; Biological and Environmental Science and Engineering Division, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia; CRS4 - Center for Advanced Studies, Research and Development in Sardinia, Pula(CA), Italy","Agus, M., Visual Computing Center, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia, CRS4 - Center for Advanced Studies, Research and Development in Sardinia, Pula(CA), Italy; Boges, D., Biological and Environmental Science and Engineering Division, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia; Gagnon, N., Biological and Environmental Science and Engineering Division, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia; Magistretti, P.J., Biological and Environmental Science and Engineering Division, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia; Hadwiger, M., Visual Computing Center, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia; Calí, C., Biological and Environmental Science and Engineering Division, King Abdullah University of Science and Technology, Thuwal, 23955-6900, Saudi Arabia","Human brain accounts for about one hundred billion neurons, but they cannot work properly without ultrastructural and metabolic support. For this reason, mammalian brains host another type of cells called “glial cells”, whose role is to maintain proper conditions for efficient neuronal function. One type of glial cell, astrocytes, are involved in particular in the metabolic support of neurons, by feeding them with lactate, one byproduct of glucose metabolism that they can take up from blood vessels, and store it under another form, glycogen granules. These energy-storage molecules, whose morphology resembles to spheres with a diameter ranging 10–80 nanometers roughly, can be easily recognized using electron microscopy, the only technique whose resolution is high enough to resolve them. Understanding and quantifying their distribution is of particular relevance for neuroscientists, in order to understand where and when neurons use energy under this form. To answer this question, we developed a visualization technique, dubbed GLAM (Glycogen-derived Lactate Absorption Map), and customized for the analysis of the interaction of astrocytic glycogen on surrounding neurites in order to formulate hypotheses on the energy absorption mechanisms. The method integrates high-resolution surface reconstruction of neurites, astrocytes, and the energy sources in form of glycogen granules from different automated serial electron microscopy methods, like focused ion beam scanning electron microscopy (FIB-SEM) or serial block face electron microscopy (SBEM), together with an absorption map computed as a radiance transfer mechanism. The resulting visual representation provides an immediate and comprehensible illustration of the areas in which the probability of lactate shuttling is higher. The computed dataset can be then explored and quantified in a 3D space, either using 3D modeling software or virtual reality environments. Domain scientists have evaluated the technique by either using the computed maps for formulating functional hypotheses or for planning sparse reconstructions to avoid excessive occlusion. Furthermore, we conducted a pioneering user study showing that immersive VR setups can ease the investigation of the areas of interest and the analysis of the absorption patterns in the cellular structures. © 2018 Elsevier Ltd","3D interactive visual analysis; Nanometric scale brain reconstructions; Neuroenergetics; Scientific visualization; Virtual Reality in Neuroscience","Blood vessels; Data visualization; Electrons; Granulation; Ion beams; Mammals; Metabolism; Neurons; Repair; Scanning electron microscopy; Three dimensional computer graphics; Virtual reality; Visualization; Brain reconstruction; Energy-storage molecule; Focused ion beam-scanning electron microscopies; Interactive visual analysis; Neuroenergetics; Virtual-reality environment; Visual representations; Visualization technique; Surface reconstruction",Article,"Final","",Scopus,2-s2.0-85047628319
"Thang T.","57203396901;","PhD Forum: Strengthening social emotional skills for individuals with developmental disabilities through virtual reality games",2018,"Proceedings - 2018 IEEE International Conference on Smart Computing, SMARTCOMP 2018",,, 8421355,"242","243",,,"10.1109/SMARTCOMP.2018.00061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051507174&doi=10.1109%2fSMARTCOMP.2018.00061&partnerID=40&md5=143ef15c191f513b250eb0bfe78af419","Computational Media, University of California, Santa Cruz Santa Cruz, CA, United States","Thang, T., Computational Media, University of California, Santa Cruz Santa Cruz, CA, United States","Defining qualities of developmental disabilities include deficits in social-emotional skills, especially with respect to emotion recognition. This study aims to assist adults with developmental disabilities in strengthening emotion recognition skills through the research and development of virtual reality games to increase accessibility to life-changing therapies. Work previously accomplished in this study includes the development of EmotionVR, a virtual reality game created for the HTC Vive. EmotionVR takes traditional methods of therapy aimed at teaching emotion recognition and translates it into an interesting and interactive narrative that provides users the opportunity to learn and practice emotion recognition in realistic settings. This work observed and analyzed the interaction between adults with developmental disabilities, and the HTC Vive and virtual environments. While the game supports the idea that virtual reality is a feasible method of providing such therapies, users found some discomfort with using the HTC Vive, and had slight difficulty translating what they had learned from the game in different situational contexts. To resolve those issues, we investigate interactions between adults with developmental disabilities and other virtual reality systems, and develop a 360 video based virtual reality game to assist with transfer of skills. © 2018 IEEE.","Assistive technology; developmental disabilities; human computer interaction; virtual reality","Human computer interaction; Speech recognition; Assistive technology; Developmental disability; Emotion recognition; Interactive narrative; Research and development; Situational context; Virtual reality system; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85051507174
"Buatois A., Flumian C., Schultheiss P., Avarguès-Weber A., Giurfa M.","57190951756;57203869544;36982215400;35721565900;7003298526;","Transfer of visual learning between a virtual and a real environment in honey bees: The role of active vision",2018,"Frontiers in Behavioral Neuroscience","12",, 139,"","",,7,"10.3389/fnbeh.2018.00139","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85053289877&doi=10.3389%2ffnbeh.2018.00139&partnerID=40&md5=1c2229d71b1b598dc01b36b32cfa5419","Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse, France","Buatois, A., Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse, France; Flumian, C., Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse, France; Schultheiss, P., Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse, France; Avarguès-Weber, A., Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse, France; Giurfa, M., Research Centre on Animal Cognition, Center for Integrative Biology, CNRS, University of Toulouse, Toulouse, France","To study visual learning in honey bees, we developed a virtual reality (VR) system in which the movements of a tethered bee walking stationary on a spherical treadmill update the visual panorama presented in front of it (closed-loop conditions), thus creating an experience of immersion within a virtual environment. In parallel, we developed a small Y-maze with interchangeable end-boxes, which allowed replacing repeatedly a freely walking bee into the starting point of the maze for repeated decision recording. Using conditioning and transfer experiments between the VR setup and the Y-maze, we studied the extent to which movement freedom and active vision are crucial for learning a simple color discrimination. Approximately 57% of the bees learned the visual discrimination in both conditions. Transfer from VR to the maze improved significantly the bees’ performances: 75% of bees having chosen the CS+ continued doing so and 100% of bees having chosen the CS- reverted their choice in favor of the CS+. In contrast, no improvement was seen for these two groups of bees during the reciprocal transfer from the Y-maze to VR. In this case, bees exhibited inconsistent choices in the VR setup. The asymmetric transfer between contexts indicates that the information learned in each environment may be different despite the similar learning success. Moreover, it shows that reducing the possibility of active vision and movement freedom in the passage from the maze to the VR impairs the expression of visual learning while increasing them in the reciprocal transfer improves it. Our results underline the active nature of visual processing in bees and allow discussing the developments required for immersive VR experiences in insects. © 2018 Buatois, Flumian, Schultheiss, Avarguès-Weber and Giurfa.","Honey bees; Insect cognition; Transfer of learning; Virtual reality; Visual conditioning; Y-maze","animal experiment; Article; color discrimination; discrimination learning; honeybee; learning; mental performance; nonhuman; simulation training; transfer of learning; virtual learning; virtual reality; vision; visual discrimination; visual discrimination learning test; visual learning; Y-maze test",Article,"Final","",Scopus,2-s2.0-85053289877
"Foloppe D.A., Richard P., Yamaguchi T., Etcharry-Bouyx F., Allain P.","55226000800;57210457077;42862771500;6701526596;16633275200;","The potential of virtual reality-based training to enhance the functional autonomy of Alzheimer's disease patients in cooking activities: A single case study",2018,"Neuropsychological Rehabilitation","28","5",,"709","733",,28,"10.1080/09602011.2015.1094394","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84944937051&doi=10.1080%2f09602011.2015.1094394&partnerID=40&md5=59dbbc30086ab0a5bc50a1a244ddd880","Laboratoire de Psychologie des Pays de Loire (EA 4638), LUNAM Université, Université d'Angers, Angers, France; Laboratoire Angevin de Recherche en Ingénierie des Systèmes (EA 7315), LUNAM Université, Université d'Angers, Angers, France; Department of Applied Electronics, Faculty of Industrial Science and Technology, Tokyo University of Science, Tokyo, Japan; Département de Neurologie, Unité de Neuropsychologie, Chu Angers, France","Foloppe, D.A., Laboratoire de Psychologie des Pays de Loire (EA 4638), LUNAM Université, Université d'Angers, Angers, France, Laboratoire Angevin de Recherche en Ingénierie des Systèmes (EA 7315), LUNAM Université, Université d'Angers, Angers, France; Richard, P., Laboratoire Angevin de Recherche en Ingénierie des Systèmes (EA 7315), LUNAM Université, Université d'Angers, Angers, France; Yamaguchi, T., Department of Applied Electronics, Faculty of Industrial Science and Technology, Tokyo University of Science, Tokyo, Japan; Etcharry-Bouyx, F., Laboratoire de Psychologie des Pays de Loire (EA 4638), LUNAM Université, Université d'Angers, Angers, France, Département de Neurologie, Unité de Neuropsychologie, Chu Angers, France; Allain, P., Laboratoire de Psychologie des Pays de Loire (EA 4638), LUNAM Université, Université d'Angers, Angers, France, Département de Neurologie, Unité de Neuropsychologie, Chu Angers, France","Impairments in performing activities of daily living occur early in the course of Alzheimer's disease (AD). There is a great need to develop non-pharmacological therapeutic interventions likely to reduce dependency in everyday activities in AD patients. This study investigated whether it was possible to increase autonomy in these patients in cooking activities using interventions based on errorless learning, vanishing-cue, and virtual reality techniques. We recruited a 79-year-old woman who met NINCDS-ADRDA criteria for probable AD. She was trained in four cooking tasks for four days per task, one hour per day, in virtual and in real conditions. Outcome measures included subjective data concerning the therapeutic intervention and the experience of virtual reality, repeated assessments of training activities, neuropsychological scores, and self-esteem and quality of life measures. The results indicated that our patient could relearn some cooking activities using virtual reality techniques. Transfer to real life was also observed. Improvement of the task performance remained stable over time. This case report supports the value of a non-immersive virtual kitchen to help people with AD to relearn cooking activities. © 2015 Informa UK Limited, trading as Taylor & Francis Group.","activities of daily living; Alzheimer's disease; cognitive rehabilitation; non-pharmacological intervention; virtual reality","aged; Alzheimer disease; case report; computer assisted therapy; daily life activity; female; human; learning; neurorehabilitation; psychology; virtual reality; Activities of Daily Living; Aged; Alzheimer Disease; Female; Humans; Learning; Neurological Rehabilitation; Therapy, Computer-Assisted; Virtual Reality",Article,"Final","",Scopus,2-s2.0-84944937051
"Huang M., Zhang X.","57194328240;57194344679;","MAC scheduling for multiuser wireless virtual reality in 5G MIMO-OFDM Systems",2018,"2018 IEEE International Conference on Communications Workshops, ICC Workshops 2018 - Proceedings",,,,"1","6",,7,"10.1109/ICCW.2018.8403486","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050263021&doi=10.1109%2fICCW.2018.8403486&partnerID=40&md5=0609bb9d4c8a4ace1e1290998f36b396","Intel Corporation, United States","Huang, M., Intel Corporation, United States; Zhang, X., Intel Corporation, United States","Wireless Virtual Reality (VR) is a new-arising technology to enable the untethered connection between VR server and VR client, which needs to support simultaneously ultra-high data rate and ultra-high transfer reliability for video streaming, and also ultra-high responsive speed for motion-to-photon latency. Such three ultra-high (3UH) requirements constitute the basic characteristics of the generalized tactile internet. This paper proposes a multiuser MAC scheduling scheme for VR service in 5G MIMO-OFDM system, which can maximize the number of simultaneous VR clients while guaranteeing their 3UH quality-of-experience (QoE). Specifically, this scheme is composed of three novel functions, including video frame differentiation and delay-based weight calculation, spatial-frequency user selection based on maximum aggregate delay-capacity utility (ADCU), and link adaptation with dynamic block-error-rate (BLER) target. In addition, a low-complexity downlink MIMO user selection algorithm is developed, which can reduce the calculation amount with one order. It is demonstrated by the simulation results that the proposed scheme increases 31.6% for the maximum number of simultaneously served VR users than the traditional scheme with maximum-sum-capacity based scheduling and fixed BLER target based link adaptation. © 2018 IEEE.","Deep Packet Inspection; Delay-Based; Link Adaptation; MAC Scheduling; MIMO-OFDM; Multiuser Wireless Virtual Reality","Gain control; MIMO systems; Orthogonal frequency division multiplexing; Quality of service; Scheduling; Virtual reality; Deep packet inspection; Delay-Based; Link adaptation; MAC scheduling; MIMO-OFDM; Multi-user; 5G mobile communication systems",Conference Paper,"Final","",Scopus,2-s2.0-85050263021
"Bier B., Ouellet E., Belleville S.","56293391400;55567624500;57203072633;","Computerized attentional training and transfer with virtual reality: Effect of age and training type",2018,"Neuropsychology","32","5",,"597","614",,13,"10.1037/neu0000417","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049186196&doi=10.1037%2fneu0000417&partnerID=40&md5=6c581ac80b223d391c8f488f654ce2b0","Research Centre, Institut universitaire de gériatrie de Montréal, Montreal, Canada; Department of Psychology, University of Montreal, Canada","Bier, B., Research Centre, Institut universitaire de gériatrie de Montréal, Montreal, Canada, Department of Psychology, University of Montreal, Canada; Ouellet, E., Research Centre, Institut universitaire de gériatrie de Montréal, Montreal, Canada, Department of Psychology, University of Montreal, Canada; Belleville, S., Research Centre, Institut universitaire de gériatrie de Montréal, Montreal, Canada, Department of Psychology, University of Montreal, Canada","Objective: The aims of this study were to assess whether computerized attentional training improves dual-tasking abilities in older adults and whether its effect and transfer are modulated by age and the type of training provided. This study also used virtual reality (VR) as a proxy to measure transfer in a real life related context. Method: Sixty participants (30 older and 30 younger adults) were randomized to either: (a) single-task training (two tasks practiced in focused attention; visual detection and alphanumeric equation task); or (b) divided attention variable-priority training (varying the amount of attention to put on each task when performed concurrently). Training effects were assessed at pre- and post-training with tasks similar to the one used in training. Transfer was measured with the virtual car ride, an immersive dual-task scenario and a self-reported questionnaire. Results: In older adults, variable-priority improved attentional control abilities and led to better transfer in the VR dual-task scenario compared with single-task. Younger adults benefited equally from the two types of training and transfer was found on the Alpha span task when performed concurrently in VR. Single-task improved the ability of all participants to carry out the tasks in the focused attention condition. No transfer effects were found on the self-reported measure for either training type or age. Conclusion: Attention remains plastic in old age and programs designed to improve attentional control might be beneficial to older adults. Importantly, training can produce transfer to more real life related tasks and transfer remains possible throughout the life span. © 2018 American Psychological Association.","Aging; Cognitive training; Dual-task; Transfer; Virtual-reality","adult; age; aged; Article; attention; cognitive therapy; computerized attentional training; controlled study; female; human; human experiment; intermethod comparison; male; normal human; priority journal; questionnaire; randomized controlled trial; self report; single task training; therapy effect; variable priority training; virtual reality; visual discrimination; aging; computer; middle aged; physiology; psychology; transfer of learning; young adult; Adult; Age Factors; Aged; Aging; Attention; Computers; Female; Humans; Male; Middle Aged; Transfer (Psychology); Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85049186196
"Huber T., Paschold M., Hansen C., Lang H., Kneist W.","18535462800;50361876100;55890379200;7402486188;7005632003;","Artificial Versus Video-Based Immersive Virtual Surroundings: Analysis of Performance and User’s Preference",2018,"Surgical Innovation","25","3",,"280","285",,5,"10.1177/1553350618761756","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85047495181&doi=10.1177%2f1553350618761756&partnerID=40&md5=0ad928be9ec543737a9d0024a2671f68","University Medicine of the Johannes Gutenberg-University, Mainz, Germany; Otto-von-Guericke University, Magdeburg, Germany","Huber, T., University Medicine of the Johannes Gutenberg-University, Mainz, Germany; Paschold, M., University Medicine of the Johannes Gutenberg-University, Mainz, Germany; Hansen, C., Otto-von-Guericke University, Magdeburg, Germany; Lang, H., University Medicine of the Johannes Gutenberg-University, Mainz, Germany; Kneist, W., University Medicine of the Johannes Gutenberg-University, Mainz, Germany","Introduction. Immersive virtual reality (VR) laparoscopy simulation connects VR simulation with head-mounted displays to increase presence during VR training. The goal of the present study was the comparison of 2 different surroundings according to performance and users’ preference. Methods. With a custom immersive virtual reality laparoscopy simulator, an artificially created VR operating room (AVR) and a highly immersive VR operating room (IVR) were compared. Participants (n = 30) performed 3 tasks (peg transfer, fine dissection, and cholecystectomy) in AVR and IVR in a crossover study design. Results. No overall difference in virtual laparoscopic performance was obtained when comparing results from AVR with IVR. Most participants preferred the IVR surrounding (n = 24). Experienced participants (n = 10) performed significantly better than novices (n = 10) in all tasks regardless of the surrounding (P <.05). Participants with limited experience (n = 10) showed differing results. Presence, immersion, and exhilaration were significantly higher in IVR. Two thirds assumed that IVR would have a positive influence on their laparoscopic simulator use. Conclusion. This first study comparing AVR and IVR did not reveal differences in virtual laparoscopic performance. IVR is considered the more realistic surrounding and is therefore preferred by the participants. © 2018, © The Author(s) 2018.","abdominal surgery; immersive virtual reality; laparoscopy; simulation; training; virtual surgery","adult; Article; cholecystectomy; clinical assessment; crossover procedure; cyber sickness; diseases; female; fine dissection; human; immersive virtual reality; laparoscopy; male; medical procedures; medical student; middle aged; peg transfer; performance; questionnaire; task performance; virtual reality; young adult; clinical competence; education; medical education; procedures; surgeon; Adult; Clinical Competence; Education, Medical; Female; Humans; Laparoscopy; Male; Middle Aged; Surgeons; Surveys and Questionnaires; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85047495181
"Riva G., Wiederhold B.K., Chirico A., Di Lernia D., Mantovani F., Gaggioli A.","56962750600;7003634518;56755080200;57189076325;7006190897;6603138127;","Brain and virtual reality: What do they have in common and how to exploit their potential",2018,"Annual Review of CyberTherapy and Telemedicine","2018","16",,"3","8",,5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067840584&partnerID=40&md5=3a878bb1f64f53b14d1ef91b66876123","Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy; Applied Technology for Neuro-Psychology Lab. Istituto Auxologico Italiano, Milan, Italy; Interactive Media Institute, San Diego, CA, United States; Department of Human Sciences for Education, Università degli Studi di Milano-Bicocca, Milan, Italy","Riva, G., Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy, Applied Technology for Neuro-Psychology Lab. Istituto Auxologico Italiano, Milan, Italy; Wiederhold, B.K., Interactive Media Institute, San Diego, CA, United States; Chirico, A., Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy; Di Lernia, D., Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy; Mantovani, F., Department of Human Sciences for Education, Università degli Studi di Milano-Bicocca, Milan, Italy; Gaggioli, A., Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy, Applied Technology for Neuro-Psychology Lab. Istituto Auxologico Italiano, Milan, Italy","Different studies suggest that Virtual Reality (VR) is an effective tool for behavioural health, with long-term effects that generalize to the real world. Here we suggest that the efficacy of VR can be explained by how it works. Specifically, VR shares with our brain the same basic mechanism: embodied simulations. Different major discoveries in the field of neuroscience suggest that our brain produces and updates an embodied simulation of the body in the world. This simulation is actively used by different cognitive processes to represent and predict actions, concepts, and emotions. VR works in a similar way: through the integration of data from trackers and contents of a simulated 3D world, a VR system builds a model (simulation) of the body and the space around it. Like the brain, the VR system uses the simulation to predict the sensory consequences of the individual’s movements. In this view, the more the VR model is similar to the brain model, the more the individual feels present in the VR world. The paper discusses the potential of this link, by suggesting the emergence of a new clinical approach that uses the simulative potential of VR to exploit/empower (transformation of flow) and/or correct/update (embodied medicine) the predictive/simulative mechanisms of the brain. © 2018, Interactive Media Institute. All rights reserved.","Behavioural health; Embodied medicine; Embodied simulation; Neuroscience; Predictive coding; Virtual reality","article; brain; drug efficacy; human; human experiment; medical decision making; neuroscience; simulation; virtual reality",Article,"Final","",Scopus,2-s2.0-85067840584
"Höfer S., Raisch J., Toussaint M., Brock O.","56423295900;7003618436;7006246144;6602822080;","No free lunch in ball catching: A comparison of Cartesian and angular representations for control",2018,"PLoS ONE","13","6", e0197803,"","",,1,"10.1371/journal.pone.0197803","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057097111&doi=10.1371%2fjournal.pone.0197803&partnerID=40&md5=62ce539e592b62295c8bcba8d2f79a9a","Robotics and Biology Laboratory (RBO), Technische Universität Berlin, Berlin, Germany; Amazon Research, Berlin, Germany; Control Systems Group, Technische Universität Berlin, Berlin, Germany; Machine Learning and Robotics Lab (MLR), Universität Stuttgart, Stuttgart, Germany","Höfer, S., Robotics and Biology Laboratory (RBO), Technische Universität Berlin, Berlin, Germany, Amazon Research, Berlin, Germany; Raisch, J., Control Systems Group, Technische Universität Berlin, Berlin, Germany; Toussaint, M., Amazon Research, Berlin, Germany, Machine Learning and Robotics Lab (MLR), Universität Stuttgart, Stuttgart, Germany; Brock, O., Robotics and Biology Laboratory (RBO), Technische Universität Berlin, Berlin, Germany","How to run most effectively to catch a projectile, such as a baseball, that is flying in the air for a long period of time? The question about the best solution to the ball catching problem has been subject to intense scientific debate for almost 50 years. It turns out that this scientific debate is not focused on the ball catching problem alone, but revolves around the research question what constitutes the ingredients of intelligent decision making. Over time, two opposing views have emerged: the generalist view regarding intelligence as the ability to solve any task without knowing goal and environment in advance, based on optimal decision making using predictive models; and the specialist view which argues that intelligent decision making does not have to be based on predictive models and not even optimal, advocating simple and efficient rules of thumb (heuristics) as superior to enable accurate decisions. We study two types of approaches to the ball catching problem, one for each view, and investigate their properties using both a theoretical analysis and a broad set of simulation experiments. Our study shows that neither of the two types of approaches can be regarded as superior in solving all relevant variants of the ball catching problem: each approach is optimal under a different realistic environmental condition. Therefore, predictive models neither guarantee nor prevent success a priori, and we further show that the key difference between the generalist and the specialist approach to ball catching is the type of input representation used to control the agent. From this finding, we conclude that the right solution to a decision making or control problem is orthogonal to the generalist and specialist approach, and thus requires a reconciliation of the two views in favor of a representation-centric view. © 2018 Höfer et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"article; controlled study; heuristics; human; intelligence; simulation; theoretical study; acceleration; baseball; decision making; depth perception; flow kinetics; forecasting; learning; movement perception; normal distribution; physiology; psychomotor performance; theoretical model; time factor; Acceleration; Baseball; Decision Making; Forecasting; Humans; Learning; Models, Theoretical; Motion Perception; Normal Distribution; Psychomotor Performance; Rheology; Space Perception; Time Factors",Article,"Final","",Scopus,2-s2.0-85057097111
"Wall K.J., Cumming T.B., Koenig S.T., Pelecanos A.M., Copland D.A.","37038732700;25222759400;35217731600;36168407200;6603939137;","Using technology to overcome the language barrier: the Cognitive Assessment for Aphasia App",2018,"Disability and Rehabilitation","40","11",,"1333","1344",,6,"10.1080/09638288.2017.1294210","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014614339&doi=10.1080%2f09638288.2017.1294210&partnerID=40&md5=153075f5fe196008f375f3ed9a5a5263","Centre for Clinical Research, The University of Queensland, Brisbane, Australia; School of Health and Rehabilitation Sciences, The University of Queensland, Brisbane, Australia; The Florey Institute for Neuroscience and Mental Health, University of MelbourneVIC, Australia; Katana Simulations Pty Ltd, Adelaide, Australia; Statistic Unit, QIMR Berghofer Medical Research Institute, Brisbane, Australia","Wall, K.J., Centre for Clinical Research, The University of Queensland, Brisbane, Australia, School of Health and Rehabilitation Sciences, The University of Queensland, Brisbane, Australia; Cumming, T.B., The Florey Institute for Neuroscience and Mental Health, University of MelbourneVIC, Australia; Koenig, S.T., Katana Simulations Pty Ltd, Adelaide, Australia; Pelecanos, A.M., Statistic Unit, QIMR Berghofer Medical Research Institute, Brisbane, Australia; Copland, D.A., Centre for Clinical Research, The University of Queensland, Brisbane, Australia, School of Health and Rehabilitation Sciences, The University of Queensland, Brisbane, Australia","Purpose: We developed and explored the feasibility and user acceptance of the Cognitive Assessment for Aphasia App: a non-immersive virtual reality cognitive assessment for stroke survivors, designed to be inclusive of individuals with aphasia. Methods: Participants were assessed on a battery of pen-and-paper cognitive tests and the Cognitive Assessment for Aphasia App. Feasibility was explored by quantifying missing data for test completion, determining user acceptance for the app by measuring participants’ preferred testing method, enjoyment and perceived task difficulty and time-taken to complete the test. Results: Sixty-four stroke participants (35 with aphasia, 29 without aphasia) and 32 controls were recruited. Only one participant with aphasia was unable to complete all the Cognitive Assessment for Aphasia App tasks, whereas 13 participants were unable to complete all pen-and-paper tasks. Only 14% of participants preferred the pen-and-paper tests, and preference did not significantly differ between groups. Ninety-five per cent of participants were neutral or enjoyed the app and 4% perceived it to be very difficult. Higher age was negatively associated with user acceptance measures. Conclusion: The study shows preliminary evidence for the Cognitive Assessment for Aphasia App to be a feasible cognitive assessment for stroke survivors with and without aphasia. The app is currently being validated in stroke.Implications for rehabilitation The Cognitive Assessment for Aphasia App is a feasible tool for assessing post-stroke cognition in acute, inpatient rehabilitation and community settings. In research trials examining cognition, individuals with aphasia are often excluded. The Cognitive Assessment for Aphasia App permits the inclusion of these individuals, enhancing generalizability. The Cognitive Assessment for Aphasia App provides an alternative method to assess cognition that is quicker and preferred over standard neuropsychological tests. © 2017 Informa UK Limited, trading as Taylor & Francis Group.","cognitive impairments; language impairments; neuropsychological tests; technology; user acceptance; Virtual reality","age; aged; aphasia; case control study; cerebrovascular accident; complication; female; human; male; mobile application; reaction time; short term memory; virtual reality; Age Factors; Aged; Aphasia; Case-Control Studies; Female; Humans; Male; Memory, Short-Term; Mobile Applications; Reaction Time; Stroke; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85014614339
"Hai W., Jain N., Wydra A., Thalmann N.M., Thalmann D.","57201904238;35498072000;57201913246;55218502200;7005885082;","Increasing the feeling of social presence by incorporating realistic interactions in multi-party VR",2018,"ACM International Conference Proceeding Series",,,,"7","10",,2,"10.1145/3205326.3205345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048396292&doi=10.1145%2f3205326.3205345&partnerID=40&md5=e227e300e07f40bfe7197535609178cd","Institute for Media Innovation, Nanyang Technological University, Singapore; École polytechnique fédérale de Lausanne, Switzerland","Hai, W., Institute for Media Innovation, Nanyang Technological University, Singapore; Jain, N., Institute for Media Innovation, Nanyang Technological University, Singapore; Wydra, A., Institute for Media Innovation, Nanyang Technological University, Singapore; Thalmann, N.M., Institute for Media Innovation, Nanyang Technological University, Singapore; Thalmann, D., École polytechnique fédérale de Lausanne, Switzerland","Behavioral realism and realistic interactions are major criteria for improving social presence in virtual reality environments. We focus on multi-party VR applications where computer agents and avatars interact, share and collaborate with each other using objects. Our formulation employs realistic animations to simulate human-like behavioral motions of computer agents while they interact with avatars to enhance the sense of social presence in the VR environment. We exemplify our proposed model in a VR volleyball game setup. We model specific underlying interactions like gazing, collision detection and miscellaneous reactions (like how to pick a volleyball, how to transfer the ball to server) between computers players and avatars in the VR Volleyball game. We conduct a preliminary user survey to illustrate the significance of inclusion of realistic interactions for improving sense of social presence in a multi-party VR environment. © 2018 Copyright held by the owner/author(s).","Agent; Avatar; Behavior realism; Interactions; Multiparty; Social presence; VR","Agents; Animation; Beam plasma interactions; Behavioral research; Interactive computer graphics; Sports; Virtual reality; Avatar; Behavior realism; Collision detection; Miscellaneous reactions; Multiparty; Social presence; Virtual-reality environment; VR applications; Computer games",Conference Paper,"Final","",Scopus,2-s2.0-85048396292
"Jung J., Ahn Y.J.","57220995238;57201853639;","Effects of interface on procedural skill transfer in virtual training: Lifeboat launching operation study",2018,"Computer Animation and Virtual Worlds","29","3-4", e1812,"","",,7,"10.1002/cav.1812","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046267906&doi=10.1002%2fcav.1812&partnerID=40&md5=0f4881ff1662eaf041a1adb3184611b7","Korea Research Institute of Ships and Ocean Engineering, Daejeon, South Korea; Korea Institute of Maritime and Fisheries Technology, Busan, South Korea","Jung, J., Korea Research Institute of Ships and Ocean Engineering, Daejeon, South Korea; Ahn, Y.J., Korea Institute of Maritime and Fisheries Technology, Busan, South Korea","A comparative study assessing the effect of interface type on procedural skill transfer during virtual training is presented. The aim of this research is to evaluate the transferability of two aspects of procedural skills, that is, procedural knowledge and technical skills. We established one group with a lecture and three virtual training groups with a combination of output and input devices: a monitor and keyboard/mouse, a head-mounted display (HMD) and joypad, and an HMD and wearable sensors. The task for assessment was a lifeboat launching operation that requires a participant to memorize a 10-step procedure utilizing 14 different pieces of equipment that should be manipulated in each step. Before and after training, we evaluated the participants' procedural knowledge and technical skill on a real lifeboat. The monitor and keyboard/mouse group showed the best performance in a procedural knowledge assessment that addressed visually induced recollections from the real lifeboat. Alternatively, in the assessment of technical skills that determined manipulation ability that requires word-based mnemonics, the HMD and wearable sensors group outperformed the other groups. Moreover, the results showed that the virtual training was a more efficient training format for short-term training than a lecture due to the freedom of observation viewpoint, despite simulator sickness. Copyright © 2018 John Wiley & Sons, Ltd.","interface; maritime safety; procedural skill transfer; virtual reality; virtual training","Helmet mounted displays; Interfaces (materials); Lifeboats; Typewriter keyboards; Virtual reality; Wearable sensors; Comparative studies; Head mounted displays; Lifeboat launching; Maritime safety; Procedural knowledge; Simulator sickness; Skill transfer; Virtual training; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85046267906
"Esmaeili A.H., Thwaites H., Woods P.C.","56789724600;23486917000;16065290700;","Immersive virtual environments for tacit knowledge transfer focusing on gestures: A workflow",2018,"Proceedings of the 2017 23rd International Conference on Virtual Systems and Multimedia, VSMM 2017","2018-January",,,"1","6",,2,"10.1109/VSMM.2017.8346255","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049737638&doi=10.1109%2fVSMM.2017.8346255&partnerID=40&md5=1a430cf6a167fb75cee6105e335a5f16","Centre for Research-Creation in Digital Media, School of Arts, Sunway University, Malaysia; Faculty of Creative Multimedia, Multimedia University, Malaysia","Esmaeili, A.H., Centre for Research-Creation in Digital Media, School of Arts, Sunway University, Malaysia; Thwaites, H., Centre for Research-Creation in Digital Media, School of Arts, Sunway University, Malaysia; Woods, P.C., Faculty of Creative Multimedia, Multimedia University, Malaysia","This study presents a workflow for creating immersive virtual environments for tacit knowledge transfer. The main focus is on gestures, which are related to skill, performance, or physical emotion (not facial) e.g. sports, martial arts, playing instruments, acting, etc. The initial idea behind this design is to provide a virtual practice environment mainly for actors in order to learn new gestures or moves. However, this virtual environment can also be used by many other target audiences based on their needs. Sometimes, ambiguity is part of knowledge transfer and becomes more salient or critical when it comes to tacit knowledge, especially at early stages of transfer. Performance while maintaining believable gesture is a must have requirement for actors. Visual references (mainly video in absence of trainer) are commonly used by actors in order to learn specific moves or gestures. However, videos are limited to 2D screen view (even if stereoscopic or 360°) and do not provide chance of studying a fre zing moment from all angles, simultaneously. Although this can be partly mimicked using multi-camera rig, it is still limited to the number of shots taken and only provides a linear frame sequence (mostly used as VFX). Immersive virtual environments not only eliminate this limitation but also provide one to one scale experience. In this study, the process of creating such environment is discussed in detail. This includes planning, concept design, selecting tools, establishing the environment, properly selecting or creating the virtual character(s), capturing the motion or using existing ones from different Mocap libraries, actor's interaction with VR equipment, user experience, etc. In addition to studying reference moves and gestures (frame by frame and from any angle), the user is able to observe his/her performance in VR. This can be achieved using motion capture cameras installed at the practice location. The captured content is later assigned to the user's virtual representative i.e. a 3d character created based on his/her physical body features for side by side analysis with the reference. This provides countless interaction possibilities that cannot be achieved in the real world. Few examples are: multiplying the reference character and freeze two or more different moments (frames) and create a walkthrough, creating an immersive timeline based on the actor's progress (also requires multiplying), assigning reference moves to the user's avatar to be compared with his/her movements by himself/herself or anyone else (different from side by side comparison with the reference character), and many others. What has been discussed above is fully illustrated and described in this paper including detailed figures. The contribution of this study can be extended to various fields from acting and sport to stop motion and creative art, as the processes presented in the paper are designed in the most affordable way, using hardware and software currently available to basic users. © 2017 IEEE.","Gesture; Htc vive; Immersive virtual environments; Immersive virtual reality; Learning in virtual reality; Mocap; Oculus rift; Steam Vr; Tacit knowledge transfer; Unity; Virtual reality","Cameras; Digital libraries; Knowledge management; Sports; Stereo image processing; Virtual reality; Gesture; Htc vive; Immersive virtual environments; Immersive virtual reality; Mocap; Oculus rift; Tacit knowledge transfers; Unity; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85049737638
"Boyd L.E., Gupta S., Vikmani S.B., Gutierrez C.M., Yang J., Linstead E., Hayes G.R.","36141837900;57209786164;57193740783;57202044763;57202050920;16307496400;8589042500;","VrSocial: Toward immersive therapeutic VR systems for children with autism",2018,"Conference on Human Factors in Computing Systems - Proceedings","2018-April",,,"","",,10,"10.1145/3173574.3173778","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046938462&doi=10.1145%2f3173574.3173778&partnerID=40&md5=1cc86c91907a43d818f2dc3fe15937ce","Department of Informatics, UC Irvine, Irvine, United States; Cornona Del Mar High School, Newport Beach, United States; Computer Science Chapman University, Orange, United States","Boyd, L.E., Department of Informatics, UC Irvine, Irvine, United States; Gupta, S., Department of Informatics, UC Irvine, Irvine, United States; Vikmani, S.B., Department of Informatics, UC Irvine, Irvine, United States; Gutierrez, C.M., Department of Informatics, UC Irvine, Irvine, United States; Yang, J., Cornona Del Mar High School, Newport Beach, United States; Linstead, E., Computer Science Chapman University, Orange, United States; Hayes, G.R., Department of Informatics, UC Irvine, Irvine, United States","Social communication frequently includes nuanced nonverbal communication cues, including eye contact, gestures, facial expressions, body language, and tone of voice. This type of communication is central to face-to-face interaction, but can be challenging for children and adults with autism. Innovative technologies can provide support by augmenting human-delivered cuing and automated prompting. Specifically, immersive virtual reality (VR) offers an option to generalize social skill interventions by concretizing nonverbal information in real-time social interactions. In this work, we explore the design and evaluation of three nonverbal communication applications in immersive VR. The results of this work indicate that delivering real-time visualizations of proximity, speaker volume, and duration of one's speech is feasible in immersive VR and effective for real-time support for proximity regulation for children with autism. We conclude with design considerations for therapeutic VR systems. © 2018 Association for Computing Machinery.","Accessibility; Assistive technology; Autism; Immersive VR; Nonverbal communication; Prosody; Proximity; Visualization","Diseases; Flow visualization; Human engineering; Visualization; Accessibility; Assistive technology; Autism; Immersive VR; Non-verbal communications; Prosody; Proximity; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85046938462
"Chen M., Saad W., Yin C., Debbah M.","57113807700;57203259001;7201995655;35588784300;","Echo state transfer learning for data correlation aware resource allocation in wireless virtual reality",2018,"Conference Record of 51st Asilomar Conference on Signals, Systems and Computers, ACSSC 2017","2017-October",,,"1852","1856",,5,"10.1109/ACSSC.2017.8335683","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046368131&doi=10.1109%2fACSSC.2017.8335683&partnerID=40&md5=03a7a8b8a15a7a202876862eada7cfa2","Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Wireless at VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, United States; Mathematical and Algorithmic Sciences Lab, Huawei France RandD, Paris, France","Chen, M., Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Saad, W., Wireless at VT, Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, United States; Yin, C., Beijing Key Laboratory of Network System Architecture and Convergence, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Debbah, M., Mathematical and Algorithmic Sciences Lab, Huawei France RandD, Paris, France","In this paper, the problem of data correlation-aware resource management is studied for a network of wireless virtual reality (VR) users communicating over cloud-based small cell networks (SCNs). In the studied model, small base stations (SBSs) with limited computational resources act as VR control centers that collect the tracking information from VR users over the cellular uplink and send them to the VR users over the downlink. In such a setting, VR users may send or request correlated or similar data (panoramic images and tracking data). This potential spatial data correlation can be factored into the resource allocation problem to reduce the traffic load in both uplink and downlink. This VR resource allocation problem is formulated as a noncooperative game that allows jointly optimizing the computational and spectrum resources, while being cognizant of the data correlation. To solve this game, a transfer learning algorithm based on the machine learning framework of echo state networks (ESNs) is proposed. Unlike conventional reinforcement learning algorithms that must be executed each time the environment changes, the proposed algorithm can intelligently transfer information on the learned utility, across time, to rapidly adapt to environmental dynamics due to factors such as changes in the users' content or data correlation. Simulation results show that the proposed algorithm achieves up to 16.7% and 18.2% gains in terms of delay compared to the Q-learning with data correlation and Q-learning without data correlation. The results also show that the proposed algorithm has a faster convergence time than Q-learning and can guarantee low delays. © 2017 IEEE.",,"E-learning; Information management; Reinforcement learning; Resource allocation; Virtual reality; Computational resources; Conventional reinforcement learning; Environmental dynamics; Noncooperative game; Resource allocation problem; Resource management; Small cell Networks; Transfer information; Learning algorithms",Conference Paper,"Final","",Scopus,2-s2.0-85046368131
"Gabriel A., Ortiz M.","56405176100;57202605654;","Virtual reality and recommendation system to design mobility system",2018,"Proceedings - 13th International Conference on Signal-Image Technology and Internet-Based Systems, SITIS 2017","2018-January",,,"490","495",,,"10.1109/SITIS.2017.86","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048889953&doi=10.1109%2fSITIS.2017.86&partnerID=40&md5=a1c55b2837395eefbd726b86ef1ddb3e","LCPI, Arts et Métiers ParisTech, Paris, France; ERPI, Université de Lorraine, Nancy, France","Gabriel, A., LCPI, Arts et Métiers ParisTech, Paris, France; Ortiz, M., ERPI, Université de Lorraine, Nancy, France","In the domain of urbanism and more particularly the design of mobility system, the end-users are poorly involved whereas they condition the success of new infrastructure. The generalization of policies for active mobility urges the importance of correctly design the system of mobility. The success goes through the consideration of end-user needs. However, there is always a gap between the needs of the users and reality. We assume that virtual reality can ease user-centered design approach by letting the users experiment the technical solutions. Although maps and mockup permit exchanges between designers and end-users to improve the final design, this research assume that immersive environment is more efficient. Virtual reality seems to be a relevant tool for a user-centered approach applied to mobility system. The difficulty remains providing the adapted information to the designers who are the responsible to make the decision of the solution. The aim is not only to use virtual reality in the design process but also suggests a methodology to imply users in the design process and assist the designer during the decision-making. © 2017 IEEE.","Mobility system; Recommandation system; Virtual reality","Decision making; Human computer interaction; Regional planning; Virtual reality; Design process; End users; Immersive environment; Mobility systems; Recommandation system; Technical solutions; User-centered approach; User-centered design approaches; User centered design",Conference Paper,"Final","",Scopus,2-s2.0-85048889953
"Perandré Y.H.T., Haydu V.B.","57196465103;15029746800;","A treatment program for social anxiety disorder by using virtual reality",2018,"Trends in Psychology","26","2",,"867","882",,,"10.9788/TP2018.2-12En","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051743736&doi=10.9788%2fTP2018.2-12En&partnerID=40&md5=fe53a3d73d890a573c04be54dd95ba74","Universidade Federal do Paraná, Campus Jandaia do Sul, Rua Doutor João Maximiano, 426, Vila Operária, Jandaia do Sul, PR, 86900-000, Brazil; Universidade Estadual de Londrina, Londrina, PR, Brazil","Perandré, Y.H.T., Universidade Federal do Paraná, Campus Jandaia do Sul, Rua Doutor João Maximiano, 426, Vila Operária, Jandaia do Sul, PR, 86900-000, Brazil, Universidade Estadual de Londrina, Londrina, PR, Brazil; Haydu, V.B., Universidade Estadual de Londrina, Londrina, PR, Brazil","Virtual Reality (VR) was used in this study as a therapeutic tool in a behavior-analytic intervention with two subjects who had social anxiety disorder. The goals were to assess the therapeutic effects of the intervention program and the VR simulator with regard to the ability to generate sense of presence and anxiety responses. The program consisted of: (a) initial session, (b) baseline, (c) intervention sessions with exposure to VR, (d) closing session, (e) follow up (up to one and three months after treatment). Sense of presence, anxiety and galvanic skin response were reported in each exposure therapy session and anxiety, depression and social phobia inventories were reported at the end of each stage. Functional analyses were formulated based on behaviors occurring in social contexts between sessions. The simulator produced anxiety and high levels of presence during exposure; and both participants had reduced levels of anxiety at the end of intervention and generalization to the natural context. In conclusion, behavior-analytic intervention with exposure to VR was effective and fostered a repertoire for coping with situations of social interaction. © The Author(s), 2018.","Behavior-analytic therapy; Galvanic skin response; Sense of presence; Social anxiety disorder; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85051743736
"Murcia-López M., Steed A.","57194036190;18435050200;","A comparison of virtual and physical training transfer of bimanual assembly tasks",2018,"IEEE Transactions on Visualization and Computer Graphics","24","4",,"1574","1583",,22,"10.1109/TVCG.2018.2793638","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041644744&doi=10.1109%2fTVCG.2018.2793638&partnerID=40&md5=df74850c0558ed09574af1eb79529d4e","University College London, United Kingdom","Murcia-López, M., University College London, United Kingdom; Steed, A., University College London, United Kingdom","As we explore the use of consumer virtual reality technology for training applications, there is a need to evaluate its validity compared to more traditional training formats. In this paper, we present a study that compares the effectiveness of virtual training and physical training for teaching a bimanual assembly task. In a between-subjects experiment, 60 participants were trained to solve three 3D burr puzzles in one of six conditions comprised of virtual and physical training elements. In the four physical conditions, training was delivered via paper-And video-based instructions, with or without the physical puzzles to practice with. In the two virtual conditions, participants learnt to assemble the puzzles in an interactive virtual environment, with or without 3D animations showing the assembly process. After training, we conducted immediate tests in which participants were asked to solve a physical version of the puzzles. We measured performance through success rates and assembly completion testing times. We also measured training times as well as subjective ratings on several aspects of the experience. Our results show that the performance of virtually trained participants was promising. A statistically significant difference was not found between virtual training with animated instructions and the best performing physical condition (in which physical blocks were available during training) for the last and most complex puzzle in terms of success rates and testing times. Performance in retention tests two weeks after training was generally not as good as expected for all experimental conditions. We discuss the implications of the results and highlight the validity of virtual reality systems in training. © 2018 IEEE Computer Society. All rights reserved.","Assembly; Learning transfer; Training; Virtual reality","Assembly; Ergonomics; Haptic interfaces; Personnel training; Testing; Virtual reality; Experimental conditions; Interactive virtual environments; Learning Transfer; Statistically significant difference; Three-dimensional display; Training applications; Virtual reality system; Virtual reality technology; E-learning; adult; comparative study; computer interface; female; human; male; physiology; task performance; transfer of learning; virtual reality; young adult; Adult; Female; Humans; Male; Task Performance and Analysis; Transfer (Psychology); User-Computer Interface; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85041644744
"Rousset T., Bourdin C., Goulon C., Monnoyer J., Vercher J.-L.","57063135900;6603566648;26535970800;57063170900;7004221343;","Misperception of egocentric distances in virtual environments: More a question of training than a technological issue?",2018,"Displays","52",,,"8","20",,2,"10.1016/j.displa.2018.02.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042939701&doi=10.1016%2fj.displa.2018.02.004&partnerID=40&md5=bb33373e8b990b9c57e6879e0a9e61d9","Aix-Marseille Univ, CNRS, ISM, Marseille, France; Groupe PSA, Velizy Villacoublay, France","Rousset, T., Aix-Marseille Univ, CNRS, ISM, Marseille, France; Bourdin, C., Aix-Marseille Univ, CNRS, ISM, Marseille, France; Goulon, C., Aix-Marseille Univ, CNRS, ISM, Marseille, France; Monnoyer, J., Aix-Marseille Univ, CNRS, ISM, Marseille, France, Groupe PSA, Velizy Villacoublay, France; Vercher, J.-L., Aix-Marseille Univ, CNRS, ISM, Marseille, France","Findings from virtual reality applications in general and driving or flight simulators in particular, are frequently generalized to the study of human behavior. Thus, it is crucial to ensure that the virtuality of the experimental setup has little or no effect on perception of space and motion. Most studies show that observers immersed in virtual environments (VE) perceive virtual space as compressed relative to the real world, resulting in systematic underestimations of egocentric distance. Parallax and stereopsis, known to be important depth cues for distance perception, at least for short distances, are rarely used together in driving simulators, so their interactive role during driving tasks is still not clear. Inter-individual differences in misperception are also referred to, though few studies have explored this. The aim of this study was, first, to determine whether egocentric distance perception in driving simulation depends on two depth cues, binocular disparity and motion parallax, and, second, to examine the effect of inter-individual differences. Several conditions were tested, both with and without stereoscopic vision of the scene and/or motion parallax of the head. We focused first on a range of long distances, 40–80 m (Experiment 1) and subsequently widened the range to distances from 5 to 80 m, thereby including short distances where stereopsis should be more relevant (Experiment 2). The study reveals great inter-individual variability, clearly distinguishing two participant profiles. However, results suggest that such differences do not depend on the availability of motion parallax and stereoscopic vision. The findings also show that an initial familiarization phase, under conditions similar to those of the experiments, can be predictive of participants’ perceptual behavior. © 2018 The Authors","Distance perception; Inter-individual variability; Parallax; Stereoscopy","Behavioral research; Depth perception; E-learning; Flight simulators; Geometrical optics; Stereo image processing; Binocular disparity; Distance perception; Driving simulation; Driving simulator; Individual variability; Inter-individual differences; Parallax; Stereoscopic vision; Virtual reality",Article,"Final","",Scopus,2-s2.0-85042939701
"Linsk A.M., Monden K.R., Sankaranarayanan G., Ahn W., Jones D.B., De S., Schwaitzberg S.D., Cao C.G.L.","57195399645;55994165000;15623319200;9334513400;55387240300;7202304567;7007036892;25957557800;","Validation of the VBLaST pattern cutting task: a learning curve study",2018,"Surgical Endoscopy","32","4",,"1990","2002",,3,"10.1007/s00464-017-5895-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031775886&doi=10.1007%2fs00464-017-5895-0&partnerID=40&md5=01643e345abff49d9627308f3e7fc267","Beth Israel Deaconess Medical Center, Boston, MA, United States; Wright State University, 207 Russ Engineering Center, 3640 Colonel Glenn Hwy, Dayton, OH  45435, United States; Baylor University Medical Center at Dallas, Dallas, TX, United States; Rensselaer Polytechnic Institute, Troy, NY, United States; University at Buffalo School of Medicine and Biomedical Sciences, Buffalo, NY, United States","Linsk, A.M., Beth Israel Deaconess Medical Center, Boston, MA, United States; Monden, K.R., Baylor University Medical Center at Dallas, Dallas, TX, United States; Sankaranarayanan, G., Baylor University Medical Center at Dallas, Dallas, TX, United States; Ahn, W., Rensselaer Polytechnic Institute, Troy, NY, United States; Jones, D.B., Beth Israel Deaconess Medical Center, Boston, MA, United States; De, S., Rensselaer Polytechnic Institute, Troy, NY, United States; Schwaitzberg, S.D., University at Buffalo School of Medicine and Biomedical Sciences, Buffalo, NY, United States; Cao, C.G.L., Wright State University, 207 Russ Engineering Center, 3640 Colonel Glenn Hwy, Dayton, OH  45435, United States","Background: Mastery of laparoscopic skills is essential in surgical practice and requires considerable time and effort to achieve. The Virtual Basic Laparoscopic Skill Trainer (VBLaST-PC © ) is a virtual simulator that was developed as a computerized version of the pattern cutting (PC) task in the Fundamentals of Laparoscopic Surgery (FLS) system. To establish convergent validity for the VBLaST-PC © , we assessed trainees’ learning curves using the cumulative summation (CUSUM) method and compared them with those on the FLS. Methods: Twenty-four medical students were randomly assigned to an FLS training group, a VBLaST training group, or a control group. Fifteen training sessions, 30 min in duration per session per day, were conducted over 3 weeks. All subjects completed pretest, posttest, and retention test (2 weeks after posttest) on both the FLS and VBLaST © simulators. Performance data, including time, error, FLS score, learning rate, learning plateau, and CUSUM score, were analyzed. Results: The learning curve for all trained subjects demonstrated increasing performance and a performance plateau. CUSUM analyses showed that five of the seven subjects reached the intermediate proficiency level but none reached the expert proficiency level after 150 practice trials. Performance was significantly improved after simulation training, but only in the assigned simulator. No significant decay of skills after 2 weeks of disuse was observed. Control subjects did not show any learning on the FLS simulator, but improved continually in the VBLaST simulator. Conclusions: Although VBLaST © - and FLS-trained subjects demonstrated similar learning rates and plateaus, the majority of subjects required more than 150 trials to achieve proficiency. Trained subjects demonstrated improved performance in only the assigned simulator, indicating specificity of training. The virtual simulator may provide better opportunities for learning, especially with limited training exposure. © 2017, Springer Science+Business Media, LLC.","Convergent validity; Cumulative summation (CUSUM); Learning curve; Surgical training; Virtual reality","analytical error; Article; clinical assessment; comparative study; controlled study; human; laparoscopic surgery; learning curve; medical student; outcome assessment; pretest posttest design; priority journal; simulation training; skill; surgical training; transfer of learning; validation process; virtual basic laparoscopic skill trainer; virtual reality; clinical competence; education; laparoscopy; medical education; procedures; randomized controlled trial; simulation training; United States; validation study; virtual reality; Clinical Competence; Education, Medical, Undergraduate; Humans; Laparoscopy; Learning Curve; Simulation Training; Students, Medical; United States; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85031775886
"Zizza C., Starr A., Hudson D., Nuguri S.S., Calyam P., He Z.","57211248776;57211248952;57211248855;57197736605;6507285722;7403885484;","Towards a social virtual reality learning environment in high fidelity",2018,"CCNC 2018 - 2018 15th IEEE Annual Consumer Communications and Networking Conference","2018-January",,,"1","4",,10,"10.1109/CCNC.2018.8319187","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046949554&doi=10.1109%2fCCNC.2018.8319187&partnerID=40&md5=315a330d55f544e11ab9dcc97ca02f56","Grinnell College, United States; Pomona College, United States; Truman State University, United States; University of Missouri, United States","Zizza, C., Grinnell College, United States; Starr, A., Pomona College, United States; Hudson, D., Truman State University, United States; Nuguri, S.S., University of Missouri, United States; Calyam, P., University of Missouri, United States; He, Z., University of Missouri, United States","Virtual Learning Environments (VLEs) are spaces designed to educate students remotely via online platforms. Although traditional VLEs such as iSocial have shown promise in educating students, they offer limited immersion that diminishes learning effectiveness. This paper outlines a virtual reality learning environment (VRLE) over a high-speed network, which promotes educational effectiveness and efficiency via our creation of flexible content and infrastructure which meet established VLE standards with improved immersion. This paper further describes our implementation of multiple learning modules developed in High Fidelity, a 'social VR' platform. Our experiment results show that the VR mode of content delivery better stimulates the generalization of lessons to the real world than non-VR lessons and provides improved immersion when compared to an equivalent desktop version. © 2018 IEEE.","High Fidelity; Multi-user Network Application; Virtual Learning Environment; Virtual Reality","Computer aided instruction; HIgh speed networks; Virtual reality; Educational effectiveness; High-fidelity; Learning effectiveness; Learning modules; Multi-user networks; Virtual learning environments; Virtual learning environments (VLEs); Virtual reality learning environments; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85046949554
"Sundareson P.","6505668826;","Parallel image pre-processing for in-game object classification",2018,"2017 IEEE International Conference on Consumer Electronics-Asia, ICCE-Asia 2017","2018-January",,,"115","116",,,"10.1109/ICCE-ASIA.2017.8309316","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050684295&doi=10.1109%2fICCE-ASIA.2017.8309316&partnerID=40&md5=ad38281a2def5d58dbaf11873cd0043e","GPU-SW, NVIDIA, United States","Sundareson, P., GPU-SW, NVIDIA, United States","Games that involve photo-realistic rendering of virtual worlds, Special effects, VR, involve highly complex calculations on the GPU (Graphics Processing Unit). While GPUs have specialized cores that accelerate Graphics operations, they are also capable of general purpose computing. In this paper, a specific data flow is chosen for the use-case of in-game object-classification. This use-case involves converting large input graphics resolutions (4k) to much lower resolutions (256×256) needed for compute. We compare the different approaches available for executing the data flow using CUDA (Compute Unified Device Architecture) without impacting gaming performance, and publish comparisons on different classes of GPUs for the first time. It is shown that best performance is achieved with a combination of well optimized algorithms, priority of work assignment, and a flexible execution framework. © 2017 IEEE.","Compute Unified Device Architecture (CUDA); DirectX; Gaming; GPU; Image Preprocessing; Machine Learning","Computer graphics equipment; Data transfer; Image classification; Learning systems; Program processors; Virtual reality; Compute Unified Device Architecture(CUDA); CUDA (compute unified device architecture); DirectX; Gaming; General-purpose computing; Image preprocessing; Object classification; Photorealistic rendering; Graphics processing unit",Conference Paper,"Final","",Scopus,2-s2.0-85050684295
"Ma X., Yao Z., Wang Y., Pei W., Chen H.","57201641690;56911568900;7601519371;8365780300;10041330500;","Combining brain-computer interface and eye tracking for high-speed text entry in virtual reality",2018,"International Conference on Intelligent User Interfaces, Proceedings IUI",,,,"263","267",,5,"10.1145/3172944.3172988","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045452448&doi=10.1145%2f3172944.3172988&partnerID=40&md5=fff13c6fae5b3a42372fadd56cf28d65","Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China; University of Chinese, Academy of Sciences, Beijing, China; Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China","Ma, X., Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China, University of Chinese, Academy of Sciences, Beijing, China, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China; Yao, Z., Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China, University of Chinese, Academy of Sciences, Beijing, China, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China; Wang, Y., Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China, University of Chinese, Academy of Sciences, Beijing, China, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China; Pei, W., Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China, University of Chinese, Academy of Sciences, Beijing, China, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China; Chen, H., Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China, University of Chinese, Academy of Sciences, Beijing, China, Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China","Gaze interaction provides an efficient way for users to communicate and control in virtual reality (VR) presented by head-mounted displays. In gaze-based text-entry systems, eye tracking and brain-computer interface (BCI) are the two most commonly used approaches. This paper presents a hybrid BCI system for text entry in VR by combining steady-state visual evoked potentials (SSVEP) and eye tracking. The user interface in VR designed a 40-target virtual keyboard using a joint frequency-phase modulation method for SSVEP. Eye position was measured by an eyetracking accessory in the VR headset. Target-related gaze direction was detected by combining simultaneously recorded SSVEP and eye position data. Offline and online experiments indicate that the proposed system can type at a speed around 10 words per minute, leading to an information transfer rate (ITR) of 270 bits per minute. The results further demonstrate the superiority of the hybrid method over single-modality methods for VR applications. © 2018 Association for Computing Machinery.","Brain-computer interface; Eye tracking; Steady-state visual evoked potentials; Text entry; Virtual reality","Electrophysiology; Eye tracking; Helmet mounted displays; Interface states; User interfaces; Virtual reality; Head mounted displays; Information transfer rate; Modulation methods; On-line experiments; Steady state visual evoked potentials; Text entry; Text entry systems; Virtual Keyboards; Brain computer interface",Conference Paper,"Final","",Scopus,2-s2.0-85045452448
"Fromberger P., Jordan K., Müller J.L.","22957487700;7202963516;7404871741;","Virtual reality applications for diagnosis, risk assessment and therapy of child abusers",2018,"Behavioral Sciences and the Law","36","2",,"235","244",,10,"10.1002/bsl.2332","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045625005&doi=10.1002%2fbsl.2332&partnerID=40&md5=556f40ad3c484a23a287c5d8d5e87f1a","Clinic for Psychiatry and Psychotherapy - Forensic Psychiatry, Human Medical Center Göttingen, Georg-August-Universität Göttingen, Germany","Fromberger, P., Clinic for Psychiatry and Psychotherapy - Forensic Psychiatry, Human Medical Center Göttingen, Georg-August-Universität Göttingen, Germany; Jordan, K., Clinic for Psychiatry and Psychotherapy - Forensic Psychiatry, Human Medical Center Göttingen, Georg-August-Universität Göttingen, Germany; Müller, J.L., Clinic for Psychiatry and Psychotherapy - Forensic Psychiatry, Human Medical Center Göttingen, Georg-August-Universität Göttingen, Germany","Despite the successful application of virtual reality (VR) in a wide variety of mental disorders and the obvious potentials that VR provides, the use of VR in the context of criminology and forensic psychology is sparse. For forensic mental health professionals, VR provides some advantages that outrun general advantages of VR, e.g., ecological validity and controllability of social situations. Most important seems to be the unique possibility to expose offenders and to train coping skills in virtual situations, which are able to elicit disorder-relevant behavior—without endangering others. VR has already been used for the assessment of deviant sexual interests, for testing the ability to transfer learned coping skills communicated during treatment to behavior, and for risk assessment of child abusers. This article reviews and discusses these innovative research projects with regard to their impact on current clinical practice regarding risk assessment and treatment as well as other implementations of VR applications in forensic mental health. Finally, ethical guidelines for VR research in forensic mental health are provided. Copyright © 2018 John Wiley & Sons, Ltd.",,"child; child abuse; human; mental disease; risk assessment; virtual reality; Child; Child Abuse; Humans; Mental Disorders; Risk Assessment; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85045625005
"Serafin S., Geronazzo M., Erkut C., Nilsson N.C., Nordahl R.","6603367536;36720522500;6507065675;54993660100;32867973300;","Sonic Interactions in Virtual Reality: State of the Art, Current Challenges, and Future Directions",2018,"IEEE Computer Graphics and Applications","38","2",,"31","43",,27,"10.1109/MCG.2018.193142628","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045191223&doi=10.1109%2fMCG.2018.193142628&partnerID=40&md5=d0263b24cb2f433025831c345d9340bd","Aalborg University, Department of Architecture, Design, and Media Technology, Denmark; Aalborg University, Denmark","Serafin, S., Aalborg University, Department of Architecture, Design, and Media Technology, Denmark; Geronazzo, M., Aalborg University, Department of Architecture, Design, and Media Technology, Denmark; Erkut, C., Aalborg University, Denmark; Nilsson, N.C., Aalborg University, Denmark; Nordahl, R., Aalborg University, Department of Architecture, Design, and Media Technology, Denmark","A high-fidelity but efficient sound simulation is an essential element of any VR experience. Many of the techniques used in virtual acoustics are graphical rendering techniques suitably modified to account for sound generation and propagation. In recent years, several advances in hardware and software technologies have been facilitating the development of immersive interactive sound-rendering experiences. In this article, we present a review of the state of the art of such simulations, with a focus on the different elements that, combined, provide a complete interactive sonic experience. This includes physics-based simulation of sound effects and their propagation in space together with binaural rendering to simulate the position of sound sources. We present how these different elements of the sound design pipeline have been addressed in the literature, trying to find the trade-off between accuracy and plausibility. Recent applications and current challenges are also presented. © 1981-2012 IEEE.","computer graphics; head-related transfer function; sonic interaction; sound rendering","Economic and social effects; Object recognition; Immersive; Information interfaces and representations; Information technology and systems; Sonic interactions; Sound and music computing; Virtual reality",Article,"Final","",Scopus,2-s2.0-85045191223
"Berger C.C., Gonzalez-Franco M., Tajadura-Jiménez A., Florencio D., Zhang Z.","57210476689;36080251200;23569030500;6602865660;13609600600;","Generic HRTFs may be good enough in virtual reality. Improving source localization through cross-modal plasticity",2018,"Frontiers in Neuroscience","12","FEB", 21,"","",,17,"10.3389/fnins.2018.00021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041845498&doi=10.3389%2ffnins.2018.00021&partnerID=40&md5=3453eac39fc20cf19e5f21f4ee10c783","Microsoft Research, Redmond, WA, United States; Division of Biology and Biological Engineering, California Institute of Technology, Pasadena, CA, United States; UCL Interaction Centre, University College London, London, United Kingdom; Interactive Systems DEI-Lab, Universidad Carlos III de Madrid, Madrid, Spain; Department Electrical Engineering, University of Washington, Seattle, WA, United States","Berger, C.C., Microsoft Research, Redmond, WA, United States, Division of Biology and Biological Engineering, California Institute of Technology, Pasadena, CA, United States; Gonzalez-Franco, M., Microsoft Research, Redmond, WA, United States; Tajadura-Jiménez, A., UCL Interaction Centre, University College London, London, United Kingdom, Interactive Systems DEI-Lab, Universidad Carlos III de Madrid, Madrid, Spain; Florencio, D., Microsoft Research, Redmond, WA, United States; Zhang, Z., Microsoft Research, Redmond, WA, United States, Department Electrical Engineering, University of Washington, Seattle, WA, United States","Auditory spatial localization in humans is performed using a combination of interaural time differences, interaural level differences, as well as spectral cues provided by the geometry of the ear. To render spatialized sounds within a virtual reality (VR) headset, either individualized or generic Head Related Transfer Functions (HRTFs) are usually employed. The former require arduous calibrations, but enable accurate auditory source localization, which may lead to a heightened sense of presence within VR. The latter obviate the need for individualized calibrations, but result in less accurate auditory source localization. Previous research on auditory source localization in the real world suggests that our representation of acoustic space is highly plastic. In light of these findings, we investigated whether auditory source localization could be improved for users of generic HRTFs via cross-modal learning. The results show that pairing a dynamic auditory stimulus, with a spatio-temporally aligned visual counterpart, enabled users of generic HRTFs to improve subsequent auditory source localization. Exposure to the auditory stimulus alone or to asynchronous audiovisual stimuli did not improve auditory source localization. These findings have important implications for human perception as well as the development of VR systems as they indicate that generic HRTFs may be enough to enable good auditory source localization in VR. © 2018 Berger, Gonzalez-Franco, Tajadura-Jiménez, Florencio and Zhang.","Auditory perception; Auditory training; Cross-modal perception; Cross-modal plasticity; HRTF (head related transfer function); Spatial audio; Virtual reality","article; auditory stimulation; calibration; head; hearing; human; learning; plasticity; virtual reality",Article,"Final","",Scopus,2-s2.0-85041845498
"Li X., Yi W., Chi H.-L., Wang X., Chan A.P.C.","57193211001;55125204800;35096047900;8945580300;56844258500;","A critical review of virtual and augmented reality (VR/AR) applications in construction safety",2018,"Automation in Construction","86",,,"150","162",,176,"10.1016/j.autcon.2017.11.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034043364&doi=10.1016%2fj.autcon.2017.11.003&partnerID=40&md5=2ee7532a8fe659b1dda070548e3767b4","Department of Building and Real Estate, The Hong Kong Polytechnic University, Hong Kong; School of Engineering and Advanced Technology, College of Sciences, Massey University, New Zealand; The Australasian Joint Research Centre for Building Information Modelling, School of Built Environment, Curtin University, Perth, Australia; The International Scholar, Department of Housing and Interior Design, Kyung Hee University, Australia","Li, X., Department of Building and Real Estate, The Hong Kong Polytechnic University, Hong Kong; Yi, W., School of Engineering and Advanced Technology, College of Sciences, Massey University, New Zealand; Chi, H.-L., Department of Building and Real Estate, The Hong Kong Polytechnic University, Hong Kong; Wang, X., The Australasian Joint Research Centre for Building Information Modelling, School of Built Environment, Curtin University, Perth, Australia, The International Scholar, Department of Housing and Interior Design, Kyung Hee University, Australia; Chan, A.P.C., Department of Building and Real Estate, The Hong Kong Polytechnic University, Hong Kong","Construction is a high hazard industry which involves many factors that are potentially dangerous to workers. Safety has always been advocated by many construction companies, and they have been working hard to make sure their employees are protected from fatalities and injuries. With the advent of Virtual and Augmented Reality (VR/AR), there has been a witnessed trend of capitalizing on sophisticated immersive VR/AR applications to create forgiving environments for visualizing complex workplace situations, building up risk-preventive knowledge and undergoing training. To better understand the state-of-the-art of VR/AR applications in construction safety (VR/AR-CS) and from which to uncover the related issues and propose possible improvements, this paper starts with a review and synthesis of research evidence for several VR/AR prototypes, products and the related training and evaluation paradigms. Predicated upon a wide range of well-acknowledged scholarly journals, this paper comes up with a generic taxonomy consisting of VR/AR technology characteristics, application domains, safety scenarios and evaluation methods. According to this taxonomy, a number of technical features and types that could be implemented in the context of construction safety enhancement are derived and further elaborated, while significant application domains and trends regarding the VR/AR-CS research are generalized, i.e., hazards recognition and identification, safety training and education, safety instruction and inspection, and so on. Last but not least, this study sets forth a list of gaps derived from the in-depth review and comes up with the prospective research works. It is envisioned that the outcomes of this paper could assist both researchers and industrial practitioners with appreciating the research and practice frontier of VR/AR-CS and soliciting the latest VR/AR applications. © 2017 Elsevier B.V.","Augmented reality; Construction; Review; Safety; Virtual reality","Accident prevention; Augmented reality; Construction; Construction industry; Hazards; Industrial research; Occupational risks; Petroleum reservoir evaluation; Reviews; Taxonomies; Construction companies; Construction safety; Evaluation methods; Industrial practitioners; Safety instructions; Scholarly journals; Technology characteristics; Virtual and augmented reality; Virtual reality",Article,"Final","",Scopus,2-s2.0-85034043364
"Chittaro L., Corbett C.L., McLean G.A., Zangrando N.","7004119007;7102781291;57196262227;36172681100;","Safety knowledge transfer through mobile virtual reality: A study of aviation life preserver donning",2018,"Safety Science","102",,,"159","168",,35,"10.1016/j.ssci.2017.10.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032438643&doi=10.1016%2fj.ssci.2017.10.012&partnerID=40&md5=7748b44406f111c455481c472e4b9707","Human-Computer Interaction Lab (HCI Lab), University of Udine, Italy; Prime Stratagem, LLC, United States","Chittaro, L., Human-Computer Interaction Lab (HCI Lab), University of Udine, Italy; Corbett, C.L., Prime Stratagem, LLC, United States; McLean, G.A., Prime Stratagem, LLC, United States; Zangrando, N., Human-Computer Interaction Lab (HCI Lab), University of Udine, Italy","Aviation safety knowledge is a key factor in determining how passengers will respond in an emergency, but the effectiveness of the tools (preflight safety briefing, safety briefing card) used by airlines to educate passengers about safety has been shown to be lacking. This paper explores how one of these tools could be made interactive in order to increase its effectiveness. In particular, we use Virtual Reality (VR) techniques, adapting them to the constraints imposed by on-board aircraft use, such as usage on non-immersive, small displays. As a practical application, the paper examines aviation life preserver donning, which the literature has shown to be particularly difficult for passengers. To evaluate the proposed mobile VR tool, we contrasted it with the traditional safety briefing card in a between-groups study with 68 participants, age 20–24, focusing on different aspects of effectiveness. The results of the study show that the participants who used the mobile VR tool were able to transfer the presented safety knowledge to the real world, and don an aviation life preserver significantly faster and with fewer errors than participants who used the traditional briefing card. Moreover, these objective results were consistent with subjective ratings by participants; the mobile VR tool was perceived as significantly more engaging, simpler, and more effective than the traditional briefing card. Finally, participants who used the mobile VR tool attained a higher level of self-efficacy. The generalizability of these results would benefit with additional work aimed at an older age cohort that would ostensibly be less familiar with interactive VR technology. © 2017 Elsevier Ltd","Aviation safety; Mobile devices; Safety education; Safety training; Virtual reality","Fighter aircraft; Knowledge management; Mobile devices; Safety engineering; Training aircraft; Transportation; Virtual reality; Aviation safety; Safety education; Safety knowledge; Safety training; Self efficacy; Small display; Subjective rating; VR technology; Safety factor; adult; aircraft; analytical error; Article; aviation; briefing card; clinical effectiveness; controlled study; female; human; knowledge; male; priority journal; self concept; simulation training; traffic safety; virtual reality; young adult",Article,"Final","",Scopus,2-s2.0-85032438643
"Casini A.E.M., Maggiore P., Viola N., Basso V., Ferrino M., Hoffman J.A., Cowley A.","57193775513;6506233007;6505893349;8412338000;35781647500;7402611619;26537038800;","Analysis of a Moon outpost for Mars enabling technologies through a Virtual Reality environment",2018,"Acta Astronautica","143",,,"353","361",,12,"10.1016/j.actaastro.2017.11.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037537507&doi=10.1016%2fj.actaastro.2017.11.023&partnerID=40&md5=20469db8480ade152049704aa49c10dc","Department of Mechanical and Aerospace Engineering (DIMEAS), Politecnico di Torino, Corso Duca degli Abruzzi 24, Torino, TO  10129, Italy; Thales Alenia Space - Italia (TAS-I), Strada Antica di Collegno 253, Torino, TO  10146, Italy; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology (MIT), 77 Massachusetts Avenue, Cambridge, MA  02139, United States; European Astronaut Centre (EAC), European Space Agency (ESA), Linder Höhe, Cologne, D-51147, Germany","Casini, A.E.M., Department of Mechanical and Aerospace Engineering (DIMEAS), Politecnico di Torino, Corso Duca degli Abruzzi 24, Torino, TO  10129, Italy; Maggiore, P., Department of Mechanical and Aerospace Engineering (DIMEAS), Politecnico di Torino, Corso Duca degli Abruzzi 24, Torino, TO  10129, Italy; Viola, N., Department of Mechanical and Aerospace Engineering (DIMEAS), Politecnico di Torino, Corso Duca degli Abruzzi 24, Torino, TO  10129, Italy; Basso, V., Thales Alenia Space - Italia (TAS-I), Strada Antica di Collegno 253, Torino, TO  10146, Italy; Ferrino, M., Thales Alenia Space - Italia (TAS-I), Strada Antica di Collegno 253, Torino, TO  10146, Italy; Hoffman, J.A., Department of Aeronautics and Astronautics, Massachusetts Institute of Technology (MIT), 77 Massachusetts Avenue, Cambridge, MA  02139, United States; Cowley, A., European Astronaut Centre (EAC), European Space Agency (ESA), Linder Höhe, Cologne, D-51147, Germany","The Moon is now being considered as the starting point for human exploration of the Solar System beyond low-Earth orbit. Many national space agencies are actively advocating to build up a lunar surface habitat capability starting from 2030 or earlier: according to ESA Technology Roadmaps for Exploration this should be the result of a broad international cooperation. Taking into account an incremental approach to reduce risks and costs of space missions, a lunar outpost can be considered as a test bed towards Mars, allowing to validate enabling technologies, such as water processing, waste management, power generation and storage, automation, robotics and human factors. Our natural satellite is rich in resources that could be used to pursue such a goal through a necessary assessment of ISRU techniques. The aim of this research is the analysis of a Moon outpost dedicated to the validation of enabling technologies for human space exploration. The main building blocks of the outpost are identified and feasible evolutionary scenarios are depicted, to highlight the incremental steps to build up the outpost. Main aspects that are dealt with include outpost location and architecture, as well as ISRU facilities, which in a far term future can help reduce the mass at launch, by producing hydrogen and oxygen for consumables, ECLSS, and propellant for Earth-Moon sorties and Mars journeys. A test outpost is implemented in a Virtual Reality (VR) environment as a first proof-of-concepts, where the elements are computer-based mock-ups. The VR facility has a first-person interactive perspective, allowing for specific in-depth analyses of ergonomics and operations. The feedbacks of these analyses are crucial to highlight requirements that might otherwise be overlooked, while their general outputs are fundamental to write down procedures. Moreover, the mimic of astronauts' EVAs is useful for pre-flight training, but can also represent an additional tool for failures troubleshooting during the flight controllers' nominal operations. Additionally, illumination maps have been obtained to study the light conditions, which are essential parameters to assess the base elements location. This unique simulation environment may offer the largest suite of benefits during the design and development phase, as it allows to design future systems to optimize operations, thus maximizing the mission's scientific return, and to enhance the astronauts training, by saving time and cost. The paper describes how a virtual environment could help to design a Moon outpost for an incremental architecture strategy towards Mars missions. © 2017 IAA","Illumination analysis; Incremental exploration architecture; Moon outpost; Virtual Reality","Automation; Earth (planet); Ergonomics; International cooperation; Interplanetary flight; Lunar missions; Manned space flight; Martian surface analysis; Orbits; Satellites; Solar system; Space flight; Space power generation; Space research; Technology transfer; Virtual reality; Waste management; Design and Development; Enabling technologies; Human space explorations; Illumination analysis; Incremental approach; Incremental exploration; Simulation environment; Virtual-reality environment; Moon",Article,"Final","",Scopus,2-s2.0-85037537507
"Ip H.H.S., Wong S.W.L., Chan D.F.Y., Byrne J., Li C., Yuan V.S.N., Lau K.S.Y., Wong J.Y.W.","7005395690;35095800900;7402216810;55327177600;56180363500;57190301256;56014513500;57190292326;","Enhance emotional and social adaptation skills for children with autism spectrum disorder: A virtual reality enabled approach",2018,"Computers and Education","117",,,"1","15",,52,"10.1016/j.compedu.2017.09.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034031316&doi=10.1016%2fj.compedu.2017.09.010&partnerID=40&md5=5461287673669e8bfbf4e12a366653f0","Centre for Innovative Applications of Internet and Multimedia Technologies, City University of Hong Kong, Kowloon Tong, Hong Kong; Department of Education Studies, Hong Kong Baptist University, Kowloon Tong, Hong Kong; Department of Paediatrics, Faculty of Medicine, The Chinese University of Hong Kong, Shatin, Hong Kong","Ip, H.H.S., Centre for Innovative Applications of Internet and Multimedia Technologies, City University of Hong Kong, Kowloon Tong, Hong Kong; Wong, S.W.L., Department of Education Studies, Hong Kong Baptist University, Kowloon Tong, Hong Kong; Chan, D.F.Y., Department of Paediatrics, Faculty of Medicine, The Chinese University of Hong Kong, Shatin, Hong Kong; Byrne, J., Centre for Innovative Applications of Internet and Multimedia Technologies, City University of Hong Kong, Kowloon Tong, Hong Kong; Li, C., Centre for Innovative Applications of Internet and Multimedia Technologies, City University of Hong Kong, Kowloon Tong, Hong Kong; Yuan, V.S.N., Centre for Innovative Applications of Internet and Multimedia Technologies, City University of Hong Kong, Kowloon Tong, Hong Kong; Lau, K.S.Y., Centre for Innovative Applications of Internet and Multimedia Technologies, City University of Hong Kong, Kowloon Tong, Hong Kong; Wong, J.Y.W., Centre for Innovative Applications of Internet and Multimedia Technologies, City University of Hong Kong, Kowloon Tong, Hong Kong","Deficits in social-emotional reciprocity, one of the diagnostic criteria of Autism Spectrum Disorder (ASD), greatly hinders children with ASD from responding appropriately and adapting themselves in various social situations. Although evidences have shown that virtual reality environment is a promising tool for emotional and social adaptation skills training on ASD population, there is a lack of large-scale trials with intensive evaluations to support such findings. This paper presents a virtual reality enabled program for enhancing emotional and social adaptation skills for children with ASD. Six unique learning scenarios, of which one focuses on emotion control and relaxation strategies, four that simulate various social situations, and one that facilitates consolidation and generalization, are designed and developed with corresponding psychoeducation procedures and protocols. The learning scenarios are presented to the children via a 4-side immersive virtual reality environment (a.k.a., half-CAVE) with non-intrusive motion tracking. A total number of 94 children between the ages of 6–12 with clinical diagnosis of ASD participated in the 28-session program that lasted for 14 weeks. By comparing pre- and post-assessments, results reported in this paper show significant improvements in the project's primary measures on children's emotion expression and regulation and social-emotional reciprocity but not on other secondary measures. © 2017 Elsevier Ltd","Autism spectrum disorders; Emotional skills; Situated learning; Social adaptation; Virtual reality","Diagnosis; Diseases; Motion tracking; Program diagnostics; Social aspects; Autism spectrum disorders; Children with autisms; Emotional skills; Immersive virtual reality; Relaxation strategies; Situated learning; Social adaptation; Virtual-reality environment; Virtual reality",Article,"Final","",Scopus,2-s2.0-85034031316
"Dehn L.B., Kater L., Piefke M., Botsch M., Driessen M., Beblo T.","55893825700;57192807227;6507173176;6602523499;56056374100;55978325200;","Training in a comprehensive everyday-like virtual reality environment compared to computerized cognitive training for patients with depression",2018,"Computers in Human Behavior","79",,,"40","52",,15,"10.1016/j.chb.2017.10.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032007894&doi=10.1016%2fj.chb.2017.10.019&partnerID=40&md5=2353908903251aac94bfb95d545d8767","Clinic for Psychiatry and Psychotherapy Bethel, Remterweg 69-71, Bielefeld, D-33617, Germany; Clinic of Internal and Geriatric Medicine, Schildische Str. 99, Bielefeld, D-33611, Germany; Department of Psychology and Psychotherapy, Witten/Herdecke University, Alfred-Herrhausen-Str. 50, Witten, D-58448, Germany; Computer Graphics and Geometry Processing, Bielefeld University, P.O. Box 10 01 31, Bielefeld, D-33501, Germany","Dehn, L.B., Clinic for Psychiatry and Psychotherapy Bethel, Remterweg 69-71, Bielefeld, D-33617, Germany; Kater, L., Clinic of Internal and Geriatric Medicine, Schildische Str. 99, Bielefeld, D-33611, Germany; Piefke, M., Department of Psychology and Psychotherapy, Witten/Herdecke University, Alfred-Herrhausen-Str. 50, Witten, D-58448, Germany; Botsch, M., Computer Graphics and Geometry Processing, Bielefeld University, P.O. Box 10 01 31, Bielefeld, D-33501, Germany; Driessen, M., Computer Graphics and Geometry Processing, Bielefeld University, P.O. Box 10 01 31, Bielefeld, D-33501, Germany; Beblo, T., Clinic for Psychiatry and Psychotherapy Bethel, Remterweg 69-71, Bielefeld, D-33617, Germany","Neurocognitive impairments in patients with depression compromise everyday functioning. Thus, should neuropsychological therapy be designed as real-life-like as possible to maximize transfer effects? We investigated whether ecological validity of computerized cognitive training could be increased by a comprehensive everyday-life-simulating training device combining virtual reality, 360°-all-around visibility and autonomous navigation motions. In an eight days training program, patients exercised the learning and purchasing of shopping list products in a virtual supermarket using either the novel training device (n = 21) or a corresponding desktop application (n = 17). In a pre-post-design, effects of the two training conditions were compared regarding several outcome measures. Altogether, results did not prove a benefit of the more naturalistic training setting regarding different training performances (recognition, performance speed, spatial orientation), self-perceived daily cognitive impairments, a real-life shopping task as well as various neuropsychological capabilities. Findings are discussed in the context of general challenges in striving after ecological validity in neuropsychology. © 2017 Elsevier Ltd","Cognitive impairment; Cognitive remediation; Computerized training; Depression; Ecological validity; Virtual reality","Application programs; Ecology; Virtual reality; Autonomous navigation; Cognitive impairment; Depression; Desktop applications; Ecological validity; Spatial orientations; Training conditions; Virtual-reality environment; E-learning",Article,"Final","",Scopus,2-s2.0-85032007894
"Rus-Calafell M., Garety P., Sason E., Craig T.J.K., Valmaggia L.R.","35094538900;7004167371;57195105778;55243134200;23006795600;","Virtual reality in the assessment and treatment of psychosis: A systematic review of its utility, acceptability and effectiveness",2018,"Psychological Medicine","48","3",,"362","391",,59,"10.1017/S0033291717001945","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025459856&doi=10.1017%2fS0033291717001945&partnerID=40&md5=53842339e061dc473278c927a1ab6c8c","King's College London, Institute of Psychiatry Psychology and Neuroscience, PO 77, De Crespigny Park, London, SE5 8AF, United Kingdom; South London and Maudsley NHS Trust, London, United Kingdom","Rus-Calafell, M., King's College London, Institute of Psychiatry Psychology and Neuroscience, PO 77, De Crespigny Park, London, SE5 8AF, United Kingdom, South London and Maudsley NHS Trust, London, United Kingdom; Garety, P., King's College London, Institute of Psychiatry Psychology and Neuroscience, PO 77, De Crespigny Park, London, SE5 8AF, United Kingdom, South London and Maudsley NHS Trust, London, United Kingdom; Sason, E., King's College London, Institute of Psychiatry Psychology and Neuroscience, PO 77, De Crespigny Park, London, SE5 8AF, United Kingdom; Craig, T.J.K., King's College London, Institute of Psychiatry Psychology and Neuroscience, PO 77, De Crespigny Park, London, SE5 8AF, United Kingdom, South London and Maudsley NHS Trust, London, United Kingdom; Valmaggia, L.R., King's College London, Institute of Psychiatry Psychology and Neuroscience, PO 77, De Crespigny Park, London, SE5 8AF, United Kingdom, South London and Maudsley NHS Trust, London, United Kingdom","Over the last two decades, there has been a rapid increase of studies testing the efficacy and acceptability of virtual reality in the assessment and treatment of mental health problems. This systematic review was carried out to investigate the use of virtual reality in the assessment and the treatment of psychosis. Web of Science, PsychInfo, EMBASE, Scopus, ProQuest and PubMed databases were searched, resulting in the identification of 638 articles potentially eligible for inclusion; of these, 50 studies were included in the review. The main fields of research in virtual reality and psychosis are: safety and acceptability of the technology; neurocognitive evaluation; functional capacity and performance evaluation; assessment of paranoid ideation and auditory hallucinations; and interventions. The studies reviewed indicate that virtual reality offers a valuable method of assessing the presence of symptoms in ecologically valid environments, with the potential to facilitate learning new emotional and behavioural responses. Virtual reality is a promising method to be used in the assessment of neurocognitive deficits and the study of relevant clinical symptoms. Furthermore, preliminary findings suggest that it can be applied to the delivery of cognitive rehabilitation, social skills training interventions and virtual reality-assisted therapies for psychosis. The potential benefits for enhancing treatment are highlighted. Recommendations for future research include demonstrating generalisability to real-life settings, examining potential negative effects, larger sample sizes and long-term follow-up studies. The present review has been registered in the PROSPERO register: CDR 4201507776. Copyright © Cambridge University Press 2017.","Hallucinations; neuropsychology; paranoia; psychosis; schizophrenia; social functioning; systematic review; virtual reality","computer interface; human; patient attitude; patient safety; psychosis; randomized controlled trial (topic); virtual reality exposure therapy; Humans; Patient Acceptance of Health Care; Patient Safety; Psychotic Disorders; Randomized Controlled Trials as Topic; User-Computer Interface; Virtual Reality Exposure Therapy",Article,"Final","",Scopus,2-s2.0-85025459856
"Ankomah P., Vangorp P.","57217224949;18435394900;","Virtual reality: A literature review and metrics-based classification",2018,"Computer Graphics and Visual Computing, CGVC 2018",,,,"173","181",,,"10.2312/cgvc.20181222","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086820445&doi=10.2312%2fcgvc.20181222&partnerID=40&md5=67913b689e62c8521ffe6266f4e15c46","Edge Hill University, United Kingdom","Ankomah, P., Edge Hill University, United Kingdom; Vangorp, P., Edge Hill University, United Kingdom","This paper presents a multi-disciplinary overview of research evaluating virtual reality (VR). The main aim is to review and classify VR research based on several metrics: presence and immersion, navigation and interaction, knowledge improvement, performance and usability. With the continuous development and consumerisation of VR, several application domains have studied the impact of VR as an enhanced alternative environment for performing tasks. However, VR experiment results often cannot be generalised but require specific datasets and tasks suited to each domain. This review and classification of VR metrics presents an alternative metrics-based view of VR experiments and research. © 2018 The Author(s) Eurographics Proceedings © 2018 The Eurographics Association.",,"Consumerisation; Continuous development; Literature reviews; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85086820445
"Sampaio A.Z.","35609919400;","Education in engineering: Bim and VR technologies improving collaborative projects",2018,"EUCEET 2018 - 4th International Conference on Civil Engineering Education: Challenges for the Third Millennium",,,,"48","57",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088275381&partnerID=40&md5=38f979b5018bc196a916d87bf260165d","University of Lisbon, IST, Dep. Civil Engineering, Av. Rovisco Pais, Lisbon, 1049-001, Portugal","Sampaio, A.Z., University of Lisbon, IST, Dep. Civil Engineering, Av. Rovisco Pais, Lisbon, 1049-001, Portugal","Building Information Modelling (BIM) is defined as the process of generating, storing, managing, exchanging, and sharing building information. The potential of BIM methodology to support a transformation of the processes of design and construction has been evident in the construction industry. A current topic that requires attention is the integration of BIM with Virtual Reality (VR) where the user visualizes a virtual world through interactive devices or a total immersion. VR combines several devices for interaction, creating virtual environment, and this must followed by studies concerning how to use devices or how to establish links for the presentation of information contained in a BIM model. By adding VR, the BIM solution can address retrieving and presenting information and increasing efficiency on communication and problem solving in an interactive and collaborative project. BIM + VR allow two main capacities: walkthrough and consulting data, and currently BIM tools allow links to VR plugins in order to achieve both capacities. As such, it is expected to be further explored in the near future. The text presents a review of actual perspective of the VR use applied over 3D/BIM models to supports multi-dimensional BIM applications, namely, 4D/BIM and 7D/BIM models. The objective of the study is to report the improvement of BIM uses with the addition of interactive capacities allowed by VR technology. Being the school the main actor in the formation of new engineers, it has the mission prepare students for the professional activity, giving the most advanced technology knowhow allowing them to make a difference in the job market. © 2018 EUCEET 2018 - 4th International Conference on Civil Engineering Education: Challenges for the Third Millennium. All rights reserved.","BIM methodology; Construction; Education; Maintenance; VR technology","Architectural design; Construction industry; Education computing; Engineering education; Engineers; Technology transfer; Three dimensional computer graphics; Advanced technology; Building Information Modelling; Collaborative projects; Design and construction; Education in engineerings; Multi dimensional; Presenting informations; Professional activities; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85088275381
"Doniger G.M., Beeri M.S., Bahar-Fuchs A., Gottlieb A., Tkachov A., Kenan H., Livny A., Bahat Y., Sharon H., Ben-Gal O., Cohen M., Zeilig G., Plotnik M.","6507913418;55664808600;24068290900;57195223683;57201615263;57201616398;57189464305;25926895000;36614758100;57197727270;57201616049;6701802378;6603202801;","Virtual reality-based cognitive-motor training for middle-aged adults at high Alzheimer's disease risk: A randomized controlled trial",2018,"Alzheimer's and Dementia: Translational Research and Clinical Interventions","4",,,"118","129",,28,"10.1016/j.trci.2018.02.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045377385&doi=10.1016%2fj.trci.2018.02.005&partnerID=40&md5=ec7cee9f2f2fad023982a4168a65d80c","Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel; Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel; Baruch Ivcher School of Psychology, Interdisciplinary Center (IDC) Herzliya, Herzliya, Israel; Department of Psychiatry, The Icahn School of Medicine at Mount Sinai, New York, NY, United States; Center for Research on Aging, Health, and Wellbeing, Research School of Population Health, The Australian National University, Canberra, ACT, Australia; The Academic Unit for Psychiatry of Old Age, Department of Psychiatry, The University of Melbourne, Victoria, Australia; Sackler Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel; Department of Diagnostic Imaging, Sheba Medical Center, Ramat Gan, Israel; Department of Neurological Rehabilitation, Sheba Medical Center, Ramat Gan, Israel; Department of Physiology and Pharmacology, Sackler Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel; Sagol School of Neuroscience, Tel Aviv University, Tel Aviv, Israel","Doniger, G.M., Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel, Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel, Baruch Ivcher School of Psychology, Interdisciplinary Center (IDC) Herzliya, Herzliya, Israel; Beeri, M.S., Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel, Baruch Ivcher School of Psychology, Interdisciplinary Center (IDC) Herzliya, Herzliya, Israel, Department of Psychiatry, The Icahn School of Medicine at Mount Sinai, New York, NY, United States; Bahar-Fuchs, A., Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel, Center for Research on Aging, Health, and Wellbeing, Research School of Population Health, The Australian National University, Canberra, ACT, Australia, The Academic Unit for Psychiatry of Old Age, Department of Psychiatry, The University of Melbourne, Victoria, Australia; Gottlieb, A., Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel; Tkachov, A., Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel; Kenan, H., Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel; Livny, A., Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel, Sackler Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel, Department of Diagnostic Imaging, Sheba Medical Center, Ramat Gan, Israel; Bahat, Y., Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel; Sharon, H., Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel; Ben-Gal, O., Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel; Cohen, M., Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel, Joseph Sagol Neuroscience Center, Sheba Medical Center, Ramat Gan, Israel; Zeilig, G., Sackler Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel, Department of Neurological Rehabilitation, Sheba Medical Center, Ramat Gan, Israel; Plotnik, M., Center of Advanced Technologies in Rehabilitation, Sheba Medical Center, Ramat Gan, Israel, Department of Physiology and Pharmacology, Sackler Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel, Sagol School of Neuroscience, Tel Aviv University, Tel Aviv, Israel","Introduction: Ubiquity of Alzheimer's disease (AD) coupled with relatively ineffectual pharmacologic treatments has spurred interest in nonpharmacologic lifestyle interventions for prevention or risk reduction. However, evidence of neuroplasticity notwithstanding, there are few scientifically rigorous, ecologically relevant brain training studies focused on building cognitive reserve in middle age to protect against cognitive decline. This pilot study will examine the ability of virtual reality (VR) cognitive training to improve cognition and cerebral blood flow (CBF) in middle-aged individuals at high AD risk due to parental history. Methods: The design is an assessor-blind, parallel group, randomized controlled trial of VR cognitive-motor training in middle-aged adults with AD family history. The experimental group will be trained with adaptive “real-world” VR tasks targeting sustained and selective attention, working memory, covert rule deduction, and planning, while walking on a treadmill. One active control group will perform the VR tasks without treadmill walking; another will walk on a treadmill while watching scientific documentaries (nonspecific cognitive stimulation). A passive (waitlist) control group will not receive training. Training sessions will be 45 minutes, twice/week for 12 weeks. Primary outcomes are global cognition and CBF (from arterial spin labeling [ASL]) at baseline, immediately after training (training gain), and 3 months post-training (maintenance gain). We aim to recruit 125 participants, including 20 passive controls and 35 in the other groups. Discussion: Current pharmacologic therapies are for symptomatic AD patients, whereas nonpharmacologic training is administrable before symptom onset. Emerging evidence suggests that cognitive training improves cognitive function. However, a more ecologically valid cognitive-motor VR setting that better mimics complex daily activities may augment transfer of trained skills. VR training has benefited clinical cohorts, but benefit in asymptomatic high-risk individuals is unknown. If effective, this trial may help define a prophylactic regimen for AD, adaptable for home-based application in high-risk individuals. © 2018 The Authors","Alzheimer's disease; Arterial spin labeling; Cerebral blood flow; Cognition; Cognitive training; MRI; Neuroplasticity; Prevention; Virtual reality","adult; age; Alzheimer disease; arterial spin labeling; Article; brain blood flow; cognition; cognitive reserve; controlled study; daily life activity; high risk patient; human; major clinical study; middle aged; motor performance; nerve cell plasticity; nerve degeneration; nuclear magnetic resonance imaging; outcome assessment; pilot study; priority journal; prospective study; quality of life; randomized controlled trial; selective attention; software design; training; transfer of learning; virtual reality; walking; working memory",Article,"Final","",Scopus,2-s2.0-85045377385
"Discher S., Masopust L., Schulz S., Richter R., Döllner J.","54580703900;57203454864;57203460069;36195159400;6602981892;","A point-based and image-based multi-pass rendering technique for visualizing massive 3D point clouds in VR environments",2018,"Journal of WSCG","26","2",,"76","84",,4,"10.24132/JWSCG.2018.26.2.2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051790175&doi=10.24132%2fJWSCG.2018.26.2.2&partnerID=40&md5=d2bf1c659270f30ccdb79203d3076cc2","Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Straße 2-3, Potsdam, 14482, Germany","Discher, S., Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Straße 2-3, Potsdam, 14482, Germany; Masopust, L., Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Straße 2-3, Potsdam, 14482, Germany; Schulz, S., Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Straße 2-3, Potsdam, 14482, Germany; Richter, R., Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Straße 2-3, Potsdam, 14482, Germany; Döllner, J., Hasso Plattner Institute, University of Potsdam, Prof.-Dr.-Helmert-Straße 2-3, Potsdam, 14482, Germany","Real-time rendering for 3D point clouds allows for interactively exploring and inspecting real-world assets, sites, or regions on a broad range of devices but has to cope with their vastly different computing capabilities. Virtual reality (VR) applications rely on high frame rates (i.e., around 90 fps as opposed to 30 - 60 fps) and show high sensitivity to any kind of visual artifacts, which are typical for 3D point cloud depictions (e.g., holey surfaces or visual clutter due to inappropriate point sizes). We present a novel rendering system that allows for an immersive, nausea-free exploration of arbitrary large 3D point clouds on state-of-the-art VR devices such as HTC Vive and Oculus Rift. Our approach applies several point-based and image-based rendering techniques that are combined using a multipass rendering pipeline. The approach does not require to derive generalized, mesh-based representations in a preprocessing step and preserves precision and density of the raw 3D point cloud data. The presented techniques have been implemented and evaluated with massive real-world data sets from aerial, mobile, and terrestrial acquisition campaigns containing up to 2.6 billion points to show the practicability and scalability of our approach. © 2018, Vaclav Skala Union Agency. All rights reserved.","3D point clouds; Real-time rendering; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85051790175
"Habgood J., Moore D., Alapont S., Ferguson C., Oostendorp H.","57070173700;57213311788;57197781258;57205183842;56764325100;","The reveal educational environmental narrative framework for playstation vr",2018,"Proceedings of the European Conference on Games-based Learning","2018-October",,,"175","183",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058978973&partnerID=40&md5=e1870e35e65d3ebc481a098bc61309f6","Steel Minions Game Studio, Sheffield Hallam University, Sheffield, United Kingdom; Institute of Information and Computing Sciences, Utrecht University, Netherlands","Habgood, J., Steel Minions Game Studio, Sheffield Hallam University, Sheffield, United Kingdom; Moore, D., Steel Minions Game Studio, Sheffield Hallam University, Sheffield, United Kingdom; Alapont, S., Steel Minions Game Studio, Sheffield Hallam University, Sheffield, United Kingdom; Ferguson, C., Institute of Information and Computing Sciences, Utrecht University, Netherlands; Oostendorp, H., Institute of Information and Computing Sciences, Utrecht University, Netherlands","The REVEAL project is pioneering the use of PlayStation VR for educational applications which engage audiences in Europe's rich scientific and cultural heritage. The REVEAL software framework facilitates the development of Educational Environmental Narrative (EEN) games in virtual reality for the PlayStation 4. The framework is composed of a set of software layers and editor plugins which augment an existing game engine technology (""The PhyreEngine"") and facilitate its transfer to educational applications. The PhyreEngine was created by Sony Interactive Entertainment Europe and is free and open source to registered PlayStation developers, including academic partners under the PlayStation First scheme. The REVEAL framework is built on top of the PhyreEngine and will be made similarly available to PlayStation developers through Sony Interactive Entertainment's developer network. This paper describes the functionality and design of the REVEAL framework, including its graph-based architecture, node-based locomotion system and high-resolution paper artefact rendering system. Key supporting tools are also described, including the Story Scaffolding Tool and its role in collecting detailed game analytics. The application of the framework is illustrated through an EEN case study application based on the life of Dr. Edward Jenner: the 18th century scientist credited with the discovery of vaccination. Finally, we discuss how we will empirically evaluate the effectiveness of a VR application and its components. © 2018, Dechema e.V. All rights reserved.","Environmental narrative games; Game-based learning; Virtual reality","Computer programming; Graphic methods; Open source software; Scaffolds; Virtual reality; Cultural heritages; Educational Applications; Environmental narrative games; Game-based Learning; Interactive entertainment; Locomotion system; Rendering system; Software frameworks; Application programs",Conference Paper,"Final","",Scopus,2-s2.0-85058978973
"Lee G.I., Lee M.R.","16022478000;56126544100;","Can a virtual reality surgical simulation training provide a self-driven and mentor-free skills learning? Investigation of the practical influence of the performance metrics from the virtual reality robotic surgery simulator on the skill learning and associated cognitive workloads",2018,"Surgical Endoscopy","32","1",,"62","72",,16,"10.1007/s00464-017-5634-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021127892&doi=10.1007%2fs00464-017-5634-6&partnerID=40&md5=c98aaa8ff23cc0ff7e7daeaf55a61487","Department of Surgery, Johns Hopkins University School of Medicine, 600 North Wolfe Street Blalock 1204, Baltimore, MD  21287, United States","Lee, G.I., Department of Surgery, Johns Hopkins University School of Medicine, 600 North Wolfe Street Blalock 1204, Baltimore, MD  21287, United States; Lee, M.R., Department of Surgery, Johns Hopkins University School of Medicine, 600 North Wolfe Street Blalock 1204, Baltimore, MD  21287, United States","Background: While it is often claimed that virtual reality (VR) training system can offer self-directed and mentor-free skill learning using the system’s performance metrics (PM), no studies have yet provided evidence-based confirmation. This experimental study investigated what extent to which trainees achieved their self-learning with a current VR simulator and whether additional mentoring improved skill learning, skill transfer and cognitive workloads in robotic surgery simulation training. Methods: Thirty-two surgical trainees were randomly assigned to either the Control-Group (CG) or Experiment-Group (EG). While the CG participants reviewed the PM at their discretion, the EG participants had explanations about PM and instructions on how to improve scores. Each subject completed a 5-week training using four simulation tasks. Pre- and post-training data were collected using both a simulator and robot. Peri-training data were collected after each session. Skill learning, time spent on PM (TPM), and cognitive workloads were compared between groups. Results: After the simulation training, CG showed substantially lower simulation task scores (82.9 ± 6.0) compared with EG (93.2 ± 4.8). Both groups demonstrated improved physical model tasks performance with the actual robot, but the EG had a greater improvement in two tasks. The EG exhibited lower global mental workload/distress, higher engagement, and a better understanding regarding using PM to improve performance. The EG’s TPM was initially long but substantially shortened as the group became familiar with PM. Conclusion: Our study demonstrated that the current VR simulator offered limited self-skill learning and additional mentoring still played an important role in improving the robotic surgery simulation training. © 2017, Springer Science+Business Media, LLC.","Mentoring; Performance metrics; Robotic surgery; Simulation; Training; Virtual reality","adult; Article; cognition; controlled study; human; learning; physical model; priority journal; resident; robot assisted surgery; simulation training; surgical training; task performance; virtual reality; workload; clinical competence; cognition; education; medical education; mentor; mentoring; procedures; questionnaire; robotic surgical procedure; simulation training; statistics and numerical data; Adult; Clinical Competence; Cognition; Humans; Internship and Residency; Mentoring; Mentors; Robotic Surgical Procedures; Simulation Training; Surveys and Questionnaires; Virtual Reality; Workload",Article,"Final","",Scopus,2-s2.0-85021127892
"Yu R., Bowman D.A.","57194156709;57203231782;","Force Push: Exploring expressive gesture-to-force mappings for remote object manipulation in virtual reality",2018,"Frontiers in ICT","5","SEP", 25,"","",,2,"10.3389/fict.2018.00025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062438355&doi=10.3389%2ffict.2018.00025&partnerID=40&md5=3987dec276a6c82ab4e4052eff44f795","Center for Human-Computer Interaction, Virginia Tech, Blacksburg, VA, United States; Department of Computer Science, Virginia Tech, Blacksburg, VA, United States","Yu, R., Center for Human-Computer Interaction, Virginia Tech, Blacksburg, VA, United States, Department of Computer Science, Virginia Tech, Blacksburg, VA, United States; Bowman, D.A., Center for Human-Computer Interaction, Virginia Tech, Blacksburg, VA, United States, Department of Computer Science, Virginia Tech, Blacksburg, VA, United States","This paper presents Force Push, a novel gesture-based interaction technique for remote object manipulation in virtual reality (VR). Inspired by the design of magic powers in popular culture, Force Push uses intuitive hand gestures to drive physics-based movement of the object. Using a novel algorithm that dynamically maps rich features of hand gestures to the properties of the physics simulation, both coarse-grained ballistic movements and fine-grained refinement movements can be achieved seamlessly and naturally. An initial user study of a limited translation task showed that, although its gesture-to-force mapping is inherently harder to control than traditional position-to-position mappings, Force Push is usable even for extremely difficult tasks. Direct position-to-position control outperformed Force Push when the initial distance between the object and the target was close relative to the required accuracy; however, the gesture-based method began to show promising results when they were far away from each other. As for subjective user experience, Force Push was perceived as more natural and fun to use, even though its controllability and accuracy were thought to be inferior to direct control. This paper expands the design space of object manipulation beyond mimicking reality, and provides hints on using magical gestures and physics-based techniques for higher usability and hedonic qualities in user experience. © 2018 Yu and Bowman.","Controllability; Hand gesture; Object manipulation; Physics-based manipulation; Transfer function; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85062438355
"Loch F., Ziegler U., Vogel-Heuser B.","55193685600;57203760799;6603480302;","Integrating Haptic Interaction into a Virtual Training System for Manual Procedures in Industrial Environments",2018,"IFAC-PapersOnLine","51","11",,"60","65",,4,"10.1016/j.ifacol.2018.08.235","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052855877&doi=10.1016%2fj.ifacol.2018.08.235&partnerID=40&md5=4dd09d028ffbbd0208d11a259f82b266","Institute for Automation and Information Systems, Technical University of Munich, Garching, Germany","Loch, F., Institute for Automation and Information Systems, Technical University of Munich, Garching, Germany; Ziegler, U., Institute for Automation and Information Systems, Technical University of Munich, Garching, Germany; Vogel-Heuser, B., Institute for Automation and Information Systems, Technical University of Munich, Garching, Germany","Many virtual training systems have been proposed to address the increasing complexity of manufacturing environments. However, existing training systems focus on visual interaction and neglect the haptic sense, which is a crucial component of manual tasks. This paper introduces a concept for a virtual training system for industrial procedures that introduces physical components to improve the training process. Introducing physical components is expected to improve the efficiency of training systems by transporting a sense for the haptic properties of tools and components and facilitate the transfer of the skills to the real work environment. The system allows practicing physical tasks using real tools and components. The didactic concept is based on the idea of multimodal learning and provides an environment that allows active experimentation. The application of the concept in an exemplary procedure is demonstrated. © 2018","Adaptive systems; Haptic interaction; Human-machine interface; Interaction mechanisms; Maintenance; Training; Virtual reality","Adaptive systems; Haptic interfaces; Maintenance; Personnel training; Virtual addresses; Virtual reality; Active experimentation; Haptic interactions; Human Machine Interface; Industrial environments; Interaction mechanisms; Manufacturing environments; Multi-modal learning; Virtual training systems; E-learning",Article,"Final","",Scopus,2-s2.0-85052855877
"Oussi N., Loukas C., Kjellin A., Lahanas V., Georgiou K., Henningsohn L., Felländer-Tsai L., Georgiou E., Enochsson L.","57194698924;6603074122;6603625212;51461624800;57194035936;6602220634;6603715643;7004603021;6602469928;","Video analysis in basic skills training: a way to expand the value and use of BlackBox training?",2018,"Surgical Endoscopy","32","1",,"87","95",,4,"10.1007/s00464-017-5641-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021694410&doi=10.1007%2fs00464-017-5641-7&partnerID=40&md5=8c70caed3bf8dff5206663f361afcb6f","The Center for Advanced Medical Simulation and Training (CAMST), Karolinska University Hospital, Stockholm, Sweden; Division of Surgery, Department of Clinical ScienceIntervention and Technology (CLINTEC), Karolinska Institutet, Stockholm, Sweden; Center for Clinical Research Sörmland, Uppsala University, Uppsala, Sweden; Medical Physics Lab-Simulation Center, Medical School, National and Kapodistrian University of Athens, Athens, Greece; Division of Urology, Department of Clinical ScienceIntervention and Technology (CLINTEC), Karolinska Institutet, Stockholm, Sweden; Division of Orthopedics and Biotechnology, Department of Clinical ScienceIntervention and Technology (CLINTEC), Karolinska Institutet, Stockholm, Sweden; Division of Surgery, Department of Surgical and Perioperative Sciences, Umeå University, Umeå, Sweden; Division of Surgery, Department of Surgical and Perioperative Sciences, Umeå University, Luleå, 971 80, Sweden","Oussi, N., The Center for Advanced Medical Simulation and Training (CAMST), Karolinska University Hospital, Stockholm, Sweden, Division of Surgery, Department of Clinical ScienceIntervention and Technology (CLINTEC), Karolinska Institutet, Stockholm, Sweden, Center for Clinical Research Sörmland, Uppsala University, Uppsala, Sweden; Loukas, C., Medical Physics Lab-Simulation Center, Medical School, National and Kapodistrian University of Athens, Athens, Greece; Kjellin, A., The Center for Advanced Medical Simulation and Training (CAMST), Karolinska University Hospital, Stockholm, Sweden, Division of Surgery, Department of Clinical ScienceIntervention and Technology (CLINTEC), Karolinska Institutet, Stockholm, Sweden; Lahanas, V., Medical Physics Lab-Simulation Center, Medical School, National and Kapodistrian University of Athens, Athens, Greece; Georgiou, K., Medical Physics Lab-Simulation Center, Medical School, National and Kapodistrian University of Athens, Athens, Greece; Henningsohn, L., The Center for Advanced Medical Simulation and Training (CAMST), Karolinska University Hospital, Stockholm, Sweden, Division of Urology, Department of Clinical ScienceIntervention and Technology (CLINTEC), Karolinska Institutet, Stockholm, Sweden; Felländer-Tsai, L., The Center for Advanced Medical Simulation and Training (CAMST), Karolinska University Hospital, Stockholm, Sweden, Division of Orthopedics and Biotechnology, Department of Clinical ScienceIntervention and Technology (CLINTEC), Karolinska Institutet, Stockholm, Sweden; Georgiou, E., Medical Physics Lab-Simulation Center, Medical School, National and Kapodistrian University of Athens, Athens, Greece; Enochsson, L., The Center for Advanced Medical Simulation and Training (CAMST), Karolinska University Hospital, Stockholm, Sweden, Division of Surgery, Department of Clinical ScienceIntervention and Technology (CLINTEC), Karolinska Institutet, Stockholm, Sweden, Division of Surgery, Department of Surgical and Perioperative Sciences, Umeå University, Umeå, Sweden, Division of Surgery, Department of Surgical and Perioperative Sciences, Umeå University, Luleå, 971 80, Sweden","Background: Basic skills training in laparoscopic high-fidelity simulators (LHFS) improves laparoscopic skills. However, since LHFS are expensive, their availability is limited. The aim of this study was to assess whether automated video analysis of low-cost BlackBox laparoscopic training could provide an alternative to LHFS in basic skills training. Methods: Medical students volunteered to participate during their surgical semester at the Karolinska University Hospital. After written informed consent, they performed two laparoscopic tasks (PEG-transfer and precision-cutting) on a BlackBox trainer. All tasks were videotaped and sent to MPLSC for automated video analysis, generating two parameters (Pl and Prtcl_tot) that assess the total motion activity. The students then carried out final tests on the MIST-VR simulator. This study was a European collaboration among two simulation centers, located in Sweden and Greece, within the framework of ACS-AEI. Results: 31 students (19 females and 12 males), mean age of 26.2 ± 0.8 years, participated in the study. However, since two of the students completed only one of the three MIST-VR tasks, they were excluded. The three MIST-VR scores showed significant positive correlations to both the Pl variable in the automated video analysis of the PEG-transfer (RSquare 0.48, P < 0.0001; 0.34, P = 0.0009; 0.45, P < 0.0001, respectively) as well as to the Prtcl_tot variable in that same exercise (RSquare 0.42, P = 0.0002; 0.29, P = 0.0024; 0.45, P < 0.0001). However, the correlations were exclusively shown in the group with less PC gaming experience as well as in the female group. Conclusions: Automated video analysis provides accurate results in line with those of the validated MIST-VR. We believe that a more frequent use of automated video analysis could provide an extended value to cost-efficient laparoscopic BlackBox training. However, since there are gender-specific as well as PC gaming experience differences, this should be taken in account regarding the value of automated video analysis. © 2017, The Author(s).","BlackBox trainer; MIST-VR simulation; Video analysis; Virtual reality","adult; Article; automation; female; Greece; high fidelity simulation training; human; human experiment; laparoscopy; male; medical education; medical student; priority journal; sex difference; Sweden; videorecording; virtual reality; clinical competence; computer simulation; education; laparoscopy; medical education; procedures; statistics and numerical data; videorecording; Adult; Clinical Competence; Computer Simulation; Education, Medical, Undergraduate; Female; Humans; Laparoscopy; Male; Video Recording",Article,"Final","",Scopus,2-s2.0-85021694410
"Zou Z., Arruda L., Ergan S.","57195301528;57208333256;55220455300;","Characteristics of models that impact transformation of BIMS to virtual environments to support facility management operations",2018,"Journal of Civil Engineering and Management","24","6",,"481","498",,4,"10.3846/jcem.2018.5689","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064496403&doi=10.3846%2fjcem.2018.5689&partnerID=40&md5=35a032e52c6b450afc702c6dc1657507","Department of Civil and Urban Engineering, New York University, New York City, United States","Zou, Z., Department of Civil and Urban Engineering, New York University, New York City, United States; Arruda, L., Department of Civil and Urban Engineering, New York University, New York City, United States; Ergan, S., Department of Civil and Urban Engineering, New York University, New York City, United States","Building information models (BIMs) have been used by the Architectural/Engineering/Construction (AEC) industry with a focus on storing and exchanging digital information about building components. However, the untapped potential of BIMs in facility operations and the experience of facility operators while they interact with digital building information have not been understood widely. One of the underlying bottlenecks in the use of BIMs in the FM phase is the lack of interactions with components to easily access information of interest, and the lack of ways to navigate in models with full spatial understanding. Virtual environments (VEs), which represent physical spaces digitally in virtual worlds, enable interactions with virtual components to access information with spatial understanding. The underlying challenges in the conversion of BIMs to VE hinder a streamlined process. This paper provides a detailed analysis of building size, geometric complexities of discipline models and level of geometric granularity as factors contributing to inefficient transformation of BIMs to VE. The paper also provides research findings on a set of computational approaches such as polygon reduction and occlusion culling to overcome challenges and improve the data transfer faced in converting BIMs into VEs over a range and size of facility models. © 2018 The Author(s).","BIM; Facility management; Virtual reality","Data transfer; Mathematical transformations; Office buildings; Virtual reality; Building Information Model - BIM; Computational approach; Digital information; Facility management; Facility operations; Geometric complexity; Support facilities; Virtual components; Architectural design",Article,"Final","",Scopus,2-s2.0-85064496403
"de Vries A.W., Faber G., Jonkers I., Van Dieen J.H., Verschueren S.M.P.","56844642100;14053768900;6701351504;7005065606;6603747889;","Virtual reality balance training for elderly: Similar skiing games elicit different challenges in balance training",2018,"Gait and Posture","59",,,"111","116",,20,"10.1016/j.gaitpost.2017.10.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030858846&doi=10.1016%2fj.gaitpost.2017.10.006&partnerID=40&md5=f2ada44b7cbb0800bfa1558540192a12","Musculoskeletal Research Unit, Department of Rehabilitation Sciences, Faculty of Kinesiology and Rehabilitation Sciences, Katholieke Universiteit Leuven, Leuven, Belgium; MOVE Research Institute Amsterdam, Faculty of Human Movement Sciences, VU University Amsterdam, Amsterdam, Netherlands; Human Movement Biomechanics Research Group, Department of Kinesiology, Faculty of Kinesiology and Rehabilitation Sciences, Katholieke Universiteit Leuven, Leuven, Belgium","de Vries, A.W., Musculoskeletal Research Unit, Department of Rehabilitation Sciences, Faculty of Kinesiology and Rehabilitation Sciences, Katholieke Universiteit Leuven, Leuven, Belgium; Faber, G., MOVE Research Institute Amsterdam, Faculty of Human Movement Sciences, VU University Amsterdam, Amsterdam, Netherlands; Jonkers, I., Human Movement Biomechanics Research Group, Department of Kinesiology, Faculty of Kinesiology and Rehabilitation Sciences, Katholieke Universiteit Leuven, Leuven, Belgium; Van Dieen, J.H., MOVE Research Institute Amsterdam, Faculty of Human Movement Sciences, VU University Amsterdam, Amsterdam, Netherlands; Verschueren, S.M.P., Musculoskeletal Research Unit, Department of Rehabilitation Sciences, Faculty of Kinesiology and Rehabilitation Sciences, Katholieke Universiteit Leuven, Leuven, Belgium","Background Virtual Reality (VR) balance training may have advantages over regular exercise training in older adults. However, results so far are conflicting potentially due to the lack of challenge imposed by the movements in those games. Therefore, the aim of this study was to assess to which extent two similar skiing games challenge balance, as reflected in center of mass (COM) movements relative to their Functional Limits of Stability (FLOS). Methods Thirty young and elderly participants performed two skiing games, one on the Wii Balance board (Wiiski), which uses a force plate, and one with the Kinect sensor (Kinski), which performs motion tracking. During gameplay, kinematics were captured using seven opto-electronical cameras. FLOS were obtained for eight directions. The influence of games and trials on COM displacement in each of the eight directions, and maximal COM speed, were tested with Generalized Estimated Equations. Results In all directions with anterior and medio-lateral, but not with a posterior component, subjects showed significantly larger maximal %FLOS displacements during the Kinski game than during the Wiiski game. Furthermore, maximal COM displacement, and COM speed in Kinski remained similar or increased over trials, whereas for Wiiski it decreased. Conclusions Our results show the importance of assessing the movement challenge in games used for balance training. Similar games impose different challenges, with the control sensors and their gain settings playing an important role. Furthermore, adaptations led to a decrease in challenge in Wiiski, which might limit the effectiveness of the game as a balance-training tool. © 2017 Elsevier B.V.","Aging; Balance; Balance training; Elderly; Virtual reality","adult; aged; Article; body equilibrium; camera; data analysis software; electronics; female; human; human experiment; kinematics; male; motion analysis system; movement (physiology); priority journal; scoring system; skiing; virtual reality; adolescent; biomechanics; body equilibrium; kinesiotherapy; physiology; procedures; skiing; video game; young adult; Adolescent; Adult; Aged; Biomechanical Phenomena; Exercise Therapy; Female; Humans; Male; Postural Balance; Skiing; Video Games; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85030858846
"Méndez S.J.R., Zao J.K.","56196622700;19934319300;","BCI ontology: A context-based sense and actuation model for brain-computer interactions",2018,"CEUR Workshop Proceedings","2213",,,"32","47",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054490708&partnerID=40&md5=ce8ef3e69362351341d4271c586bfc60","Pervasive Embedded Technology (PET) Lab, Computer Science Department, National Chiao Tung University (NCTU), Hsinchu, Taiwan","Méndez, S.J.R., Pervasive Embedded Technology (PET) Lab, Computer Science Department, National Chiao Tung University (NCTU), Hsinchu, Taiwan; Zao, J.K., Pervasive Embedded Technology (PET) Lab, Computer Science Department, National Chiao Tung University (NCTU), Hsinchu, Taiwan","Key developments in wearable sensors, wireless networks, and distributed computing will largely enable Brain-Computer Interaction (BCI) as a powerful, natural and intuitive mainstream human-computer interaction in real-world activities. BCI systems annotate the sensed signals in order to classify the analysis of brain states/dynamics in diverse daily-life circumstances. There is no any complete and standardized formal semantic structure to model the BCI metadata annotations, which are essential to capture the descriptive and predictive features of the brain signals. We present the BCI Ontology (BCI-O): The first OWL 2 ontology that formalizes relevant metadata for BCI data capture activities by integrating BCI-domain-specific Sense and Actuation Models along with a novel Context Model for describing any kind of real/virtual environments. At its core, BCI-O defines a human-environment interaction model for any BCI, based on design patterns and primarily aligned to the SOSA/SSN, SAN-IoT-O- A nd DUL ontologies. Its axiomatizations aid BCI systems to implement an ontological overlay upon vast data recording collections to support semantic query constructions (to perform Adaptive BCI) and reasoning for situation-specific data analytics (to apply inference rules for Transfer Learning in multimodal classification). © 2018 CEUR-WS. All rights reserved.","Brain-Computer Interaction; Context-awareness; Context-based; Internet of Things; Ontology; Sense-Actuation Model","Brain; Distributed computer systems; Human computer interaction; Internet of things; Metadata; Ontology; Query processing; Sanitary sewers; Search engines; Semantics; Sensor networks; Wearable sensors; Brain computer interactions; Context modeling; Context- awareness; Context-based; Human-environment interaction; Metadata annotations; Real-world activities; Transfer learning; Brain computer interface",Conference Paper,"Final","",Scopus,2-s2.0-85054490708
"Sanal Kumar V.R., Sankar V., Chandrasekaran N., Murugesh P., M S.A.R.","6507613306;6701525810;57195513090;57003493400;57209102194;","Prediction of 3d boundary layer blockage and the grain design optimization of hvt dual-thrust hybrid rockets",2018,"2018 Joint Propulsion Conference",,, AIAA 2018-4446,"","",20,2,"10.2514/6.2018-4446","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066492183&doi=10.2514%2f6.2018-4446&partnerID=40&md5=752bc9c515472910de080c0f5974b014","Indian Space Research Organisation, Trivandrum, Kerala  695022, India; Indian Institute of Science, Bangalore, Karnataka  560012, India; Kumaraguru College of Technology, Coimbatore, Tamil Nadu  641049, India","Sanal Kumar, V.R., Indian Space Research Organisation, Trivandrum, Kerala  695022, India, Indian Institute of Science, Bangalore, Karnataka  560012, India, Kumaraguru College of Technology, Coimbatore, Tamil Nadu  641049, India; Sankar, V., Kumaraguru College of Technology, Coimbatore, Tamil Nadu  641049, India; Chandrasekaran, N., Kumaraguru College of Technology, Coimbatore, Tamil Nadu  641049, India; Murugesh, P., Kumaraguru College of Technology, Coimbatore, Tamil Nadu  641049, India; M, S.A.R., Kumaraguru College of Technology, Coimbatore, Tamil Nadu  641049, India","An innovative and powerful closed-form analytical model is developed for predicting the 3D boundary layer blockage in high-velocity transient (HVT) dual-thrust hybrid rockets obeying the compressible diabatic viscous flow theory. This is the continuation of our previous connected paper pertaining to the boundary layer blockage prediction at the Sanal flow choking condition for adiabatic flows (V. R. Sanal Kumar et al. [1], AIP Advances, 8, 025315, 2018). The Sanal flow choking for diabatic flow is a unique condition of any internal flow system at which both the thermal choking (Rayleigh flow effect) and the wall-friction induced flow choking (Fanno flow effect) occur at a single sonic-fluid-throat location. A dual-thrust hybrid rocket with constant upstream cylindrical port having large length-to-diameter ratio (l/d > 27) is selected as a three-dimensional physical model. During the numerical simulation, for achieving the Sanal flow choking effect the igniter jet Mach number is selected based on the thermal choking condition and the average wall friction coefficient of the cylindrical port is selected based on the Fanno flow model. The beauty and novelty of the Sanal flow choking condition for diabatic flow is that, without missing the real flow physics we could exactly predict the 3D boundary layer blockage of the dual-thrust hybrid rocket motors with different liquid fuel and liquid oxidizer combinations aiming for achieving the highest possible solid fuel or solid oxidizer loading density coupled with high ΔV benefits without creating any internal flow choking effect within the given envelop during the entire period of its operation. We concluded that, though the boundary layer blockage is relatively higher, the liquid oxidizer or liquid fuel with the highest heat capacity ratio is the best choice for increasing the propellant loading density without inviting any undesirable internal flow choking phenomenon leading to catastrophic failures of the rocket motor due to the formation of pressure overshoot as a result of the internal shock waves. Note that the pressure ratio for choking will increase while increasing the heat capacity ratio of the gas. The closed-form analytical model presented herein is a brilliant tool for the validation of 3D Navier-Stokes solvers for the design optimization of any HVT internal flow system involving the transfer of heat with confidence. Furthermore, using the closed-form analytical model at the Sanal flow choking condition for diabatic flows, the HVT rocket designers can accurately predict the possibilities of the internal flow choking in the dual-thrust hybrid rockets at the given jet flow Mach number for a credible decision making for improving its propellant loading density within the given envelope lucratively. © 2018 by the American Institute of Aeronautics and Astronautics, Inc. All rights reserved.",,"Aerodynamics; Analytical models; Decision making; Forecasting; Friction; Liquid fuels; Liquids; Mach number; Navier Stokes equations; Propellants; Propulsion; Rockets; Shock waves; Specific heat; Catastrophic failures; Design optimization; Hybrid rocket motors; Length to diameter ratio; Liquid oxidizers; Navier-Stokes solver; Propellant loading; Solid oxidizers; Boundary layers",Conference Paper,"Final","",Scopus,2-s2.0-85066492183
"Kumar P., Agrawal A., Prasad S.","57199976385;56900480800;36997272500;","Multimodal interface for temporal pattern based interactive large volumetric visualization",2017,"IEEE Region 10 Annual International Conference, Proceedings/TENCON","2017-December",,,"1239","1244",,2,"10.1109/TENCON.2017.8228047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85044224017&doi=10.1109%2fTENCON.2017.8228047&partnerID=40&md5=bd35782deaf2c7989d27dc21afbc4f41","Indian Institute of Information Technology, Allahabad, India; Nanyang Technical University, Singapore","Kumar, P., Indian Institute of Information Technology, Allahabad, India; Agrawal, A., Indian Institute of Information Technology, Allahabad, India; Prasad, S., Nanyang Technical University, Singapore","Scientific data visualization is a prominent area of research in the development of Virtual Reality Applications in order to make it more interactive and robotic. But the efficient interaction with the large size of medical data is a challenging task to diagnose virtual surgerical environment learning for a Physician. In this paper, we proposed a multimodal interface for GPU-accelerated interactive large scale volumetric data rendering to overcome this limitation. The large data has been pre-processed by octree method. An improved raycasting algorithm is used in association with a transfer function classification method for the effective rendering. The temporal data is used for defining gestures, retrieving in a pattern from the wearable device for providing multimodality with the large rendered data. A gesture vocabulary has been defined by these patterns for the navigation in visualizing the large scale medical data, which consists of five complex interactive postures used for Normal, Picking, Rotation, Dragging, and Zooming gestures. These gesture vocabularies have been categorized by kNN classification method of pattern recognition. Experimental results of the proposed approach are analyzed with the help of various ANOVA and T-testing graphs using SPSS 20 version tool and confidence interval of interaction with hand gestures vocabulary. The results of proposed approach are further compared with the existing approaches in which Microsoft Kinect and P5 dataglove have been used. The proposed system has been navigated by the DG5 VHand 2.0 Bluetooth version hand dataglove as wearable assistive device to achieve an effective interaction. The system has been tested on 10 different sizes of volume datasets ranging from 10MB to 3.15 GB. The scope of this paper is basically to develop system training with robotic arm in medical domain. © 2017 IEEE.","Hand DataGlove; Human-Computer Interaction; Large scale; Medical Dataset; Multimodal Inteface; Volume Rendering","Human computer interaction; Interactive computer systems; Pattern recognition; Robotics; Virtual reality; Visualization; Volume rendering; Volumetric analysis; Wearable technology; Dataglove; Inteface; Large scale; Medical dataset; Multi-modal interfaces; Scientific data visualization; Volumetric visualization; Wearable assistive devices; Data visualization",Conference Paper,"Final","",Scopus,2-s2.0-85044224017
"Li Y., Zhang J., Sun W., Wang J., Gao X.","56201159300;35436414500;57196712013;57201057458;8694616600;","VREX: Virtual reality education eXpansion could help to improve the class experience (VREX Platform and Community for VR based Education)",2017,"Proceedings - Frontiers in Education Conference, FIE","2017-October",,,"1","5",,7,"10.1109/FIE.2017.8190660","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043232821&doi=10.1109%2fFIE.2017.8190660&partnerID=40&md5=3f64d16993e0b0815f54443965183308","School of Computer Science and Engineering, Beihang University, Beijing, China; Electrical Engineering, Princeton UniversityNJ, United States; Dept. for Cyber Online Popularization of Science, Chinese Science and Technology Museum, Beijing, China","Li, Y., School of Computer Science and Engineering, Beihang University, Beijing, China, Electrical Engineering, Princeton UniversityNJ, United States; Zhang, J., School of Computer Science and Engineering, Beihang University, Beijing, China, Dept. for Cyber Online Popularization of Science, Chinese Science and Technology Museum, Beijing, China; Sun, W., School of Computer Science and Engineering, Beihang University, Beijing, China; Wang, J., Dept. for Cyber Online Popularization of Science, Chinese Science and Technology Museum, Beijing, China; Gao, X., School of Computer Science and Engineering, Beihang University, Beijing, China","This paper proposed an innovative education platform-VREX (Virtual Reality based Education eXpansion), with combination of online and offline, to improve the curriculum building and teaching experience. VREX is based on Virtual Reality (VR) and we believe VR can revolutionize the education ecosystem. With some trials, we found VR can be used to promote curriculum effectiveness in an immersive environment so that students can have intuitive sense to understand some abstract knowledge, which is always hard for teachers to describe. We have tried to transfer slides into VR scenes, for the students to learn knowledge in a rather real but totally virtual world. The main contributions were made: (1) VREX build an open and immersion virtual O2O classroom with internet and VR devices so that real classrooms might be used in a different way in the future. (2) VREX provides a distributed mode for students to experience an interactive learning process at anytime, anywhere and any-frequency. (3) VREX can be used to support education in different disciplines, from K-12 to Universities, and we provided some practical cases, like 'Marine Life' to show creatures in deep sea, which provides immersive experience to makes students feel they were there. Finally, the feasibility and advantage of VREX are proved by the actual statistical data in the 3rd season 2017. © 2017 IEEE.","Immersion; Interaction; Virtual classroom; Virtual reality; VR cloud platform","Computer aided instruction; Curricula; Learning systems; Marine education; Students; Teaching; Virtual reality; Cloud platforms; Curriculum buildings; Immersion; Immersive environment; Innovative education; Interaction; Interactive learning; Virtual Classroom; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85043232821
"Zhao S., Medhi D.","56267593400;35576162400;","SDN-Assisted adaptive streaming framework for tile-based immersive content using MPEG-DASH",2017,"2017 IEEE Conference on Network Function Virtualization and Software Defined Networks, NFV-SDN 2017","2017-January",,,"1","6",,17,"10.1109/NFV-SDN.2017.8169831","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043255095&doi=10.1109%2fNFV-SDN.2017.8169831&partnerID=40&md5=97d53c7d9943e8303ea76d5f5ab72271","Department of Computer Science Electrical Engineering University, Missouri–Kansas, United States","Zhao, S., Department of Computer Science Electrical Engineering University, Missouri–Kansas, United States; Medhi, D., Department of Computer Science Electrical Engineering University, Missouri–Kansas, United States","Video streaming over the internet for new 3D immersive media such as Virtual Reality and 360-degree videos has drawn great attention from both consumers and researchers in recent years. One of the biggest challenges in streaming such 3D media is the high bandwidth demands. While traditional 2D video streaming is still dominating network peak traffic, new inventions are accelerating the adoption of immersive contents and devices. A new Tile-based video is introduced in both a video codec and streaming layer to reduce the transferred media size. Dynamic adaptive streaming over HTTP has become one of the de facto effective adaptive streaming approaches that can fully utilize the existing physical IP network infrastructure. In this paper, we propose a tile-based streaming framework using software-defined networking. By prioritizing streaming flows, based on the region of interests, our approach can improve the user’s quality of experience (QoE). © 2017 IEEE.","DASH Streaming; Immersive VR/360; MPEG-DASH; Software-Defined Networking; Spatial Relationship Description","HTTP; Motion Picture Experts Group standards; Network function virtualization; Quality of service; Software defined networking; Transfer functions; Video streaming; Virtual reality; Virtualization; Adaptive streaming; Dynamic Adaptive Streaming over HTTP; Immersive media; Immersive VR; Mpeg dashes; Quality of experience (QoE); Region of interest; Spatial relationships; Media streaming",Conference Paper,"Final","",Scopus,2-s2.0-85043255095
"Vargas González A.N., Kapalo K., Koh S.L., Laviola J.J., Jr.","57190589688;57210987038;55641302700;6602792780;","Exploring the virtuality continuum for complex rule-set education in the context of soccer rule comprehension",2017,"Multimodal Technologies and Interaction","1","4", 30,"","",,7,"10.3390/mti1040030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068838830&doi=10.3390%2fmti1040030&partnerID=40&md5=fcf9fab289bca459397f7138eadf5e18","Department of Computer Science, University of Central Florida, 4000 Central Florida Blvd., Orlando, FL  32816, United States","Vargas González, A.N., Department of Computer Science, University of Central Florida, 4000 Central Florida Blvd., Orlando, FL  32816, United States; Kapalo, K., Department of Computer Science, University of Central Florida, 4000 Central Florida Blvd., Orlando, FL  32816, United States; Koh, S.L., Department of Computer Science, University of Central Florida, 4000 Central Florida Blvd., Orlando, FL  32816, United States; Laviola, J.J., Jr., Department of Computer Science, University of Central Florida, 4000 Central Florida Blvd., Orlando, FL  32816, United States","We present an exploratory study to assess the benefits of using Augmented Reality (AR) in training sports rule comprehension. Soccer is the chosen context for this study due to the wide range of complexity in the rules and regulations. Observers must understand and holistically evaluate the proximity of players in the game to the ball and other visual objects, such as the goal, penalty area, and other players. Grounded in previous literature investigating the effects of Virtual Reality (VR) scenarios on transfer of training (ToT), we explore how three different interfaces influence user perception using both qualitative and quantitative measures. To better understand how effective augmented reality technology is when combined with learning systems, we compare results on the effects of learning outcomes in three interface conditions: AR, VR and a traditional Desktop interface. We also compare these interfaces as measured by user experience, engagement, and immersion. Results show that there were no significance difference among VR and AR; however, these participants outperformed the Desktop group which needed a higher number of adaptations to acquire the same knowledge. © 2017 by the authors.","Augmented reality; Intelligent tutoring systems; Soccer; Sports training; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85068838830
"Johnson-Glenberg M.C., Megowan-Romanowicz C.","6507238066;26537877500;","Embodied science and mixed reality: How gesture and motion capture affect physics education",2017,"Cognitive Research: Principles and Implications","2","1", 24,"","",,30,"10.1186/s41235-017-0060-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038820372&doi=10.1186%2fs41235-017-0060-9&partnerID=40&md5=f5b98014a9c22b3850ab96e5474bf458","Department of Psychology, Arizona State University, Tempe, AZ, United States; Embodied Games LLC, Tempe, AZ, United States; Modeling Instruction Institute, Sacramento, CA, United States","Johnson-Glenberg, M.C., Department of Psychology, Arizona State University, Tempe, AZ, United States, Embodied Games LLC, Tempe, AZ, United States; Megowan-Romanowicz, C., Modeling Instruction Institute, Sacramento, CA, United States","A mixed design was created using text and game-like multimedia to instruct in the content of physics. The study assessed which variables predicted learning gains after a 1-h lesson on the electric field. The three manipulated variables were: (1) level of embodiment; (2) level of active generativity; and (3) presence of story narrative. Two types of tests were administered: (1) a traditional text-based physics test answered with a keyboard; and (2) a more embodied, transfer test using the Wacom large tablet where learners could use gestures (long swipes) to create vectors and answers. The 166 participants were randomly assigned to four conditions: (1) symbols and text; (2) low embodied; (3) high embodied/active; or (4) high embodied/active with narrative. The last two conditions were active because the on-screen content could be manipulated with gross body gestures gathered via the Kinect sensor. Results demonstrated that the three groups that included embodiment learned significantly more than the symbols and text group on the traditional keyboard post-test. When knowledge was assessed with the Wacom tablet format that facilitated gestures, the two active gesture-based groups scored significantly higher. In addition, engagement scores were significantly higher for the two active embodied groups. The Wacom results suggest test sensitivity issues; the more embodied test revealed greater gains in learning for the more embodied conditions. We recommend that as more embodied learning comes to the fore, more sensitive tests that incorporate gesture be used to accurately assess learning. The predicted differences in engagement and learning for the condition with the graphically rich story narrative were not supported. We hypothesize that a narrative effect for motivation and learning may be difficult to uncover in a lab experiment where participants are primarily motivated by course credit. Several design principles for mediated and embodied science education are proposed. © 2017, The Author(s).","Embodied science; Game-based learning; Gesture and learning; Mixed reality; Narrative; Physics; Science education; STEM; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85038820372
"Bork F., Barmaki R., Eck U., Yu K., Sandor C., Navab N.","57188681620;57079124100;6507331080;57202881272;15061666200;7003458998;","Empirical study of non-reversing magic mirrors for augmented reality anatomy learning",2017,"Proceedings of the 2017 IEEE International Symposium on Mixed and Augmented Reality, ISMAR 2017",,, 8115415,"169","176",,13,"10.1109/ISMAR.2017.33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041662291&doi=10.1109%2fISMAR.2017.33&partnerID=40&md5=675b96017db2c791bfef11db7746c384","Technische Universität München, Munich, Germany; Johns Hopkins University, Baltimore, MD, United States; Nara Institute of Technology, Nara, Japan","Bork, F., Technische Universität München, Munich, Germany; Barmaki, R., Johns Hopkins University, Baltimore, MD, United States; Eck, U., Technische Universität München, Munich, Germany; Yu, K., Technische Universität München, Munich, Germany; Sandor, C., Nara Institute of Technology, Nara, Japan; Navab, N., Technische Universität München, Munich, Germany, Johns Hopkins University, Baltimore, MD, United States","Left-right confusion occurs across the entire population and refers to an impeded ability to distinguish between left and right. In medicine this phenomenon is particularly relevant as left and right are always defined with respect to the patient's point of view, i.e. the doctor's right is the patient's left. Traditional anatomy learning resources such as illustrations in textbooks naturally consider this by consistently depicting the anatomy of a patient as seen by an observer standing in front. Augmented Reality Magic Mirrors (MM) are one example of novel anatomy teaching resources and show a user's digital mirror image augmented with virtual anatomy on a large display. As left and right appear to be reversed in such MM setups, similar to real-world physical mirrors, intriguing perceptual questions arise: is a non-reversing MM (NRMM) the more natural choice for the task of anatomy learning and do users even learn anatomy the wrong way with a traditional, reversing MM (RMM)' In this paper, we explore the perceptual differences between an NRMM and RMM design and present the first empirical study comparing these two concepts for the purpose of anatomy learning. Experimental results demonstrate that medical students perform significantly better at identifying anatomically correct placement of virtual organs in an NRMM. However, interaction was significantly more difficult compared to an RMM. We explore the underlying psychological effects and discuss the implications of using an NRMM on user perception, knowledge transfer, and interaction. This study is relevant for the design of future MM systems in the medical domain and lessons-learned can be transferred to other application domains. © 2017 IEEE.",,"Augmented reality; Knowledge management; Mirrors; Empirical studies; Knowledge transfer; Learning resource; Medical students; Perceptual difference; Psychological effects; Teaching resources; User perceptions; Education",Conference Paper,"Final","",Scopus,2-s2.0-85041662291
"Palestini C., Basso A.","56541484100;57194550137;","The photogrammetric survey methodologies applied to low cost 3D virtual exploration in multidisciplinary field",2017,"International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives","42","2W8",,"195","202",,8,"10.5194/isprs-archives-XLII-2-W8-195-2017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85051478984&doi=10.5194%2fisprs-archives-XLII-2-W8-195-2017&partnerID=40&md5=b9204e423480a9407c0ec4a93ea08647","Dipartimento di Architettura, Università degli Studi g. d'Annunzio, Pescara, Italy","Palestini, C., Dipartimento di Architettura, Università degli Studi g. d'Annunzio, Pescara, Italy; Basso, A., Dipartimento di Architettura, Università degli Studi g. d'Annunzio, Pescara, Italy","In recent years, an increase in international investment in hardware and software technology to support programs that adopt algorithms for photomodeling or data management from laser scanners significantly reduced the costs of operations in support of Augmented Reality and Virtual Reality, designed to generate real-time explorable digital environments integrated to virtual stereoscopic headset. The research analyzes transversal methodologies related to the acquisition of these technologies in order to intervene directly on the phenomenon of acquiring the current VR tools within a specific workflow, in light of any issues related to the intensive use of such devices , outlining a quick overview of the possible ""virtual migration"" phenomenon, assuming a possible integration with the new internet hyper-speed systems, capable of triggering a massive cyberspace colonization process that paradoxically would also affect the everyday life and more in general, on human space perception. The contribution aims at analyzing the application systems used for low cost 3d photogrammetry by means of a precise pipeline, clarifying how a 3d model is generated, automatically retopologized, textured by color painting or photo-cloning techniques, and optimized for parametric insertion on virtual exploration platforms. Workflow analysis will follow some case studies related to photomodeling, digital retopology and ""virtual 3d transfer"" of some small archaeological artifacts and an architectural compartment corresponding to the pronaus of Aurum, a building designed in the 1940s by Michelucci. All operations will be conducted on cheap or free licensed software that today offer almost the same performance as their paid counterparts, progressively improving in the data processing speed and management. © 2017 Authors.","3d; Interaction; Photogrammetric survey; Virtual empathy; Virtual reality","Augmented reality; Costs; Data handling; Information management; Photogrammetry; Software engineering; Stereo image processing; Surveys; Three dimensional computer graphics; 3d photogrammetries; Archaeological artifacts; Colonization process; Digital environment; Hardware and software; Interaction; International investments; Virtual empathy; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85051478984
"Våpenstad C., Hofstad E.F., Bø L.E., Kuhry E., Johnsen G., Mårvik R., Langø T., Hernes T.N.","36092316200;54884909600;35769151000;14014548200;7003564155;55905402700;6602161988;57189855206;","Lack of transfer of skills after virtual reality simulator training with haptic feedback",2017,"Minimally Invasive Therapy and Allied Technologies","26","6",,"346","354",,28,"10.1080/13645706.2017.1319866","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019094881&doi=10.1080%2f13645706.2017.1319866&partnerID=40&md5=77256ab023ad87bb850ce85444826abe","Faculty of Medicine, Norwegian University of Science and Technology (NTNU), Trondheim, Norway; Department of Medical Technology, SINTEF Technology and Society, Trondheim, Norway; The Central Norway Regional Health Authority, Trondheim, Norway; The Norwegian National Advisory Unit for Advanced Laparoscopic Surgery, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway; The Norwegian National Advisory Unit for Ultrasound and Image-Guided Therapy, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway; Department of Gastrointestinal Surgery, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway","Våpenstad, C., Faculty of Medicine, Norwegian University of Science and Technology (NTNU), Trondheim, Norway, Department of Medical Technology, SINTEF Technology and Society, Trondheim, Norway, The Central Norway Regional Health Authority, Trondheim, Norway, The Norwegian National Advisory Unit for Advanced Laparoscopic Surgery, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway, The Norwegian National Advisory Unit for Ultrasound and Image-Guided Therapy, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway; Hofstad, E.F., Department of Medical Technology, SINTEF Technology and Society, Trondheim, Norway, The Norwegian National Advisory Unit for Advanced Laparoscopic Surgery, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway, The Norwegian National Advisory Unit for Ultrasound and Image-Guided Therapy, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway; Bø, L.E., Faculty of Medicine, Norwegian University of Science and Technology (NTNU), Trondheim, Norway, Department of Medical Technology, SINTEF Technology and Society, Trondheim, Norway, The Central Norway Regional Health Authority, Trondheim, Norway, The Norwegian National Advisory Unit for Advanced Laparoscopic Surgery, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway, The Norwegian National Advisory Unit for Ultrasound and Image-Guided Therapy, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway; Kuhry, E., Faculty of Medicine, Norwegian University of Science and Technology (NTNU), Trondheim, Norway, Department of Gastrointestinal Surgery, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway; Johnsen, G., The Norwegian National Advisory Unit for Advanced Laparoscopic Surgery, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway, Department of Gastrointestinal Surgery, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway; Mårvik, R., Faculty of Medicine, Norwegian University of Science and Technology (NTNU), Trondheim, Norway, The Norwegian National Advisory Unit for Advanced Laparoscopic Surgery, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway, The Norwegian National Advisory Unit for Ultrasound and Image-Guided Therapy, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway, Department of Gastrointestinal Surgery, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway; Langø, T., Department of Medical Technology, SINTEF Technology and Society, Trondheim, Norway, The Norwegian National Advisory Unit for Ultrasound and Image-Guided Therapy, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway; Hernes, T.N., Faculty of Medicine, Norwegian University of Science and Technology (NTNU), Trondheim, Norway, The Norwegian National Advisory Unit for Ultrasound and Image-Guided Therapy, St. Olavs Hospital, Trondheim University Hospital, Trondheim, Norway","Background and objective: Virtual reality (VR) simulators enrich surgical training and offer training possibilities outside of the operating room (OR). In this study, we created a criterion-based training program on a VR simulator with haptic feedback and tested it by comparing the performances of a simulator group against a control group. Material and methods: Medical students with no experience in laparoscopy were randomly assigned to a simulator group or a control group. In the simulator group, the candidates trained until they reached predefined criteria on the LapSim® VR simulator (Surgical Science AB, Göteborg, Sweden) with haptic feedback (XitactTM IHP, Mentice AB, Göteborg, Sweden). All candidates performed a cholecystectomy on a porcine organ model in a box trainer (the clinical setting). The performances were video rated by two surgeons blinded to subject training status. Results: In total, 30 students performed the cholecystectomy and had their videos rated (N = 16 simulator group, N = 14 control group). The control group achieved better video rating scores than the simulator group (p &lt;.05). Conclusions: The criterion-based training program did not transfer skills to the clinical setting. Poor mechanical performance of the simulated haptic feedback is believed to have resulted in a negative training effect. © 2017 Society of Medical Innovation and Technology.","haptic feedback; laparoscopy; simulator; surgical education; Virtual reality","adult; animal tissue; Article; cholecystectomy; clinical evaluation; controlled study; data analysis software; depth perception; female; human; laparoscopy; male; medical student; nonhuman; porcine model; predictive validity; priority journal; randomized controlled trial; simulation; skill; software; surgeon; surgical training; tactile feedback; videorecording; virtual reality; animal; computer simulation; constructive feedback; devices; education; laparoscopic cholecystectomy; pig; transfer of learning; virtual reality; Adult; Animals; Cholecystectomy, Laparoscopic; Computer Simulation; Educational Measurement; Female; Formative Feedback; Humans; Male; Swine; Transfer (Psychology); Virtual Reality",Article,"Final","",Scopus,2-s2.0-85019094881
"Huber T., Paschold M., Hansen C., Wunderling T., Lang H., Kneist W.","18535462800;50361876100;55890379200;57193857398;7402486188;7005632003;","New dimensions in surgical training: immersive virtual reality laparoscopic simulation exhilarates surgical staff",2017,"Surgical Endoscopy","31","11",,"4472","4477",,56,"10.1007/s00464-017-5500-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017182338&doi=10.1007%2fs00464-017-5500-6&partnerID=40&md5=83d81dd35d910a73edf015e3e70d0f69","Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Langenbeckstraße 1, Mainz, 55131, Germany; Department of Simulation and Graphics, Faculty of Computer Science, Otto-von-Guericke University Magdeburg, Magdeburg, Germany","Huber, T., Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Langenbeckstraße 1, Mainz, 55131, Germany; Paschold, M., Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Langenbeckstraße 1, Mainz, 55131, Germany; Hansen, C., Department of Simulation and Graphics, Faculty of Computer Science, Otto-von-Guericke University Magdeburg, Magdeburg, Germany; Wunderling, T., Department of Simulation and Graphics, Faculty of Computer Science, Otto-von-Guericke University Magdeburg, Magdeburg, Germany; Lang, H., Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Langenbeckstraße 1, Mainz, 55131, Germany; Kneist, W., Department of General, Visceral and Transplant Surgery, University Medicine of the Johannes Gutenberg-University Mainz, Langenbeckstraße 1, Mainz, 55131, Germany","Introduction: Virtual reality (VR) and head mount displays (HMDs) have been advanced for multimedia and information technologies but have scarcely been used in surgical training. Motion sickness and individual psychological changes have been associated with VR. The goal was to observe first experiences and performance scores using a new combined highly immersive virtual reality (IVR) laparoscopy setup. Methods: During the study, 10 members of the surgical department performed three tasks (fine dissection, peg transfer, and cholecystectomy) on a VR simulator. We then combined a VR HMD with the VR laparoscopic simulator and displayed the simulation on a 360° video of a laparoscopic operation to create an IVR laparoscopic simulation. The tasks were then repeated. Validated questionnaires on immersion and motion sickness were used for the study. Results: Participants’ times for fine dissection were significantly longer during the IVR session (regular: 86.51 s [62.57 s; 119.62 s] vs. IVR: 112.35 s [82.08 s; 179.40 s]; p = 0.022). The cholecystectomy task had higher error rates during IVR. Motion sickness did not occur at any time for any participant. Participants experienced a high level of exhilaration, rarely thought about others in the room, and had a high impression of presence in the generated IVR world. Conclusion: This is the first clinical and technical feasibility study using the full IVR laparoscopy setup combined with the latest laparoscopic simulator in a 360° surrounding. Participants were exhilarated by the high level of immersion. The setup enables a completely new generation of surgical training. © 2017, Springer Science+Business Media New York.","Abdominal surgery; Immersive virtual reality; Laparoscopy; Simulation; Training; Virtual surgery","abdominal surgery; Article; cholecystectomy; dissection; feasibility study; female; human; laparoscopic surgery; male; motion sickness; operating room personnel; priority journal; surgical training; time; virtual reality; clinical competence; education; health care personnel; laparoscopy; procedures; questionnaire; simulation training; statistics and numerical data; Clinical Competence; Feasibility Studies; Female; Health Personnel; Humans; Laparoscopy; Male; Simulation Training; Surveys and Questionnaires; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85017182338
"Al-Saud L.M., Mushtaq F., Allsop M.J., Culmer P.C., Mirghani I., Yates E., Keeling A., Mon-Williams M.A., Manogue M.","55361574200;56999078200;35602715400;34978234000;57191096853;57191095015;55969850600;7006287402;6701334811;","Feedback and motor skill acquisition using a haptic dental simulator",2017,"European Journal of Dental Education","21","4",,"240","247",,25,"10.1111/eje.12214","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84993660524&doi=10.1111%2feje.12214&partnerID=40&md5=1d900e9f061f9a90f8b701789ab21d3f","School of Dentistry, University of Leeds, Leeds, West Yorkshire, United Kingdom; School of Psychology, University of Leeds, Leeds, United Kingdom; College of Dentistry, King Saud University, Riyadh, Saudi Arabia; Leeds Institute of Health Sciences, University of Leeds, Leeds, United Kingdom; School of Mechanical Engineering, University of Leeds, Leeds, United Kingdom; School of Dentistry, The University of Western Australia, Crawley, Australia","Al-Saud, L.M., School of Dentistry, University of Leeds, Leeds, West Yorkshire, United Kingdom, School of Psychology, University of Leeds, Leeds, United Kingdom, College of Dentistry, King Saud University, Riyadh, Saudi Arabia; Mushtaq, F., School of Psychology, University of Leeds, Leeds, United Kingdom; Allsop, M.J., Leeds Institute of Health Sciences, University of Leeds, Leeds, United Kingdom; Culmer, P.C., School of Mechanical Engineering, University of Leeds, Leeds, United Kingdom; Mirghani, I., School of Dentistry, University of Leeds, Leeds, West Yorkshire, United Kingdom, School of Psychology, University of Leeds, Leeds, United Kingdom; Yates, E., School of Dentistry, The University of Western Australia, Crawley, Australia; Keeling, A., School of Dentistry, University of Leeds, Leeds, West Yorkshire, United Kingdom; Mon-Williams, M.A., School of Psychology, University of Leeds, Leeds, United Kingdom; Manogue, M., School of Dentistry, University of Leeds, Leeds, West Yorkshire, United Kingdom","Aim: To investigate the effect of qualitatively different types of pedagogical feedback (FB) on the training, transfer and retention of basic manual dexterity dental skills using a virtual reality (VR) haptic dental simulator. Methods: Sixty-three participants (M = 22.7 years; SD = 3.4 years), with no previous dental training, were randomly allocated to one of three groups (n = 21 each). Group 1 received device-only feedback during the training phase, that is the visual display of the simulator (DFB); Group 2 received verbal feedback from a qualified dental instructor (IFB); and Group 3 received a combination of instructor and device feedback (IDFB). Participants completed four tasks during which feedback was given according to group allocation as well as two skills transfer tests. Skill retention was examined immediately after training, at 1 week and at 1 month post-test. Results: Statistically significant differences were found between the groups in overall performance (P < 0.001) and error (P = 0.006). Post hoc comparisons revealed the IDFB group produced substantially better performance and fewer errors in comparison with DFB and IFB training. This difference translated to improved performance in skill retention and generalisation of knowledge to novel tasks. Conclusion: These data indicate that the acquisition and retention of basic dental motor skills in novice trainees is best optimised through a combination of instructor and visual display (VR)-driven feedback. The results have implications for the utility and implementation of VR haptic technology in dental education. © 2016 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd","dentistry; feedback; motor learning; skill acquisition; undergraduate dental education; virtual reality","computer simulation; controlled study; dental education; human; motor performance; procedures; randomized controlled trial; sensory feedback; teaching; touch; young adult; Computer Simulation; Computer-Assisted Instruction; Education, Dental; Feedback, Sensory; Humans; Motor Skills; Touch; Young Adult",Article,"Final","",Scopus,2-s2.0-84993660524
"Mathews S., Brodman M., D'Angelo D., Chudnoff S., McGovern P., Kolev T., Bensinger G., Mudiraj S., Nemes A., Feldman D., Kischak P., Ascher-Walsh C.","57188963328;6603640864;57195364646;8433953400;7101833346;57035067100;9736649800;57191925412;57195369746;7402702831;57191917317;6505924251;","Predictors of laparoscopic simulation performance among practicing obstetrician gynecologists",2017,"American Journal of Obstetrics and Gynecology","217","5",,"596.e1","596.e7",,4,"10.1016/j.ajog.2017.07.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027491573&doi=10.1016%2fj.ajog.2017.07.002&partnerID=40&md5=be321a47e72ef965367ffca3791f9f1e","Icahn School of Medicine at Mount Sinai, New York, NY, United States; Hospital Insurance Company, New York, NY, United States; Montefiore Medical Center, New York, NY, United States; Mount Sinai West, New York, NY, United States; Mount Sinai Beth Israel, New York, NY, United States; Maimonides Medical Center, New York, NY, United States","Mathews, S., Icahn School of Medicine at Mount Sinai, New York, NY, United States; Brodman, M., Icahn School of Medicine at Mount Sinai, New York, NY, United States; D'Angelo, D., Hospital Insurance Company, New York, NY, United States; Chudnoff, S., Montefiore Medical Center, New York, NY, United States; McGovern, P., Mount Sinai West, New York, NY, United States; Kolev, T., Mount Sinai Beth Israel, New York, NY, United States; Bensinger, G., Maimonides Medical Center, New York, NY, United States; Mudiraj, S., Hospital Insurance Company, New York, NY, United States; Nemes, A., Hospital Insurance Company, New York, NY, United States; Feldman, D., Hospital Insurance Company, New York, NY, United States; Kischak, P., Hospital Insurance Company, New York, NY, United States; Ascher-Walsh, C., Icahn School of Medicine at Mount Sinai, New York, NY, United States","Background While simulation training has been established as an effective method for improving laparoscopic surgical performance in surgical residents, few studies have focused on its use for attending surgeons, particularly in obstetrics and gynecology. Surgical simulation may have a role in improving and maintaining proficiency in the operating room for practicing obstetrician gynecologists. Objective We sought to determine if parameters of performance for validated laparoscopic virtual simulation tasks correlate with surgical volume and characteristics of practicing obstetricians and gynecologists. Study Design All gynecologists with laparoscopic privileges (n = 347) from 5 academic medical centers in New York City were required to complete a laparoscopic surgery simulation assessment. The physicians took a presimulation survey gathering physician self-reported characteristics and then performed 3 basic skills tasks (enforced peg transfer, lifting/grasping, and cutting) on the LapSim virtual reality laparoscopic simulator (Surgical Science Ltd, Gothenburg, Sweden). The association between simulation outcome scores (time, efficiency, and errors) and self-rated clinical skills measures (self-rated laparoscopic skill score or surgical volume category) were examined with regression models. Results The average number of laparoscopic procedures per month was a significant predictor of total time on all 3 tasks (P =.001 for peg transfer; P =.041 for lifting and grasping; P <.001 for cutting). Average monthly laparoscopic surgical volume was a significant predictor of 2 efficiency scores in peg transfer, and all 4 efficiency scores in cutting (P =.001 to P =.015). Surgical volume was a significant predictor of errors in lifting/grasping and cutting (P <.001 for both). Self-rated laparoscopic skill level was a significant predictor of total time in all 3 tasks (P <.0001 for peg transfer; P =.009 for lifting and grasping; P <.001 for cutting) and a significant predictor of nearly all efficiency scores and errors scores in all 3 tasks. Conclusion In addition to total time, there was at least 1 other objective performance measure that significantly correlated with surgical volume for each of the 3 tasks. Higher-volume physicians and those with fellowship training were more confident in their laparoscopic skills. By determining simulation performance as it correlates to active physician practice, further studies may help assess skill and individualize training to maintain skill levels as case volumes fluctuate. © 2017 Elsevier Inc.","gynecologic surgery; laparoscopy; simulation; virtual reality simulation","Article; correlation analysis; grip strength; gynecologic surgery; gynecologist; human; incision; laparoscopic surgery; lifting effort; linear regression analysis; multicenter study; New York; obstetrician; priority journal; regression analysis; simulation training; surgeon; surgical technique; surgical training; university hospital; virtual reality; anatomic model; clinical competence; computer interface; computer simulation; gynecology; laparoscopy; obstetrics; physician; standards; time factor; Clinical Competence; Computer Simulation; Gynecology; Humans; Laparoscopy; Models, Anatomic; Obstetrics; Physicians; Time Factors; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-85027491573
"McClelland J.C., Teather R.J., Girouard A.","57197781412;24588246800;16303494200;","HaptoBend: Shape-changing passive haptic feedback in virtual reality",2017,"SUI 2017 - Proceedings of the 2017 Symposium on Spatial User Interaction",,,,"82","90",,20,"10.1145/3131277.3132179","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85037047945&doi=10.1145%2f3131277.3132179&partnerID=40&md5=f5343c613cffb410c595b59c94070b0e","Carleton University, Ottawa, Canada","McClelland, J.C., Carleton University, Ottawa, Canada; Teather, R.J., Carleton University, Ottawa, Canada; Girouard, A., Carleton University, Ottawa, Canada","We present HaptoBend, a novel shape-changing input device providing passive haptic feedback (PHF) for a wide spectrum of objects in virtual reality (VR). Past research in VR shows that PHF increases presence and improves user task performance. However, providing PHF for multiple objects usually requires complex, immobile systems, or multiple props. HaptoBend addresses this problem by allowing users to bend the device into 2D plane-like shapes and multi-surface 3D shapes. We believe HaptoBend’s physical approximations of virtual objects can provide realistic haptic feedback through research demonstrating the dominance of human vision over other senses in VR. To test the effectiveness of HaptoBend in matching 2D planar and 3D multi-surface shapes, we conducted an experiment modeled after gesture elicitation studies with 20 participants. High goodness and ease scores show shape-changing passive haptic devices, like HaptoBend, are an effective approach to generalized haptics. Further analysis supports the use of physical approximations for realistic haptic feedback. © 2017 Copyright is held by the owner/author(s).","Haptic feedback; Shape-changing interactions; Virtual Reality","Haptic interfaces; Effective approaches; Haptic feedbacks; Multiple objects; Passive haptic devices; Physical approximations; Task performance; Virtual objects; Wide spectrum; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85037047945
"Dubovi I., Levy S.T., Dagan E.","57194381219;7402774725;6701806618;","Now I know how! The learning process of medication administration among nursing students with non-immersive desktop virtual reality simulation",2017,"Computers and Education","113",,,"16","27",,41,"10.1016/j.compedu.2017.05.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019934867&doi=10.1016%2fj.compedu.2017.05.009&partnerID=40&md5=919db5ba81874d7253ec797d5f546f84","Department of Learning, Instruction and Teacher Education, Faculty of Education, University of Haifa, Israel; The Cheryl Spencer Department of Nursing, Faculty of Social Welfare and Health Sciences, University of Haifa, Israel","Dubovi, I., Department of Learning, Instruction and Teacher Education, Faculty of Education, University of Haifa, Israel, The Cheryl Spencer Department of Nursing, Faculty of Social Welfare and Health Sciences, University of Haifa, Israel; Levy, S.T., Department of Learning, Instruction and Teacher Education, Faculty of Education, University of Haifa, Israel; Dagan, E., The Cheryl Spencer Department of Nursing, Faculty of Social Welfare and Health Sciences, University of Haifa, Israel","The purpose of this study was to create and explore an effective and accessible teaching method for the higher education of professionals requiring practical skills. We aimed to evaluate the effectiveness of our Pharmacology Inter-Leaved Learning Virtual Reality (PILL-VR) simulation when applied to nursing education, as a tool for learning medication administration procedures. A quasi-experimental pretest-intervention-posttest comparison group design was conducted based on quantitative analysis of questionnaires, video recordings and worksheets. Participants were nursing students who either learned medication administration processes with a PILL-VR simulation platform (experimental group; n = 82) or who learned with lecture-based curriculum (n = 47; comparison group). The results revealed significantly higher conceptual and procedural knowledge learning gains following activity with the PILL-VR simulation compared to studying via lecture-based curriculum. PILL-VR exposed the students to their own errors, allowing procedure rehearsal followed by constant feedback which is essential to skill acquisition. Although PILL-VR is based on a desktop system, it facilitated a strong sense of presence. A small positive correlation was found on questionnaire scores between the sense of presence, particularly the sense of control, and conceptual-procedural learning of medication administration. This indicates that by improving students' sense of control in the PILL-VR, the learning process can be improved. Hence, VR simulations may provide affordable and flexible access to practice necessary practical skills in higher education, which is crucial to developing students’ expertise. © 2017 Elsevier Ltd","Higher education; Nursing education; Simulation; Virtual reality","Curricula; E-learning; Learning systems; Nursing; Surveys; Technology transfer; Video recording; Virtual reality; Analysis of questionnaire; Desktop virtual reality; Higher education; Nursing education; Positive correlations; Procedural knowledge; Procedural learning; Simulation; Students",Article,"Final","",Scopus,2-s2.0-85019934867
"Gomez J., Hoffman H.G., Bistricky S.L., Gonzalez M., Rosenberg L., Sampaio M., Garcia-Palacios A., Navarro-Haro M.V., Alhalabi W., Rosenberg M., Meyer W.J., III, Linehan M.M.","57220827769;7201677607;18036721500;57195929836;7201774858;57192413810;55917735200;56955636800;35316856000;9275212500;55444517900;7005724678;","The use of virtual reality facilitates dialectical behavior therapy® ""observing sounds and visuals"" mindfulness skills training exercises for a Latino patient with severe burns: A case study",2017,"Frontiers in Psychology","8","SEP", 1611,"","",,9,"10.3389/fpsyg.2017.01611","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030161102&doi=10.3389%2ffpsyg.2017.01611&partnerID=40&md5=cfc6de9a2ef8d7ba69415b3340aa8e50","Department of Psychology, Shriners Hospitals for Children-Galveston, Galveston, TX, United States; Clinical Health and Applied Sciences, University of Houston-Clear Lake, Houston, TX, United States; Virtual Reality Research Center at the Human Photonics Lab, Mechanical Engineering Department, University of Washington, Seattle, WA, United States; Department of Psychiatry and Behavioral Sciences, University of Texas Medical Branch, Galveston, TX, United States; Psychology Department, Jaume I University, Castellón de la Plana, Spain; Centro de Investigación Biomedica en Red-Fisiopatologia de la Obesidad y Nutricion (CIBERobn), Madrid, Spain; Hospital General de Catalunya, Barcelona, Spain; Virtual Reality Research Center, Computer Science Department, Effat University, Jeddah, Saudi Arabia; Behavioral Research and Therapy Clinics, Department of Psychology, University of Washington, Seattle, WA, United States","Gomez, J., Department of Psychology, Shriners Hospitals for Children-Galveston, Galveston, TX, United States, Clinical Health and Applied Sciences, University of Houston-Clear Lake, Houston, TX, United States; Hoffman, H.G., Virtual Reality Research Center at the Human Photonics Lab, Mechanical Engineering Department, University of Washington, Seattle, WA, United States; Bistricky, S.L., Clinical Health and Applied Sciences, University of Houston-Clear Lake, Houston, TX, United States; Gonzalez, M., Department of Psychology, Shriners Hospitals for Children-Galveston, Galveston, TX, United States, Department of Psychiatry and Behavioral Sciences, University of Texas Medical Branch, Galveston, TX, United States; Rosenberg, L., Department of Psychology, Shriners Hospitals for Children-Galveston, Galveston, TX, United States, Department of Psychiatry and Behavioral Sciences, University of Texas Medical Branch, Galveston, TX, United States; Sampaio, M., Virtual Reality Research Center at the Human Photonics Lab, Mechanical Engineering Department, University of Washington, Seattle, WA, United States; Garcia-Palacios, A., Psychology Department, Jaume I University, Castellón de la Plana, Spain, Centro de Investigación Biomedica en Red-Fisiopatologia de la Obesidad y Nutricion (CIBERobn), Madrid, Spain; Navarro-Haro, M.V., Hospital General de Catalunya, Barcelona, Spain; Alhalabi, W., Virtual Reality Research Center, Computer Science Department, Effat University, Jeddah, Saudi Arabia; Rosenberg, M., Department of Psychology, Shriners Hospitals for Children-Galveston, Galveston, TX, United States, Department of Psychiatry and Behavioral Sciences, University of Texas Medical Branch, Galveston, TX, United States; Meyer, W.J., III, Department of Psychology, Shriners Hospitals for Children-Galveston, Galveston, TX, United States, Department of Psychiatry and Behavioral Sciences, University of Texas Medical Branch, Galveston, TX, United States; Linehan, M.M., Behavioral Research and Therapy Clinics, Department of Psychology, University of Washington, Seattle, WA, United States","Sustaining a burn injury increases an individual's risk of developing psychological problems such as generalized anxiety, negative emotions, depression, acute stress disorder, or post-traumatic stress disorder. Despite the growing use of Dialectical Behavioral Therapy® (DBT®) by clinical psychologists, to date, there are no published studies using standard DBT® or DBT® skills learning for severe burn patients. The current study explored the feasibility and clinical potential of using Immersive Virtual Reality (VR) enhanced DBT® mindfulness skills training to reduce negative emotions and increase positive emotions of a patient with severe burn injuries. The participant was a hospitalized (in house) 21-year-old Spanish speaking Latino male patient being treated for a large (> 35% TBSA) severe flame burn injury. Methods: The patient looked into a pair of Oculus Rift DK2 virtual reality goggles to perceive the computer-generated virtual reality illusion of floating down a river, with rocks, boulders, trees, mountains, and clouds, while listening to DBT® mindfulness training audios during 4 VR sessions over a 1 month period. Study measures were administered before and after each VR session. Results: As predicted, the patient reported increased positive emotions and decreased negative emotions. The patient also accepted the VR mindfulness treatment technique. He reported the sessions helped him become more comfortable with his emotions and he wanted to keep using mindfulness after returning home. Conclusions: Dialectical Behavioral Therapy is an empirically validated treatment approach that has proved effective with non-burn patient populations for treating many of the psychological problems experienced by severe burn patients. The current case study explored for the first time, the use of immersive virtual reality enhanced DBT® mindfulness skills training with a burn patient. The patient reported reductions in negative emotions and increases in positive emotions, after VR DBT® mindfulness skills training. Immersive Virtual Reality is becoming widely available to mainstream consumers, and thus has the potential to make this treatment available to a much wider number of patient populations, including severe burn patients. Additional development, and controlled studies are needed. © 2017 Gomez, Hoffman, Bistricky, Gonzalez, Rosenberg, Sampaio, Garcia-Palacios, Navarro-Haro, Alhalabi, Rosenberg, Meyer and Linehan.","Burn patients; Dialectical behavioral therapy; Emotions; Mindfulness; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85030161102
"Ossmy O., Mukamel R.","55338997600;16444928300;","Using virtual reality to transfer motor skill knowledge from one hand to another",2017,"Journal of Visualized Experiments","2017","127", e55965,"","",,4,"10.3791/55965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85031003576&doi=10.3791%2f55965&partnerID=40&md5=0eeb90d335e0ea82dd7710f89d081759","Sagol School of Neuroscience, Tel-Aviv University, Israel; School of Psychological Sciences, Tel-Aviv University, Israel","Ossmy, O., Sagol School of Neuroscience, Tel-Aviv University, Israel, School of Psychological Sciences, Tel-Aviv University, Israel; Mukamel, R., Sagol School of Neuroscience, Tel-Aviv University, Israel, School of Psychological Sciences, Tel-Aviv University, Israel","As far as acquiring motor skills is concerned, training by voluntary physical movement is superior to all other forms of training (e.g. training by observation or passive movement of trainee’s hands by a robotic device). This obviously presents a major challenge in the rehabilitation of a paretic limb since voluntary control of physical movement is limited. Here, we describe a novel training scheme we have developed that has the potential to circumvent this major challenge. We exploited the voluntary control of one hand and provided real-time movement-based manipulated sensory feedback as if the other hand is moving. Visual manipulation through virtual reality (VR) was combined with a device that yokes left-hand fingers to passively follow right-hand voluntary finger movements. In healthy subjects, we demonstrate enhanced within-session performance gains of a limb in the absence of voluntary physical training. Results in healthy subjects suggest that training with the unique VR setup might also be beneficial for patients with upper limb hemiparesis by exploiting the voluntary control of their healthy hand to improve rehabilitation of their affected hand. © 2017 Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported License.","Behavior; Cross-education; Finger sequence; Issue 127; Motor learning; Sensory feedback; Virtual reality; Visual perception","hand; human; motor performance; movement (physiology); physiology; virtual reality; Hand; Humans; Motor Skills; Movement; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85031003576
"Wakisaka S., Hiyama A., Inami M.","55604107400;8866503200;9640047900;","Transmission of experiences with augmented human techniques",2017,"UbiComp/ISWC 2017 - Adjunct Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International Symposium on Wearable Computers",,,,"740","744",,,"10.1145/3123024.3129276","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030833467&doi=10.1145%2f3123024.3129276&partnerID=40&md5=f0d290c5cb1d850bd07dbff7bc5feb58","Information Somatics Laboratory, Research Center for Advanced Science and Technology, Eng.1-403,7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan","Wakisaka, S., Information Somatics Laboratory, Research Center for Advanced Science and Technology, Eng.1-403,7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Hiyama, A., Information Somatics Laboratory, Research Center for Advanced Science and Technology, Eng.1-403,7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan; Inami, M., Information Somatics Laboratory, Research Center for Advanced Science and Technology, Eng.1-403,7-3-1 Hongo, Bunkyo-ku, Tokyo, 113-8656, Japan","Transferring human experience is one of fundamental and vital activities in our history. Teachers, trainers, textbooks, instruction movies, etc. has been introduced for the transmission. New methods that enhance transmission of human experiences are always desired according to the social and economic situations. Recent developments of virtual reality (VR), augmented realty (AR) and augmented human (AH) technologies make us expect a future that we can instantaneously (or at least more efficiently) transfer the skills or knowledges from one to another, like in Sci-Fi movies. However, for that, we need to optimize the transmission method for each person. We propose the augmented-human based approach for the experience transmission, and review some factors that are essential but not well focused in past studies. Copyright © 2017 ACM.","Augmented human; Cognitive bias; Experimental supplement; Health care; Sports","Health care; Sports; Teaching; Ubiquitous computing; Wearable computers; Wearable technology; Augmented human; Cognitive bias; Economic situation; Experimental supplement; Human techniques; Transmission methods; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85030833467
"Tidoni E., Abu-Alqumsan M., Leonardis D., Kapeller C., Fusco G., Guger C., Hintermuller C., Peer A., Frisoli A., Tecchia F., Bergamasco M., Aglioti S.M.","46261708700;41261045900;54389543000;37083868500;56388423300;55903211100;8440419500;15823160300;6603070041;6603477008;7003907071;7007006465;","Local and Remote Cooperation with Virtual and Robotic Agents: A P300 BCI Study in Healthy and People Living with Spinal Cord Injury",2017,"IEEE Transactions on Neural Systems and Rehabilitation Engineering","25","9", 7797151,"1622","1632",,19,"10.1109/TNSRE.2016.2626391","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029600422&doi=10.1109%2fTNSRE.2016.2626391&partnerID=40&md5=b17bb08935767322e6f8bed36b476792","Department of Psychology, University of Rome la Sapienza, Rome, 00185, Italy; Fondazione Santa Lucia IRCCS, Rome, Italy; Chair of Automatic Control Engineering, Technical University of Munich, TUM, Munich, Germany; Percro Laboratory, Scuola Superiore sant'Anna, Pisa, Italy; Guger Technologies OG, Graz, 8020, Austria; G.tec Medical Engineering GmbH, Schiedlberg, Austria; Bristol Robotics Laboratory, University of the West of England, Bristol, Bristol, United Kingdom","Tidoni, E., Department of Psychology, University of Rome la Sapienza, Rome, 00185, Italy, Fondazione Santa Lucia IRCCS, Rome, Italy; Abu-Alqumsan, M., Chair of Automatic Control Engineering, Technical University of Munich, TUM, Munich, Germany; Leonardis, D., Percro Laboratory, Scuola Superiore sant'Anna, Pisa, Italy; Kapeller, C., Guger Technologies OG, Graz, 8020, Austria, G.tec Medical Engineering GmbH, Schiedlberg, Austria; Fusco, G., Department of Psychology, University of Rome la Sapienza, Rome, 00185, Italy, Fondazione Santa Lucia IRCCS, Rome, Italy; Guger, C., Guger Technologies OG, Graz, 8020, Austria, G.tec Medical Engineering GmbH, Schiedlberg, Austria; Hintermuller, C., Guger Technologies OG, Graz, 8020, Austria, G.tec Medical Engineering GmbH, Schiedlberg, Austria; Peer, A., Bristol Robotics Laboratory, University of the West of England, Bristol, Bristol, United Kingdom; Frisoli, A., Percro Laboratory, Scuola Superiore sant'Anna, Pisa, Italy; Tecchia, F., Percro Laboratory, Scuola Superiore sant'Anna, Pisa, Italy; Bergamasco, M., Percro Laboratory, Scuola Superiore sant'Anna, Pisa, Italy; Aglioti, S.M., Department of Psychology, University of Rome la Sapienza, Rome, 00185, Italy, Fondazione Santa Lucia IRCCS, Rome, Italy","The development of technological applications that allow people to control and embody external devices within social interaction settings represents a major goal for current and future brain-computer interface (BCI) systems. Prior research has suggested that embodied systems may ameliorate BCI end-user's experience and accuracy in controlling external devices. Along these lines, we developed an immersive P300-based BCI application with a head-mounted display for virtual-local and robotic-remote social interactions and explored in a group of healthy participants the role of proprioceptive feedback in the control of a virtual surrogate (Study 1). Moreover, we compared the performance of a small group of people with spinal cord injury (SCI) to a control group of healthy subjects during virtual and robotic social interactions (Study 2), where both groups received a proprioceptive stimulation. Our attempt to combine immersive environments, BCI technologies and neuroscience of body ownership suggests that providing realistic multisensory feedback still represents a challenge. Results have shown that healthy and people living with SCI used the BCI within the immersive scenarios with good levels of performance (as indexed by task accuracy, optimizations calls and Information Transfer Rate) and perceived control of the surrogates. Proprioceptive feedback did not contribute to alter performance measures and body ownership sensations. Further studies are necessary to test whether sensorimotor experience represents an opportunity to improve the use of future embodied BCI applications. © 2001-2011 IEEE.","Body illusions - tendon vibration; brain-computer interface (BCI) P300; spinal cord injury; teleoperation; virtual reality","Computer control systems; Feedback; Helmet mounted displays; Interfaces (computer); Patient rehabilitation; Remote control; Robotics; Sensory perception; Social sciences; Virtual reality; Body illusions - tendon vibration; Head mounted displays; Immersive environment; Information transfer rate; Multi-sensory feedback; Performance measure; Spinal cord injuries (SCI); Technological applications; Brain computer interface; adult; Article; biceps brachii muscle; brain computer interface; clinical article; computer graphics; controlled study; discriminant analysis; female; human; human computer interaction; kinematics; male; mathematical analysis; middle aged; neuroscience nursing; proprioceptive feedback; questionnaire; real time tracking system; remote sensing; sensorimotor cortex; social interaction; spinal cord injury; telemonitoring; tendon; virtual reality; visual acuity; visual stimulation; computer interface; event related potential; imagination; man machine interaction; movement (physiology); pathophysiology; procedures; randomized controlled trial; reproducibility; robotics; sensitivity and specificity; Spinal Cord Injuries; task performance; young adult; Adult; Brain-Computer Interfaces; Event-Related Potentials, P300; Female; Humans; Imagination; Male; Man-Machine Systems; Movement; Reproducibility of Results; Robotics; Sensitivity and Specificity; Spinal Cord Injuries; Task Performance and Analysis; User-Computer Interface; Young Adult",Article,"Final","",Scopus,2-s2.0-85029600422
"Tatsumi T., Sato H., Takadama K.","57188810333;55731915800;35496082000;","Learning classifier system based on mean of reward",2017,"Journal of Advanced Computational Intelligence and Intelligent Informatics","21","5",,"895","906",,2,"10.20965/jaciii.2017.p0895","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032797826&doi=10.20965%2fjaciii.2017.p0895&partnerID=40&md5=8cbf405139ed5595fd711a9d4a3ed6f0","University of Electro-Communications, 1-5-1 Chofugaoka, Chofu-shi, Tokyo, 182-8585, Japan","Tatsumi, T., University of Electro-Communications, 1-5-1 Chofugaoka, Chofu-shi, Tokyo, 182-8585, Japan; Sato, H., University of Electro-Communications, 1-5-1 Chofugaoka, Chofu-shi, Tokyo, 182-8585, Japan; Takadama, K., University of Electro-Communications, 1-5-1 Chofugaoka, Chofu-shi, Tokyo, 182-8585, Japan","This paper focuses on the generalization of classifiers in noisy problems and aims at construction learning classifier system (LCS) that can acquire the optimal classifier subset by dynamically determining the classifier generalization criteria. In this paper, an accuracy-based LCS (XCS) that uses the mean of the reward (XCS-MR) is introduced, which can correctly identify classifiers as either accurate or inaccurate for noisy problems, and investigates its effectiveness when used for several noisy problems. Applying XCS and an XCS based on the variance of reward (XCS-VR) as the conventional LCSs, along with XCS-MR, to noisy 11-multiplexer problems where the reward value changes according to a Gaussian distribution, Cauchy distribution, and lognormal distribution revealed the following: (1) XCS-VR and XCS-MR could select the correct action for every type of reward distribution; (2) XCSMR could appropriately generalize the classifiers with the smallest amount of data; and (3) XCS-MR could acquire the optimal classifier subset in every trial for every type of reward distribution.","Accuracy criteria; Learning classifier system; Reward; Sample standard deviation","Reinforcement learning; Accuracy criteria; Cauchy distribution; Construction learning; Learning classifier system; Log-normal distribution; Optimal classifiers; Reward; Standard deviation; Learning systems",Article,"Final","",Scopus,2-s2.0-85032797826
"Zhang C., Tatsumi T., Nakata M., Takadama K.","57193063354;57188810333;54784960600;35496082000;","Approach to clustering with variance-based XCS",2017,"Journal of Advanced Computational Intelligence and Intelligent Informatics","21","5",,"885","894",,1,"10.20965/jaciii.2017.p0885","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032819680&doi=10.20965%2fjaciii.2017.p0885&partnerID=40&md5=c267585fbdd1214fa79e41679160b599","University of Electro-Communications, 1-5-1 Chofugaoka, Chofu-shi, Tokyo, 182-8585, Japan; Yokohama National University, 79-1 Tokiwadai, Hodogaya-ku, Yokohama, Japan","Zhang, C., University of Electro-Communications, 1-5-1 Chofugaoka, Chofu-shi, Tokyo, 182-8585, Japan; Tatsumi, T., University of Electro-Communications, 1-5-1 Chofugaoka, Chofu-shi, Tokyo, 182-8585, Japan; Nakata, M., Yokohama National University, 79-1 Tokiwadai, Hodogaya-ku, Yokohama, Japan; Takadama, K., University of Electro-Communications, 1-5-1 Chofugaoka, Chofu-shi, Tokyo, 182-8585, Japan","This paper presents an approach to clustering that extends the variance-based Learning Classifier System (XCS-VR). In real world problems, the ability to combine similar rules is crucial in the knowledge discovery and data mining field. Conventionally, XCS-VR is able to acquire generalized rules, but it cannot further acquire more generalized rules from these rules. The proposed approach (called XCS-VRc) accomplishes this by integrating similar generalized rules. To validate the proposed approach, we designed a benchmark problem to examine whether XCS-VRc can cluster both the generalized andmore generalized features in the input data. The proposed XCS-VRc proved to be more efficient than XCS and the conventional XCSVR.","Learning classifier system; Machine learning","Data mining; Reinforcement learning; Bench-mark problems; Input datas; Knowledge discovery and data minings; Learning classifier system; Real-world problem; Learning systems",Article,"Final","",Scopus,2-s2.0-85032819680
"Kiefer A.W., Dicesare C., Bonnette S., Kitchen K., Gadd B., Thomas S., Barber Foss K.D., Myer G.D., Riley M.A., Silva P.","35316086800;55620685100;55004035700;57195460949;57003350800;55772425700;6507308390;6701852696;7203009785;16302548400;","Sport-specific virtual reality to identify profiles of anterior cruciate ligament injury risk during unanticipated cutting",2017,"International Conference on Virtual Rehabilitation, ICVR","2017-June",, 8007511,"","",,4,"10.1109/ICVR.2017.8007511","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034266510&doi=10.1109%2fICVR.2017.8007511&partnerID=40&md5=cf5780b41e2b5c33be48505f311391ad","Division of Sports Medicine, Cincinnati Children's Hospital, Cincinnati, OH, United States; Center for Cognition Action, and Perception, University of Cincinnati, Cincinnati, OH, United States","Kiefer, A.W., Division of Sports Medicine, Cincinnati Children's Hospital, Cincinnati, OH, United States; Dicesare, C., Division of Sports Medicine, Cincinnati Children's Hospital, Cincinnati, OH, United States; Bonnette, S., Division of Sports Medicine, Cincinnati Children's Hospital, Cincinnati, OH, United States; Kitchen, K., Division of Sports Medicine, Cincinnati Children's Hospital, Cincinnati, OH, United States; Gadd, B., Division of Sports Medicine, Cincinnati Children's Hospital, Cincinnati, OH, United States; Thomas, S., Division of Sports Medicine, Cincinnati Children's Hospital, Cincinnati, OH, United States; Barber Foss, K.D., Division of Sports Medicine, Cincinnati Children's Hospital, Cincinnati, OH, United States; Myer, G.D., Division of Sports Medicine, Cincinnati Children's Hospital, Cincinnati, OH, United States; Riley, M.A., Center for Cognition Action, and Perception, University of Cincinnati, Cincinnati, OH, United States; Silva, P., Center for Cognition Action, and Perception, University of Cincinnati, Cincinnati, OH, United States","Female athletes are at an increased risk of anterior cruciate ligament (ACL) injury in competitive sport during running, jumping and cutting tasks. This risk is due to deficits in posterior chain and hip recruitment associated with aberrant frontal knee loads. The identification of these risk factors has led to targeted neuromuscular training (NMT) interventions to enhance hip neuromuscular control during such tasks. Despite the successful modification of ACL injury risk factors following NMT, the transfer of these corrected movement patterns to the sport-specific contexts has not been directly evaluated. Sport-specific virtual reality (VR) may provide the best method to measure training transfer to realistic sport performance, while still allowing appropriate experimental control and high-fidelity performance measurements. The current study examined the effect of a biofeedback-driven augmented NMT (aNMT) on skill transfer of ACL-injury resistant movement patterns during performance of sport-specific VR scenarios. Five trained athletes participated, and their performance on an unanticipated cutting task was assessed in VR prior to and after six weeks of aNMT. A significant 87% reduction in internal hip rotation was observed on the plant leg during the loading phase of cutting (p =.05), along with an observed 116% reduction during the push-off phase (p =.02), from pre-to post-training. A non-significant trend of a 19% reduction in knee abduction was also observed (p =.15). This study is the first that has utilized free ambulatory wireless VR to assess injury risk in athletes during performance of sport-specific tasks. The reduction in internal hip rotation and knee abduction align with previous findings on laboratory based tests. The current results are the first step in the validation of sport-specific VR as a tool for understanding injury risk during simulation of real-world sport performance. © 2017 IEEE.","anterior cruciate ligament; cutting; soccer; sport; virtual reality","Biofeedback; Cutting; Health risks; Risk assessment; Virtual reality; Anterior cruciate ligament; Anterior cruciate ligament injury; Competitive sports; Experimental control; Neuromuscular control; Performance measurements; soccer; Sport performance; Sports",Conference Paper,"Final","",Scopus,2-s2.0-85034266510
"Shochat G., Maoz S., Stark-Inbar A., Blumenfeld B., Rand D., Preminger S., Sacher Y.","57197733805;57197737292;57191206641;13408503500;8610999900;14833131300;6506781178;","Motion-based virtual reality cognitive training targeting executive functions in acquired brain injury community-dwelling individuals: A feasibility and initial efficacy pilot",2017,"International Conference on Virtual Rehabilitation, ICVR","2017-June",, 8007530,"","",,4,"10.1109/ICVR.2017.8007530","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034269195&doi=10.1109%2fICVR.2017.8007530&partnerID=40&md5=f02845a48c89fde17904e5b502faa247","Department of Traumatic Brain Injury, Loewenstein Rehabilitation Center, Raanana, Israel; Intendu Ltd, Herzliya, Israel; Department of Occupational Therapy, Tel Aviv University, Tel Aviv, Israel","Shochat, G., Department of Traumatic Brain Injury, Loewenstein Rehabilitation Center, Raanana, Israel; Maoz, S., Intendu Ltd, Herzliya, Israel; Stark-Inbar, A., Intendu Ltd, Herzliya, Israel; Blumenfeld, B., Intendu Ltd, Herzliya, Israel; Rand, D., Department of Occupational Therapy, Tel Aviv University, Tel Aviv, Israel; Preminger, S., Intendu Ltd, Herzliya, Israel; Sacher, Y., Department of Traumatic Brain Injury, Loewenstein Rehabilitation Center, Raanana, Israel","Acquired brain injury (ABI) is a leading cause of long-term cognitive disability, often involving deficits in executive functions (EF). ABI patients usually stop receiving cognitive treatment when leaving the rehabilitation facility or shortly thereafter, due to the high cost of therapy sessions and the mobility requirement to access therapy. Software solutions offer a promising tool for accessible and affordable cognitive rehabilitation in the home environment. However, research provides limited evidence for effective transfer of benefits from computerized cognitive training to real-life functions. Virtual reality (VR) exergames using motion-interaction offer a more realistic and natural training environment, and are therefore expected to facilitate a more effective transfer. Although commercial exergames may bring about some cognitive gains, they usually do not target cognitive functions directly. Here we describe a novel exergames platform, the Active Brain Trainer (ABT), designed to directly target EF, using games in multiple realistic contexts. The software adapts in real-time to the patient's behavior, providing feedback and rewards, and hence may enhance usability and compliance. The primary goal of the current study is to assess the feasibly and acceptability of this platform for community-dwelling ABI patients during the chronic phase. A secondary goal is to assess the initial efficacy on EF and functional benefits from program training. Participants were instructed to use the games for 15-20 sessions. Neuropsychological assessments of EF and daily life functions were performed before and after training. Participants also filled a satisfaction questionnaire following training. All training and assessments were conducted in the participants' homes. Game performance was recorded throughout training sessions. Preliminary results from the six ABI patients who successfully completed the program so far show no adverse effects. Participants reported enjoyment and satisfaction from training. Participants performed increasingly more challenging EF tasks within game environments. Initial results show improvements in functional tasks and most executive neuropsychological assessments following training. Additional participants are currently being trained to increase the power of the results. These preliminary findings support the feasibility and potential efficacy of the motion-based cognitive training of EF for community-dwelling individuals with ABI. © 2017 IEEE.","acquired brain injury; Cognitive training; community-dwelling; executive functions; exergames; motion-based","Buildings; E-learning; Housing; Patient treatment; Virtual reality; Acquired brain injuries; Cognitive training; community-dwelling; Executive function; Exergames; motion-based; Patient rehabilitation",Conference Paper,"Final","",Scopus,2-s2.0-85034269195
"Ragan E.D., Scerbo S., Bacim F., Bowman D.A.","26667185300;55210765300;16174310700;57203231782;","Amplified Head Rotation in Virtual Reality and the Effects on 3D Search, Training Transfer, and Spatial Orientation",2017,"IEEE Transactions on Visualization and Computer Graphics","23","8", 7547900,"1880","1895",,22,"10.1109/TVCG.2016.2601607","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028407406&doi=10.1109%2fTVCG.2016.2601607&partnerID=40&md5=36f5ebc4f3b8d70469432fd11b448a6f","Texas A and M University, College Station, TX  77843, United States; Virginia Tech, Blacksburg, VA  24061, United States","Ragan, E.D., Texas A and M University, College Station, TX  77843, United States; Scerbo, S., Virginia Tech, Blacksburg, VA  24061, United States; Bacim, F., Virginia Tech, Blacksburg, VA  24061, United States; Bowman, D.A., Virginia Tech, Blacksburg, VA  24061, United States","Many types of virtual reality (VR) systems allow users to use natural, physical head movements to view a 3D environment. In some situations, such as when using systems that lack a fully surrounding display or when opting for convenient low-effort interaction, view control can be enabled through a combination of physical and virtual turns to view the environment, but the reduced realism could potentially interfere with the ability to maintain spatial orientation. One solution to this problem is to amplify head rotations such that smaller physical turns are mapped to larger virtual turns, allowing trainees to view the entire surrounding environment with small head movements. This solution is attractive because it allows semi-natural physical view control rather than requiring complete physical rotations or a fully-surrounding display. However, the effects of amplified head rotations on spatial orientation and many practical tasks are not well understood. In this paper, we present an experiment that evaluates the influence of amplified head rotation on 3D search, spatial orientation, and cybersickness. In the study, we varied the amount of amplification and also varied the type of display used (head-mounted display or surround-screen CAVE) for the VR search task. By evaluating participants first with amplification and then without, we were also able to study training transfer effects. The findings demonstrate the feasibility of using amplified head rotation to view 360 degrees of virtual space, but noticeable problems were identified when using high amplification with a head-mounted display. In addition, participants were able to more easily maintain a sense of spatial orientation when using the CAVE version of the application, which suggests that visibility of the user's body and awareness of the CAVE's physical environment may have contributed to the ability to use the amplification technique while keeping track of orientation. © 1995-2012 IEEE.","3D interaction; cybersickness; Rotation amplification; Search; Spatial orientation; Virtual reality","Caves; E-learning; Helmet mounted displays; Virtual reality; 3D interactions; Amplification technique; Cybersickness; Head mounted displays; Physical environments; Search; Spatial orientations; Surrounding environment; Rotation",Article,"Final","",Scopus,2-s2.0-85028407406
"Shoaib M., Hussain I., Mirza H.T., Tayyab M.","57216061898;55523101579;36806461600;57217473760;","The role of information and innovative technology for rehabilitation of children with Autism: A Systematic Literature Review",2017,"Proceedings of the 2017 17th International Conference on Computational Science and Its Applications, ICCSA 2017",,, 7999647,"","",,8,"10.1109/ICCSA.2017.7999647","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041241972&doi=10.1109%2fICCSA.2017.7999647&partnerID=40&md5=5afa2ab6b33f37ccbf85045815ef706b","Department of Computer Science, Sharif College of Engineering and Technology, Lahore, Pakistan; Department of Computer Science and IT, University of Lahore, Lahore, Pakistan; Department of Computer Science, COMSATS Institute of Information Technology, Lahore, Pakistan; Department of Electrical Engineering, King Fahd University of Petroleum and Minerals, Saudi Arabia","Shoaib, M., Department of Computer Science, Sharif College of Engineering and Technology, Lahore, Pakistan; Hussain, I., Department of Computer Science and IT, University of Lahore, Lahore, Pakistan; Mirza, H.T., Department of Computer Science, COMSATS Institute of Information Technology, Lahore, Pakistan; Tayyab, M., Department of Electrical Engineering, King Fahd University of Petroleum and Minerals, Saudi Arabia","This paper presents a literature review of roles played by information and innovative technologies for helping children suffering from Autism Spectrum Disease (ASD). ASD is a pervasive developmental disorder having issues 1with social communication, interests, coordination, attention, and health. People with autism are very sensitive and cannot afford a minor change in their surrounding environment. They do not know how to react according to the situation. The information technology is very helpful to resolve their issues. The best solution for autistic children is to educate them. The education in younger age is considered as more helpful for autistic people. The method of education for autistic people through computers is very promising nowadays with advanced information and communication technologies. Computers represent a considerable and valuable part in educational techniques of autism. Many software's can be used to help children with autism. A detailed comparison of different games and applications which are helpful for kids with autism is described. Information and Computer Technologies are very helpful to predict facial expression, speaking and writing skills. Virtual Reality based frameworks are very helpful to estimate a different kind of fears faced by autistic people. © 2017 IEEE.","Autism Spectrum Disease; Children; Innovative and Information technologies; Rehabilitation","Diseases; Education; Technology transfer; Virtual reality; Advanced informations; Children; Children with autisms; Innovative technology; Pervasive developmental disorders; Social communications; Surrounding environment; Systematic literature review; Patient rehabilitation",Conference Paper,"Final","",Scopus,2-s2.0-85041241972
"Brinkmann C., Fritz M., Pankratius U., Bahde R., Neumann P., Schlueter S., Senninger N., Rijcken E.","57192989407;54985745400;57192977262;23479307100;55308774800;57192976298;7005472666;6602903668;","Box- or Virtual-Reality Trainer: Which Tool Results in Better Transfer of Laparoscopic Basic Skills?—A Prospective Randomized Trial",2017,"Journal of Surgical Education","74","4",,"724","735",,15,"10.1016/j.jsurg.2016.12.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009826742&doi=10.1016%2fj.jsurg.2016.12.009&partnerID=40&md5=aeac28a5d3c169dbd0990e793dc53b92","Department of General and Visceral Surgery, University Hospital Muenster, Muenster, Germany","Brinkmann, C., Department of General and Visceral Surgery, University Hospital Muenster, Muenster, Germany; Fritz, M., Department of General and Visceral Surgery, University Hospital Muenster, Muenster, Germany; Pankratius, U., Department of General and Visceral Surgery, University Hospital Muenster, Muenster, Germany; Bahde, R., Department of General and Visceral Surgery, University Hospital Muenster, Muenster, Germany; Neumann, P., Department of General and Visceral Surgery, University Hospital Muenster, Muenster, Germany; Schlueter, S., Department of General and Visceral Surgery, University Hospital Muenster, Muenster, Germany; Senninger, N., Department of General and Visceral Surgery, University Hospital Muenster, Muenster, Germany; Rijcken, E., Department of General and Visceral Surgery, University Hospital Muenster, Muenster, Germany","Objective Simulation training improves laparoscopic performance. Laparoscopic basic skills can be learned in simulators as box- or virtual-reality (VR) trainers. However, there is no clear recommendation for either box or VR trainers as the most appropriate tool for the transfer of acquired laparoscopic basic skills into a surgical procedure. Design Both training tools were compared, using validated and well-established curricula in the acquirement of basic skills, in a prospective randomized trial in a 5-day structured laparoscopic training course. Participants completed either a box- or VR-trainer curriculum and then applied the learned skills performing an ex situ laparoscopic cholecystectomy on a pig liver. The performance was recorded on video and evaluated offline by 4 blinded observers using the Global Operative Assessment of Laparoscopic Skills (GOALS) score. Learning curves of the various exercises included in the training course were compared and the improvement in each exercise was analyzed. Setting Surgical Skills Lab of the Department of General and Visceral Surgery, University Hospital Muenster. Participants Surgical novices without prior surgical experience (medical students, n = 36). Results Posttraining evaluation showed significant improvement compared with baseline in both groups, indicating acquisition of laparoscopic basic skills. Learning curves showed almost the same progression with no significant differences. In simulated laparoscopic cholecystectomy, total GOALS score was significantly higher for the box-trained group than the VR-trained group (box: 15.31 ± 3.61 vs. VR: 12.92 ± 3.06; p = 0.039; Hedge׳s g* = 0.699), indicating higher technical skill levels. Conclusions Despite both systems having advantages and disadvantages, they can both be used for simulation training for laparoscopic skills. In the setting with 2 structured, validated and almost identical curricula, the box-trained group appears to be superior in the better transfer of basic skills into an experimental but structured surgical procedure. © 2017 Association of Program Directors in Surgery","computer simulation; education; GOALS; laparoscopy; Practice-Based Learning and Improvement; prospective studies; simulation training; Systems-Based Practice","adult; Article; box reality; depth perception; female; human; human experiment; internal consistency; interrater reliability; laparoscopic cholecystectomy; learning curve; male; priority journal; professional competence; randomized controlled trial; self evaluation; simulation training; surgical training; virtual reality; animal; animal model; clinical competence; controlled study; education; laparoscopic cholecystectomy; liver; medical education; pig; procedures; prospective study; questionnaire; simulation training; surgery; Adult; Animals; Cholecystectomy, Laparoscopic; Clinical Competence; Education, Medical, Undergraduate; Female; Humans; Learning Curve; Liver; Male; Models, Animal; Prospective Studies; Simulation Training; Surveys and Questionnaires; Swine",Article,"Final","",Scopus,2-s2.0-85009826742
"Alam M.F., Katsikas S., Beltramello O., Hadjiefthymiades S.","57061419000;54939590000;57206137363;6603881052;","Augmented and virtual reality based monitoring and safety system: A prototype IoT platform",2017,"Journal of Network and Computer Applications","89",,,"109","119",,38,"10.1016/j.jnca.2017.03.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016438031&doi=10.1016%2fj.jnca.2017.03.022&partnerID=40&md5=fd03a592a947579fdc656ace6be24708","Department of Informatics and Telecommunications, National and Kapodistrian University of Athens, Greece; Head of Research and Development, Prisma Electronics SA, Greece; EDUSAFE project coordinator, The European Organization for Nuclear Research (CERN), Switzerland","Alam, M.F., Department of Informatics and Telecommunications, National and Kapodistrian University of Athens, Greece; Katsikas, S., Head of Research and Development, Prisma Electronics SA, Greece; Beltramello, O., EDUSAFE project coordinator, The European Organization for Nuclear Research (CERN), Switzerland; Hadjiefthymiades, S., Department of Informatics and Telecommunications, National and Kapodistrian University of Athens, Greece","This paper presents an Augmented and Virtual Reality (AR/VR) based IoT prototype system. Performing maintenance tasks in a complex environment is quite challenging and difficult due to complex, and possibly, underground facilities, uneasy access, human factors, heavy machineries, etc. Current technology is not acceptable because of significant delays in communication and data transmission, missing multi-input interfaces, and simultaneous supervision of multiple workers who are working in the extreme environment. The aim is to technically advance and combine several technologies and integrate them as integral part of a personnel safety system to improve safety, maintain availability, reduce errors and decrease the time needed for scheduled or ad hoc interventions. We emphasize on the aspects that were made “feasible” on the worker's side due to the equipment used (mobile computing equipment). We present that the demanding tasks that previously were simply undertaken on the fixed infrastructure are now possible on the mobile end. The research challenges lie in the development of real-time data-transmission, instantaneous analysis of data coming from different inputs, local intelligence in low power embedded systems, interaction with multiple on-site users, complex user interfaces, portability and wearability. This work is part EDUSAFE, a Marie Curie ITN (Initial Training Network) project focusing on research into the use of Augmented and Virtual Reality (AR/VR) during planned and ad hoc maintenance in extreme work environments. © 2017 Elsevier Ltd","AR/VR design; IoT; Maintenance; Mobile; Modular; Prototype; Safety system/application","Complex networks; Data communication systems; Data transfer; Embedded systems; Machinery; Maintenance; Real time systems; Safety engineering; Security systems; User interfaces; Virtual reality; Augmented and virtual realities; Low power embedded systems; Mobile; Modular; Performing maintenance; Personnel safety systems; Prototype; Real time data transmission; Internet of things",Article,"Final","",Scopus,2-s2.0-85016438031
"Makransky G., Lilleholt L., Aaby A.","50361371800;57193521141;57193521677;","Development and validation of the Multimodal Presence Scale for virtual reality environments: A confirmatory factor analysis and item response theory approach",2017,"Computers in Human Behavior","72",,,"276","285",,43,"10.1016/j.chb.2017.02.066","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014524688&doi=10.1016%2fj.chb.2017.02.066&partnerID=40&md5=38581efe04b8f5a82be1de793b7d6b6d","Department of Psychology, University of Southern Denmark, Denmark","Makransky, G., Department of Psychology, University of Southern Denmark, Denmark; Lilleholt, L., Department of Psychology, University of Southern Denmark, Denmark; Aaby, A., Department of Psychology, University of Southern Denmark, Denmark","Presence is one of the most important psychological constructs for understanding human-computer interaction. However, different terminology and operationalizations of presence across fields have plagued the comparability and generalizability of results across studies. Lee's (2004) unified understanding of presence as a multidimensional construct made up of physical, social, and self-presence, has created a unified theory of presence; nevertheless, there are still no psychometrically valid measurement instruments based on the theory. Two studies were conducted that describe the development of a standardized multidimensional measure of presence (the MPS) for a VR learning context based on this theory, and its validation using confirmatory factor analysis and item response theory. The results from Study 1 which included 161 medical students from Denmark indicated that the items used in the MPS measure a three dimensional theoretical model of presence: physical, social, and self-presence. Furthermore, IRT analyses indicated that it was possible to limit the number of items in the MPS to 15 (five items per sub-dimension) while maintaining the construct validity and reliability of the measure. The results of Study 2, which included 118 biology students from Scotland, supported the validity and generalizability of the MPS in a new context. © 2017 Elsevier Ltd","Confirmatory factor analysis; Item response theory; Presence; Virtual reality; Virtual simulations","Human computer interaction; Multivariant analysis; Virtual reality; Confirmatory factor analysis; Construct validity; Item response theory; Measurement instruments; Presence; Theoretical modeling; Virtual simulations; Virtual-reality environment; Factor analysis; biology; confirmatory factor analysis; construct validity; Denmark; human; learning; major clinical study; medical student; physical model; reliability; Scotland; simulation; theoretical model; validation process; virtual reality",Article,"Final","",Scopus,2-s2.0-85014524688
"Lugmayr A., Sutinen E., Suhonen J., Sedano C.I., Hlavacs H., Montero C.S.","35071658200;7004846097;7006843907;35146683600;6506041648;15726175800;","Serious storytelling – a first definition and review",2017,"Multimedia Tools and Applications","76","14",,"15707","15733",,44,"10.1007/s11042-016-3865-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984903771&doi=10.1007%2fs11042-016-3865-5&partnerID=40&md5=aeb9bee0bebf2f84a5bc741d26e5b3d4","Curtin University of Technology, Perth, Australia; University of Turku, Turku, Finland; University of Eastern Finland, Joensuu, Finland; University of Vienna, Vienna, Austria","Lugmayr, A., Curtin University of Technology, Perth, Australia; Sutinen, E., University of Turku, Turku, Finland; Suhonen, J., University of Eastern Finland, Joensuu, Finland; Sedano, C.I., University of Eastern Finland, Joensuu, Finland; Hlavacs, H., University of Vienna, Vienna, Austria; Montero, C.S., University of Eastern Finland, Joensuu, Finland","In human culture, storytelling is a long-established tradition. The reasons people tell stories are manifold: to entertain, to transfer knowledge between generations, to maintain cultural heritage, or to warn others of dangers. With the emergence of the digitisation of media, many new possibilities to tell stories in serious and non-entertainment contexts emerged. A very simple example is the idea of serious gaming, as in, digital games without the primary purpose of entertainment. In this paper, we introduce the term serious storytelling as a new potential media genre – defining serious storytelling as storytelling with a purpose beyond entertainment. We also put forward a review of existing potential application areas, and develop a framework for serious storytelling. We foresee several application areas for this fundamental concept, including wellbeing and health, medicine, psychology, education, ethical problem solving, e-leadership and management, qualitative journalism, serious digital games, simulations and virtual training, user experience studies, and online communication. © 2016, Springer Science+Business Media New York.","Ambient media; Design science; Digital interactive media; Digital narratives; E-health; E-leadership; E-learning; Education; Forensics; Human-computer interaction; Journalism; Persuasive messages; Serious games; Serious storytelling; Smart media; Storytelling, digital storytelling; Ubiquitous computation; Ubiqutious media; User-experience; Virtual reality","Computer games; Design; E-learning; Education; Education computing; Problem solving; Virtual reality; Ambient media; Design science; Digital narratives; Digital storytelling; E health; Forensics; Interactive media; Journalism; Persuasive messages; Serious games; Serious storytelling; Smart media; Ubiquitous computation; Ubiqutious media; User experience; Human computer interaction",Article,"Final","",Scopus,2-s2.0-84984903771
"Jacob M.","56443422700;","Towards lifelong interactive learning for open-ended embodied narrative improvisation",2017,"C and C 2017 - Proceedings of the 2017 ACM SIGCHI Conference on Creativity and Cognition",,,,"502","507",,3,"10.1145/3059454.3078699","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025630461&doi=10.1145%2f3059454.3078699&partnerID=40&md5=515927b3642f52741258cd1ae89a2170","Georgia Institute of Technology, Atlanta, GA  30305, United States","Jacob, M., Georgia Institute of Technology, Atlanta, GA  30305, United States","This paper describes a doctoral research plan modeling collaborative embodied narrative improvisation, using lifelong interactive learning to mitigate the knowledgeauthoring bottleneck. Research methodology involves building interactive system models of the improvisation process, public installation/exhibition, user experience studies in public/lab settings, and ablation experiments. The article concludes with a research timeline. © 2017 ACM.","Embodied narrative; Generalized hypergraph; Imitation learning; Improvisation; Modeling creativity; VR","Educational technology; Learning systems; Ablation experiments; Embodied narrative; Hypergraph; Imitation learning; Improvisation; Interactive learning; Interactive system; Research methodologies; Education",Conference Paper,"Final","",Scopus,2-s2.0-85025630461
"Song S., Yang J.","55340188800;37045870100;","Configurable component framework supporting motion platform-based VR simulators",2017,"Journal of Mechanical Science and Technology","31","6",,"2985","2996",,2,"10.1007/s12206-017-0542-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025633040&doi=10.1007%2fs12206-017-0542-1&partnerID=40&md5=3864684d5c2c89bba0d90acd7c4c99e6","Department of Industrial Engineering, Ajou University, 206 Worldcup-ro, Suwon, 16499, South Korea","Song, S., Department of Industrial Engineering, Ajou University, 206 Worldcup-ro, Suwon, 16499, South Korea; Yang, J., Department of Industrial Engineering, Ajou University, 206 Worldcup-ro, Suwon, 16499, South Korea","This paper classifies functional elements of a motion platform-based VR simulator by its component types, and proposes a VR simulator component framework (VSCF) that can be used in various VR simulators by integrating associated components. The VSCF consists of a VSCF component manager (VCM), VSCF components (VCs), and a VSCF data interface (VDI). The functional elements of a VR simulator are defined by the VC units that are registered to the VCM and operated on by the VR simulator. The VCM manages the registered VCs and plays a role in controlling information exchange between VCs. The information for VCs is defined at the VDI while the VCM stores essential elements necessary to collect and transfer information into the VDI and provide it to VCs. Simulator developers configure VCs depending on functional elements required by the VR simulator and define the VDI for information exchange between VCs from which they are able to build various motion platform-based VR simulators by integrating the VCs through the VCM. In this study, two VR simulators were developed to verify the applicability of the VSCF: The first was a VR simulator for firefighting robot training and the second was a VR simulator for electrical wheelchair operation. © 2017, The Korean Society of Mechanical Engineers and Springer-Verlag GmbH Germany.","Component framework; Component framework; Motion platform; Virtual reality simulator","Information dissemination; Virtual reality; Component framework; Fire-fighting robot; Functional elements; Information exchanges; Motion platforms; Simulator components; Transfer information; Virtual reality simulator; Simulators",Article,"Final","",Scopus,2-s2.0-85025633040
"Vergara D., Rubio M.P., Lorenzo M.","57211856936;56817934900;34979055000;","On the design of virtual reality learning environments in engineering",2017,"Multimodal Technologies and Interaction","1","2", 11,"","",,43,"10.3390/mti1020011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043994822&doi=10.3390%2fmti1020011&partnerID=40&md5=874bccfd998af002acd8c1ac19fa2e93","Technological Department, University Catholic of Ávila, C/Canteros, s/n, Avila, 05005, Spain; Construction Department, University of Salamanca, Campus Viriato, Zamora, 37008, Spain; Department of Mechanical Engineering, University of Salamanca, ETSII, Avda. Fernando Ballesteros, 2, Béjar, Salamanca  37700, Spain","Vergara, D., Technological Department, University Catholic of Ávila, C/Canteros, s/n, Avila, 05005, Spain; Rubio, M.P., Construction Department, University of Salamanca, Campus Viriato, Zamora, 37008, Spain; Lorenzo, M., Department of Mechanical Engineering, University of Salamanca, ETSII, Avda. Fernando Ballesteros, 2, Béjar, Salamanca  37700, Spain","Currently, the use of virtual reality (VR) is being widely applied in different fields, especially in computer science, engineering, and medicine. Concretely, the engineering applications based on VR cover approximately one half of the total number of VR resources (considering the research works published up to last year, 2016). In this paper, the capabilities of different computational software for designing VR applications in engineering education are discussed. As a result, a general flowchart is proposed as a guide for designing VR resources in any application. It is worth highlighting that, rather than this study being based on the applications used in the engineering field, the obtained results can be easily extrapolated to other knowledge areas without any loss of generality. This way, this paper can serve as a guide for creating a VR application. © 2017 by the authors. Licensee MDPI, Basel, Switzerland.","Design; Education; Engineering; Instruction; Virtual laboratory; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85043994822
"Fovet T., Hernout J., Pelissolo A.","56054691600;57193884718;7004174344;","Motor semiology in anxiety and obsessive-compulsive disorders [La sémiologie motrice dans les troubles anxieux et obsessionnels]",2017,"Annales Medico-Psychologiques","175","5",,"469","473",,,"10.1016/j.amp.2017.03.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017390307&doi=10.1016%2fj.amp.2017.03.005&partnerID=40&md5=86baf4227371ae789ee7b7b9a5473805","UMR-9193, SCA-Lab, équipe psyCHIC, université de Lille, CNRS, CHU de Lille, pôle de psychiatrie (CURE), hôpital Fontan, Lille, 59000, France; Service de psychiatrie et DHU PePSy, Inserm U955, hôpital Henri-Mondor, université Paris-Est Créteil, fondation FondaMental, AP–HP, Créteil, 94000, France","Fovet, T., UMR-9193, SCA-Lab, équipe psyCHIC, université de Lille, CNRS, CHU de Lille, pôle de psychiatrie (CURE), hôpital Fontan, Lille, 59000, France; Hernout, J., UMR-9193, SCA-Lab, équipe psyCHIC, université de Lille, CNRS, CHU de Lille, pôle de psychiatrie (CURE), hôpital Fontan, Lille, 59000, France; Pelissolo, A., Service de psychiatrie et DHU PePSy, Inserm U955, hôpital Henri-Mondor, université Paris-Est Créteil, fondation FondaMental, AP–HP, Créteil, 94000, France","Anxiety can vary from simple and physiological emotional states to structured pathologies with well-established syndromes such as phobia, panic disorder or generalized anxiety. In this article, we firstly present the motor components of subclinical anxiety (simple embarrassment) and acute fear. These components are represented by: muscular tension, tremor, instability, posture changes (withdrawal, defense, self-contact), facial expression or behaviour (agitation or inhibition). Then, we show how motor semiology fit in the description of the main anxiety and obsessive-compulsive disorders (classifications and rating scales). For some of these disorders, social anxiety for example, specific approaches as eye movement studies can highlight subtle motor signs. Regarding obsessive-compulsive disorders, they are characterized by a particular motor dimension, with repetitive, specific and non-operant gestures, and modifications of spatial behaviour. Finally, we discuss the interest of using virtual reality to explore the motor symptomatology in anxiety disorders. © 2017 Elsevier Masson SAS","Anxiety; Motricity; Neuromuscular symptoms; Obsessive Compulsive Disorder; Semiology; Social phobia","anxiety disorder; Article; eye movement; human; motor dimension; motor dysfunction; motor performance; motor semiology; obsessive compulsive disorder; symptomatology; virtual reality",Article,"Final","",Scopus,2-s2.0-85017390307
"Brunhart-Lupo N., Bush B.W., Gruchalla K., Smith S.","55781621700;36866246700;25960789400;57212961760;","Simulation exploration through immersive parallel planes",2017,"2016 Workshop on Immersive Analytics, IA 2016",,, 7932377,"19","24",,3,"10.1109/IMMERSIVE.2016.7932377","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025675994&doi=10.1109%2fIMMERSIVE.2016.7932377&partnerID=40&md5=76040040e11aa7e93b6095f7bc40b631","National Renewable Energy Laboratory, United States; Los Alamos Visualization Associates, United States","Brunhart-Lupo, N., National Renewable Energy Laboratory, United States; Bush, B.W., National Renewable Energy Laboratory, United States; Gruchalla, K., National Renewable Energy Laboratory, United States; Smith, S., Los Alamos Visualization Associates, United States","We present a visualization-driven simulation system that tightly couples systems dynamics simulations with an immersive virtual environment to allow analysts to rapidly develop and test hypotheses in a high-dimensional parameter space. To accomplish this, we generalize the two-dimensional parallel-coordinates statistical graphic as an immersive «parallel-planes» visualization for multivariate time series emitted by simulations running in parallel with the visualization. In contrast to traditional parallel coordinate's mapping the multivariate dimensions onto coordinate axes represented by a series of parallel lines, we map pairs of the multivariate dimensions onto a series of parallel rectangles. As in the case of parallel coordinates, each individual observation in the dataset is mapped to a polyline whose vertices coincide with its coordinate values. Regions of the rectangles can be «brushed» to highlight and select observations of interest: A «slider» control allows the user to filter the observations by their time coordinate. In an immersive virtual environment, users interact with the parallel planes using a joystick that can select regions on the planes, manipulate selection, and filter time. The brushing and selection actions are used to both explore existing data as well as to launch additional simulations corresponding to the visually selected portions of the input parameter space. As soon as the new simulations complete, their resulting observations are displayed in the virtual environment. This tight feedback loop between simulation and immersive analytics accelerates users' realization of insights about the simulation and its output. © 2016 IEEE.","I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Virtual reality","Computer aided software engineering; Computer graphics; Data visualization; Three dimensional computer graphics; Visualization; High-dimensional; I.3.7 [computer graphics]: three-dimensional graphics and realism - virtual realities; Immersive virtual environments; Multivariate time series; Parallel coordinates; Simulation systems; Statistical graphics; Time coordinates; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85025675994
"Matzke J., Ziegler C., Martin K., Crawford S., Sutton E.","57192930219;7101826991;57199986106;57192928869;57202845044;","Usefulness of virtual reality in assessment of medical student laparoscopic skill",2017,"Journal of Surgical Research","211",,,"191","195",,5,"10.1016/j.jss.2016.11.054","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009198036&doi=10.1016%2fj.jss.2016.11.054&partnerID=40&md5=6253c43eb5c9d6655de4f3c5d42468be","Hiram C. Polk, Jr. MD Department of Surgery, University of Louisville School of Medicine, Louisville, Kentucky, United States","Matzke, J., Hiram C. Polk, Jr. MD Department of Surgery, University of Louisville School of Medicine, Louisville, Kentucky, United States; Ziegler, C., Hiram C. Polk, Jr. MD Department of Surgery, University of Louisville School of Medicine, Louisville, Kentucky, United States; Martin, K., Hiram C. Polk, Jr. MD Department of Surgery, University of Louisville School of Medicine, Louisville, Kentucky, United States; Crawford, S., Hiram C. Polk, Jr. MD Department of Surgery, University of Louisville School of Medicine, Louisville, Kentucky, United States; Sutton, E., Hiram C. Polk, Jr. MD Department of Surgery, University of Louisville School of Medicine, Louisville, Kentucky, United States","Background This study evaluates if undergraduate medical trainees' laparoscopic skills acquisition could be assessed using a virtual reality (VR) simulator and how the resultant metrics correlate with performance of Fundamentals of Laparoscopic Surgery (FLS) tasks. Our hypothesis is that the VR simulator metrics will correlate with passing results in a competency-based curriculum (FLS). Materials and methods Twenty-eight fourth-year medical students applying for surgical residency were recruited to participate in a VR training curriculum comprised of camera navigation, hand eye coordination, and FLS tasks: circle cutting (CC), ligating loop (LL), peg transfer (PT), and intracorporeal knot tying (IKT). Students were given 8 wk to achieve proficiency goals, after which they were observed performing FLS tasks. The ability of the VR simulator to detect penalties in each of the FLS tasks and correlations of time taken to complete tasks are reported. Results Twenty-five students trained in all components of the curriculum. All students were proficient in camera navigation and hand eye coordination tasks. Proficiency was achieved in CC, LL, PT, and IKT by 21, 19, 23, and one student, respectively. VR simulation showed high specificity for predicting zero penalties on the observed CC, LL, and PT tasks (80%, 75%, and 80%, respectively). Conclusions VR can be used to assess medical student's acquisition of laparoscopic skills. The absence of penalties in the simulator reasonably predicts the absence of penalties in all FLS skills, except IKT. The skills acquired by trainees can be used in residency for further monitoring of progress toward proficiency. © 2016 Elsevier Inc.","Laparoscopic skills; Medical students; Virtual reality","Article; curriculum; eye hand coordination; human; laparoscopic surgery; medical student; priority journal; residency education; simulator; surgical training; task performance; virtual reality; clinical competence; computer interface; education; Kentucky; laparoscopy; medical education; procedures; simulation training; Clinical Competence; Competency-Based Education; Curriculum; Education, Medical, Undergraduate; Humans; Kentucky; Laparoscopy; Simulation Training; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-85009198036
"Middleton R.M., Alvand A., Garfjeld Roberts P., Hargrove C., Kirby G., Rees J.L.","57189612134;22949717700;56320830900;56712090000;56712089500;55597569300;","Simulation-Based Training Platforms for Arthroscopy: A Randomized Comparison of Virtual Reality Learning to Benchtop Learning",2017,"Arthroscopy - Journal of Arthroscopic and Related Surgery","33","5",,"996","1003",,13,"10.1016/j.arthro.2016.10.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009216312&doi=10.1016%2fj.arthro.2016.10.021&partnerID=40&md5=46845762572f0cbb61404293ea6ba678","Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences, NIHR Biomedical Research Unit, University of Oxford, Oxford, United Kingdom; McLaren Applied Technologies, McLaren Technology Centre, Woking, Surrey, United Kingdom","Middleton, R.M., Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences, NIHR Biomedical Research Unit, University of Oxford, Oxford, United Kingdom; Alvand, A., Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences, NIHR Biomedical Research Unit, University of Oxford, Oxford, United Kingdom; Garfjeld Roberts, P., Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences, NIHR Biomedical Research Unit, University of Oxford, Oxford, United Kingdom; Hargrove, C., McLaren Applied Technologies, McLaren Technology Centre, Woking, Surrey, United Kingdom; Kirby, G., McLaren Applied Technologies, McLaren Technology Centre, Woking, Surrey, United Kingdom; Rees, J.L., Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences, NIHR Biomedical Research Unit, University of Oxford, Oxford, United Kingdom","Purpose To determine whether a virtual reality (VR) arthroscopy simulator or benchtop (BT) arthroscopy simulator showed superiority as a training tool. Methods Arthroscopic novices were randomized to a training program on a BT or a VR knee arthroscopy simulator. The VR simulator provided user performance feedback. Individuals performed a diagnostic arthroscopy on both simulators before and after the training program. Performance was assessed using wireless objective motion analysis and a global rating scale. Results The groups (8 in the VR group, 9 in the BT group) were well matched at baseline across all parameters (P >.05). Training on each simulator resulted in significant performance improvements across all parameters (P <.05). BT training conferred a significant improvement in all parameters when trainees were reassessed on the VR simulator (P <.05). In contrast, VR training did not confer improvement in performance when trainees were reassessed on the BT simulator (P >.05). BT-trained subjects outperformed VR-trained subjects in all parameters during final assessments on the BT simulator (P <.05). There was no difference in objective performance between VR-trained and BT-trained subjects on final VR simulator wireless objective motion analysis assessment (P >.05). Conclusions Both simulators delivered improvements in arthroscopic skills. BT training led to skills that readily transferred to the VR simulator. Skills acquired after VR training did not transfer as readily to the BT simulator. Despite trainees receiving automated metric feedback from the VR simulator, the results suggest a greater gain in psychomotor skills for BT training. Further work is required to determine if this finding persists in the operating room. Clinical Relevance This study suggests that there are differences in skills acquired on different simulators and skills learnt on some simulators may be more transferable. Further work in identifying user feedback metrics that enhance learning is also required. © 2016 Arthroscopy Association of North America",,"arthroscopy; Article; feedback system; hand movement; human; motion; psychomotor performance; simulation training; simulator; surgical training; time; virtual reality; adult; arthroscopy; clinical competence; computer interface; controlled study; education; female; knee; male; medical education; procedures; randomized controlled trial; simulation training; surgery; teaching; university hospital; virtual reality; young adult; Adult; Arthroscopy; Clinical Competence; Computer-Assisted Instruction; Female; Hospitals, University; Humans; Internship and Residency; Knee Joint; Male; Simulation Training; User-Computer Interface; Virtual Reality; Young Adult",Article,"Final","",Scopus,2-s2.0-85009216312
"Bertrand J., Bhargava A., Madathil K.C., Gramopadhye A., Babu S.V.","55858839700;57194158382;37075253800;7005569103;9039004700;","The effects of presentation method and simulation fidelity on psychomotor education in a bimanual metrology training simulation",2017,"2017 IEEE Symposium on 3D User Interfaces, 3DUI 2017 - Proceedings",,, 7893318,"59","68",,7,"10.1109/3DUI.2017.7893318","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019003187&doi=10.1109%2f3DUI.2017.7893318&partnerID=40&md5=01f06159d13212f502fbea389f779a5b","Clemson University, United States","Bertrand, J., Clemson University, United States; Bhargava, A., Clemson University, United States; Madathil, K.C., Clemson University, United States; Gramopadhye, A., Clemson University, United States; Babu, S.V., Clemson University, United States","In this study, we empirically evaluated the effects of presentation method and simulation fidelity on task performance and psychomotor skills acquisition in an immersive bimanual simulation towards precision metrology education. In a 2 × 2 experiment design, we investigated a large-screen immersive display (LSID) with a head-mounted display (HMD), and the presence versus absence of gravity. Advantages of the HMD include interacting with the simulation in a more natural manner as compared to using a large-screen immersive display due to the similarities between the interactions afforded in the virtual compared to the real-world task. Suspending the laws of physics may have an effect on usability and in turn could affect learning outcomes. Our dependent variables consisted of a pre and post cognition questionnaire, quantitative performance measures, perceived workload and system usefulness, and a psychomotor assessment to measure to what extent transfer of learning took place from the virtual to the real world. Results indicate that the HMD condition was preferable to the immersive display in several metrics while the no-gravity condition resulted in users adopting strategies that were not advantageous for task performance. © 2017 IEEE.","and virtual realities; augmented; H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial","Personnel training; Units of measurement; User interfaces; Virtual reality; augmented; Dependent variables; H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial; Head mounted displays; Large-screen immersive displays; Simulation fidelity; Training simulation; Transfer of learning; Helmet mounted displays",Conference Paper,"Final","",Scopus,2-s2.0-85019003187
"Anglin J., Saldana D., Schmiesing A., Liew S.-L.","57193856710;57194044260;57194041188;36992162200;","Transfer of a skilled motor learning task between virtual and conventional environments",2017,"Proceedings - IEEE Virtual Reality",,, 7892346,"401","402",,10,"10.1109/VR.2017.7892346","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018412711&doi=10.1109%2fVR.2017.7892346&partnerID=40&md5=65da755f34034bf37533b59e030ddbca","University of Southern California, Los Angeles, CA, United States","Anglin, J., University of Southern California, Los Angeles, CA, United States; Saldana, D., University of Southern California, Los Angeles, CA, United States; Schmiesing, A., University of Southern California, Los Angeles, CA, United States; Liew, S.-L., University of Southern California, Los Angeles, CA, United States","Immersive, head-mounted virtual reality (HMD-VR) can be a potentially useful tool for motor rehabilitation. However, it is unclear whether the motor skills learned in HMD-VR transfer to the non-virtual world and vice-versa. Here we used a well-established test of skilled motor learning, the Sequential Visual Isometric Pinch Task (SVIPT), to train individuals in either an HMD-VR or conventional training (CT) environment. Participants were then tested in both environments. Our results show that participants who train in the CT environment have an improvement in motor performance when they transfer to the HMD-VR environment. In contrast, participants who train in the HMD-VR environment show a decrease in skill level when transferring to the CT environment. This has implications for how training in HMD-VR and CT may affect performance in different environments. © 2017 IEEE.","Skilled motor learning; Transfer; Virtual reality","E-learning; Helmet mounted displays; Virtual reality; Head mounted virtual reality; Motor learning; Motor performance; Motor rehabilitation; Motor skills; Skill levels; Transfer; Virtual worlds; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-85018412711
"Ng A.K.T.","57190281471;","Cognitive psychology and human factors engineering of virtual reality",2017,"Proceedings - IEEE Virtual Reality",,, 7892349,"407","408",,1,"10.1109/VR.2017.7892349","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018458440&doi=10.1109%2fVR.2017.7892349&partnerID=40&md5=21c24a780861ae214df7983eca402d37","University of Hong Kong, Hong Kong, Hong Kong","Ng, A.K.T., University of Hong Kong, Hong Kong, Hong Kong","This position paper summarizes the author's research interest in Cognitive Psychology and Human-Computer Interaction in the imseCAVE, a CAVE-like system in the University of Hong Kong. Several areas of interest were explored while finding the thesis topic for the Ph.D. research. They include a perception research on distance estimation with proposed error correction mechanism, neurofeedback meditation with EEG in VR and the effect with audio and video, the study of training transfer in VR training, the comparison and research of cybersickness between HMD and the imseCAVE, and comparing VR gaming in TV, HMD, and the imseCAVE by performance, activity level and time perception. With a broad interest, the exact direction is still in the search and requires future exploration. © 2017 IEEE.","Cognitive psychology; HCI; Virtual environment","Error correction; Human computer interaction; Human engineering; Psychophysiology; Activity levels; Audio and video; Cognitive psychology; Correction mechanism; Distance estimation; Position papers; Research interests; Time perception; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85018458440
"Xu M., Murcia-Lopez M., Steed A.","57194043735;57194036190;18435050200;","Object location memory error in virtual and real environments",2017,"Proceedings - IEEE Virtual Reality",,, 7892303,"315","316",,9,"10.1109/VR.2017.7892303","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018434814&doi=10.1109%2fVR.2017.7892303&partnerID=40&md5=a93916712582a06b89ab064f03b0fe94","University College London, United Kingdom","Xu, M., University College London, United Kingdom; Murcia-Lopez, M., University College London, United Kingdom; Steed, A., University College London, United Kingdom","We aim to further explore the transfer of spatial knowledge from virtual to real spaces. Based on previous research on spatial memory in immersive virtual reality (VR) we ran a study that looked at the effect of three locomotion techniques (joystick, pointing-and-teleporting and walking-in-place) on object location learning and recall. Participants were asked to learn the location of a virtual object in a virtual environment (VE). After a short period of time they were asked to recall the location by placing a real version of the object in the real-world equivalent environment. Results indicate that the average placement error, or distance between original and recalled object location, is approximately 20cm for all locomotion technique conditions. This result is similar to the outcome of a previous study on spatial memory in VEs that used real walking. We report this unexpected finding and suggest further work on spatial memory in VR by recommending the replication of this study in different environments and using objects with a wider diversity of properties, including varying sizes and shapes. © 2017 IEEE.","Augmented; H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism - Virtual Reality; Virtual Realities","Computer graphics; Three dimensional computer graphics; Virtual reality; Augmented; H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial; I.3.7 [computer graphics]: three-dimensional graphics and realism - virtual realities; Immersive virtual reality; Locomotion technique; Real environments; Spatial knowledge; Walking-in-place; Location",Conference Paper,"Final","",Scopus,2-s2.0-85018434814
"Schissler C., Stirling P., Mehra R.","54413295100;57194036871;35790270300;","Efficient construction of the spatial room impulse response",2017,"Proceedings - IEEE Virtual Reality",,, 7892239,"122","130",,7,"10.1109/VR.2017.7892239","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018420464&doi=10.1109%2fVR.2017.7892239&partnerID=40&md5=9f1f9b7205b4490b383554d7a8f44212","Oculus and Facebook, United States","Schissler, C., Oculus and Facebook, United States; Stirling, P., Oculus and Facebook, United States; Mehra, R., Oculus and Facebook, United States","An important component of the modeling of sound propagation for virtual reality (VR) is the spatialization of the room impulse response (RIR) for directional listeners. This involves convolution of the listener's head-related transfer function (HRTF) with the RIR to generate a spatial room impulse response (SRIR) which can be used to auralize the sound entering the listener's ear canals. Previous approaches tend to evaluate the HRTF for each sound propagation path, though this is too slow for interactive VR latency requirements. We present a new technique for computation of the SRIR that performs the convolution with the HRTF in the spherical harmonic (SH) domain for RIR partitions of a fixed length. The main contribution is a novel perceptually-driven metric that adaptively determines the lowest SH order required for each partition to result in no perceptible error in the SRIR. By using lower SH order for some partitions, our technique saves a significant amount of computation and is almost an order of magnitude faster than the previous approach. We compared the subjective impact of this new method to the previous one and observe a strong scene-dependent preference for our technique. As a result, our method is the first that can compute high-quality spatial sound for the entire impulse response fast enough to meet the audio latency requirements of interactive virtual reality applications. © 2017 IEEE.","HRTF; Sound propagation; Spatial audio; Spherical harmonics","Acoustic wave propagation; Convolution; Harmonic analysis; Impulse response; Transfer functions; Virtual reality; Efficient construction; Head related transfer function; HRTF; Interactive virtual reality; Room impulse response (RIR); Sound propagation; Spatial audio; Spherical harmonics; Audio acoustics",Conference Paper,"Final","",Scopus,2-s2.0-85018420464
"Kron F.W., Fetters M.D., Scerbo M.W., White C.B., Lypson M.L., Padilla M.A., Gliva-McConvey G.A., Belfore L.A., II, West T., Wallace A.M., Guetterman T.C., Schleicher L.S., Kennedy R.A., Mangrulkar R.S., Cleary J.F., Marsella S.C., Becker D.M.","6507996266;7004019124;7004570474;7404153169;7801547132;57204399859;6507367882;6701466625;57192807346;54581868300;56652174000;57192804112;55426202400;6603310114;35304582500;6603739353;7401884246;","Using a computer simulation for teaching communication skills: A blinded multisite mixed methods randomized controlled trial",2017,"Patient Education and Counseling","100","4",,"748","759",,38,"10.1016/j.pec.2016.10.024","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008205645&doi=10.1016%2fj.pec.2016.10.024&partnerID=40&md5=710665b12ba082123fd3497a2090b92c","Department of Family Medicine, University of Michigan, Ann Arbor, MI  48104, United States; Department of Psychology, Old Dominion University, Norfolk, VA  23529, United States; Department of Medical Education, University of Virginia School of Medicine, Charlottesville, VA  22908, United States; Department of Internal Medicine, Department of Learning Health Sciences, University of Michigan Medical School, Ann Arbor, MI  48104, United States; Sentara Center for Simulation and Immersive Learning, Eastern Virginia Medical School, Norfolk, VA  23501, United States; Department of Electrical and Computer Engineering, Old Dominion University, Norfolk, VA  23529, United States; Department of Medicine, School of Medicine and Public Health, University of Wisconsin-MadisonWI  53706, United States; Department of Computer Science, Department of Psychology, Northeastern University, Boston, MA  02115, United States; Department of Medicine, University of Virginia Health System, Charlottesville, VA  22908, United States","Kron, F.W., Department of Family Medicine, University of Michigan, Ann Arbor, MI  48104, United States; Fetters, M.D., Department of Family Medicine, University of Michigan, Ann Arbor, MI  48104, United States; Scerbo, M.W., Department of Psychology, Old Dominion University, Norfolk, VA  23529, United States; White, C.B., Department of Medical Education, University of Virginia School of Medicine, Charlottesville, VA  22908, United States; Lypson, M.L., Department of Internal Medicine, Department of Learning Health Sciences, University of Michigan Medical School, Ann Arbor, MI  48104, United States; Padilla, M.A., Department of Psychology, Old Dominion University, Norfolk, VA  23529, United States; Gliva-McConvey, G.A., Sentara Center for Simulation and Immersive Learning, Eastern Virginia Medical School, Norfolk, VA  23501, United States; Belfore, L.A., II, Department of Electrical and Computer Engineering, Old Dominion University, Norfolk, VA  23529, United States; West, T., Sentara Center for Simulation and Immersive Learning, Eastern Virginia Medical School, Norfolk, VA  23501, United States; Wallace, A.M., Sentara Center for Simulation and Immersive Learning, Eastern Virginia Medical School, Norfolk, VA  23501, United States; Guetterman, T.C., Department of Family Medicine, University of Michigan, Ann Arbor, MI  48104, United States; Schleicher, L.S., Department of Family Medicine, University of Michigan, Ann Arbor, MI  48104, United States; Kennedy, R.A., Department of Psychology, Old Dominion University, Norfolk, VA  23529, United States; Mangrulkar, R.S., Department of Internal Medicine, Department of Learning Health Sciences, University of Michigan Medical School, Ann Arbor, MI  48104, United States; Cleary, J.F., Department of Medicine, School of Medicine and Public Health, University of Wisconsin-MadisonWI  53706, United States; Marsella, S.C., Department of Computer Science, Department of Psychology, Northeastern University, Boston, MA  02115, United States; Becker, D.M., Department of Medicine, University of Virginia Health System, Charlottesville, VA  22908, United States","Objectives To assess advanced communication skills among second-year medical students exposed either to a computer simulation (MPathic-VR) featuring virtual humans, or to a multimedia computer-based learning module, and to understand each group's experiences and learning preferences. Methods A single-blinded, mixed methods, randomized, multisite trial compared MPathic-VR (N = 210) to computer-based learning (N = 211). Primary outcomes: communication scores during repeat interactions with MPathic-VR's intercultural and interprofessional communication scenarios and scores on a subsequent advanced communication skills objective structured clinical examination (OSCE). Multivariate analysis of variance was used to compare outcomes. Secondary outcomes: student attitude surveys and qualitative assessments of their experiences with MPathic-VR or computer-based learning. Results MPathic-VR-trained students improved their intercultural and interprofessional communication performance between their first and second interactions with each scenario. They also achieved significantly higher composite scores on the OSCE than computer-based learning-trained students. Attitudes and experiences were more positive among students trained with MPathic-VR, who valued its providing immediate feedback, teaching nonverbal communication skills, and preparing them for emotion-charged patient encounters. Conclusions MPathic-VR was effective in training advanced communication skills and in enabling knowledge transfer into a more realistic clinical situation. Practice implications MPathic-VR's virtual human simulation offers an effective and engaging means of advanced communication training. © 2016 Elsevier Ireland Ltd","Breaking bad news; Communication training; Computer simulation; Computer-based conversational agent; Cultural competence; Doctor-patient relationship; Healthcare communication; Human-computer interaction; Intelligent tutoring systems; Inter-professional communication; Intercultural communication; Knowledge transfer; Mindful practice; Mixed methods research; Nonverbal communication; Reflection in action; Reflection on action; Simulation; Training transfer; Virtual Human","adult; Article; clinical examination; communication skill; computer simulation; computer system; controlled study; emotion; female; human; male; medical student; Modeling Professionalism and Teaching Humanistic Communication in Virtual Reality; nonverbal communication; objective structured clinical examination; randomized controlled trial; single blind procedure; student attitude; clinical competence; computer interface; computer simulation; curriculum; doctor patient relation; interpersonal communication; medical education; patient simulation; psychology; Adult; Clinical Competence; Communication; Computer Simulation; Curriculum; Education, Medical; Female; Humans; Male; Patient Simulation; Physician-Patient Relations; Single-Blind Method; Students, Medical; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-85008205645
"Noureldin Y.A., Andonian S.","56108813000;6602848731;","Simulation for percutaneous renal access: where are we?",2017,"Journal of Endourology","31",,,"S10","S19",,15,"10.1089/end.2016.0587","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018658134&doi=10.1089%2fend.2016.0587&partnerID=40&md5=13f062c3d1bb156945e7338665eb4187","Division of Urology, McGill University, 1001 Boulevard Decarie, Montréal, QC  H4A 3J1, Canada; Urology Department, Benha University Hospital, Benha University, Benha, Egypt","Noureldin, Y.A., Division of Urology, McGill University, 1001 Boulevard Decarie, Montréal, QC  H4A 3J1, Canada, Urology Department, Benha University Hospital, Benha University, Benha, Egypt; Andonian, S., Division of Urology, McGill University, 1001 Boulevard Decarie, Montréal, QC  H4A 3J1, Canada","Objectives: Percutaneous renal access (PCA) is a challenging step during percutaneous nephrolithotomy. The aim of this study is to review the literature for different types of simulators described for PCA. Methods: Databases of Medline, Embase, Cochrane Library, OvidSP, and Google Scholar were systematically searched until May 2016. The studies were analyzed regarding the type of simulator (nonbiologic, biologic, live animal, and virtual reality [VR]), type of validity (face, content, construct, and predictive), cost-effectiveness, and whether these simulators have been used for training and/or assessment of PCA. In addition, the study looked at the educational impact of these simulators in terms of the transfer of PCA skills to the operating room. Results: Several bench, animal, and VR simulators for training in PCA were identified. Only few studies were found on assessment of PCA skills. Biological bench models used porcine or bovine kidneys wrapped within foam, silicone, chicken carcass, or full-thickness skin flap alone. Other biological models used additional subcutaneous fascia, muscle, or ribs. Nonbiological models used prototypes, including 3D printing. Only one study reported the use of anesthetized live pig for training. The PERC Mentor™ was the only VR simulator, which has been validated for training and assessment of PCA skills. However, none of these studies assessed the educational impact of PCA simulators. Furthermore, most of the studies did not address the validity and the cost of the simulator. Conclusions: While several biological and nonbiological PCA models exist, there is paucity of literature regarding the validity and educational impact of these simulators. The PERC Mentor simulator is the sole validated simulator for training and assessment of PCA skills. However, it is expensive and there is little evidence of its educational impact. Therefore, more research is needed to validate the available simulators and assess their educational impact for urology trainees. © Mary Ann Liebert, Inc. 2017.","clinical skills; computer simulation; outcome and process assessment; percutaneous nephrolithotomy","silicone; Article; carcass; clinical competence; construct validity; content validity; cost effectiveness analysis; face validity; fascia; foam; human; kidney; muscle; nonhuman; packaging; percutaneous renal access; performance measurement system; predictive validity; program impact; rib; simulation; simulator; skin flap; surgical technique; surgical training; systematic review; three dimensional printing; virtual reality; animal; biological model; bovine; computer interface; computer simulation; cost benefit analysis; education; percutaneous nephrostomy; pig; simulation training; surgery; urologic surgery; urology; Animals; Cattle; Clinical Competence; Computer Simulation; Cost-Benefit Analysis; Humans; Kidney; Models, Biological; Nephrostomy, Percutaneous; Simulation Training; Swine; Urologic Surgical Procedures; Urology; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-85018658134
"De La Garza J.R., Kowalewski K.-F., Friedrich M., Schmidt M.W., Bruckner T., Kenngott H.G., Fischer L., Müller-Stich B.-P., Nickel F.","57193726976;56909719800;57193207936;57191077022;34567844800;23097654000;24179145000;14322034300;35603936500;","Does rating the operation videos with a checklist score improve the effect of E-learning for bariatric surgical training? Study protocol for a randomized controlled trial",2017,"Trials","18","1", 134,"","",,5,"10.1186/s13063-017-1886-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016130042&doi=10.1186%2fs13063-017-1886-7&partnerID=40&md5=6da4cbebdfec5b47c4b86c308a6b85ca","University of Heidelberg, Department of General, Visceral, and Transplantation Surgery, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; University of Heidelberg, Institute for Medical Biometry and Informatics, Im Neuenheimer Feld 130.3, Heidelberg, 69120, Germany","De La Garza, J.R., University of Heidelberg, Department of General, Visceral, and Transplantation Surgery, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Kowalewski, K.-F., University of Heidelberg, Department of General, Visceral, and Transplantation Surgery, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Friedrich, M., University of Heidelberg, Department of General, Visceral, and Transplantation Surgery, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Schmidt, M.W., University of Heidelberg, Department of General, Visceral, and Transplantation Surgery, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Bruckner, T., University of Heidelberg, Institute for Medical Biometry and Informatics, Im Neuenheimer Feld 130.3, Heidelberg, 69120, Germany; Kenngott, H.G., University of Heidelberg, Department of General, Visceral, and Transplantation Surgery, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Fischer, L., University of Heidelberg, Department of General, Visceral, and Transplantation Surgery, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Müller-Stich, B.-P., University of Heidelberg, Department of General, Visceral, and Transplantation Surgery, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany; Nickel, F., University of Heidelberg, Department of General, Visceral, and Transplantation Surgery, Im Neuenheimer Feld 110, Heidelberg, 69120, Germany","Background: Laparoscopic training has become an important part of surgical education. Laparoscopic Roux-en-Y gastric bypass (RYGB) is the most common bariatric procedure performed. Surgeons must be well trained prior to operating on a patient. Multimodality training is vital for bariatric surgery. E-learning with videos is a standard approach for training. The present study investigates whether scoring the operation videos with performance checklists improves learning effects and transfer to a simulated operation. Methods/design: This is a monocentric, two-arm, randomized controlled trial. The trainees are medical students from the University of Heidelberg in their clinical years with no prior laparoscopic experience. After a laparoscopic basic virtual reality (VR) training, 80 students are randomized into one of two arms in a 1:1 ratio to the checklist group (group A) and control group without a checklist (group B). After all students are given an introduction of the training center, VR trainer and laparoscopic instruments, they start with E-learning while watching explanations and videos of RYGB. Only group A will perform ratings with a modified Bariatric Objective Structured Assessment of Technical Skill (BOSATS) scale checklist for all videos watched. Group B watches the same videos without rating. Both groups will then perform an RYGB in the VR trainer as a primary endpoint and small bowel suturing as an additional test in the box trainer for evaluation. Discussion: This study aims to assess if E-learning and rating bariatric surgical videos with a modified BOSATS checklist will improve the learning curve for medical students in an RYGB VR performance. This study may help in future laparoscopic and bariatric training courses. Trial registration: German Clinical Trials Register, DRKS00010493. Registered on 20 May 2016. © 2017 The Author(s).","Education; First-person view; Human mirror system; Laparoscopy; Minimally invasive surgery; Perspective; Serious gaming; Training","bariatric surgery; checklist; clinical trial; control group; controlled clinical trial; controlled study; human; learning curve; major clinical study; medical student; minimally invasive surgery; patient history of laparoscopy; randomized controlled trial; registration; Roux-en-Y gastric bypass; simulation; skill; small intestine; surgery; surgical training; university; virtual reality; clinical competence; clinical protocol; curriculum; education; gastric bypass surgery; Germany; laparoscopy; learning curve; medical education; medical student; methodology; procedures; prospective study; simulation training; suture technique; task performance; teaching; videorecording; Checklist; Clinical Competence; Clinical Protocols; Computer-Assisted Instruction; Curriculum; Education, Medical, Undergraduate; Gastric Bypass; Germany; Humans; Laparoscopy; Learning Curve; Prospective Studies; Research Design; Simulation Training; Students, Medical; Suture Techniques; Task Performance and Analysis; Video Recording",Article,"Final","",Scopus,2-s2.0-85016130042
"Zahiri M., Booton R., Siu K.-C., Nelson C.A.","55873128300;56728218700;57192938181;15073221300;","Design and evaluation of a portable laparoscopic training system using virtual reality",2017,"Journal of Medical Devices, Transactions of the ASME","11","1", 011002,"","",,9,"10.1115/1.4034881","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007507410&doi=10.1115%2f1.4034881&partnerID=40&md5=e728512ab20cfeb79cd1917c02b4c59d","Department of Mechanical and Materials Engineering, University of Nebraska-Lincoln, W342 Nebraska Hall, Lincoln, NE  68588-0526, United States; College of Public Health, University of Nebraska Medical Center, Nebraska Medical Center, Omaha, NE  68198-4310, United States; Division of Physical Therapy Education, College of Allied Health Professions, University of Nebraska Medical Center, Nebraska Medical Center, Omaha, NE  68198-4420, United States","Zahiri, M., Department of Mechanical and Materials Engineering, University of Nebraska-Lincoln, W342 Nebraska Hall, Lincoln, NE  68588-0526, United States; Booton, R., College of Public Health, University of Nebraska Medical Center, Nebraska Medical Center, Omaha, NE  68198-4310, United States; Siu, K.-C., Division of Physical Therapy Education, College of Allied Health Professions, University of Nebraska Medical Center, Nebraska Medical Center, Omaha, NE  68198-4420, United States; Nelson, C.A., Department of Mechanical and Materials Engineering, University of Nebraska-Lincoln, W342 Nebraska Hall, Lincoln, NE  68588-0526, United States","The ubiquitous nature of laparoscopic surgery and the decreased training time available for surgeons are driving an increased need for effective training systems to help surgeons learn different procedures. A cost-effective and user-friendly simulator has been designed to imitate specific training tasks for laparoscopic surgery in virtual environments via image processing and computer vision. The capability of using various actual surgical instruments suited for these specific procedures gives heightened fidelity to the simulator. Image processing via MATLAB software provides real-time mapping of the graspers in the workspace to the virtual reality (VR) environment (VIZARD software). Two different tasks (peg transfer and needle passing) were designed to evaluate trainees and compare their performance with characteristics of expert surgeons. Pilot testing of the system was carried out with 11 subjects to validate the similarity of this device with an existing surgical box trainer. Task completion time and muscle activity have been used as metrics for evaluation. The decrease in completion time for all subjects suggests similarity of skills transfer for both simulators. In addition, the p-value of muscle activity showed no significant differences for most muscles in the peg transfer task when using either the VR or physical analog environment and no significant differences for about half of the muscles in the needle passing task. Based on the results, the new proposed VR simulator appears to be a viable alternative to help trainees gain laparoscopic skills. © 2017 by ASME.",,"Computer vision; Cost effectiveness; E-learning; Image processing; Laparoscopy; MATLAB; Muscle; Needles; Simulators; Surgery; Virtual reality; Design and evaluations; Image processing and computer vision; Laparoscopic surgery; Muscle activities; Real-time mapping; Surgical instrument; Task completion time; User-friendly simulators; Surgical equipment; Article; human; image processing; laparoscopic surgery; medical student; muscle contraction; portable camera aided training system; portable equipment; simulator; surgical equipment; task performance; virtual reality",Article,"Final","",Scopus,2-s2.0-85007507410
"Bonney E., Jelsma L.D., Ferguson G.D., Smits-Engelsman B.C.M.","57193273004;55621705900;7202203990;7003613961;","Learning better by repetition or variation? Is transfer at odds with task specific training?",2017,"PLoS ONE","12","3", 0174214,"","",,18,"10.1371/journal.pone.0174214","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016155309&doi=10.1371%2fjournal.pone.0174214&partnerID=40&md5=930cdd5b6ca44231adac5d1e0e942672","Department of Health and Rehabilitation Sciences, University of Cape Town, Cape Town, South Africa; Department of Physical Therapy, University of Ghana, Accra, Ghana; Developmental and Clinical Neuropsychology, University of Groningen, Groningen, Netherlands","Bonney, E., Department of Health and Rehabilitation Sciences, University of Cape Town, Cape Town, South Africa, Department of Physical Therapy, University of Ghana, Accra, Ghana; Jelsma, L.D., Developmental and Clinical Neuropsychology, University of Groningen, Groningen, Netherlands; Ferguson, G.D., Department of Health and Rehabilitation Sciences, University of Cape Town, Cape Town, South Africa; Smits-Engelsman, B.C.M., Department of Health and Rehabilitation Sciences, University of Cape Town, Cape Town, South Africa","Objective Transfer of motor skills is the ultimate goal of motor training in rehabilitation practice. In children with Developmental Coordination Disorder (DCD), very little is known about how skills are transferred from training situations to real life contexts. In this study we examined the influence of two types of practice on transfer of motor skills acquired in a virtual reality (VR) environment. Method One hundred and eleven children with DCD and their typically developing (TD) peers, aged 6±10 years (M = 8.0 SD = 1.0) were randomly assigned to either variable (n = 56) or repetitive practice (n = 55). Participants in the repetitive practice played the same exergame (ski slalom) twice weekly for 20 minutes, over a period of 5 weeks, while those in the variable group played 10 different games. Motor skills such as balance tasks (hopping), running and agility tasks, ball skills and functional activities were evaluated before and after 5 weeks of training. Results ANOVA repeated measures indicated that both DCD and TD children demonstrated transfer effects to real life skills with identical and non-identical elements at exactly the same rate, irrespective of the type of practice they were assigned to. Conclusion Based on these findings, we conclude that motor skills acquired in the VR environment, transfers to real world contexts in similar proportions for both TD and DCD children. The type of practice adopted does not seem to influence children's ability to transfer skills acquired in an exergame to life situations but the number of identical elements does. © 2017 Bonney et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"academic achievement; agility; Article; body composition; Bruininks Oseretsky test of motor proficiency 2; child; clinical assessment tool; cognition; Cognitive Orientation to Occupational Performance Approach; controlled study; developmental coordination disorder; dexterity test; effect size; Functional strength tasks; human; intervention study; jumping; major clinical study; motor coordination; motor learning; motor performance; Movement Assessment Battery for Children; Neuromotor Task Training; randomized controlled trial; running; single blind procedure; social life; task performance; video game; virtual reality; Virtual Reality gaming; case control study; female; learning; male; motor performance; pathophysiology; psychology; psychomotor disorder; repetition priming; Case-Control Studies; Child; Female; Humans; Learning; Male; Motor Skills; Motor Skills Disorders; Repetition Priming; Video Games",Article,"Final","",Scopus,2-s2.0-85016155309
"Dong M., Guo R.","57193733822;55211939300;","Towards understanding the capability of spatial audio feedback in virtual environments for people with visual impairments",2017,"2016 IEEE 2nd Workshop on Everyday Virtual Reality, WEVR 2016",,, 7859538,"15","20",,2,"10.1109/WEVR.2016.7859538","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016202855&doi=10.1109%2fWEVR.2016.7859538&partnerID=40&md5=dcc177c18146e2d51b17f8469cf200ab","Kennesaw State University, United States","Dong, M., Kennesaw State University, United States; Guo, R., Kennesaw State University, United States","This research analyzes if and how the Head Related Transfer Function (HRTF) can be used to support effective Human-Computer Interaction when people in a Virtual Environment (VE) without visual feedback. If sounds can be located in a VE by using HRTF only, designing and developing considerably safer but diversified training environments might greatly benefit individuals with visual impairments. To investigate this, we ran 2 usability studies: 1) to ascertain whether the HRTF could provide sufficient position information in VEs; 2) to learn whether the HRTF could provide sufficient distance and direction information in VEs. The results showed that a continuous audio feedback could help navigate in a VE without vision feedback. © 2016 IEEE.","3D Audio; Assistive technology; HRTF; User study","Human computer interaction; Sound reproduction; Transfer functions; Visual communication; 3D audio; Assistive technology; Head related transfer function; HRTF; Position information; Usability studies; User study; Visual impairment; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85016202855
"Kurenov S., Cendan J., Dindar S., Attwood K., Hassett J., Nawotniak R., Cherr G., Cance W.G., Peters J.","12805876500;6602115562;37053615000;53263257600;7006464053;11140311000;7006425188;57204347336;56743855500;","Surgeon-authored virtual laparoscopic adrenalectomy module is judged effective and preferred over traditional teaching tools",2017,"Surgical Innovation","24","1",,"72","81",,3,"10.1177/1553350616672971","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029754497&doi=10.1177%2f1553350616672971&partnerID=40&md5=79128119510671d75285520da6f724f3","Roswell Park Cancer Institute, Buffalo, NY, United States; University of Central Florida, Orlando, FL, United States; University of Florida, Gainesville, FL, United States; University at Buffalo, Buffalo, NY, United States","Kurenov, S., Roswell Park Cancer Institute, Buffalo, NY, United States; Cendan, J., University of Central Florida, Orlando, FL, United States; Dindar, S., University of Florida, Gainesville, FL, United States; Attwood, K., Roswell Park Cancer Institute, Buffalo, NY, United States; Hassett, J., University at Buffalo, Buffalo, NY, United States; Nawotniak, R., University at Buffalo, Buffalo, NY, United States; Cherr, G., University at Buffalo, Buffalo, NY, United States; Cance, W.G., Roswell Park Cancer Institute, Buffalo, NY, United States; Peters, J., University of Florida, Gainesville, FL, United States","Objective. The study assesses user acceptance and effectiveness of a surgeon-authored virtual reality (VR) training module authored by surgeons using the Toolkit for Illustration of Procedures in Surgery (TIPS). Methods. Laparoscopic adrenalectomy was selected to test the TIPS framework on an unusual and complex procedure. No commercial simulation module exists to teach this procedure. A specialist surgeon authored the module, including force-feedback interactive simulation, and designed a quiz to test knowledge of the key procedural steps. Five practicing surgeons, with 15 to 24 years of experience, peer reviewed and tested the module. In all, 14 residents and 9 fellows trained with the module and answered the quiz, preuse and postuse. Participants received an overview during Surgical Grand Rounds session and a 20-minute one-on-one tutorial followed by 30 minutes of instruction in addition to a forcefeedback interactive simulation session. Additionally, in answering questionnaires, the trainees reflected on their learning experience and their experience with the TIPS framework. Results. Correct quiz response rates on procedural steps improved significantly postuse over preuse. In the questionnaire, 96% of the respondents stated that the TIPS module prepares them well or very well for the adrenalectomy, and 87% indicated that the module successfully teaches the steps of the procedure. All participants indicated that they preferred the module compared to training using purely physical props, one-on-one teaching, medical atlases, and video recordings. Conclusions. Improved quiz scores and endorsement by the participants of the TIPS adrenalectomy module establish the viability of surgeons authoring VR training. © The Author(s) 2016.","Education; Haptic device; Laparoscopic adrenalectomy; Surgical simulation; Training","adrenalectomy; adult; female; human; human experiment; learning; male; questionnaire; resident; simulation; student; surgery; teaching; videorecording; virtual reality; adrenalectomy; clinical competence; computer interface; computer simulation; constructive feedback; curriculum; education; health personnel attitude; laparoscopy; simulation training; Adrenalectomy; Attitude of Health Personnel; Clinical Competence; Computer Simulation; Curriculum; Formative Feedback; Humans; Laparoscopy; Simulation Training; Transfer (Psychology); User-Computer Interface",Article,"Final","",Scopus,2-s2.0-85029754497
"Cooper N., Milella F., Cant I., Pinto C., White M., Meyer G.","57193613538;6602739760;57193607743;57193603497;56315199000;7402850996;","Augmented Cues Facilitate Learning Transfer from Virtual to Real Environments",2017,"Adjunct Proceedings of the 2016 IEEE International Symposium on Mixed and Augmented Reality, ISMAR-Adjunct 2016",,, 7836496,"194","198",,4,"10.1109/ISMAR-Adjunct.2016.0075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015258466&doi=10.1109%2fISMAR-Adjunct.2016.0075&partnerID=40&md5=6296b41a51237548cbfed6c5ac6f6db5","University of Liverpool, United Kingdom; Virtual Engineering Centre, United Kingdom","Cooper, N., University of Liverpool, United Kingdom; Milella, F., Virtual Engineering Centre, United Kingdom; Cant, I., Virtual Engineering Centre, United Kingdom; Pinto, C., Virtual Engineering Centre, United Kingdom; White, M., University of Liverpool, United Kingdom; Meyer, G., University of Liverpool, United Kingdom","The aim of this study was to investigate whether augmented cues that have previously been shown to enhance performance and user satisfaction in VR training translate into performance improvements in real environments. Subjects were randomly allocated into 3 groups. Group 1 were trained to perform a real tyre change, group 2 were trained in a conventional VR setting, while group 3 were trained in VR with augmented cues. After training participants were tested on a real tyre change task. Overall time to completion was recorded as objective measure; subjective ratings of presence, perceived workload and discomfort were recorded using questionnaires. The performances of the three groups were compared. Overall, participants who received VR training performed significantly faster on the real task than participants who completed the real tyre change only. The difference between the virtual reality training groups was found to be not significant. However, participants who were trained with augmented cues performed the real tyre change with fewer errors than participants in the minimal cues training group. Systematic differences in subjective ratings that reflected objective performance were also observed. © 2016 IEEE.","augmented cues; multisensory feedback; performance; presence; simulation sickness; training transfer; virtual reality; workload","Augmented reality; Surveys; Tires; Virtual reality; augmented cues; Multi-sensory feedback; performance; presence; simulation sickness; workload; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-85015258466
"Blume F., Hudak J., Dresler T., Ehlis A.-C., Kühnhausen J., Renner T.J., Gawrilow C.","57113781000;57192717210;24466569200;35567040300;55877977600;15833222900;16233108200;","NIRS-based neurofeedback training in a virtual reality classroom for children with attention-deficit/hyperactivity disorder: Study protocol for a randomized controlled trial",2017,"Trials","18","1", 41,"","",,25,"10.1186/s13063-016-1769-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010468148&doi=10.1186%2fs13063-016-1769-3&partnerID=40&md5=6042fef07804f51fefba56f92650b7c4","University of Tübingen, LEAD Graduate School and Research Network, Gartenstrasse 29, Tübingen, 72074, Germany; University of Tübingen, Department of Psychiatry and Psychotherapy, Calwerstrasse 14, Tübingen, 72076, Germany; University of Tübingen, Department of Psychology, Schleichstrasse 4, Tübingen, 72076, Germany; University of Tübingen, Department of Child and Adolescence Psychiatry and Psychotherapy, Osianderstrasse 14-16, Tübingen, 72076, Germany; Deutsches Institut für Internationale Pädagogische Forschung (DIPF), Schlossstrasse 29, Frankfurt/Main, 60486, Germany","Blume, F., University of Tübingen, LEAD Graduate School and Research Network, Gartenstrasse 29, Tübingen, 72074, Germany; Hudak, J., University of Tübingen, LEAD Graduate School and Research Network, Gartenstrasse 29, Tübingen, 72074, Germany; Dresler, T., University of Tübingen, LEAD Graduate School and Research Network, Gartenstrasse 29, Tübingen, 72074, Germany, University of Tübingen, Department of Psychiatry and Psychotherapy, Calwerstrasse 14, Tübingen, 72076, Germany; Ehlis, A.-C., University of Tübingen, Department of Psychiatry and Psychotherapy, Calwerstrasse 14, Tübingen, 72076, Germany; Kühnhausen, J., University of Tübingen, LEAD Graduate School and Research Network, Gartenstrasse 29, Tübingen, 72074, Germany, University of Tübingen, Department of Psychology, Schleichstrasse 4, Tübingen, 72076, Germany; Renner, T.J., University of Tübingen, LEAD Graduate School and Research Network, Gartenstrasse 29, Tübingen, 72074, Germany, University of Tübingen, Department of Child and Adolescence Psychiatry and Psychotherapy, Osianderstrasse 14-16, Tübingen, 72076, Germany; Gawrilow, C., University of Tübingen, LEAD Graduate School and Research Network, Gartenstrasse 29, Tübingen, 72074, Germany, University of Tübingen, Department of Psychology, Schleichstrasse 4, Tübingen, 72076, Germany, Deutsches Institut für Internationale Pädagogische Forschung (DIPF), Schlossstrasse 29, Frankfurt/Main, 60486, Germany","Background: Children with attention-deficit/hyperactivity disorder (ADHD) suffer from attention deficits, motor hyperactivity, and impulsive behaviour. These impairments are experienced at home, at school, and with friends. Functional imaging studies show that ADHD behaviour and impairments in executive functions (EFs) are mirrored by aberrant neurophysiological functioning. Moreover, several studies show that ADHD behaviour, impairments in EFs, and a lack of self-control contribute to poor school performance. Non-pharmacological interventions such as neurofeedback training (NFT), for instance, aim at improving neurophysiological and neuropsychological functioning as well as behaviour. Consequently, NFT is expected to improve school performance, EFs, and self-control in children with ADHD. Generalization of acquired self-regulation skills from laboratory to real life is crucial for a transfer to everyday situations and is hypothesized to be facilitated via training using virtual reality (VR) environments. Consequently, experiencing NFT in VR is expected to yield greater effects than training in two dimensions (2D). Methods/design: Ninety children with a clinical diagnosis of ADHD will be included in the study. Participants may be medicated or unmedicated. After random assignation to one of three conditions, all participants receive 15 training sessions of either near-infrared spectroscopy (NIRS)-based NFT in VR, NIRS-based NFT in 2D, or electromyogram-based biofeedback training in VR. ADHD symptoms, self-control, EF, health-related quality of life, school performance, and motor activity measured via parent, teacher, and child reports or objectively will be assessed before and after the intervention and at a 6 months follow-up. Furthermore, we are interested in parents' expectations about the training's effects. Discussion: This is, to our knowledge, the first study investigating the efficacy of NFT for children with ADHD in a VR compared to a 2D environment. Furthermore, this study will contribute to the discussion about the efficacy and specific and unspecific effects of NFTs in children with ADHD. In addition to commonly assessed variables such as ADHD symptoms, NIRS and behavioural data obtained in EF measures, health-related quality of life, and parents' expectations about the intervention's effects, this study will investigate the effects on self-control, school performance, and motor activity. Trial registration: ClinicalTrials.gov, NCT02572180. Registered on 19 November 2015. © 2017 The Author(s).","Attention-deficit/hyperactivity disorder; Biofeedback; Electromyography; Near-infrared spectroscopy; Neurofeedback; Randomized controlled trial; School performance; Virtual reality","Article; attention deficit disorder; child; child health; clinical effectiveness; clinical protocol; controlled study; expectation; female; follow up; human; major clinical study; male; motor activity; near infrared spectroscopy; neurofeedback training; neurological and sensorial procedures; quality of life; randomized controlled trial; self control; treatment planning; virtual reality; attention; attention deficit disorder; child behavior; educational status; electromyography; Germany; methodology; neurofeedback; parent; pathophysiology; procedures; psychology; time factor; treatment outcome; Attention; Attention Deficit Disorder with Hyperactivity; Child; Child Behavior; Educational Status; Electromyography; Female; Germany; Humans; Male; Motor Activity; Neurofeedback; Parents; Quality of Life; Research Design; Self-Control; Spectroscopy, Near-Infrared; Time Factors; Treatment Outcome; Virtual Reality",Article,"Final","",Scopus,2-s2.0-85010468148
"Halabi O., El-Seoud S.A., Aljaam J.M., Alpona H., Al-Hemadi M., Al-Hassan D.","57203219290;6507058670;24528095900;56407207400;57194434607;57194429167;","Design of immersive virtual reality system to improve communication skills in individuals with autism",2017,"International Journal of Emerging Technologies in Learning","12","5",,"50","64",,10,"10.3991/ijet.v12i05.6766","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85020066717&doi=10.3991%2fijet.v12i05.6766&partnerID=40&md5=e2208a321c0b786aa1272f0ea478869e","Department of Computer Science and Engineering, Qatar University, P.O. Box 2713, Doha, Qatar; Faculty of Informatics and Computer Science, The British University in Egypt, El Sherouk City, Cairo, Egypt","Halabi, O., Department of Computer Science and Engineering, Qatar University, P.O. Box 2713, Doha, Qatar; El-Seoud, S.A., Faculty of Informatics and Computer Science, The British University in Egypt, El Sherouk City, Cairo, Egypt; Aljaam, J.M., Department of Computer Science and Engineering, Qatar University, P.O. Box 2713, Doha, Qatar; Alpona, H., Department of Computer Science and Engineering, Qatar University, P.O. Box 2713, Doha, Qatar; Al-Hemadi, M., Department of Computer Science and Engineering, Qatar University, P.O. Box 2713, Doha, Qatar; Al-Hassan, D., Department of Computer Science and Engineering, Qatar University, P.O. Box 2713, Doha, Qatar","Individuals with autism spectrum disorder (ASD) regularly experience situations in which they need to give answers but do not know how to respond; for example, questions related to everyday life activities that are asked by strangers. Research geared at utilizing technology to mend social and communication impairments in children with autism is actively underway. Immersive virtual reality (VR) is a relatively recent technology that has the potential of being an effective therapeutic tool for developing various skills in autistic children. This paper presents an interactive scenario-based VR system developed to improve the communications skills of autistic children. The system utilizes speech recognition to provide natural interaction and role-play and turntaking to evaluate and verify the effectiveness of the immersive environment on the social performance of autistic children. In experiments conducted, participants showed more improved performance with a computer augmented virtual environment (CAVE) than with a head mounted display (HMD) or a normal desktop. The results indicate that immersive VR could be more satisfactory and motivational than desktop for children with ASD.","Autism spectrum disorder; Communication skill; Immersion; Social performance; Virtual reality","Diseases; Helmet mounted displays; Speech recognition; Technology transfer; Virtual reality; Autism spectrum disorders; Children with autisms; Communication skills; Head mounted displays; Immersion; Immersive environment; Immersive virtual reality; Social performance; Education",Article,"Final","",Scopus,2-s2.0-85020066717
"Hai N.D., Chaudhary N.K., Peksi S., Ranjan R., He J., Gan W.-S.","57201183624;57201189529;56770063300;55635587900;55968222200;7103165543;","Fast HRFT measurement system with unconstrained head movements for 3D audio in virtual and augmented reality applications",2017,"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings","2017-March",,,"6576","6577",,6,"10.1109/ICASSP.2017.8005299","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043706787&doi=10.1109%2fICASSP.2017.8005299&partnerID=40&md5=2e61ea590626739ebb07bbeba7d4c3fd","School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Maxim Integrated Products, Inc., Singapore","Hai, N.D., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Chaudhary, N.K., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Peksi, S., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Ranjan, R., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; He, J., Maxim Integrated Products, Inc., Singapore; Gan, W.-S., School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore","Binaural audio plays an indispensable role in virtual reality (VR) and augmented reality (AR). Binaural audio recreates the sensation of the three dimensional auditory experience using Head- Related Transfer Functions (HRTFs). HRTFs are as unique as our fingerprint. To achieve an immersive audio experience, HRTFs measured from every particular user is required. Nowadays, the conventional methods for HRTF measurements requires a wellcontrolled environment, hardly any movement of the user, and projecting to the user a high level of unpleasant sound in a rather long duration. Such difficulties have greatly limited the use of individually measurement HRTFs and hinder the authenticity of immersive audio. To solve these problems, we proposed a fast and convenient HRTF measurement system that is an order of magnitude faster and more importantly, it does not place any constraints on the user's movement. With the help of a head-Tracker and advanced adaptive signal processing algorithms, this system is able to achieve satisfactory HRTF measurement accuracy. In this demonstration, we will present a fast real-Time HRTF acquisition system and show how the individualized HRTFs improve the audio experience in VR/AR applications. © 2017 IEEE.","Augmented reality (AR); Binauralrendering; Fast and relaxed HRTF acquisition; Virtual reality (VR)","Augmented reality; Bins; Signal processing; Transfer functions; Virtual reality; Acquisition systems; Adaptive signal processing; Binauralrendering; Conventional methods; Fast and relaxed HRTF acquisition; Head related transfer function; Measurement accuracy; Virtual and augmented reality; Sound reproduction",Conference Paper,"Final","",Scopus,2-s2.0-85043706787
"Lee H., Cho Y.-S.","57204033467;57204041517;","Virtual and mixed reality for students: How to control human factors",2017,"ICCE 2017 - 25th International Conference on Computers in Education: Technology and Innovation: Computer-Based Educational Systems for the 21st Century, Workshop Proceedings",,,,"343","354",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054174464&partnerID=40&md5=489c0f8f593877d3aeca1f316d0aa874","Korea Education and Research Information Service, South Korea","Lee, H., Korea Education and Research Information Service, South Korea; Cho, Y.-S., Korea Education and Research Information Service, South Korea","Emerging technologies, such as virtual reality and mixed reality, help teachers as well as students understand educational contents more easily. But we need to consider more deeply. Because most of the devices and contents that released recently are targeted at the game and entertainment market, it may well be doubted whether they are proper for education. Some people have difficulty in health and social aspects after experience virtual or mixed reality. In this paper, we introduce the human factors issues in the virtual and mixed reality area. If we know how to control human factors, virtual and mixed reality could be used more safely in education. We gathered the usage guides, best practices and guidelines about those. We analyze and put the parts commonly mentioned together. But the consideration of hardware itself is excluded. As a result, we propose human factor guideline for users and contents creators using virtual and mixed reality in education. © 2017 Asia-Pacific Society for Computers in Education. All rights reserved.","Augmented reality; Education; Guidelines; Human factors; Virtual reality","Augmented reality; E-learning; Education; Educational technology; Engineering research; Human engineering; Social aspects; Students; Teaching; Technology transfer; Virtual reality; Best practices; Educational contents; Emerging technologies; Guidelines; Mixed reality",Conference Paper,"Final","",Scopus,2-s2.0-85054174464
"Pedram Sh., Perez P., Palmisano S., Farrelly M.","56429736400;7201902645;6701694405;57194973291;","The application of simulation (Virtual Reality) for safety training in the context of mining industry",2017,"Proceedings - 22nd International Congress on Modelling and Simulation, MODSIM 2017",,,,"361","367",,3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063933709&partnerID=40&md5=3341710b6efa35c5dcdceba0bc1e6cbd","SMART Infrastructure Facility, School of Engineering, University of WollongongNSW, Australia; School of Psychology, University of WollongongNSW, Australia; Mines Rescue, Coal Services, Woonona, NSW, Australia","Pedram, Sh., SMART Infrastructure Facility, School of Engineering, University of WollongongNSW, Australia; Perez, P., SMART Infrastructure Facility, School of Engineering, University of WollongongNSW, Australia; Palmisano, S., School of Psychology, University of WollongongNSW, Australia; Farrelly, M., Mines Rescue, Coal Services, Woonona, NSW, Australia","Virtual Reality (VR) technology has been used to train for various operations and dangerous circumstances where it is believed that training objectives cannot be achieved easily or the cost will prohibitive. Van Wyk and colleagues (2009) define VR-based training environments as “real-time computer simulations of the real world, in which visual realism, object behavior and user interaction are essential elements”. The use of VR-based training environments assumes that Human-Machine interaction stimulates learning processes through better experiencing and improved memorization, leading to a more effective transfer of the learning outcomes into workplace environments. However, there are many human factors (internally and externally), which have impact on the quality of the training and learning process which need to be identified and investigated. In this article, initially factors affecting the quality of the training and learning process for underground mine rescuers have been identified and then measured by using pre- and post-training questionnaires. Then statistical analyses have been performed to investigate the relationship among trainees’ perceived realism, usefulness and success. Also, trainers’ perception on 360-VR usefulness and success has been measured and compared with trainees. As the result of analysis indicated, trainees typically found the training sessions useful and perceived them to be successful; many felt that it was not really consistent with their real life experience. It would appear that perceived usefulness plays important role in forming the perception of success with high correlation and that the level of realism is not necessarily a deciding factor. Also, there was no significant difference between perceived usefulness and success between trainees and trainers. This research was conducted in collaboration with Mines Rescue Pty Ltd (a training provider for the coal mining industry in NSW, Australia) and was focused on training programs developed for mine rescue brigades. Data was collected from 94 mine rescue brigades (trainees) who attended a 360-VR training session over a twelvemonth period and 25 trainers who run the training sessions. © 2017 Proceedings - 22nd International Congress on Modelling and Simulation, MODSIM 2017. All rights reserved.","Evaluation; Mining industry; Safety training; Virtual Reality (VR)","Accident prevention; Behavioral research; Coal industry; E-learning; Learning systems; Mineral industry; Operations research; Risk assessment; Surveys; Transfer learning; Virtual reality; Coal mining industry; Evaluation; Human machine interaction; Perceived usefulness; Real time computer simulation; Safety training; Training providers; Workplace environments; Mine rescue",Conference Paper,"Final","",Scopus,2-s2.0-85063933709
"Mastmeyer A., Wilms M., Handels H.","14056412100;55211200500;6701686055;","Interpatient respiratory motion model transfer for virtual reality simulations of liver punctures",2017,"Journal of WSCG","25","1",,"1","9",,4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027045452&partnerID=40&md5=c502a443c54f29ad47c54a49d5d6a223","Univ. of Luebeck, Inst. Of Med. Inform, Ratzeburger Allee 160, Luebeck, 23568, Germany","Mastmeyer, A., Univ. of Luebeck, Inst. Of Med. Inform, Ratzeburger Allee 160, Luebeck, 23568, Germany; Wilms, M., Univ. of Luebeck, Inst. Of Med. Inform, Ratzeburger Allee 160, Luebeck, 23568, Germany; Handels, H., Univ. of Luebeck, Inst. Of Med. Inform, Ratzeburger Allee 160, Luebeck, 23568, Germany","Current virtual reality (VR) training simulators of liver punctures often rely on static 3D patient data and use an unrealistic (sinusoidal) periodic animation of the respiratory movement. Existing methods for the animation of breathing motion support simple mathematical or patient-specific, estimated breathing models. However with personalized breathing models for each new patient, a heavily dose relevant or expensive 4D data acquisition is mandatory for keyframe-based motion modeling. Given the reference 4D data, first a model building stage using linear regression motion field modeling takes place. Then the methodology shown here allows the transfer of existing reference respiratory motion models of a 4D reference patient to a new static 3D patient. This goal is achieved by using non-linear inter-patient registration to warp one personalized 4D motion field model to new 3D patient data. This cost- and dose-saving new method is shown here visually in a qualitative proof-of-concept study. © 2017, Vaclav Skala Union Agency. All rights reserved.","4D motion models; Inter-patient registration of motion models; Liver puncture training; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85027045452
"Pan X., You Y., Wang Z., Lu C.","57196036026;57207780351;57211047180;23035659100;","Virtual to real reinforcement learning for autonomous driving",2017,"British Machine Vision Conference 2017, BMVC 2017",,,,"","",,24,"10.5244/c.31.11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088065938&doi=10.5244%2fc.31.11&partnerID=40&md5=82ffde1e2e5f6f05fec3bf404e1045d7","University of California, Berkeley, Berkeley, CA, United States; Shanghai Jiao Tong University, Shanghai, China; Tsinghua University, Beijing, China","Pan, X., University of California, Berkeley, Berkeley, CA, United States; You, Y., Shanghai Jiao Tong University, Shanghai, China; Wang, Z., Tsinghua University, Beijing, China; Lu, C., Shanghai Jiao Tong University, Shanghai, China","Reinforcement learning is considered as a promising direction for driving policy learning. However, training autonomous driving vehicle with reinforcement learning in real environment involves non-affordable trial-and-error. It is more desirable to first train in a virtual environment and then transfer to the real environment. In this paper, we propose a novel realistic translation network to make model trained in virtual environment be workable in real world. The proposed network can convert non-realistic virtual image input into a realistic one with similar scene structure. Given realistic frames as input, driving policy trained by reinforcement learning can nicely adapt to real world driving. Experiments show that our proposed virtual to real (VR) reinforcement learning (RL) works pretty well. To our knowledge, this is the first successful case of driving policy trained by reinforcement learning that can adapt to real world driving data. © 2017. The copyright of this document resides with its authors.",,"Autonomous vehicles; Computer vision; E-learning; Machine learning; Virtual reality; Autonomous driving; Policy learning; Real environments; Real-world; Real-world drivings; Scene structure; Trial and error; Virtual images; Reinforcement learning",Conference Paper,"Final","",Scopus,2-s2.0-85088065938
"Spicer R.P., Russell S.M., Rosenberg E.S.","25723810300;57190403263;23991764900;","The mixed reality of things: Emerging challenges for human-information interaction",2017,"Proceedings of SPIE - The International Society for Optical Engineering","10207",, 102070A,"","",,4,"10.1117/12.2268004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025639079&doi=10.1117%2f12.2268004&partnerID=40&md5=d839fefcd114f2d66f187a208b9a6873","University of Southern California, United States; U.S. Army Research Lab, United States","Spicer, R.P., University of Southern California, United States; Russell, S.M., U.S. Army Research Lab, United States; Rosenberg, E.S., University of Southern California, United States","Virtual and mixed reality technology has advanced tremendously over the past several years. This nascent medium has the potential to transform how people communicate over distance, train for unfamiliar tasks, operate in challenging environments, and how they visualize, interact, and make decisions based on complex data. At the same time, the marketplace has experienced a proliferation of network-connected devices and generalized sensors that are becoming increasingly accessible and ubiquitous. As the nternet of Things"" expands to encompass a predicted 50 billion connected devices by 2020, the volume and complexity of information generated in pervasive and virtualized environments will continue to grow exponentially. The convergence of these trends demands a theoretically grounded research agenda that can address emerging challenges for human-information interaction (HII). Virtual and mixed reality environments can provide controlled settings where HII phenomena can be observed and measured, new theories developed, and novel algorithms and interaction techniques evaluated. In this paper, we describe the intersection of pervasive computing with virtual and mixed reality, identify current research gaps and opportunities to advance the fundamental understanding of HII, and discuss implications for the design and development of cyber-human systems for both military and civilian use. © 2017 SPIE.","Human-Information Interaction; Mixed Reality; Virtual Reality","Complex networks; Ubiquitous computing; Design and Development; Human-information interaction; Interaction techniques; Mixed reality; Mixed reality technologies; Mixed-reality environment; Novel algorithm; Virtualized environment; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85025639079
"Agrawal R., Knodler M., Fisher D.L., Samuel S.","57196008158;57207533831;7403343358;55064216300;","Advanced virtual reality based training to improve young drivers' latent hazard anticipation ability",2017,"Proceedings of the Human Factors and Ergonomics Society","2017-October",,,"1995","1999",,4,"10.1177/1541931213601994","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042512417&doi=10.1177%2f1541931213601994&partnerID=40&md5=2be4231b6e89e395aef198a5c5a98cb0","University of Massachusetts, Amherst, United States; Volpe National Transportation Center, United States","Agrawal, R., University of Massachusetts, Amherst, United States; Knodler, M., University of Massachusetts, Amherst, United States; Fisher, D.L., Volpe National Transportation Center, United States; Samuel, S., University of Massachusetts, Amherst, United States","The crash rate for young novice drivers is at least eight times higher than that of their experienced counterparts. Literature shows that the young novice drivers are not careless drivers but they are clueless drivers' - clueless because of their inability to predict the risk ahead of time that might materialize on the forward roadway. Other error-feedback training programs exist that emphasize the teaching of risk awareness and perception skills to young drivers. In the current study, a Virtual reality based risk awareness and perception training program (V-RAPT) was developed on the Oculus Rift and evaluated on a driving simulator. The training program provides 360 degrees' views of 6 high risk driving scenarios towards training the young driver to anticipate and mitigate latent hazards. Twenty-four participants in three experiment groups were trained on one of 3 training programs-VRAPT, RAPT and Control, and were evaluated on a driving simulator. Eye movements were collected throughout the experiment. The simulator evaluation drives included six near-transfer scenarios used in the training and four far-transfer scenarios not used in the training but validated previously in other similar studies. The young drivers trained on the V-RAPT were found to anticipate a significantly greater proportion (86.25%) of the potential latent hazards as compared to the RAPT trained young drivers (62.36%) and control trained drivers (30.97%). The VR-based training program is shown to be effective in improving young drivers' ability to anticipate latent threats. Copyright 2017 by Human Factors and Ergonomics Society.","Active training; Driving simulation; Eye movements; Road safety; Virtual reality","Automobile simulators; Curricula; E-learning; Ergonomics; Eye movements; Hazards; Human engineering; Motor transportation; Risk perception; Simulators; Virtual reality; Active trainings; Driving scenarios; Driving simulation; Driving simulator; Novice drivers; Risk awareness; Road safety; Training program; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-85042512417
"Zhou P., Morales U., Wang X., Yang X.","57192267604;55287597300;8661390100;35774975600;","Integration of virtual reality and CFD techniques for thermal fluid education",2017,"ASME 2017 Heat Transfer Summer Conference, HT 2017","1",,,"","",,2,"10.1115/HT2017-4793","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032990661&doi=10.1115%2fHT2017-4793&partnerID=40&md5=08fa8544029bbc7898b56c03ac73a359","Mechanical Engineering Department, Purdue University Northwest, Hammond, IN, United States; Electrical and Computer Engineering Department, Purdue University Northwest, Hammond, IN, United States","Zhou, P., Mechanical Engineering Department, Purdue University Northwest, Hammond, IN, United States; Morales, U., Electrical and Computer Engineering Department, Purdue University Northwest, Hammond, IN, United States; Wang, X., Mechanical Engineering Department, Purdue University Northwest, Hammond, IN, United States; Yang, X., Electrical and Computer Engineering Department, Purdue University Northwest, Hammond, IN, United States","Engineering courses such as thermodynamics, fluid mechanics and heat transfer always involve many abstract math, physics concepts and equations-which are difficult to teach and understand. As fundamental courses in engineering programs, they are sometimes taught in big class size-where students may not receive adequate attention and assistance from instructors. To improve the teaching and learning efficiency, we proposed to develop virtual reality based interactive modules for learning computational fluid dynamics. In this paper, case-study learning module is demonstrated for conduction heat transfer. The programming languages of C# and Unity3D were used for the software development. Computational fluid dynamics simulation results obtained from ANSYS/FLUENT were incorporated in the program. The program has the integrated modules of mobility, interactivity, and controllability for the 3D modeling and simulations. Each module was developed separately for facilitating the program management, extension, and upgrades in the future. The developed interactive programs, incorporating rich, interactive, and engaging learning contexts, will help students gain and apply knowledge to solve real-world problems in mechanical engineering. Copyright © 2017 ASME.",,"Computational fluid dynamics; Curricula; E-learning; Education; Electronic equipment; Fluid dynamics; Fluid mechanics; Gas turbines; Heat conduction; Oscillators (electronic); Software design; Students; Teaching; Thermodynamics; Virtual reality; Computational fluid dynamics simulations; Engineering course; Engineering program; Integrated module; Interactive programs; Program management; Real-world problem; Teaching and learning; Heat transfer",Conference Paper,"Final","",Scopus,2-s2.0-85032990661
"Fechter M., Wartzack S.","57115088300;6506007420;","Natural finger interaction for cad assembly modeling",2017,"Proceedings of the ASME Design Engineering Technical Conference","1",, 67555,"","",,2,"10.1115/DETC2017-67555","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034773383&doi=10.1115%2fDETC2017-67555&partnerID=40&md5=72d41fefc5239e3e102d2bdfca44f30d","Department of Mechanical Engineering, Friedrich-Alexander-University Erlangen-Nuremberg, Erlangen, Germany","Fechter, M., Department of Mechanical Engineering, Friedrich-Alexander-University Erlangen-Nuremberg, Erlangen, Germany; Wartzack, S., Department of Mechanical Engineering, Friedrich-Alexander-University Erlangen-Nuremberg, Erlangen, Germany","In current CAD software the process of assembly modeling is hindered by a large number of separate rotation and translation actions necessary, especially in case of larger assemblies. Additionally matching faces, edges or points must be selected by clicking to define the appropriate constraint. In contrast to that, the process of assembling two normal sized physical parts in the real world seems to be rather simple. That is because we know how to grasp and move objects with our hands intuitively from our everyday experience. The idea behind this contribution is to enable the product developer to assemble CAD parts in a virtual environment through natural finger interaction like in reality. Therefore we present an overall method that combines the natural finger interaction with virtual objects and the insertion of constraints between rotationally symmetric CAD parts. The developed algorithms identify matching surfaces on the basis of the geometry as well as position and orientation of the parts in 3D space. This paper highlights the method to use a combination of real-Time physics simulation and a heuristic approach to achieve an intuitive interaction interface. Additionally, we describe the detection algorithms developed to find assembly relationships between rotationally symmetric CAD parts without prior constraint definition. We also present a prototype system to demonstrate the functionality of the overall method. Furthermore, challenges for future research, such as extending the functionality of the detection algorithms on additional part types, like non-rotationally symmetric shapes, are discussed. Draft Video: https://vimeo.com/203437638. © 2017 ASME.","Assembly modeling; Computer-Aided design; Natural user interface; Virtual reality","Geometry; Heuristic methods; Signal detection; Technology transfer; User interfaces; Virtual reality; Assembly model; Detection algorithm; Finger interactions; Heuristic approach; Intuitive interaction; Natural user interfaces; Position and orientations; Product developers; Computer aided design",Conference Paper,"Final","",Scopus,2-s2.0-85034773383
"Gilbert K.A.","57195204967;","Investigating the use and design of immersive simulation to improve self-efficacy for aspiring principals",2017,"Journal of Information Technology Education: Innovations in Practice","16","1",,"127","169",,2,"10.28945/3726","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026251032&doi=10.28945%2f3726&partnerID=40&md5=4a6ea259d7cabedc8f81be6143e3afb1","Department of Teaching and Leading, Augusta University, Augusta, GA, United States","Gilbert, K.A., Department of Teaching and Leading, Augusta University, Augusta, GA, United States","Aim/Purpose Improving public schools is a focus of federal legislation in the United States with much of the burden placed on principals. However, preparing principals for this task has proven elusive despite many changes in programming by insti-tutions of higher learning. Emerging technologies that rely on augmented and virtual realities are posited to be powerful pedagogical tools for closing this gap. Background This study investigated the effects of immersive simulation technologies on principals' self-efficacy after treatment and the perceived significance of the design of the immersive simulation experience as an effective tool for adult learners. Methodology The investigator employed a multiple-methods study that relied on a purposive sample of graduate students enrolled in educational leadership programs at two small universities in the southeastern United States. Participants completed a two-hour module of immersive simulation designed to facilitate transfer of knowledge to skills thereby increasing their self-efficacy. Contribution This paper contributes to a small body of literature that examines the use of immersive simulation to prepare aspiring principals. Findings The findings indicate moderate effect sizes in changes in self-efficacy, positive attitudes toward immersive simulation as a pedagogical tool, and significance in the design of immersive simulation modules. This suggests that immersive sim-ulation, when properly designed, aids principals in taking action to improve schools. Recommendations for Practitioners Educational leadership programs might consider the use of immersive simula-tions to enhance principals' ability to meet the complex demands of leading in the 21st century. Impact on Society Principals may be more adept at improving schools if preparation programs provided consistent opportunities to engage in immersive simulations.Future Research Future research should be conducted with larger sample sizes and longitudinally to determine the effectiveness of this treatment.","Action re-view cycle; Critical pedagogy; Immersive simulation; Principals; School improvement; Self-efficacy; Situated learning","Knowledge management; Virtual reality; Action re-view cycle; Critical pedagogies; Immersive; Principals; School improvement; Self efficacy; Situated learning; Students",Article,"Final","",Scopus,2-s2.0-85026251032
"Tan L., Mcgarry M.D.J., Van Houten E.E.W., Ji M., Solamen L., Weaver J.B., Paulsen K.D.","57191272437;57204295150;6602490335;57191265902;55655107400;13605276000;7102750366;","Gradient-based optimization for poroelastic and viscoelastic MR elastography",2017,"IEEE Transactions on Medical Imaging","36","1",,"236","250",,17,"10.1109/TMI.2016.2604568","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027439667&doi=10.1109%2fTMI.2016.2604568&partnerID=40&md5=9da5809a6e2da29e1f0f6f57b71451ea","Thayer School of Engineering, Dartmouth College, Hanover, NH  03755, United States; Department of Biomedical Engineering, Columbia University, New York, NY  10027, United States; Department of Mechanical Engineering, University de Sherbrooke, Sherbrooke, QC  J1K 2R1, Canada; Department of Molecular Biology and Genetics, Johns Hopkins University, School of Medicine, Baltimore, MD  21205, United States; Department of Radiology, Dartmouth-Hitchcock Medical Center, Lebanon, NH  03756, United States; Norris Cotton Cancer Center, Dartmouth-Hitchcock Medical Center, Lebanon, NH  03756, United States","Tan, L., Thayer School of Engineering, Dartmouth College, Hanover, NH  03755, United States; Mcgarry, M.D.J., Department of Biomedical Engineering, Columbia University, New York, NY  10027, United States; Van Houten, E.E.W., Department of Mechanical Engineering, University de Sherbrooke, Sherbrooke, QC  J1K 2R1, Canada; Ji, M., Department of Molecular Biology and Genetics, Johns Hopkins University, School of Medicine, Baltimore, MD  21205, United States; Solamen, L., Thayer School of Engineering, Dartmouth College, Hanover, NH  03755, United States; Weaver, J.B., Thayer School of Engineering, Dartmouth College, Hanover, NH  03755, United States, Department of Radiology, Dartmouth-Hitchcock Medical Center, Lebanon, NH  03756, United States; Paulsen, K.D., Thayer School of Engineering, Dartmouth College, Hanover, NH  03755, United States, Norris Cotton Cancer Center, Dartmouth-Hitchcock Medical Center, Lebanon, NH  03756, United States","We describe an efficient gradient computation for solving inverse problems arising in magnetic resonance elastography (MRE). The algorithm can be considered as a generalized 'adjoint method' based on a Lagrangian formulation. One requirement for the classic adjoint method is assurance of the self-adjoint property of the stiffness matrix in the elasticity problem. In this paper, we show this property is no longer a necessary condition in our algorithm, but the computational performance can be as efficient as the classic method, which involves only two forward solutions and is independent of the number of parameters to be estimated. The algorithm is developed and implemented in material property reconstructions using poroelastic and viscoelastic modeling. Various gradient- and Hessian-based optimization techniques have been tested on simulation, phantom and in vivo brain data. The numerical results show the feasibility and the efficiency of the proposed scheme for gradient calculation. © 1982-2012 IEEE.","Adjoint method; inverse problem; MR elastography; poroelastic modeling; viscoelastic modeling","Computational efficiency; Magnetic resonance; Matrix algebra; Medical imaging; Optimization; Problem solving; Stiffness matrix; Viscoelasticity; Adjoint methods; Computational performance; Gradient-based optimization; Lagrangian formulations; Magnetic resonance elastography; MR elastography; Poroelastic model; Viscoelastic modeling; Inverse problems; algorithm; Article; brain tissue; conjugate; echo planar imaging; elasticity; fluid flow; human; hydraulic conductivity; in vivo study; interstitial fluid; magnetic resonance elastography; memory consolidation; neuroimaging; porosity; pressure gradient; process optimization; rigidity; simulation; solid; surface property; viscoelasticity; brain; elasticity; elastography; imaging phantom; Algorithms; Brain; Elasticity; Elasticity Imaging Techniques; Phantoms, Imaging",Article,"Final","",Scopus,2-s2.0-85027439667
"Filonik D., Bednarz T., Rittenbruch M., Foth M.","35147976600;23089950100;6505859363;14826608900;","Glance - Generalized geometric primitives and transformations for information visualization in AR/VR environments",2016,"Proceedings - VRCAI 2016: 15th ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Applications in Industry","1",,,"461","468",,6,"10.1145/3013971.3014006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009769631&doi=10.1145%2f3013971.3014006&partnerID=40&md5=bf25f39627eaadcf5794c23fd217156a","Urban Informatics Research Lab., Australia; Institute for Future Environments, Australia; Queensland University of Technology, ARC Centre of Excellence for Mathematical and Statistical Frontiers, CSIRO Data61, Australia","Filonik, D., Urban Informatics Research Lab., Australia; Bednarz, T., Queensland University of Technology, ARC Centre of Excellence for Mathematical and Statistical Frontiers, CSIRO Data61, Australia; Rittenbruch, M., Urban Informatics Research Lab., Australia, Institute for Future Environments, Australia; Foth, M., Urban Informatics Research Lab., Australia","This paper outlines Glance, a unifying framework for exploring multidimensional, multivariate data in the context of AR/VR environments, along with specific implementation techniques that utilize programmable GPUs. The presented techniques extend the graphics pipeline through programmable shaders in order to support more general geometries and operations. Our point of departure from existing structural theories of graphics is a general spatial substrate, where data is encoded using higher-dimensional geometric primitives. From there, we define a series of processing stages, utilizing shaders to enable flexible and dynamic coordinate transformations. Furthermore, we describe how advanced visualization techniques, such as faceting and multiple views, can be integrated elegantly into our model. Bridging between Computer Graphics and Information Visualization theories, the elements of our framework are composable and expressive, allowing a diverse set of visualizations to be specified in a universal manner (see figure 1). © 2016 ACM.","GPU-acceleration; Interaction; Shaders; Visualization","Computer graphics; Flow visualization; Geometry; Information analysis; Information science; Information systems; Interactive computer graphics; Mathematical transformations; Program processors; Virtual reality; Advanced visualizations; Geometric primitives; GPU accelerations; Implementation techniques; Information visualization; Interaction; Programmable shaders; Shaders; Visualization",Conference Paper,"Final","",Scopus,2-s2.0-85009769631
"Chellali A., Mentis H., Miller A., Ahn W., Arikatla V.S., Sankaranarayanan G., De S., Schwaitzberg S.D., Cao C.G.L.","26767578800;57203381862;55956855100;9334513400;26654027600;15623319200;7202304567;7007036892;25957557800;","Achieving interface and environment fidelity in the Virtual Basic Laparoscopic Surgical Trainer",2016,"International Journal of Human Computer Studies","96",,,"22","37",,9,"10.1016/j.ijhcs.2016.07.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979747876&doi=10.1016%2fj.ijhcs.2016.07.005&partnerID=40&md5=343a4468d7b192400ee9a598468ded84","Department of Computer Engineering, IBISC Laboratory, University of Evry, Evry, France; Department of Surgery, Cambridge Health Alliance, Harvard Medical School, Cambridge, MA, United States; Department of Information Systems, University of Maryland Baltimore County, Baltimore, MD, United States; Department of Surgery, Wright State University, Dayton, OH, United States; Center for Modeling, Simulation and Imaging in Medicine, Rensselaer Polytechnic InstituteNY, United States; Department of Biomedical, Industrial and Human Factors Engineering, Wright State University, Dayton, OH, United States","Chellali, A., Department of Computer Engineering, IBISC Laboratory, University of Evry, Evry, France, Department of Surgery, Cambridge Health Alliance, Harvard Medical School, Cambridge, MA, United States; Mentis, H., Department of Surgery, Cambridge Health Alliance, Harvard Medical School, Cambridge, MA, United States, Department of Information Systems, University of Maryland Baltimore County, Baltimore, MD, United States; Miller, A., Department of Surgery, Cambridge Health Alliance, Harvard Medical School, Cambridge, MA, United States, Department of Surgery, Wright State University, Dayton, OH, United States; Ahn, W., Center for Modeling, Simulation and Imaging in Medicine, Rensselaer Polytechnic InstituteNY, United States; Arikatla, V.S., Center for Modeling, Simulation and Imaging in Medicine, Rensselaer Polytechnic InstituteNY, United States; Sankaranarayanan, G., Center for Modeling, Simulation and Imaging in Medicine, Rensselaer Polytechnic InstituteNY, United States; De, S., Center for Modeling, Simulation and Imaging in Medicine, Rensselaer Polytechnic InstituteNY, United States; Schwaitzberg, S.D., Department of Surgery, Cambridge Health Alliance, Harvard Medical School, Cambridge, MA, United States; Cao, C.G.L., Department of Biomedical, Industrial and Human Factors Engineering, Wright State University, Dayton, OH, United States","Virtual reality trainers are educational tools with great potential for laparoscopic surgery. They can provide basic skills training in a controlled environment and free of risks for patients. They can also offer objective performance assessment without the need for proctors. However, designing effective user interfaces that allow the acquisition of the appropriate technical skills on these systems remains a challenge. This paper aims to examine a process for achieving interface and environment fidelity during the development of the Virtual Basic Laparoscopic Surgical Trainer (VBLaST). Two iterations of the design process were conducted and evaluated. For that purpose, a total of 42 subjects participated in two experimental studies in which two versions of the VBLaST were compared to the accepted standard in the surgical community for training and assessing basic laparoscopic skills in North America, the FLS box-trainer. Participants performed 10 trials of the peg transfer task on each trainer. The assessment of task performance was based on the validated FLS scoring method. Moreover, a subjective evaluation questionnaire was used to assess the fidelity aspects of the VBLaST relative to the FLS trainer. Finally, a focus group session with expert surgeons was conducted as a comparative situated evaluation after the first design iteration. This session aimed to assess the fidelity aspects of the early VBLaST prototype as compared to the FLS trainer. The results indicate that user performance on the earlier version of the VBLaST resulting from the first design iteration was significantly lower than the performance on the standard FLS box-trainer. The comparative situated evaluation with domain experts permitted us to identify some issues related to the visual, haptic and interface fidelity on this early prototype. Results of the second experiment indicate that the performance on the second generation VBLaST was significantly improved as compared to the first generation and not significantly different from that of the standard FLS box-trainer. Furthermore, the subjects rated the fidelity features of the modified VBLaST version higher than the early version. These findings demonstrate the value of the comparative situated evaluation sessions entailing hands on reflection by domain experts to achieve the environment and interface fidelity and training objectives when designing a virtual reality laparoscopic trainer. This suggests that this method could be used successfully in the future to enhance the value of VR systems as an alternative to physical trainers for laparoscopic surgery skills. Some recommendations on how to use this method to achieve the environment and interface fidelity of a VR laparoscopic surgical trainer are identified. © 2016 Elsevier Ltd","Interaction design; Iterative design; Simulator fidelity; surgical training; Virtual reality (VR)","Design; Haptic interfaces; Iterative methods; Laparoscopy; Surgery; User interfaces; Virtual reality; Controlled environment; Interaction design; Iterative design; Performance assessment; Simulator fidelity; Subjective evaluations; Surgical training; Virtual reality trainer; Surgical equipment",Article,"Final","",Scopus,2-s2.0-84979747876
"Van Dijk L., Van Der Sluis C.K., Van Dijk H.W., Bongers R.M.","55986349800;6701309500;14523705200;6602524481;","Task-Oriented Gaming for Transfer to Prosthesis Use",2016,"IEEE Transactions on Neural Systems and Rehabilitation Engineering","24","12",,"1384","1394",,28,"10.1109/TNSRE.2015.2502424","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990958782&doi=10.1109%2fTNSRE.2015.2502424&partnerID=40&md5=d3f04d30a4122c08af8e6dfbedf89e9c","University Medical Center Groningen, Center for Human Movement Science, University of Groningen, Groningen, 9700 AD, Netherlands; University Medical Center Groningen, Department of Rehabilitation Medicine, University of Groningen, Groningen, 9700 RB, Netherlands; Faculty of Engineering, Serious Gaming Group, NHL University of Applied Sciences, Leeuwarden, 8900 CB, Netherlands","Van Dijk, L., University Medical Center Groningen, Center for Human Movement Science, University of Groningen, Groningen, 9700 AD, Netherlands; Van Der Sluis, C.K., University Medical Center Groningen, Department of Rehabilitation Medicine, University of Groningen, Groningen, 9700 RB, Netherlands; Van Dijk, H.W., Faculty of Engineering, Serious Gaming Group, NHL University of Applied Sciences, Leeuwarden, 8900 CB, Netherlands; Bongers, R.M., University Medical Center Groningen, Center for Human Movement Science, University of Groningen, Groningen, 9700 AD, Netherlands","The aim of this study is to establish the effect of task-oriented video gaming on using a myoelectric prosthesis in a basic activity of daily life (ADL). Forty-one able-bodied right-handed participants were randomly assigned to one of four groups. In three of these groups the participants trained to control a video game using the myosignals of the flexors and extensors of the wrist: in the Adaptive Catching group participants needed to catch falling objects by opening and closing a grabber and received ADL-relevant feedback during performance. The Free Catching group used the same game, but without augmented feedback. The Interceptive Catching group trained a game where the goal was to intercept a falling object by moving a grabber to the left and right. They received no additional feedback. The control group played a regular Mario computer game. All groups trained 20 minutes a day for four consecutive days. Two tests were conducted before and after training: one level of the training game was performed, and participants grasped objects with a prosthesis simulator. Results showed all groups improved their game performance over controls. In the prosthesis-simulator task, after training the Adaptive Catching group outperformed the other groups in their ability to adjust the hand aperture to the size of the objects and the degree of compression of compressible objects. This study is the first to demonstrate transfer effects from a serious game to a myoelectric prosthesis task. The specificity of the learning effects suggests that research into serious gaming will benefit from placing ADL-specific constraints on game development. © 2001-2011 IEEE.","Artificial limbs; electromyography; transfer of training; video games","Artificial limbs; Computer games; Electromyography; Feedback; Human computer interaction; Interactive computer graphics; Prosthetics; Serious games; Software design; Activity of daily lives; Adaptive catching; Augmented feedback; Game development; Myoelectric prosthesis; Relevant feedback; Transfer of trainings; Video game; Myoelectrically controlled prosthetics; arm; computer interface; daily life activity; devices; female; human; limb prosthesis; male; neurorehabilitation; physiology; procedures; psychomotor performance; teaching; video game; young adult; Activities of Daily Living; Arm; Artificial Limbs; Computer-Assisted Instruction; Female; Humans; Male; Neurological Rehabilitation; Psychomotor Performance; User-Computer Interface; Video Games; Young Adult",Article,"Final","",Scopus,2-s2.0-84990958782
"Yu J., Park J.","56131024300;57192642325;","Real-time facial tracking in virtual reality",2016,"SA 2016 - SIGGRAPH ASIA 2016 VR Showcase",,, a3,"","",,5,"10.1145/2996376.2996390","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006968903&doi=10.1145%2f2996376.2996390&partnerID=40&md5=162a2b3d033461b479bad62831e3db98","BinaryVR. Inc., United States","Yu, J., BinaryVR. Inc., United States; Park, J., BinaryVR. Inc., United States","Virtual reality (VR) emerges as the next social computing platform. For realizing immersive social interactions, projecting facial expressions onto the virtual avatar a crucial component. This is a challenge in VR as it requires capturing the facial motions behind the VR head mounted displays (HMDs). In this paper, we present a real-time facial expression tracking system in VR HMDs. The core of the system is a 3D camera attached to the HMDs, capturing motions on the lower half of the face, which enables users to track and retarget their facial animations in realtime onto CG avatars. The system is capable of capturing 20 facial expression parameters and transfer it onto the 3D character in real-time. © 2016. ACM.","Facial capture; Virtual reality","Cameras; Helmet mounted displays; Interactive computer graphics; Three dimensional computer graphics; Virtual reality; Facial animation; Facial capture; Facial expression parameters; Facial Expressions; Head mounted displays; Social computing; Social interactions; Tracking system; Face recognition",Conference Paper,"Final","",Scopus,2-s2.0-85006968903
"Geronazzo M., Fantin J., Sorato G., Baldovino G., Avanzini F.","36720522500;57192160918;57192165752;57192163530;7005300654;","Acoustic selfies for extraction of external ear features in mobile audio augmented reality",2016,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST","02-04-November-2016",,,"23","26",,6,"10.1145/2993369.2993376","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84998673798&doi=10.1145%2f2993369.2993376&partnerID=40&md5=baaf37ec647ecc8a17f0ae21946a13bd","Dept. of Neurosciences, Biomedicine and Movement Sciences, University of Verona, Italy; Dept. of Information Engineering, University of Padova, Italy","Geronazzo, M., Dept. of Neurosciences, Biomedicine and Movement Sciences, University of Verona, Italy; Fantin, J., Dept. of Information Engineering, University of Padova, Italy; Sorato, G., Dept. of Information Engineering, University of Padova, Italy; Baldovino, G., Dept. of Information Engineering, University of Padova, Italy; Avanzini, F., Dept. of Information Engineering, University of Padova, Italy","Virtual and augmented realities are expected to become more and more important in everyday life in the next future; the role of spatial audio technologies over headphones will be pivotal for application scenarios which involve mobility. This paper introduces the SelfEar project, aimed at low-cost acquisition and personalization of Head-Related Transfer Functions (HRTFs) on mobile devices. This first version focuses on capturing individual spectral features which characterize external ear acoustics, through a self-adjustable procedure which guides users in collecting such information: their mobile device must be held with the stretched arm and positioned at several specific elevation points; acoustic data are acquired by an audio augmented reality headset which embeds a pair of microphones at listener ear-canals. A preliminary measurement session assesses the ability of the system to capture spectral features which are crucial for elevation perception. Moreover, a virtual experiment using a computational auditory model predicts clear vertical localization cues in the measured features.","Binaural audio; Computational auditory model; Head-related transfer function; Headphones; Mobile augmented reality","Augmented reality; Headphones; Loudspeakers; Mobile devices; Transfer functions; Virtual reality; Audio augmented reality; Auditory modeling; Binaural audio; Elevation perceptions; Head related transfer function; Mobile augmented reality; Vertical localization; Virtual and augmented reality; Audio acoustics",Conference Paper,"Final","",Scopus,2-s2.0-84998673798
"Pannala V.R., Camara A.K.S., Dash R.K.","36161969700;7005091446;7103175154;","Modeling the detailed kinetics of mitochondrial cytochrome c oxidase: Catalytic mechanism and nitric oxide inhibition",2016,"Journal of Applied Physiology","121","5",,"1196","1207",,9,"10.1152/japplphysiol.00524.2016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021095865&doi=10.1152%2fjapplphysiol.00524.2016&partnerID=40&md5=84fb91b35d3357b0b3f1e29d38b1af3c","Depts. of Biomedical Engineering and Physiology, Medical College of Wisconsin, 8701 Watertown Plank Rd., Milwaukee, WI  53226, United States; Department of Biomedical Engineering, Medical College of Wisconsin, Milwaukee, WI, United States; Department of Anesthesiology, Medical College of Wisconsin, Milwaukee, WI, United States","Pannala, V.R., Depts. of Biomedical Engineering and Physiology, Medical College of Wisconsin, 8701 Watertown Plank Rd., Milwaukee, WI  53226, United States; Camara, A.K.S., Department of Anesthesiology, Medical College of Wisconsin, Milwaukee, WI, United States; Dash, R.K., Depts. of Biomedical Engineering and Physiology, Medical College of Wisconsin, 8701 Watertown Plank Rd., Milwaukee, WI  53226, United States, Department of Biomedical Engineering, Medical College of Wisconsin, Milwaukee, WI, United States","Pannala VR, Camara AK, Dash RK. Modeling the detailed kinetics of mitochondrial cytochrome c oxidase: Catalytic mechanism and nitric oxide inhibition. J Appl Physiol 121: 1196-1207, 2016. First published September 15, 2016; doi:10.1152/japplphysiol.00524.2016.- Cytochrome c oxidase (CcO) catalyzes the exothermic reduction of O2 to H2O by using electrons from cytochrome c, and hence plays a crucial role in ATP production. Although details on the enzyme structure and redox centers involved in O2 reduction have been known, there still remains a considerable ambiguity on its mechanism of action, e.g., the number of sequential electrons donated to O2 in each catalytic step, the sites of protonation and proton pumping, and nitric oxide (NO) inhibition mechanism. In this work, we developed a thermodynamically constrained mechanistic mathematical model for the catalytic action of CcO based on available kinetic data. The model considers a minimal number of redox centers on CcO and couples electron transfer and proton pumping driven by proton motive force (PMF), and accounts for the inhibitory effects of NO on the reaction kinetics. The model is able to fit well all the available kinetic data under diverse experimental conditions with a physiologically realistic unique parameter set. The model predictions show that: 1) the apparent Km of O2 varies considerably and increases from fully reduced to fully oxidized cytochrome c depending on pH and the energy state of mitochondria, and 2) the intermediate enzyme states depend on pH and cytochrome c redox fraction and play a central role in coupling mito-chondrial respiration to PMF. The developed CcO model can easily be integrated into existing mitochondrial bioenergetics models to understand the role of the enzyme in controlling oxidative phosphorylation in normal and disease conditions. © 2016 the American Physiological Society.","Half-saturation constant; Kinetic modeling; Oxygen reduction; Proton pumping","cytochrome c oxidase; nitric oxide; oxygen; proton; biological model; catalysis; cell respiration; electron transport; kinetics; metabolism; mitochondrion; oxidation reduction reaction; oxidative phosphorylation; pH; physiology; thermodynamics; Catalysis; Cell Respiration; Electron Transport; Electron Transport Complex IV; Hydrogen-Ion Concentration; Kinetics; Mitochondria; Models, Biological; Nitric Oxide; Oxidation-Reduction; Oxidative Phosphorylation; Oxygen; Protons; Thermodynamics",Article,"Final","",Scopus,2-s2.0-85021095865
"Teng J., Loukin S.H., Anishkin A., Kung C.","21234314500;6603213434;6506642220;7102125564;","A competing hydrophobic tug on L596 to the membrane core unlatches S4-S5 linker elbow from TRP helix and allows TRPV4 channel to open",2016,"Proceedings of the National Academy of Sciences of the United States of America","113","42",,"11847","11852",,12,"10.1073/pnas.1613523113","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991577881&doi=10.1073%2fpnas.1613523113&partnerID=40&md5=fcf482be71bccda4ec225341c16ebdde","Laboratory of Molecular and Cell Biology, University of Wisconsin, Madison, WI  53706, United States; Department of Physiology, University of Texas Southwestern Medical Center, Dallas, TX  75390, United States; Department of Biology, University of Maryland, College Park, MD  20742, United States; Department of Genetics, University of Wisconsin, Madison, WI  53706, United States","Teng, J., Laboratory of Molecular and Cell Biology, University of Wisconsin, Madison, WI  53706, United States, Department of Physiology, University of Texas Southwestern Medical Center, Dallas, TX  75390, United States; Loukin, S.H., Laboratory of Molecular and Cell Biology, University of Wisconsin, Madison, WI  53706, United States; Anishkin, A., Department of Biology, University of Maryland, College Park, MD  20742, United States; Kung, C., Laboratory of Molecular and Cell Biology, University of Wisconsin, Madison, WI  53706, United States, Department of Genetics, University of Wisconsin, Madison, WI  53706, United States","We have some generalized physical understanding of how ion channels interact with surrounding lipids but few detailed descriptions on how interactions of particular amino acids with contacting lipids may regulate gating. Here we discovered a structure-specific interaction between an amino acid and inner-leaflet lipid that governs the gating transformations of TRPV4 (transient receptor potential vanilloid type 4). Many cation channels use a S4-S5 linker to transmit stimuli to the gate. At the start of TRPV4's linker helix is leucine 596. A hydrogen bond between the indole of W733 of the TRP helix and the backbone oxygen of L596 secures the helix/linker contact, which acts as a latch maintaining channel closure. The modeled side chain of L596 interacts with the inner lipid leaflet near the polar-nonpolar interface in our model - an interaction that we explored by mutagenesis. We examined the outward currents of TRPV4-expressing Xenopus oocyte upon depolarizations as well as phenotypes of expressing yeast cells. Making this residue less hydrophobic (L596A/G/W/Q/K) reduces open probability [Po; loss-of-function (LOF)], likely due to altered interactions at the polar-nonpolar interface. L596I raises Po [gain-of-function (GOF)], apparently by placing its methyl group further inward and receiving stronger water repulsion. Molecular dynamics simulations showed that the distance between the levels of α-carbons of H-bonded residues L596 and W733 is shortened in the LOFs and lengthened in the GOFs, strengthening or weakening the linker/TRP helix latch, respectively. These results highlight that L596 lipid attraction counteracts the latch bond in a tug-of-war to tune the Po of TRPV4. © 2016, National Academy of Sciences. All rights reserved.","Gating; Lipids; Opening mechanism; TRP channels; TRP domain","indole; leucine; lipid; methyl group; oxygen; vanilloid receptor 4; amino acid; vanilloid receptor; amino acid substitution; animal cell; Article; cell swelling; channel gating; chemical bond; controlled study; depolarization; female; hydrogen bond; hydrophobicity; molecular dynamics; nonhuman; oocyte; priority journal; protein lipid interaction; Saccharomyces cerevisiae; Xenopus; agonists; amino acid sequence; animal; chemical phenomena; chemistry; drug effects; gain of function mutation; genetics; loss of function mutation; membrane; metabolism; molecular model; phenotype; protein conformation; protein domain; structure activity relation; yeast; Amino Acid Sequence; Amino Acids; Animals; Gain of Function Mutation; Hydrogen Bonding; Hydrophobic and Hydrophilic Interactions; Ion Channel Gating; Lipids; Loss of Function Mutation; Membranes; Models, Molecular; Phenotype; Protein Conformation; Protein Interaction Domains and Motifs; Structure-Activity Relationship; TRPV Cation Channels; Xenopus; Yeasts",Article,"Final","",Scopus,2-s2.0-84991577881
"Ariza O., Freiwald J., Laage N., Feist M., Salloum M., Bruder G., Steinicke F.","57197830700;57191980479;57191982482;57191977364;35753484300;23391698600;8883314100;","Inducing body-transfer illusions in VR by providing brief phases of visual-tactile stimulation",2016,"SUI 2016 - Proceedings of the 2016 Symposium on Spatial User Interaction",,,,"61","68",,4,"10.1145/2983310.2985760","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995687176&doi=10.1145%2f2983310.2985760&partnerID=40&md5=6963e453917408cd9526505c632cd9aa","Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany","Ariza, O., Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany; Freiwald, J., Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany; Laage, N., Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany; Feist, M., Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany; Salloum, M., Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany; Bruder, G., Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany; Steinicke, F., Human-Computer Interaction, Department of Informatics, Universität Hamburg, Germany","Current developments in the area of virtual reality (VR) allow numerous users to experience immersive virtual environments (VEs) in a broad range of application fields. In the same way, some research has shown novel advances in wearable devices to provide vibrotactile feedback which can be combined with low-cost technology for hand tracking and gestures recognition. The combination of these technologies can be used to investigate interesting psychological illusions. For instance, body-transfer illusions, such as the rubber-hand illusion or elongated-arm illusion, have shown that it is possible to give a person the persistent illusion of body transfer after only brief phases of synchronized visual-haptic stimulation. The motivation of this paper is to induce such perceptual illusions by combining VR, vibrotactile and tracking technologies, offering an interesting way to create new spatial interaction experiences centered on the senses of sight and touch. We present a technology framework that includes a pair of self-made gloves featuring vibrotactile feedback that can be synchronized with audio-visual stimulation in order to reproduce body-transfer illusions in VR. We present in detail the implementation of the framework and show that the proposed technology setup is able to induce the elongatedarm illusion providing automatic tactile stimuli, instead of the traditional approach based on manually synchronized stimulation. © 2016 ACM.","3D touch interaction; Body-transfer illusions; Head-mounted display; Vibrotactile feedback; Virtual environments","Helmet mounted displays; Sensory perception; Synchronization; Virtual reality; Audio-visual stimulation; Body-transfer illusions; Gestures recognition; Head mounted displays; Immersive virtual environments; Touch interaction; Traditional approaches; Vibro-tactile feedbacks; Wearable technology",Conference Paper,"Final","",Scopus,2-s2.0-84995687176
"Chen W., Ladeveze N., Clavel C., Bourdot P.","55918917900;26537655000;57210674262;14051447300;","Refined experiment of the altered human joystick for user cohabitation in multi-stereocopic immersive CVEs",2016,"2016 IEEE 3rd VR International Workshop on Collaborative Virtual Environments, 3DCVE 2016",,, 7563558,"1","8",,1,"10.1109/3DCVE.2016.7563558","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991287566&doi=10.1109%2f3DCVE.2016.7563558&partnerID=40&md5=bb8eb089f580f84d422dbe6a238fec7c","VENISE Group, CNRS-LIMSI, Orsay, France; CPU Group, CNRS-LIMSI, Orsay, France","Chen, W., VENISE Group, CNRS-LIMSI, Orsay, France; Ladeveze, N., VENISE Group, CNRS-LIMSI, Orsay, France; Clavel, C., CPU Group, CNRS-LIMSI, Orsay, France; Bourdot, P., VENISE Group, CNRS-LIMSI, Orsay, France","Immersive multi-user virtual environments give good support for closely-coupled collaboration between co-located users. More complex collaborative tasks may require individual user navigation to achieve loosely-coupled collaboration. We designed a navigation framework based on the human joystick metaphor with some alterations for cohabitation management. This model allows each user to navigate independently using a human joystick based control while avoiding physical obstacles and staying within the usable part of the system. We conducted a series of user studies to investigate the influence of each alteration by testing their combinations on various navigation tasks. The results show that modified transfer functions and adaptive neutral orientations improve users' cohabitation performance, while the impact of adaptive neutral positions need to be further studied. © 2016 IEEE.","I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism-Virtual Reality","Computer graphics; Navigation; Virtual reality; Co-located; Collaborative tasks; I.3.7 [computer graphics]: three-dimensional graphics and realism - virtual realities; Loosely coupled; Multi-user virtual environment; Navigation tasks; User navigation; User study; Three dimensional computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-84991287566
[No author name available],[No author id available],"3D collaborative interaction for aerospace industry",2016,"2016 IEEE 3rd VR International Workshop on Collaborative Virtual Environments, 3DCVE 2016",,, 7563560,"13","15",,2,"10.1109/3DCVE.2016.7563560","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991288183&doi=10.1109%2f3DCVE.2016.7563560&partnerID=40&md5=24b3302663bdf11ae98e7c28dab8d490",,"","3D collaborative interaction raises issues like awareness of the Virtual Environment that have been well known for some time. They have been the subject of research activities that have led to some interesting results described in the literature. Unfortunately, most of these results have not yet been not implemented in the software systems daily used by industry and remains only theoretical concepts. That is why we recently started a project to transfer some of these results in the aerospace industry for the Airbus Group. Beyond this first transfer target, we also intend to measure the real gains (in real industrial conditions) for the users, and then for the company. This second goal is essential because in most publications, user testing is not satisfying (lack of real users, lack of real procedures, non significant number of subjects). In this paper, we describe the first step of this work in progress and more precisely, the basic interaction features we have developed. Currently, we are designing the first user tests. © 2016 IEEE.",,"Virtual reality; Collaborative interaction; Industrial conditions; Interaction features; Research activities; Software systems; User testing; User tests; Work in progress; Aerospace industry",Conference Paper,"Final","",Scopus,2-s2.0-84991288183
"Mei C., Quarles J.","56421487500;55868360300;","A software framework for developing mathematical model driven virtual human",2016,"2016 IEEE Virtual Humans and Crowds for Immersive Environments, VHCIE 2016",,, 7563567,"12","16",,,"10.1109/VHCIE.2016.7563567","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991325547&doi=10.1109%2fVHCIE.2016.7563567&partnerID=40&md5=852f12a7b2d423cfb8f9e0d9ad2b0961","Department of Computer Science, University of Texas, San Antonio, United States","Mei, C., Department of Computer Science, University of Texas, San Antonio, United States; Quarles, J., Department of Computer Science, University of Texas, San Antonio, United States","Virtual Humans (VH) have many benefits, such as simulating humans when using real humans is difficult, impossible, or dangerous. VHs realism in behavior and response may be improved by mathematical models, which can provide dynamic responses and interactions and have the potential to be widely applied in training and education, such as medical training (e.g. physiological models of blood flow). However, the difficulties of developing mathematical model driven VHs may restrict the application of it, especially in the areas where the professionals do not know how to program (e.g. doctors). We present Mathematical Virtual People (MVP), which is a software framework that may simplify the developing job and encourage the applications of VHs driven by mathematical models, such as the drug reaction models and the cardiovascular system models. © 2016 IEEE.","Mathematical Model; Software Framework; Virtual Human","Application programs; Cardiovascular system; Computer programming; Mathematical models; Technology transfer; Virtual reality; Blood flow; Cardiovascular system models; Medical training; Reaction model; Software frameworks; Training and education; Virtual humans; Physiological models",Conference Paper,"Final","",Scopus,2-s2.0-84991325547
"Ferrer-Torregrosa J., Jiménez-Rodríguez M.Á., Torralba-Estelles J., Garzón-Farinós F., Pérez-Bermejo M., Fernández-Ehrling N.","56497953600;57168816300;57190985796;57190983121;57191966548;57190981162;","Distance learning ects and flipped classroom in the anatomy learning: Comparative study of the use of augmented reality, video and notes",2016,"BMC Medical Education","16","1", 230,"","",,35,"10.1186/s12909-016-0757-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985023167&doi=10.1186%2fs12909-016-0757-3&partnerID=40&md5=2e184d9ddd34f0b6947a0cca5249f5bf","Department of Podiatry, School of Physiotherapy and Podiatry, Catholic University of Valencia, San Vicente Martir, C/ Ramiro de Maeztu 14, Torrente, 46900, Spain; Didactics and Educational Innovation, School of Psychology, Teaching and Educational Sciences, Catholic University of Valencia, San Vicente Martir, Valencia, Spain; Faculty of Nursing, Catholic University of Valencia, San Vicente Martir, Valencia, Spain; Doctoral School, Catholic University of Valencia, San Vicente Martir, Valencia, Spain","Ferrer-Torregrosa, J., Department of Podiatry, School of Physiotherapy and Podiatry, Catholic University of Valencia, San Vicente Martir, C/ Ramiro de Maeztu 14, Torrente, 46900, Spain; Jiménez-Rodríguez, M.Á., Didactics and Educational Innovation, School of Psychology, Teaching and Educational Sciences, Catholic University of Valencia, San Vicente Martir, Valencia, Spain; Torralba-Estelles, J., Department of Podiatry, School of Physiotherapy and Podiatry, Catholic University of Valencia, San Vicente Martir, C/ Ramiro de Maeztu 14, Torrente, 46900, Spain; Garzón-Farinós, F., Department of Podiatry, School of Physiotherapy and Podiatry, Catholic University of Valencia, San Vicente Martir, C/ Ramiro de Maeztu 14, Torrente, 46900, Spain; Pérez-Bermejo, M., Faculty of Nursing, Catholic University of Valencia, San Vicente Martir, Valencia, Spain; Fernández-Ehrling, N., Doctoral School, Catholic University of Valencia, San Vicente Martir, Valencia, Spain","Background: The establishment of the ECTS (European Credit Transfer System) is one of the pillars of the European Space of Higher Education. This way of accounting for the time spent in training has two essential parts, classroom teaching (work with the professor) and distance learning (work without the professor, whether in an individual or collective way). Much has been published on the distance learning part, but less on the classroom teaching section. In this work, the authors investigate didactic strategies and associated aids for distance learning work in a concept based on flipped classroom where transmitting information is carried out with aids that the professor prepares, so that the student works in an independent way before the classes, thus being able to dedicate the classroom teaching time to more complex learning and being able to count on the professor's help. Methods: Three teaching aids applied to the study of anatomy have been compared: Notes with images, videos, and augmented reality. Four dimensions have been compared: the time spent, the acquired learnings, the metacognitive perception, and the prospects of the use of augmented reality for study. Results: The results show the effectiveness, in all aspects, of augmented reality when compared with the rest of aids. The questionnaire assessed the acquired knowledge through a course exam, where 5.60 points were obtained for the notes group, 6.54 for the video group, and 7.19 for the augmented reality group. That is 0.94 more points for the video group compared with the notes and 1.59 more points for the augmented reality group compared with the notes group. Conclusions: This research demonstrates that, although technology has not been sufficiently developed for education, it is expected that it can be improved in both the autonomous work of the student and the academic training of health science students and that we can teach how to learn. Moreover, one can see how the grades of the students who studied with augmented reality are more grouped and that there is less dispersion in the marks compared with other materials. © 2016 The Author(s).","Anatomy; Augmented reality; Autonomous learning; ECTS; Flipped classroom; Metacognition","anatomy; comparative study; health science; human; human experiment; learning; metacognition; perception; questionnaire; rest; teaching; videorecording; academic achievement; anatomy; comparative study; computer interface; education; educational model; health personnel attitude; learning; medical literature; organization and management; problem based learning; procedures; program evaluation; Spain; standards; Anatomy; Attitude of Health Personnel; Computer-Assisted Instruction; Education, Distance; Education, Graduate; Educational Measurement; Humans; Learning; Medical Writing; Models, Educational; Problem-Based Learning; Program Evaluation; Spain; User-Computer Interface; Video Recording",Article,"Final","",Scopus,2-s2.0-84985023167
"Loukas C., Georgiou E.","6603074122;7004603021;","Performance comparison of various feature detector-descriptors and temporal models for video-based assessment of laparoscopic skills",2016,"International Journal of Medical Robotics and Computer Assisted Surgery","12","3",,"387","398",,9,"10.1002/rcs.1702","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84985040464&doi=10.1002%2frcs.1702&partnerID=40&md5=6c1f9420c6928ef168deb2f0ce49d2ec","Medical Physics Lab-Simulation Center, School of Medicine, University of Athens, Greece","Loukas, C., Medical Physics Lab-Simulation Center, School of Medicine, University of Athens, Greece; Georgiou, E., Medical Physics Lab-Simulation Center, School of Medicine, University of Athens, Greece","Background: Despite the significant progress in hand gesture analysis for surgical skills assessment, video-based analysis has not received much attention. In this study we investigate the application of various feature detector-descriptors and temporal modeling techniques for laparoscopic skills assessment. Methods: Two different setups were designed: static and dynamic video-histogram analysis. Four well-known feature detection-extraction methods were investigated: SIFT, SURF, STAR-BRIEF and STIP-HOG. For the dynamic setup two temporal models were employed (LDS and GMMAR model). Each method was evaluated for its ability to classify experts and novices on peg transfer and knot tying. Results: STIP-HOG yielded the best performance (static: 74–79%; dynamic: 80–89%). Temporal models had equivalent performance. Important differences were found between the two groups with respect to the underlying dynamics of the video-histogram sequences. Conclusions: Temporal modeling of feature histograms extracted from laparoscopic training videos provides information about the skill level and motion pattern of the operator. Copyright © 2015 John Wiley & Sons, Ltd. Copyright © 2015 John Wiley & Sons, Ltd.","feature extraction; laparoscopy; simulation; skills assessment; surgery; video processing","Article; clinical article; controlled study; histogram; human; intermethod comparison; laparoscopic surgery; minimally invasive surgery; performance; skill; surgical training; virtual reality",Article,"Final","",Scopus,2-s2.0-84985040464
"Kramp K.H., van Det M.J., Veeger N.J.G.M., Pierie J.-P.E.N.","55976669200;24462649100;6603904857;8656937000;","The Pareto Analysis for Establishing Content Criteria in Surgical Training",2016,"Journal of Surgical Education","73","5",,"892","901",,5,"10.1016/j.jsurg.2016.04.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971656943&doi=10.1016%2fj.jsurg.2016.04.010&partnerID=40&md5=c4ac8d5fa10b3b2ce282943be7f96c50","Department of Surgery, Leeuwarden Medical Centre, Leeuwarden, Netherlands; Department of Surgery, Hospital Group Twente, Almelo, Netherlands; Department of Epidemiology, Leeuwarden Medical Centre, Leeuwarden, Netherlands; University of Groningen, University Medical Centre Groningen, Department of Epidemiology, Groningen, Netherlands; Post Graduate School of Medicine, University of Groningen, University Medical Centre Groningen, Groningen, Netherlands","Kramp, K.H., Department of Surgery, Leeuwarden Medical Centre, Leeuwarden, Netherlands; van Det, M.J., Department of Surgery, Leeuwarden Medical Centre, Leeuwarden, Netherlands, Department of Surgery, Hospital Group Twente, Almelo, Netherlands; Veeger, N.J.G.M., Department of Epidemiology, Leeuwarden Medical Centre, Leeuwarden, Netherlands, University of Groningen, University Medical Centre Groningen, Department of Epidemiology, Groningen, Netherlands; Pierie, J.-P.E.N., Department of Surgery, Leeuwarden Medical Centre, Leeuwarden, Netherlands, Post Graduate School of Medicine, University of Groningen, University Medical Centre Groningen, Groningen, Netherlands","Introduction Current surgical training is still highly dependent on expensive operating room (OR) experience. Although there have been many attempts to transfer more training to the skills laboratory, little research is focused on which technical behaviors can lead to the highest profit when they are trained outside the OR. The Pareto principle states that in any population that contributes to a common effect, a few account for the bulk of the effect. This principle has been widely used in business management to increase company profits. This study uses the Pareto principle for establishing content criteria for more efficient surgical training. Method A retrospective study was conducted to assess verbal guidance provided by 9 supervising surgeons to 12 trainees performing 64 laparoscopic cholecystectomies in the OR. The verbal corrections were documented, tallied, and clustered according to the aimed change in novice behavior. The corrections were rank ordered, and a cumulative distribution curve was used to calculate which corrections accounted for 80% of the total number of verbal corrections. Results In total, 253 different verbal corrections were uttered 1587 times and were categorized into 40 different clusters of aimed changes in novice behaviors. The 35 highest-ranking verbal corrections (14%) and the 11 highest-ranking clusters (28%) accounted for 80% of the total number of given verbal corrections. Conclusions Following the Pareto principle, we were able to identify the aspects of trainee behavior that account for most corrections given by supervisors during a laparoscopic cholecystectomy on humans. This strategy can be used for the development of new training programs to prepare the trainee in advance for the challenges encountered in the clinical setting in an OR. © 2016 Association of Program Directors in Surgery","content validity; Interpersonal and Communication Skills; laparoscopic cholecystectomy; Medical Knowledge; pareto principle; Practice-Based Learning and Improvement; surgical training","Article; behavior; human; laparoscopic cholecystectomy; medical student; priority journal; retrospective study; simulation training; skill; surgeon; surgical skill; surgical training; task performance; videorecording; clinical competence; curriculum; education; health care quality; medical education; procedures; productivity; Cholecystectomy, Laparoscopic; Clinical Competence; Curriculum; Education, Medical, Graduate; Efficiency; Humans; Internship and Residency; Quality Assurance, Health Care; Retrospective Studies; Video Recording",Article,"Final","",Scopus,2-s2.0-84971656943
"Mastmeyer A., Fortmeier D., Handels H.","14056412100;55208146100;6701686055;","Efficient patient modeling for visuo-haptic VR simulation using a generic patient atlas",2016,"Computer Methods and Programs in Biomedicine","132",,,"161","175",,14,"10.1016/j.cmpb.2016.04.017","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966605200&doi=10.1016%2fj.cmpb.2016.04.017&partnerID=40&md5=9d6f7799cd805c496fd7c3406f417d08","Institute of Medical Informatics, University of Lübeck, Lübeck, Germany; Institute of Medical Informatics and the Graduate School for Computing in Medicine and Life Sciences, University of Lübeck, Lübeck, Germany","Mastmeyer, A., Institute of Medical Informatics, University of Lübeck, Lübeck, Germany; Fortmeier, D., Institute of Medical Informatics and the Graduate School for Computing in Medicine and Life Sciences, University of Lübeck, Lübeck, Germany; Handels, H., Institute of Medical Informatics, University of Lübeck, Lübeck, Germany","Background and Objective: This work presents a new time-saving virtual patient modeling system by way of example for an existing visuo-haptic training and planning virtual reality (VR) system for percutaneous transhepatic cholangio-drainage (PTCD). Methods: Our modeling process is based on a generic patient atlas to start with. It is defined by organ-specific optimized models, method modules and parameters, i.e. mainly individual segmentation masks, transfer functions to fill the gaps between the masks and intensity image data. In this contribution, we show how generic patient atlases can be generalized to new patient data. The methodology consists of patient-specific, locally-adaptive transfer functions and dedicated modeling methods such as multi-atlas segmentation, vessel filtering and spline-modeling. Results: Our full image volume segmentation algorithm yields median DICE coefficients of 0.98, 0.93, 0.82, 0.74, 0.51 and 0.48 regarding soft-tissue, liver, bone, skin, blood and bile vessels for ten test patients and three selected reference patients. Compared to standard slice-wise manual contouring time saving is remarkable. Conclusions: Our segmentation process shows out efficiency and robustness for upper abdominal puncture simulation systems. This marks a significant step toward establishing patient-specific training and hands-on planning systems in a clinical environment. © 2016 Elsevier Ireland Ltd.","Atlas-based segmentation; Cloud computing; Efficient image segmentation; Full body segmentation; Virtual reality simulation","Blood vessels; Cloud computing; Hospital data processing; Transfer functions; Virtual reality; Atlas-based segmentation; Clinical environments; Full body; Segmentation masks; Segmentation process; Simulation systems; Virtual patient models; Virtual reality simulations; Image segmentation; Article; blood; bone; cloud computing; computer assisted tomography; fascia; first cervical vertebra; human; liver; lumbar puncture; patient coding; percutaneous transhepatic cholangio drainage; percutaneous transhepatic drainage; skin; soft tissue; tactile stimulation; virtual reality; visual stimulation; voxel based morphometry; algorithm; computer interface; theoretical model; Algorithms; Humans; Models, Theoretical; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84966605200
"Mendell M.J., Eliseeva E.A., Davies M.M., Lobscheid A.","6701420647;24587011400;55919329900;6508229605;","Do classroom ventilation rates in California elementary schools influence standardized test scores? Results from a prospective study",2016,"Indoor Air","26","4",,"546","557",,28,"10.1111/ina.12241","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027931663&doi=10.1111%2fina.12241&partnerID=40&md5=08b518fc46f75e209221652baea64731","Environmental Energy Technologies Division, Lawrence Berkeley National Laboratory, Berkeley, CA, United States; Environmental Health Laboratory Branch, California Department of Public Health, Richmond, CA, United States; Integral Ad Science, New York, NY, United States; Group in Biostatistics, University of California, Berkeley, Berkeley, CA, United States","Mendell, M.J., Environmental Energy Technologies Division, Lawrence Berkeley National Laboratory, Berkeley, CA, United States, Environmental Health Laboratory Branch, California Department of Public Health, Richmond, CA, United States; Eliseeva, E.A., Environmental Energy Technologies Division, Lawrence Berkeley National Laboratory, Berkeley, CA, United States, Integral Ad Science, New York, NY, United States; Davies, M.M., Environmental Energy Technologies Division, Lawrence Berkeley National Laboratory, Berkeley, CA, United States, Group in Biostatistics, University of California, Berkeley, Berkeley, CA, United States; Lobscheid, A., Environmental Energy Technologies Division, Lawrence Berkeley National Laboratory, Berkeley, CA, United States","Limited evidence has associated lower ventilation rates (VRs) in schools with reduced student learning or achievement. We analyzed longitudinal data collected over two school years from 150 classrooms in 28 schools within three California school districts. We estimated daily classroom VRs from real-time indoor carbon dioxide measured by web-connected sensors. School districts provided individual-level scores on standard tests in Math and English, and classroom-level demographic data. Analyses assessing learning effects used two VR metrics: average VRs for 30 days prior to tests, and proportion of prior daily VRs above specified thresholds during the year. We estimated relationships between scores and VR metrics in multivariate models with generalized estimating equations. All school districts had median school-year VRs below the California VR standard. Most models showed some positive associations of VRs with test scores; however, estimates varied in magnitude and few 95% confidence intervals excluded the null. Combined-district models estimated statistically significant increases of 0.6 points (P = 0.01) on English tests for each 10% increase in prior 30-day VRs. Estimated increases in Math were of similar magnitude but not statistically significant. Findings suggest potential small positive associations between classroom VRs and learning. Published 2015. This article is a U.S. Government work and is in the public domain in the USA.","Achievement; Children; Indoor air quality; Learning; Schools; Ventilation",,Article,"Final","",Scopus,2-s2.0-85027931663
"Van Dijk L., Van Der Sluis C.K., Van Dijk H.W., Bongers R.M.","55986349800;6701309500;14523705200;6602524481;","Learning an EMG controlled game: Task-specific adaptations and transfer",2016,"PLoS ONE","11","8", e0160817,"","",,17,"10.1371/journal.pone.0160817","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990913286&doi=10.1371%2fjournal.pone.0160817&partnerID=40&md5=16c6e19289160026049364bd1ed0531e","University of Groningen, University Medical Center Groningen, Center for Human Movement Science, Groningen, Netherlands; University of Groningen, University Medical Center Groningen, Department of Rehabilitation Medicine, Groningen, Netherlands; NHL University of Applied Sciences, Faculty of Engineering, Serious Gaming Group, Leeuwarden, Netherlands","Van Dijk, L., University of Groningen, University Medical Center Groningen, Center for Human Movement Science, Groningen, Netherlands; Van Der Sluis, C.K., University of Groningen, University Medical Center Groningen, Department of Rehabilitation Medicine, Groningen, Netherlands; Van Dijk, H.W., NHL University of Applied Sciences, Faculty of Engineering, Serious Gaming Group, Leeuwarden, Netherlands; Bongers, R.M., University of Groningen, University Medical Center Groningen, Center for Human Movement Science, Groningen, Netherlands","Video games that aim to improve myoelectric control (myogames) are gaining popularity and are often part of the rehabilitation process following an upper limb amputation. However, direct evidence for their effect on prosthetic skill is limited. This study aimed to determine whether and how myogaming improves EMG control and whether performance improvements transfer to a prosthesis-simulator task. Able-bodied right-handed participants (N = 28) were randomly assigned to 1 of 2 groups. The intervention group was trained to control a video game (Breakout-EMG) using the myosignals of wrist flexors and extensors. Controls played a regular Mario computer game. Both groups trained 20 minutes a day for 4 consecutive days. Before and after training, two tests were conducted: one level of the Breakout-EMG game, and grasping objects with a prosthesis-simulator. Results showed a larger increase of in-game accuracy for the Breakout-EMG group than for controls. The Breakout-EMG group moreover showed increased adaptation of the EMG signal to the game. No differences were found in using a prosthesis-simulator. This study demonstrated that myogames lead to task-specific myocontrol skills. Transfer to a prosthesis task is therefore far from easy. We discuss several implications for future myogame designs. © 2016 van Dijk et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"adaptation; adult; Article; controlled study; electromyogram; female; human; human experiment; male; myoelectric control; normal human; prosthesis; randomized controlled trial; simulator; task performance; video game; analysis of variance; learning; limb prosthesis; motor performance; upper limb; video game; young adult; Adult; Analysis of Variance; Artificial Limbs; Female; Humans; Learning; Male; Motor Skills; Task Performance and Analysis; Upper Extremity; Video Games; Young Adult",Article,"Final","",Scopus,2-s2.0-84990913286
"Hindlekar S., Zordan V.B., Smith E.E., III, Welter J.C., McKay W.G.","57190856629;6506123075;57190862696;57190858179;57190862863;","MechVR: Interactive VR motion simulation of ""mech"" biped robot",2016,"ACM SIGGRAPH 2016 VR Village, SIGGRAPH 2016",,, a14,"","",,5,"10.1145/2929490.2932422","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983474967&doi=10.1145%2f2929490.2932422&partnerID=40&md5=0d1a3d843da1949194dcb16907062b6f","Clemson University, United States","Hindlekar, S., Clemson University, United States; Zordan, V.B., Clemson University, United States; Smith, E.E., III, Clemson University, United States; Welter, J.C., Clemson University, United States; McKay, W.G., Clemson University, United States","MechVR is an interactive VR/Motion simulator that offers an experience of driving a 3D simulated robot in a custom training world. From the user's perspective, they ""enter"" the cockpit of a giant motorized biped, and experience an immersive, interactive virtual reality training ride as they drive the simulated robotic machine themselves. The idea is not unlike a flight simulator, but for an imaginary, giant walking, running, and flying robot machine. Under the hood is a custom software base that drives state-of-the-art motion simulation equipment based on a custom user interface. Our research questions include the control and physical fidelity of the virtual robot, and the transfer of the experience into an interactive realworld simulation (hardware) as well as the design of the user experience for this and similar applications, e.g. prototyping amusement park rides, and/or novel arcade-style motion experiences. © 2016 Copyright held by the owner/author(s).","Motion simulation in the real world and virtual; Virtual reality","Computer graphics; Computer software; Flight simulators; Interface states; Machine design; Robots; User interfaces; Virtual reality; Amusement-park rides; Interactive virtual reality; Motion simulations; Real-world; Real-world simulation; Research questions; Simulated robot; State of the art; Interactive computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-84983474967
"Oh S.Y., Shriram K., Laha B., Baughman S., Ogle E., Bailenson J.","57149166100;57192920978;36093147000;55595658500;57190405635;6602840468;","Immersion at scale: Researcher's guide to ecologically valid mobile experiments",2016,"Proceedings - IEEE Virtual Reality","2016-July",, 7504747,"249","250",,6,"10.1109/VR.2016.7504747","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979777886&doi=10.1109%2fVR.2016.7504747&partnerID=40&md5=243f587709ce0639cbac41ccf2ac87e0","Department of Communication, Stanford University, United States","Oh, S.Y., Department of Communication, Stanford University, United States; Shriram, K., Department of Communication, Stanford University, United States; Laha, B., Department of Communication, Stanford University, United States; Baughman, S., Department of Communication, Stanford University, United States; Ogle, E., Department of Communication, Stanford University, United States; Bailenson, J., Department of Communication, Stanford University, United States","While there have been hundreds of psychological studies using virtual reality (VR) over the past few decades, those studies have almost exclusively been conducted in laboratory settings using small samples of college students with little demographic variance. Hence, the generalizability of the results is limited, as not all findings will apply outside the college demographic. In this paper, we present our mobile VR project (Immersion at Scale) where we conduct VR experiment sessions in naturalistic settings (e.g., local events, museums, etc.). On average, we were able to collect data from 20-25 people for each 4-hour data collection session of Immersion at Scale. We discovered a number of obstacles and opportunities based on bringing VR out into the field. Thus, we do not focus on experimental stimuli and results, but methodological guidelines based on our iterative design improvements from pilot testing. © 2016 IEEE.","Experimental methodology; Field study; Psychology","Iterative methods; Population statistics; Students; Virtual reality; College students; Data collection; Demographic variance; Experimental methodology; Field studies; Iterative design; Methodological guidelines; Psychology; Data acquisition",Conference Paper,"Final","",Scopus,2-s2.0-84979777886
"Daher S., Kim K., Lee M., Raij A., Schubert R., Bailenson J., Welch G.","57062307400;56159628700;56159565300;9735776700;55550102700;6602840468;35572266400;","Exploring social presence transfer in real-virtual human interaction",2016,"Proceedings - IEEE Virtual Reality","2016-July",, 7504705,"165","166",,3,"10.1109/VR.2016.7504705","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979780820&doi=10.1109%2fVR.2016.7504705&partnerID=40&md5=0475bd8bf66bb730025fb18d977c3e83","University of Central Florida, United States; UNC-Chapel Hill, United States; Stanford University, United States","Daher, S., University of Central Florida, United States; Kim, K., University of Central Florida, United States; Lee, M., University of Central Florida, United States; Raij, A., University of Central Florida, United States; Schubert, R., University of Central Florida, United States, UNC-Chapel Hill, United States; Bailenson, J., Stanford University, United States; Welch, G., University of Central Florida, United States","We explore whether a peripheral observation of apparent mutual social presence between a real human (RH) and a virtual human (VH) can in turn increase a subject's sense of social presence with the VH. In other words, we explore whether social presence can transfer from one RH-VH interaction to another. Specifically, we carried out an experiment where human subjects were asked to play a game with a VH. As they entered the game room, approximately half of the subjects were exposed to a brief but apparently engaging conversation between an RH and the VH. The subjects who were exposed to the brief RH-VH interaction had significantly higher measures of both emotional connection and the attentional allocation dimension of social presence for the VH, compared to those who were not. We describe the motivation, the experiment, and the results. © 2016 IEEE.","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial, Augmented, and Virtual Realities; J.4 [Computer Applications]: Social and Behavioral Sciences - Psychology","Behavioral research; Emotional connections; Exposed to; H.5.1 [Information interfaces and presentation]: Multimedia Information Systems Artificial , augmented , and virtual realities; Human subjects; J.4 [computer applications]: social and behavioral sciences - psychologies; Social presence; Virtual humans; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84979780820
"Lee M., Kim K., Daher S., Raij A., Schubert R., Bailenson J., Welch G.","56159565300;56159628700;57062307400;9735776700;55550102700;6602840468;35572266400;","The Wobbly Table: Increased Social Presence via Subtle Incidental Movement of a Real-Virtual Table",2016,"Proceedings - IEEE Virtual Reality","2016-July",, 7504683,"11","17",,27,"10.1109/VR.2016.7504683","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979788594&doi=10.1109%2fVR.2016.7504683&partnerID=40&md5=f824efacb20dd6e82bbe106e978d234b","University of Central Florida, United States; UNC, Chapel Hill, United States; Stanford University, United States","Lee, M., University of Central Florida, United States; Kim, K., University of Central Florida, United States; Daher, S., University of Central Florida, United States; Raij, A., University of Central Florida, United States; Schubert, R., University of Central Florida, United States, UNC, Chapel Hill, United States; Bailenson, J., Stanford University, United States; Welch, G., University of Central Florida, United States","While performing everyday interactions, we often incidentally touch and move objects in subtle ways. These objects are not necessarily directly related to the task at hand, and the movement of an object might even be entirely unintentional. If another person is touching the object at the same time, the movement can transfer through the object and be experienced - however subtly - by the other person. For example, when one person hands a drink to another, at some point both individuals will be touching the glass, and consequently exerting small (often unnoticed) forces on the other person. Despite the frequency of such subtle incidental movements of shared objects in everyday interactions, few have examined how these movements affect human-virtual human (VH) interaction. We ran an experiment to assess how presence and social presence are affected when a person experiences subtle, incidental movement through a shared real-virtual object. We constructed a real-virtual room with a table that spanned the boundary between the real and virtual environments. The participant was seated on the real side of the table, which visually extended into the virtual world via a projection screen, and the VH was seated on the virtual side of the table. The two interacted by playing a game of Twenty Questions, where one player asked the other a series of 20 yes/no questions to deduce what object the other player was thinking about. During the game, the wobbly group of subjects experienced subtle incidental movements of the real-virtual table: the entire real-virtual table tilted slightly away/toward the subject when the virtual/real human leaned on it. The control group also played the same game, except the table did not wobble. Results indicate that the wobbly group had higher presence and social presence with the virtual human in general, with statistically significant increases in presence, co-presence, and attentional allocation. We present the experiment and results, and discuss some potential implications for virtual human systems and some potential future studies. © 2016 IEEE.","Augmented and Virtual Realities; H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial; J.4 [Computer Applications]: Social and Behavioral Sciences - Psychology","Behavioral research; Augmented and virtual realities; H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Artificial; J.4 [computer applications]: social and behavioral sciences - psychologies; Social presence; Virtual human systems; Virtual humans; Virtual objects; Virtual tables; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84979788594
"Park C.S., Le Q.T., Pedro A., Lim C.R.","55728031400;55536113800;56402928500;56163405400;","Interactive Building Anatomy Modeling for Experiential Building Construction Education",2016,"Journal of Professional Issues in Engineering Education and Practice","142","3", 4015019,"","",,23,"10.1061/(ASCE)EI.1943-5541.0000268","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84975246807&doi=10.1061%2f%28ASCE%29EI.1943-5541.0000268&partnerID=40&md5=2fc6735a3beb25438346d88629acc28a","Dept. of Architectural Engineering, Chung-Ang Univ., Seoul, 06974, South Korea; Mutual Aid Project Division, Construction Workers Mutual Aid Association06151, South Korea","Park, C.S., Dept. of Architectural Engineering, Chung-Ang Univ., Seoul, 06974, South Korea; Le, Q.T., Dept. of Architectural Engineering, Chung-Ang Univ., Seoul, 06974, South Korea; Pedro, A., Dept. of Architectural Engineering, Chung-Ang Univ., Seoul, 06974, South Korea; Lim, C.R., Mutual Aid Project Division, Construction Workers Mutual Aid Association06151, South Korea","Building construction education is crucial in ensuring university students are adequately knowledgeable and competent to meet industry demands. Attributable to the changeable and complex environment, traditional pedagogical methods in building construction courses cannot equip students with concrete experience and knowledge. Despite several studies, adapting information and communication technology (ICT) tools such as virtual reality (VR) to enhance construction education, limited interaction and low detail of virtual contents still remain an unsolved issue. To address this problem, this study proposes an interactive building anatomy modeling (IBAM) system, which allows students to conveniently interact with VR environment for experiential building construction education. The IBAM system is developed based on the medical anatomy concept, including intuitive features, which support detaching and attaching components; and dissecting which enhances student-model interaction. To identify the advantages and limitations of IBAM, a prototype was developed, and its applicability was verified through a case study. Interim results suggest that the system facilitates experiential learning and provides adequate levels of interaction to effectively transfer knowledge to learners. © 2015 American Society of Civil Engineers.","Building information modeling; Construction education; Experiential learning; Virtual reality","Buildings; Education; Education computing; Students; Teaching; Virtual reality; Building construction; Building Information Model - BIM; Complex environments; Construction education; Experiential learning; Information and Communication Technologies; Pedagogical method; University students; Construction",Article,"Final","",Scopus,2-s2.0-84975246807
"Waterman B.R., Martin K.D., Cameron K.L., Owens B.D., Belmont P.J., Jr.","36085868600;54406996500;7102930668;7102230541;6701737430;","Simulation training improves surgical proficiency and safety during diagnostic shoulder arthroscopy performed by residents",2016,"Orthopedics","39","3",,"e479","e485",,48,"10.3928/01477447-20160427-02","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971246029&doi=10.3928%2f01477447-20160427-02&partnerID=40&md5=5e80085528a0a7734d46167ba33238ab","Department of Orthopaedic Surgery and Rehabilitation, William Beaumont Army Medical Center, El Paso, TX, United States; Keller Army Hospital, US Military Academy, 900 Washington Rd., West Point, NY  10996, United States","Waterman, B.R., Department of Orthopaedic Surgery and Rehabilitation, William Beaumont Army Medical Center, El Paso, TX, United States; Martin, K.D., Department of Orthopaedic Surgery and Rehabilitation, William Beaumont Army Medical Center, El Paso, TX, United States; Cameron, K.L., Keller Army Hospital, US Military Academy, 900 Washington Rd., West Point, NY  10996, United States; Owens, B.D., Keller Army Hospital, US Military Academy, 900 Washington Rd., West Point, NY  10996, United States; Belmont, P.J., Jr., Department of Orthopaedic Surgery and Rehabilitation, William Beaumont Army Medical Center, El Paso, TX, United States","Although virtual reality simulators have established construct validity, no studies have proven transfer of skills from a simulator to improved in vivo surgical skill. The current authors hypothesized that simulation training would improve residents' basic arthroscopic performance and safety. Twenty-two orthopedic surgery trainees were randomized into simulation or standard practice groups. At baseline testing, all of the participants performed simulator-based testing and a supervised, in vivo diagnostic shoulder arthroscopy with video recording. The simulation group subsequently received 1 hour of total instruction during a 3-month period, and the standard practice group received no simulator training. After intervention, both groups were reevaluated with simulator testing and a second recorded diagnostic shoulder arthroscopy. Two blinded, independent experts evaluated arthroscopic performance using the anatomic checklist, Arthroscopic Surgery Skill Evaluation Tool (ASSET) score, and total elapsed time. All outcome measures were compared within and between groups. After intervention, mean time required by the simulation group to complete the simulator task (30.64 seconds) was 8±1.2 seconds faster than the time required by the control group (38.64 seconds; P=.001). Probe distance (51.65 mm) was improved by 41.2±6.08 mm compared with the control (92.83 mm; P=.001). When comparing ASSET safety scores, the simulation group was competent (3.29) and significantly better than the control group (3.00; P=.005) during final arthroscopic testing. This study establishes transfer validity for an arthroscopic shoulder simulator model. Simulator training for residents in training can decrease surgical times, improve basic surgical skills, and confer greater patient safety during shoulder arthroscopy. Copyright © SLACK Incorporated.",,"Arthroscopic Surgery Skill Evaluation Tool score; Article; clinical competence; clinical evaluation; clinical practice; controlled study; diagnostic imaging; female; human; in vivo study; learning curve; male; patient safety; residency education; resident; scoring system; shoulder arthroscopy; simulation; simulator; single blind procedure; surgical training; task performance; videorecording; adult; arthroscopy; diagnostic imaging; education; medical education; orthopedics; prospective study; randomized controlled trial; shoulder; simulation training; Adult; Arthroscopy; Clinical Competence; Female; Humans; Internship and Residency; Male; Orthopedics; Patient Safety; Prospective Studies; Shoulder Joint; Simulation Training; Single-Blind Method",Article,"Final","",Scopus,2-s2.0-84971246029
"McVey R., Goldenberg M.G., Bernardini M.Q., Yasufuku K., Quereshy F.A., Finelli A., Pace K.T., Lee J.Y.","36340279500;57189320337;8605461700;6701562901;56182489300;57203105051;7003993629;36970926700;","Baseline Laparoscopic Skill May Predict Baseline Robotic Skill and Early Robotic Surgery Learning Curve",2016,"Journal of Endourology","30","5",,"588","593",,4,"10.1089/end.2015.0774","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969211017&doi=10.1089%2fend.2015.0774&partnerID=40&md5=d1a0f9b78826256a1254eceb823115ae","Department of Obstetrics and Gynecology, Sunnybrook Health Sciences Centre, Toronto, Canada; Department of Urology, St. Michael's Hospital, St. Michael's Health Centre, 61 Queen Street East, Toronto, M5C 2T2, Canada; Department of Gynecologic Oncology, University Health Network, Toronto, Canada; Department of Thoracic Surgery, University of Toronto, Toronto, Canada; Department of General Surgery, University Health Network, Toronto, Canada; Department of Urology, University Hospital Network, Toronto, Canada","McVey, R., Department of Obstetrics and Gynecology, Sunnybrook Health Sciences Centre, Toronto, Canada; Goldenberg, M.G., Department of Urology, St. Michael's Hospital, St. Michael's Health Centre, 61 Queen Street East, Toronto, M5C 2T2, Canada; Bernardini, M.Q., Department of Gynecologic Oncology, University Health Network, Toronto, Canada; Yasufuku, K., Department of Thoracic Surgery, University of Toronto, Toronto, Canada; Quereshy, F.A., Department of General Surgery, University Health Network, Toronto, Canada; Finelli, A., Department of Urology, University Hospital Network, Toronto, Canada; Pace, K.T., Department of Urology, St. Michael's Hospital, St. Michael's Health Centre, 61 Queen Street East, Toronto, M5C 2T2, Canada; Lee, J.Y., Department of Urology, St. Michael's Hospital, St. Michael's Health Centre, 61 Queen Street East, Toronto, M5C 2T2, Canada","Introduction: Robotic surgery is associated with a learning curve unique to each trainee. Knowledge about a trainee's baseline skill and learning curve would facilitate the development of a more individualized training curriculum. The aim of our study was to determine whether baseline laparoscopic skill is predictive of one's baseline robotic skill and short-term learning curve. Methods: Trainees from four different surgical specialties were included in the study. Each trainee participated in a 4-week, simulation-based robotic surgery basic skills training course. Precourse, baseline laparoscopic and robotic skills were assessed using validated test tasks; a basic peg transfer (PT) and an advanced intracorporeal suturing and knot tying (ISKT) task. Trainee robotic skill was assessed again 1 week postcourse. Each task performance was video recorded and scored by two blinded expert surgeons. Results: A total of 32 trainees were included; 14 urology, 7 gynecology, 8 thoracic Sx, 3 general Sx. Most (91%) were senior residents or clinical fellows and 50% had no prior robotic experience. There were no differences in baseline laparoscopic and robotic skill related to reported prior robotic experience. Between specialties, no differences were seen on baseline laparoscopic skill and only small differences were seen on baseline robotic skill. Both baseline Lap PT (p = 0.01) and Lap ISKT (p = 0.01) performances correlated with baseline robotic ISKT performance, but not robotic PT scores. Only baseline Lap ISKT performance correlated with postcourse robotic PT (p = 0.01) and ISKT (p < 0.01) performance. Baseline robotic ISKT scores, but not PT scores, correlated with postcourse robotic performance (p = 0.02 for PT, p < 0.01 for ISKT). Conclusions: In this study, a trainee's baseline laparoscopic skill correlated with certain baseline robotic skills. Better baseline performance on an advanced, but not basic, laparoscopic and robotic skill task may correlate with a shorter learning curve for basic robotic skills. Further exploration of this finding may yield better training curricula. © Copyright 2016, Mary Ann Liebert, Inc. 2016.",,"Article; controlled study; gynecology; human; laparoscopic surgery; learning curve; priority journal; robot assisted surgery; simulation training; surgical training; task performance; thorax surgery; urology; videorecording; Canada; clinical competence; curriculum; education; general surgery; laparoscopy; learning curve; robotic surgical procedure; Canada; Clinical Competence; Curriculum; General Surgery; Humans; Laparoscopy; Learning Curve; Robotic Surgical Procedures; Simulation Training; Task Performance and Analysis; Urology; Video Recording",Article,"Final","",Scopus,2-s2.0-84969211017
"Jensen U.J., Jensen J., Ahlberg G., Tornvall P.","54583657900;55584892900;55651189600;7004839362;","Virtual reality training in coronary angiography and its transfer effect to real-life catheterisation lab",2016,"EuroIntervention","11","13",,"1503","1510",,10,"10.4244/EIJY15M06_05","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016444950&doi=10.4244%2fEIJY15M06_05&partnerID=40&md5=1bc15ad28990460a9bf611149e18c602","Department of Clinical Science and Education, Södersjukhuset, Karolinska Institutet, Stockholm, Sweden; Department of Medicine, Sundsvall-Härnösand County Hospital, Karolinska Institutet, Stockholm, Sweden; Department of Molecular Medicine and Surgery, Karolinska Institutet, Stockholm, Sweden","Jensen, U.J., Department of Clinical Science and Education, Södersjukhuset, Karolinska Institutet, Stockholm, Sweden; Jensen, J., Department of Medicine, Sundsvall-Härnösand County Hospital, Karolinska Institutet, Stockholm, Sweden; Ahlberg, G., Department of Molecular Medicine and Surgery, Karolinska Institutet, Stockholm, Sweden; Tornvall, P., Department of Clinical Science and Education, Södersjukhuset, Karolinska Institutet, Stockholm, Sweden","Aims: The aim of this study was to explore if proficiency-based training in a coronary angiography (CA) simulator can transfer acquired skills from virtual reality (VR) to the real world in order to improve early performance. Methods and results: Sixteen senior cardiology residents were randomised to proficiency-based VR training or control. Two consecutive CAs were performed on patients. Skills metrics and errors were compared between the groups. Thirty-two CAs were performed under the supervision of an experienced interventionalist. VR-trained residents practised for a mean of 10 hours in a CA simulator. In real life, the VR-trained group had shorter fluoroscopy and total procedure times than the controls (median 558 vs. 842 seconds, p=0.003 and 1,356 vs. 1,623 seconds, p=0.032, respectively). The controls had a higher error score (median 27 vs. 15, p=0.002) and a lower performance score (median 47 vs. 68, p=0.006) than the VR-trained residents. Conclusions: Simulator-based training in CA improved skills and decreased errors compared to mentor-based training only. CA training in VR resulted in a superior performance, measured by fluoroscopy and total procedure times, and superior error and performance scores, thereby confirming transfer validity. Our recommendation is to incorporate VR training in the curriculum for the general cardiologist to improve safe learning in CA. © Europa Digital & Publishing 2016. All rights reserved.","Complication; Coronary angiography; Proficiency; Simulator; Validation","adult; Article; cardiologist; controlled study; coronary angiography; female; fluoroscopy; human; male; medical practice; professional competence; simulation training; simulator; virtual reality; catheterization; clinical competence; computer interface; computer simulation; Coronary Disease; curriculum; education; learning; procedures; Adult; Catheterization; Clinical Competence; Computer Simulation; Coronary Angiography; Coronary Disease; Curriculum; Female; Humans; Learning; Male; Preceptorship; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-85016444950
"Laha B., Bowman D.A., Laidlaw D.H., Socha J.J.","36093147000;57203231782;56652601600;8585845700;","A classification of user tasks in visual analysis of volume data",2016,"2015 IEEE Scientific Visualization Conference, SciVis 2015 - Proceedings",,, 7429485,"1","8",,8,"10.1109/SciVis.2015.7429485","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966270171&doi=10.1109%2fSciVis.2015.7429485&partnerID=40&md5=8c95c71341bd6416906fada0144deda0","Stanford University, United States; Virginia Tech, United States; Brown University, United States","Laha, B., Stanford University, United States; Bowman, D.A., Virginia Tech, United States; Laidlaw, D.H., Brown University, United States; Socha, J.J., Virginia Tech, United States","Empirical findings from studies in one scientific domain have very limited applicability to other domains, unless we formally establish deeper insights on the generalizability of task types. We present a domain-independent classification of visual analysis tasks with volume visualizations. This taxonomy will help researchers design experiments, ensure coverage, and generate hypotheses in empirical studies with volume datasets. To develop our taxonomy, we first interviewed scientists working with spatial data in disparate domains. We then ran a survey to evaluate the design participants in which were scientists and professionals from around the world, working with volume data in various scientific domains. Respondents agreed substantially with our taxonomy design, but also suggested important refinements. We report the results in the form of a goal-based generic categorization of visual analysis tasks with volume visualizations. Our taxonomy covers tasks performed with a wide variety of volume datasets. © 2015 IEEE.","3D Interaction; Empirical Evaluation; Scientific Visualization; Task Taxonomy; Virtual Reality; Volume Visualization","Data visualization; Surveys; Taxonomies; Virtual reality; Visualization; 3D interactions; Design experiments; Domain independents; Empirical evaluations; Empirical findings; Empirical studies; Volume data sets; Volume visualization; Three dimensional computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-84966270171
"Sankaranarayanan G., Li B., Manser K., Jones S.B., Jones D.B., Schwaitzberg S., Cao C.G.L., De S.","15623319200;57169023100;55996844500;15739783000;55387240300;7007036892;25957557800;7202304567;","Face and construct validation of a next generation virtual reality (Gen2-VR©) surgical simulator",2016,"Surgical Endoscopy","30","3",,"979","985",,13,"10.1007/s00464-015-4278-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959176014&doi=10.1007%2fs00464-015-4278-7&partnerID=40&md5=a5508327f4021456b0383555601182e6","Center for Modeling, Simulation and Imaging in Medicine (CeMSIM), Rensselaer Polytechnic Institute, 110 8th Street, JEC 2049, Troy, NY  12180, United States; School of Mechanical Engineering and Automation, Northeastern University, Shenyang, China; Cambridge Health Alliance, Cambridge, MA, United States; Beth Israel Deaconess Medical Center, Boston, MA, United States; Wright State University, Dayton, OH, United States; Department of Mechanical, Aerospace and Nuclear Engineering, Rensselaer Polytechnic Institute, 110 8th Street, JEC 2049, Troy, NY  12180, United States","Sankaranarayanan, G., Center for Modeling, Simulation and Imaging in Medicine (CeMSIM), Rensselaer Polytechnic Institute, 110 8th Street, JEC 2049, Troy, NY  12180, United States; Li, B., Center for Modeling, Simulation and Imaging in Medicine (CeMSIM), Rensselaer Polytechnic Institute, 110 8th Street, JEC 2049, Troy, NY  12180, United States, School of Mechanical Engineering and Automation, Northeastern University, Shenyang, China; Manser, K., Cambridge Health Alliance, Cambridge, MA, United States; Jones, S.B., Beth Israel Deaconess Medical Center, Boston, MA, United States; Jones, D.B., Beth Israel Deaconess Medical Center, Boston, MA, United States; Schwaitzberg, S., Cambridge Health Alliance, Cambridge, MA, United States; Cao, C.G.L., Wright State University, Dayton, OH, United States; De, S., Center for Modeling, Simulation and Imaging in Medicine (CeMSIM), Rensselaer Polytechnic Institute, 110 8th Street, JEC 2049, Troy, NY  12180, United States, Department of Mechanical, Aerospace and Nuclear Engineering, Rensselaer Polytechnic Institute, 110 8th Street, JEC 2049, Troy, NY  12180, United States","Introduction: Surgical performance is affected by distractors and interruptions to surgical workflow that exist in the operating room. However, traditional surgical simulators are used to train surgeons in a skills laboratory that does not recreate these conditions. To overcome this limitation, we have developed a novel, immersive virtual reality (Gen2-VR©) system to train surgeons in these environments. This study was to establish face and construct validity of our system. Methods and procedures: The study was a within-subjects design, with subjects repeating a virtual peg transfer task under three different conditions: Case I: traditional VR; Case II: Gen2-VR© with no distractions and Case III: Gen2-VR© with distractions and interruptions. In Case III, to simulate the effects of distractions and interruptions, music was played intermittently, the camera lens was fogged for 10 s and tools malfunctioned for 15 s at random points in time during the simulation. At the completion of the study subjects filled in a 5-point Likert scale feedback questionnaire. A total of sixteen subjects participated in this study. Results: Friedman test showed significant difference in scores between the three conditions (p &lt; 0.0001). Post hoc analysis using Wilcoxon signed-rank tests with Bonferroni correction further showed that all the three conditions were significantly different from each other (Case I, Case II, p &lt; 0.0001), (Case I, Case III, p &lt; 0.0001) and (Case II, Case III, p = 0.009). Subjects rated that fog (mean 4.18) and tool malfunction (median 4.56) significantly hindered their performance. Conclusion: The results showed that Gen2-VR© simulator has both face and construct validity and that it can accurately and realistically present distractions and interruptions in a simulated OR, in spite of limitations of the current HMD hardware technology. © 2015, Springer Science+Business Media New York.","Cognitive simulator; Face and construct validation; Gen2-VR©; Head-mounted display; Immersive virtual reality; Surgery simulator","accuracy; Article; Bonferroni correction; camera; computer program; construct validity; face validity; female; Friedman test; human; human experiment; Likert scale; male; monitor; music; operating room; post hoc analysis; priority journal; simulator; statistical model; surgeon; surgery simulator; surgical training; virtual reality; Wilcoxon signed ranks test; attention; computer interface; education; feedback system; laparoscopy; procedures; simulation training; validation study; Attention; Feedback; Female; Humans; Laparoscopy; Male; Simulation Training; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84959176014
"Bissonnette J., Dubé F., Provencher M.D., Moreno Sala M.T.","56851382000;56847321800;6701663481;56849540700;","Evolution of music performance anxiety and quality of performance during virtual reality exposure training",2016,"Virtual Reality","20","1",,"71","81",,20,"10.1007/s10055-016-0283-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956974350&doi=10.1007%2fs10055-016-0283-y&partnerID=40&md5=7505058e9853e029faf1370ade2c0945","Laval University, Pavillon Louis-Jacques-Casault, 1055 Avenue du Séminaire, Québec, QC  G1V 0A6, Canada; School of Psychology, Laval University, Québec, QC, Canada","Bissonnette, J., Laval University, Pavillon Louis-Jacques-Casault, 1055 Avenue du Séminaire, Québec, QC  G1V 0A6, Canada; Dubé, F., Laval University, Pavillon Louis-Jacques-Casault, 1055 Avenue du Séminaire, Québec, QC  G1V 0A6, Canada; Provencher, M.D., School of Psychology, Laval University, Québec, QC, Canada; Moreno Sala, M.T., Laval University, Pavillon Louis-Jacques-Casault, 1055 Avenue du Séminaire, Québec, QC  G1V 0A6, Canada","Virtual reality exposure is increasingly used as a method of treatment for anxiety disorders. This exploratory study examines a virtual reality exposure training (VRET) conceived for the treatment of music performance anxiety (MPA). The aim is to obtain first-level knowledge in the music field concerning VRET. This article analyzes how MPA, concentration and quality of performance evolve during VRET. Nine music students participated in six 1-h sessions of VRET spread out over 3 weeks. They were exposed to four different virtual environments representing typical audiences for musicians. The findings indicate a significant decrease in MPA between sessions. They also indicate a significant increase in performance quality within sessions and a positive correlation between absorption ability and level of anxiety at the beginning of the VRET. Further studies must be conducted to evaluate the generalizability potential of these results to real performance situations. © 2016, Springer-Verlag London.","Exposure; Immersion ability; Music; Performance anxiety; Treatment; Virtual reality","Virtual reality; Exposure; Immersion ability; Music; Performance anxiety; Treatment; E-learning",Article,"Final","",Scopus,2-s2.0-84956974350
"Belke T.W., Pierce W.D.","7003284060;57210989154;","Wheel-running reinforcement in free-feeding and food-deprived rats",2016,"Behavioural Processes","124",,,"1","9",,9,"10.1016/j.beproc.2015.11.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949580298&doi=10.1016%2fj.beproc.2015.11.018&partnerID=40&md5=ab39224e6ee81bba84d05618febd81d8","Mount Allison University, Sackville, NB, Canada; University of Alberta, Edmonton, AB, Canada","Belke, T.W., Mount Allison University, Sackville, NB, Canada; Pierce, W.D., University of Alberta, Edmonton, AB, Canada","Rats experiencing sessions of 30 min free access to wheel running were assigned to ad-lib and food-deprived groups, and given additional sessions of free wheel activity. Subsequently, both ad-lib and deprived rats lever pressed for 60 s of wheel running on fixed ratio (FR) 1, variable ratio (VR) 3, VR 5, and VR 10 schedules, and on a response-initiated variable interval (VI) 30 s schedule. Finally, the ad-lib rats were switched to food deprivation and the food-deprived rats were switched to free food, as rats continued responding on the response-initiated VI 30-s schedule. Wheel running functioned as reinforcement for both ad-lib and food-deprived rats. Food-deprived rats, however, ran faster and had higher overall lever-pressing rates than free-feeding rats. On the VR schedules, wheel-running rates positively correlated with local and overall lever pressing rates for deprived, but not ad-lib rats. On the response-initiated VI 30 s schedule, wheel-running rates and lever-pressing rates changed for ad-lib rats switched to food deprivation, but not for food-deprived rats switched to free-feeding. The overall pattern of results suggested different sources of control for wheel running: intrinsic motivation, contingencies of automatic reinforcement, and food-restricted wheel running. An implication is that generalizations about operant responding for wheel running in food-deprived rats may not extend to wheel running and operant responding of free-feeding animals. © 2015 Elsevier B.V.","Ad-libitum; Food deprivation; Lever pressing; Rats; Reinforcement schedule; Wheel-running reinforcement","behavioral response; feeding behavior; food availability; rodent; animal experiment; feeding; food deprivation; motivation; nonhuman; rat; reinforcement; running; animal; female; food deprivation; instrumental conditioning; Long Evans rat; motor activity; physiology; psychology; running; Animalia; Rattus; Animals; Conditioning, Operant; Female; Food Deprivation; Motivation; Motor Activity; Rats; Rats, Long-Evans; Reinforcement Schedule; Running",Article,"Final","",Scopus,2-s2.0-84949580298
"Gortari A.B.O.D.","55977387100;","What Can Game Transfer Phenomena Tell Us about the Impact of Highly Immersive Gaming Technologies?",2016,"Proceedings - 2015 International Conference on Interactive Technologies and Games, ITAG 2015",,, 7399494,"84","89",,2,"10.1109/iTAG.2015.15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84969204309&doi=10.1109%2fiTAG.2015.15&partnerID=40&md5=b149a3dda72c0b588ce2026e18d1999e","Division of Psychology, Nottingham Trent University, Nottingham, United Kingdom","Gortari, A.B.O.D., Division of Psychology, Nottingham Trent University, Nottingham, United Kingdom","The imminent introduction of highly immersive technologies for entertainment that bring exciting possibilities for the users also raises important questions regarding the impact on their well-being. Game Transfer Phenomena (GTP), a research approach focusing on understanding the psychosocial effects of video game playing by examining non-volitional phenomena (e.g., Altered sensorial perceptions, automatic mental processes, involuntary motoric activations and behaviours related to playing video games), suggests similarities between gamers' experiences reported after playing on conventional devices and side effects of highly immersive technologies (e.g., Head-up displays, highly realistic virtual environments). The aim of this paper is to discuss the challenges highly immersive technologies posit to the malleable human mind, taking into account not only the side-effects of the virtual immersion manifesting as physical symptoms, but also the psychosocial implications. © 2015 IEEE.","effects of video game playing; Game Transfer Phenomena; head-up displays; impact of VR; Virtual reality","Head-up displays; Interactive computer graphics; Virtual reality; Immersive gaming; Immersive technologies; impact of VR; Physical symptoms; Psycho-social effects; Research approach; Transfer phenomenon; Video game playing; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-84969204309
"Davis M.C., Can D.D., Pindrik J., Rocque B.G., Johnston J.M.","56443189000;57000171300;12805714800;57212093445;55426656500;","Virtual Interactive Presence in Global Surgical Education: International Collaboration Through Augmented Reality",2016,"World Neurosurgery","86",,,"103","111",,53,"10.1016/j.wneu.2015.08.053","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959496176&doi=10.1016%2fj.wneu.2015.08.053&partnerID=40&md5=ab27ccbb7a0fecc1928f74721fe0b98c","University of Alabama at Birmingham, Birmingham, AL, United States; Neurosurgical Department, Children's Hospital #2, Ho Chi Minh City, Viet Nam","Davis, M.C., University of Alabama at Birmingham, Birmingham, AL, United States; Can, D.D., Neurosurgical Department, Children's Hospital #2, Ho Chi Minh City, Viet Nam; Pindrik, J., University of Alabama at Birmingham, Birmingham, AL, United States; Rocque, B.G., University of Alabama at Birmingham, Birmingham, AL, United States; Johnston, J.M., University of Alabama at Birmingham, Birmingham, AL, United States","Background Technology allowing a remote, experienced surgeon to provide real-time guidance to local surgeons has great potential for training and capacity building in medical centers worldwide. Virtual interactive presence and augmented reality (VIPAR), an iPad-based tool, allows surgeons to provide long-distance, virtual assistance wherever a wireless internet connection is available. Local and remote surgeons view a composite image of video feeds at each station, allowing for intraoperative telecollaboration in real time. Methods Local and remote stations were established in Ho Chi Minh City, Vietnam, and Birmingham, Alabama, as part of ongoing neurosurgical collaboration. Endoscopic third ventriculostomy with choroid plexus coagulation with VIPAR was used for subjective and objective evaluation of system performance. Results VIPAR allowed both surgeons to engage in complex visual and verbal communication during the procedure. Analysis of 5 video clips revealed video delay of 237 milliseconds (range, 93-391 milliseconds) relative to the audio signal. Excellent image resolution allowed the remote neurosurgeon to visualize all critical anatomy. The remote neurosurgeon could gesture to structures with no detectable difference in accuracy between stations, allowing for submillimeter precision. Fifteen endoscopic third ventriculostomy with choroid plexus coagulation procedures have been performed with the use of VIPAR between Vietnam and the United States, with no significant complications. 80% of these patients remain shunt-free. Conclusion Evolving technologies that allow long-distance, intraoperative guidance, and knowledge transfer hold great potential for highly efficient international neurosurgical education. VIPAR is one example of an inexpensive, scalable platform for increasing global neurosurgical capacity. Efforts to create a network of Vietnamese neurosurgeons who use VIPAR for collaboration are underway. © 2016 Elsevier Inc. All rights reserved.","Global Health; Neurosurgery; Pediatrics; Telecommunications","anastomosis; anatomy; choroid plexus; gesture; human; human experiment; neurosurgeon; surgical training; United States; verbal communication; videorecording; Viet Nam; case report; computer interface; female; hydrocephalus; infant; international cooperation; male; neuroendoscopy; preschool child; teleconsultation; ventriculostomy; Child, Preschool; Female; Humans; Hydrocephalus; Infant; International Cooperation; Male; Neuroendoscopy; Remote Consultation; United States; User-Computer Interface; Ventriculostomy; Vietnam",Article,"Final","",Scopus,2-s2.0-84959496176
"Liu Y.-T., Lin Y.-Y., Wu S.-L., Hsieh T.-Y., Lin C.-T.","56333993300;35096651600;55903965000;56583448800;8942403600;","Assessment of Mental Fatigue: An EEG-Based Forecasting System for Driving Safety",2016,"Proceedings - 2015 IEEE International Conference on Systems, Man, and Cybernetics, SMC 2015",,, 7379693,"3233","3238",,4,"10.1109/SMC.2015.561","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84964555959&doi=10.1109%2fSMC.2015.561&partnerID=40&md5=f8801f612b040bde522cc8fb1adfeb04","Institute of Electrical Control Engineering, National Chiao-Tung University, Hsinchu, Taiwan; Brain Research Center, National Chiao-Tung University, Hsinchu, Taiwan","Liu, Y.-T., Institute of Electrical Control Engineering, National Chiao-Tung University, Hsinchu, Taiwan; Lin, Y.-Y., Brain Research Center, National Chiao-Tung University, Hsinchu, Taiwan; Wu, S.-L., Institute of Electrical Control Engineering, National Chiao-Tung University, Hsinchu, Taiwan; Hsieh, T.-Y., Institute of Electrical Control Engineering, National Chiao-Tung University, Hsinchu, Taiwan; Lin, C.-T., Institute of Electrical Control Engineering, National Chiao-Tung University, Hsinchu, Taiwan, Brain Research Center, National Chiao-Tung University, Hsinchu, Taiwan","This study proposes an EEG-based forecasting system based on a functional-link recurrent self-evolving fuzzy neural network (FL-RSEFNN) for assessing mental fatigue during a highway driving task. Drivers' cognitive states significantly affect driving safety, especially for fatigue or drowsy driving which is one of common factors to endanger individuals and the public safety. In this study, a FL-RSEFNN employs an on-line gradient descent (GD) learning rule to address the EEG regression problem in brain dynamics for estimation of driving fatigue. We analyze brain dynamics in a car driving task, which is constructed in a simulated virtual reality (VR) environment. The EEG-based forecasting system is evaluated using the generalized cross-subject approach, and the results indicate that the FLRSEFNN is superior to state-of-The-Art models regardless of the use of recurrent or non-recurrent structures. © 2015 IEEE.","braincomputer interface (BCI); driving safety; Electroencephalography (EEG); functional-link recurrent self-evolving fuzzy neural network (FL-RSEFNN)","Brain computer interface; Cybernetics; Diseases; Electrophysiology; Forecasting; Fuzzy inference; Fuzzy logic; Fuzzy neural networks; Virtual reality; Cognitive state; Driving safety; Evolving fuzzy neural networks; Forecasting system; Functional links; Gradient descent; Regression problem; State of the art; Electroencephalography",Conference Paper,"Final","",Scopus,2-s2.0-84964555959
"Lu X.-Q., Davis S.R.","57157731400;7405958602;","Priming effects on people’s safety decision in a virtual reality construction simulator",2016,"Civil Engineering and Urban Planning IV - Proceedings of the 4th International Conference on Civil Engineering and Urban Planning, CEUP 2015",,,,"501","505",,,"10.1201/b19880-94","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016748831&doi=10.1201%2fb19880-94&partnerID=40&md5=d3881ff710ca41f39d4e2ac3088122cf","University of New South Wales, Sydney, Australia","Lu, X.-Q., University of New South Wales, Sydney, Australia; Davis, S.R., University of New South Wales, Sydney, Australia","A Virtual Reality (VR) simulation is the imitation of a real-world process or system in a virtual environment. It has been considered to assist training in many fields. This study investigated the priming effects on people’s safety decision in a virtual construction simulator, in order to improve the design of a virtual reality simulator to be used in training. Preliminary study results show that the addition of priming factors to a VR simulator contributes to people’s sense of presence in a virtual environment. When people are primed by the concept of safety, they are more likely to perceive more risks and observe the environment carefully. Limitations of the research are that it applies to a specific problem and results need to be generalized over a larger set of problems. Future research is required to collect data over a large sample size. © 2016 Taylor & Francis Group, London.",,"Safety engineering; Simulators; Urban planning; Priming effects; Real-world process; Sample sizes; Sense of presences; Specific problems; Virtual construction; Virtual reality simulator; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85016748831
"Nathanael D., Mosialos S., Vosniakos G.-C., Tsagkas V.","6506068895;14058702100;6701789136;37105230000;","Development and Evaluation of a Virtual Reality Training System Based on Cognitive Task Analysis: The Case of CNC Tool Length Offsetting",2016,"Human Factors and Ergonomics In Manufacturing","26","1",,"52","67",,12,"10.1002/hfm.20613","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955099078&doi=10.1002%2fhfm.20613&partnerID=40&md5=8a1e68c2850b77abc085eb5d383bc1f5","School of Mechanical Engineering, National Technical University of Athens, Zografou, GR-15780, Greece","Nathanael, D., School of Mechanical Engineering, National Technical University of Athens, Zografou, GR-15780, Greece; Mosialos, S., School of Mechanical Engineering, National Technical University of Athens, Zografou, GR-15780, Greece; Vosniakos, G.-C., School of Mechanical Engineering, National Technical University of Athens, Zografou, GR-15780, Greece; Tsagkas, V., School of Mechanical Engineering, National Technical University of Athens, Zografou, GR-15780, Greece","This article reports on the development and evaluation of a virtual reality training system (VRTS) for a specific machining task. A cognitive task analysis of expert machinists was conducted to examine whether this can be effective in developing a VRTS concerning tool length offsetting for a machining center. This analysis provided the necessary information for development and calibration of such a system. Subsequently, the effectiveness of the VRTS was evaluated by conducting an experiment with 29 mechanical engineering students. The VRTS set-up comprised a video projection of the machining center and a physical mock-up of its interface. The system demonstrated positive training transfer for the toll length offsetting task in terms of task accomplishment and of time to complete the task. No positive transfer was observed in terms of task accuracy, probably due to perceptual biases induced by the detailed specification of the VRTS. The present work provides evidence that cognitive task analysis was effective in identifying a number of key skills pertaining to the tool length offsetting task and in implementing ways to facilitate training in such tasks in a virtual environment. This article also demonstrates that even for tasks that include subtle perceptual skills VRTS may be beneficial regardless of the level of physical fidelity, provided that the cognitive organization of a task is adequately mapped in the system. © 2014 Wiley Periodicals, Inc.","CNC machining; Perceptual skills; Simulation; Training; Virtual reality","Job analysis; Machining; Machining centers; Personnel training; Virtual reality; Cnc machining; Cognitive organization; Cognitive task analysis; Mechanical engineering students; Perceptual skills; Simulation; Task accomplishment; Virtual reality training; E-learning",Article,"Final","",Scopus,2-s2.0-84955099078
"Fordell H., Bodin K., Eklund A., Malm J.","36863417800;36141751000;56417299600;56251047600;","RehAtt – Scanning training for neglect enhanced by multi-sensory stimulation in virtual reality",2016,"Topics in Stroke Rehabilitation","23","3",,"191","199",,13,"10.1080/10749357.2016.1138670","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976589910&doi=10.1080%2f10749357.2016.1138670&partnerID=40&md5=6727d51c16e6aca715bdaf7273ebe3c4","Department of Pharmacology and Clinical Neuroscience, Umeå University, Sweden; Department of Computing Science (HPC2N and UMIT), Umeå University, Sweden; Department of Radiation Sciences, Umeå University, Sweden","Fordell, H., Department of Pharmacology and Clinical Neuroscience, Umeå University, Sweden; Bodin, K., Department of Computing Science (HPC2N and UMIT), Umeå University, Sweden; Eklund, A., Department of Radiation Sciences, Umeå University, Sweden; Malm, J., Department of Pharmacology and Clinical Neuroscience, Umeå University, Sweden","Background: There is a lack of effective treatment for neglect. We have developed a new training method, RehAtt™. The objective of this study was to determine whether RehAtt™ improves spatial attention in chronic neglect after stroke. Methods: RehAtt™ consists of a computer with monitor, 3D glasses, and a force feedback interface (Robotic pen) giving sensory motor activation to the contra-lesional arm. The software combines visual scanning training with multi-sensory stimulation in 3D virtual reality (VR) game environment. Fifteen stroke patients with chronic neglect (duration > 6 month) had repeated baseline evaluations to confirm stability of symptoms. There were no test–retest effects for any of the tests. Thereafter, all patients trained 15 h in RehAtt™ (3 x 1 h for 5 weeks). A neglect test battery and Catherine Bergego Scale, CBS, were used to assess behavioral outcome after intervention. CBS was also used at a 6-month follow-up. Results: Using repeated measurement analysis improvements due to the training were found for Star cancellation test (p = 0.006), Baking tray task (p < 0.001), and Extinction test (p = 0.05). In the Posner task improvements were seen fewer missed targets (p = 0.024). CBS showed improvements in activities of daily life immediately after training (p < 0.01). After 6 months the patients still reported improvement in CBS. Conclusion: RehAtt™ is a new concept for rehabilitation of neglect. Training with the VR-method improved spatial attention and showed transfer to improved spatial attention in activities of daily living in chronic neglect. Our results are promising and merit further studies. © 2015 Informa UK Limited, trading as Taylor & Francis Group.","Attention; Cognitive rehabilitation; Spatial neglect; Stroke; Treatment; Virtual reality","aged; Article; attention; attention test; Baking tray task; cancellation test; cerebrovascular accident; clinical article; computer; computer program; disease duration; Extinction test; feedback system; female; human; male; monitor; Posner task; sensory stimulation; spectacles; Star cancellation test; stroke patient; task performance; virtual reality; visual deprivation; cerebrovascular accident; complication; daily life activity; depth perception; devices; outcome assessment; perception disorder; physiology; procedures; stroke rehabilitation; transfer of learning; Activities of Daily Living; Aged; Attention; Female; Humans; Male; Outcome Assessment (Health Care); Perceptual Disorders; Space Perception; Stroke; Stroke Rehabilitation; Transfer (Psychology); Virtual Reality",Article,"Final","",Scopus,2-s2.0-84976589910
"Lok B.","57203616548;","Training with virtual operating room teammates to influence team behaviors",2016,"Proceedings - 2016 International Conference on Collaboration Technologies and Systems, CTS 2016",,, 7871053,"615","616",,,"10.1109/CTS.2016.115","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016990802&doi=10.1109%2fCTS.2016.115&partnerID=40&md5=43b8f2a891be99dc9798e92fe575cfde","University of Florida, Gainesville, FL, United States","Lok, B., University of Florida, Gainesville, FL, United States","Imagine you are an operating room nurse. Could training with virtual human teammates empower you to speak up to a bullying teammate? Could virtual teammates change the way you speak as to reduce errors? How about learn new patient safety policies or efficiently transfer care? In this talk, we will explore the emerging area of using virtual humans to subtly influence healthcare teams' teamwork and communication skills. This application of virtual humans could have significant patient safety impact as teamwork and communication is the top reason for adverse events in critical care areas, such as the emergency room, intensive care unit, and operating room. We will examine the latest research into simulating healthcare teams with mixed reality humans. Mixed reality humans are virtual humans that can share the same physical space as the user. These virtual humans combine interactive graphics, natural language processing, artificial intelligence, human-computer interaction, and data mining to create in situ learning experiences. In these learning experiences, critical care personnel can work to improve teamwork with life-sized interactive virtual team-mates [1]. These learning experiences can also help implement best-practices to address address difficult teamwork concepts such as authority gradients, conflict negotiation, empathy and critical thinking [2][3]. Our research team (Samsun Lampotang, Anesthesia Department, University of Florida, Adam Wendling, Anesthesia Department, University of Florida, and Casey White, College of Medicine, University of Virginia) has developed VR hardware and software platforms to create compelling experiences for users to work on teams with mixed reality humans (MRHs). MRHs are virtual humans that can inhabit the user's physical space [4]. The MRH virtual team members can respond to the user's speech and actions and respond with natural speech and gestures. The virtual team members cannot physically interact with the environment. However, they can present realistic personalities and role-play the roles of operating room teammates, such as surgeons, anesthesiologists, nurses, and surgical technicians. The virtual team members combine the benefits of dynamic visuals of virtual humans with the physicality of mannequins (Figure 1). (Figure Presented) The virtual teammates are composed of comprise a minitower desktop for computation, networking, and rendering, a 40′ TV for display, and a Microsoft Kinect® (version 2) for tracking. All of these components are mounted onto a TV stand. Additionally, a Sennheiser DW-Pro 1 wireless headset is used for speech capture. ANDI's torso, arms, and head are rendered using a virtual human model from Autodesk's Character Generator. The virtual teammate's legs were physical and were composed of shoes and pants filled with stuffing. The physical props were used to integrate the virtual teammate into the user's space. A series of studies evaluated the social presence impact of ANDI design decisions and the current system configuration was shown to provide a virtual teammate with which participants reported a high sense of presence [5]. The virtual teammates' audio responses are pre-recorded by voice talent, and gestures are generated using motion capture and professionally key-framed animations. The virtual teammates can gaze at whoever is speaking, and intermittently glance at the other team members. They also blink and mimic idle motions when not speaking. We will examine results from studies evaluating the perception of virtual teammates, lessons learned in integrating such systems into hospital training, and areas for future research. © 2016 IEEE.","Healthcare; Team training; Virtual humans","Anesthesiology; Computer graphics; Data mining; E-learning; Health care; Human computer interaction; In situ processing; Intensive care units; Natural language processing systems; Nursing; Operating rooms; Personnel training; Rendering (computer graphics); Communication skills; Hardware and software; NAtural language processing; System configurations; Team training; University of Florida; University of Virginia; Virtual humans; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-85016990802
"Gustafson-Pearce O., Grant S.","26656627700;26030369100;","Supply chain knowledge networking using a 3D virtual world environment",2016,"Proceedings of the European Conference on IS Management and Evaluation, ECIME",,,,"68","75",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016188993&partnerID=40&md5=93b4e1addc66cadc4897068b5ff85b3a","Brunel University, London, United Kingdom","Gustafson-Pearce, O., Brunel University, London, United Kingdom; Grant, S., Brunel University, London, United Kingdom","The specific aims of the paper are to highlight the use of 3D Virtual World (VW) tools for knowledge sharing (explicit and tacit knowledge) within a complex supply chain managed by a principal insurer. A set of web based tools, applications and exercises supporting the formation of communities of inquiry and promoting learning through social interaction is presented. These results are from a pilot study that was run over a 4 month period across an insurance supply chain, to explore how suppliers and the principal insurer shared knowledge using these tools. With the IoT (Internet of Things) generating multiple sources of 'streamed' data, the potential for using this type of data in a format that allows users to access data that is 'understandable' to them, is expanding. The paper focusses on one of these tools, a 3D web based Virtual World environment. Within the insurance industry, and specifically home insurers, a key priority is to have current and meaningful data on physical events and conditions available to their stakeholders and members of the supply chain. This is to enable them to make correct and timely decisions on claims, for example, weather related claims. Therefore an environment was designed and created, which used live streaming data from the United States Geological Survey, and a variety of VW tools and techniques to illustrate this data, and to orient it to make it relevant to the home claims teams. The use of social media tools such as Virtual Reality (VR) presents a new set of challenges to organizations that are not used to managing knowledge and information transfer in this way, and where lessons learnt from research endeavours into the use of VR/VW technology in knowledge management, are limited.","IoT; Knowledge sharing; Streamed data; Virtual reality; Virtual World environment","Economic and social effects; Information systems; Internet of things; Knowledge management; Supply chains; Video streaming; Virtual reality; Web crawler; Websites; 3D virtual world environments; Explicit and tacit knowledge; Information transfers; Knowledge-sharing; Streamed data; Supply chain knowledge; United states geological surveys; Virtual worlds; Information management",Conference Paper,"Final","",Scopus,2-s2.0-85016188993
"Allain K., Dado B., Gelderen M.V., Hokke O., Oliveira M., Bidarra R., Gaubitch N.D., Hendriks R.C., Kybartas B.","57188864917;57188867795;57188866678;57188868769;56260321500;6602846970;14825163800;7005452305;56120159200;","An audio game for training navigation skills of blind children",2015,"2015 IEEE 2nd VR Workshop on Sonic Interactions for Virtual Environments, SIVE 2015 - Proceedings",,, 7361292,"49","52",,13,"10.1109/SIVE.2015.7361292","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963935798&doi=10.1109%2fSIVE.2015.7361292&partnerID=40&md5=41ebe438968f6467bd23d886adbdf9b1","Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands","Allain, K., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Dado, B., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Gelderen, M.V., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Hokke, O., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Oliveira, M., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Bidarra, R., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Gaubitch, N.D., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Hendriks, R.C., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands; Kybartas, B., Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Netherlands","Training blind children to use audio-based navigation is a demanding and risky task, as children can walk into objects and hurt themselves. Furthermore, training outdoors is dangerous due to traffic, noise and weather conditions. Having a controlled indoor environment is safer but not always available. To tackle this problem, we developed an audio-based computer game, Legend of Iris (LOI), specifically designed to train navigation skills. The game is a 3D exploration game, which uses the headtracking capabilities of the Oculus Rift to create an immersive experience, and the new sound libraries AstoundSound and Phonon3D, to generate an accurate and realistic soundscape. These libraries use a head-related transfer function, allowing the player to localize the audio source in 3D space. The design of LOI involved selecting sounds that are easily recognizable to provide cues to blind people playing the game. A subset of these cues were incorporated into the game. To verify the effectiveness of the game in developing audio orientation and navigation skills, we performed a preliminary qualitative experiment with blind children in a dedicated school. LOI scored high in terms of accuracy and immersion, but a larger test is required to make statistical conclusions. © 2015 IEEE.",,"Libraries; Motion compensation; Navigation; Virtual reality; 3d explorations; Audio sources; Audio-based navigation; Blind children; Head related transfer function; Indoor environment; Orientation and navigation; Qualitative experiments; Computer games",Conference Paper,"Final","",Scopus,2-s2.0-84963935798
"Park H.-S., Chae S.H., Yoon J.W., Kim J., Sudduth A., Stanley C.","55703108500;57188743526;57218802958;57196195220;56027634800;36606920700;","Implementing overground turning on a linear treadmill",2015,"2015 12th International Conference on Ubiquitous Robots and Ambient Intelligence, URAI 2015",,, 7358882,"390","391",,,"10.1109/URAI.2015.7358882","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962651763&doi=10.1109%2fURAI.2015.7358882&partnerID=40&md5=705a429498b59a494eebb6634f34a599","Department of Mechanical Engineering, KAIST, Daejeon, South Korea; Department of Mechanical Engineering, Gyeongsang National University, Jinju, South Korea; Department of Robotics Engineering, DGIST, Daegu, South Korea; Rehabilitation Medicine Department, National Institutes of Health, Bethesda, United States","Park, H.-S., Department of Mechanical Engineering, KAIST, Daejeon, South Korea; Chae, S.H., Department of Mechanical Engineering, KAIST, Daejeon, South Korea; Yoon, J.W., Department of Mechanical Engineering, Gyeongsang National University, Jinju, South Korea; Kim, J., Department of Robotics Engineering, DGIST, Daegu, South Korea; Sudduth, A., Rehabilitation Medicine Department, National Institutes of Health, Bethesda, United States; Stanley, C., Rehabilitation Medicine Department, National Institutes of Health, Bethesda, United States","The purpose of treadmill-based locomotor training is to transfer walking skills obtained from training to real world walking (overground: OG). For optimal skill transfer, treadmill-based training should simulate OG as closely as possible. The constant speed of a standard treadmill encourages automaticity rather than engagement and fails to simulate the variable speeds encountered during OG walking. Our effort to overcome this limitation has focused on developing user-driven treadmill (UDT) velocity control schemes that allow the user to freely change walking speed and feel the same inertial force that they feel during OG walking. In this study, we have combined the user driven treadmill control with the virtual reality (VR) display to simulate realistic turning in a safe environment. © 2015 IEEE.","Gait Rehabilitation; Turning; User-driven Treadmill; Virtual Reality","Artificial intelligence; Intelligent robots; Turning; Virtual reality; Constant speed; Gait rehabilitation; Inertial forces; Locomotor training; Skill transfer; Treadmill controls; User driven; Variable speed; Sporting goods",Conference Paper,"Final","",Scopus,2-s2.0-84962651763
"Buchs G., Maidenbaum S., Amedi A., Levy-Tzedek S.","56416351000;54585718400;6506450805;42061792400;","Virtually zooming-in with sensory substitution for blind users",2015,"International Conference on Virtual Rehabilitation, ICVR",,, 7358613,"133","134",,1,"10.1109/ICVR.2015.7358613","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014673480&doi=10.1109%2fICVR.2015.7358613&partnerID=40&md5=08879b40fe6a45b5717d939ebdd215fd","Faculties of Medicine (IMRIC), Brain (ELSC) and Cognition Hebrew, University of Jerusalem, Jerusalem, Israel; Department of Physical Therapy, Ben Gurion University of the Negev, Beer-Sheva, Israel","Buchs, G., Faculties of Medicine (IMRIC), Brain (ELSC) and Cognition Hebrew, University of Jerusalem, Jerusalem, Israel; Maidenbaum, S., Faculties of Medicine (IMRIC), Brain (ELSC) and Cognition Hebrew, University of Jerusalem, Jerusalem, Israel; Amedi, A., Faculties of Medicine (IMRIC), Brain (ELSC) and Cognition Hebrew, University of Jerusalem, Jerusalem, Israel; Levy-Tzedek, S., Department of Physical Therapy, Ben Gurion University of the Negev, Beer-Sheva, Israel","When perceiving a scene visually we constantly move our eyes and focus on particular details, which we integrate into a coherent percept. Can blind individuals integrate visual information this way? Can they even conceptualize zooming-in on sub-parts of visual images? We explore this question virtually using the EyeMusic Sensory Substitution Device (SSD). SSDs transfer information usually received by one sense via another, here 'seeing' with sound. This question is especially important for SSD users since SSDs typically down-sample the visual stimuli into low-resolution images in which zooming-in to sub-parts could significantly improve users' perception. Five blind participants used the EyeMusic with a zoom-mechanism in a virtual environment to identify cartoon figures. Using a touchscreen they could zoom into different parts of the image, identify individual facial features and integrate them into a full facial representation. These findings show that indeed such integration of visual information is possible even for users who are blind from birth and demonstrates the approach's potential for practical visual rehabilitation. © 2015 IEEE.","action-perception; active sensing; motor control; sensory substitution; vision rehabilitation","Eye movements; Virtual reality; Active Sensing; Low resolution images; Motor control; Sensory substitution; Transfer information; Vision rehabilitation; Visual information; Visual rehabilitation; Sensory perception",Conference Paper,"Final","",Scopus,2-s2.0-85014673480
"Saiano M., Garbarino E., Lumachi S., Solari S., Sanguineti V.","56236785100;56237552600;57039116000;57038555300;7003348473;","Effect of interface type in the VR-based acquisition of pedestrian skills in persons with ASD",2015,"Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS","2015-November",, 7319693,"5728","5731",,4,"10.1109/EMBC.2015.7319693","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953330181&doi=10.1109%2fEMBC.2015.7319693&partnerID=40&md5=34a0a68588b5edf3b8b7f9892e9dc3db","Dept of Informatics, Bioengineering, Robotics and Systems Engineering, University of Genoa, Via all'Opera Pia 13, Genoa, 16145, Italy; Dept. of Primary Care, ASL3 Genovese, Genoa, Italy; Philos Counseling Academy, Genoa, Italy; Dept. of Education Sciences, University of Genoa, Corso A. Podestá 2, Genoa, Italy","Saiano, M., Dept of Informatics, Bioengineering, Robotics and Systems Engineering, University of Genoa, Via all'Opera Pia 13, Genoa, 16145, Italy, Dept. of Primary Care, ASL3 Genovese, Genoa, Italy; Garbarino, E., Dept. of Primary Care, ASL3 Genovese, Genoa, Italy; Lumachi, S., Philos Counseling Academy, Genoa, Italy; Solari, S., Dept. of Education Sciences, University of Genoa, Corso A. Podestá 2, Genoa, Italy; Sanguineti, V., Dept of Informatics, Bioengineering, Robotics and Systems Engineering, University of Genoa, Via all'Opera Pia 13, Genoa, 16145, Italy","Possession of 'social' skills is crucial for persons with autism spectrum disorders (ASD) to maintain a certain independence and a better quality of life, and interaction with virtual environments seems an effective learning aid. In a previous study, we reported that in adults with ASD interaction with a virtual environment (a virtual city) is beneficial to the acquisition of pedestrian skills (street crossing and street navigation). Interaction was based on a gesture-based interface (Microsoft Kinect). Here we compare the learning performance when the same virtual environment is operated by a gamepad interface. We used exactly the same training protocol and data analysis than the original study. We found that both interface types are effective in the acquisition of street crossing and city navigation skills. The gamepad interface seems easier to use (thus leading to faster interaction), but gesture-based interfaces are superior in terms of transfer of the learned skills to real road environments (as reported by parents and caregivers). © 2015 IEEE.",,"autism; computer interface; human; pedestrian; quality of life; traffic accident; Accidents, Traffic; Autism Spectrum Disorder; Humans; Pedestrians; Quality of Life; User-Computer Interface",Conference Paper,"Final","",Scopus,2-s2.0-84953330181
"De Gouvêa J.X.M., Perez D.B., Miranda C.S., De Paula Oliveira T., Piemonte M.E.P.","57144436900;57143700400;55904702000;55966255900;24081312100;","Upper limb training using virtual reality in patients with chronic sequels of stroke",2015,"ACM International Conference Proceeding Series","01-02-October-2015",,,"85","88",,,"10.1145/2838944.2838965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959293287&doi=10.1145%2f2838944.2838965&partnerID=40&md5=990bd3e74e9ca062bfe1603e598ec405","Department of Physical Therapy, Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Brazil; Institute of Psychology, University of São Paulo, Brazil","De Gouvêa, J.X.M., Institute of Psychology, University of São Paulo, Brazil; Perez, D.B., Institute of Psychology, University of São Paulo, Brazil; Miranda, C.S., Department of Physical Therapy, Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Brazil; De Paula Oliveira, T., Department of Physical Therapy, Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Brazil; Piemonte, M.E.P., Department of Physical Therapy, Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Brazil, Institute of Psychology, University of São Paulo, Brazil","Objectives: A large number of studies have showed a positive effect of training associated to virtual reality (VR) to improve the function of paretic upper limb (PUL) in patients with Stroke. However, there is a lack in the evidences about the transfer's potential of the gains obtained in the VR to real environment. Thus, the purpose of this study was to investigate the transfer of gains obtained through training in VR to motor function of the PUL tested in real environment (RE) in individuals with chronic sequels of stroke (CSS). Participants: Twenty-two patients with chronic sequels of stroke with a mean age of 66.4 ±7.14 years, 15 men and 7 women, mean time post stroke, 4.1± 5.14 years; 13 with left hemiparesis. Interventions: Three sessions of training in VR using four games of the Nintendo Wii (NW) that elicited large and fast upper limb movements. Main outcome measures: Goniometric measures were used as the main outcome to evaluate the transfer of gain to range of motion. As well as a computerizing test was used to evaluate the transfer of gains to movement velocity. Additionally, the scores obtained from the patients in the four games were also used as measure of learning. All measures were evaluated in two assessment time points: baseline (BA) and at end of study (EA). Results: The ANOVA for repeated measure showed that there were statistically significant improvements for all trained games and transfer tests (range of motion and movement velocity). Conclusions: Patients with CSS were able to transfer the gains obtained in the VR to motor function, specifically in range of motion and movement velocity in the PUL. © 2015 ACM.","Rehabilitation; Stroke; Upper limb; Virtual reality exposure therapy","E-learning; Function evaluation; Interactive computer graphics; Virtual reality; Motor function; Outcome measures; Range of motions; Real environments; Repeated measures; Stroke; Upper limbs; Virtual reality exposure therapies; Patient rehabilitation",Conference Paper,"Final","",Scopus,2-s2.0-84959293287
"Miranda C.S., De Paula Oliveira T., De Gouvêa J.X.M., Perez D.B., Marques A.P., Piemonte M.E.P.","55904702000;55966255900;57144436900;57143700400;9043065700;24081312100;","Lack to Transfer the Performance's Improvements Obtained in Virtual Reality Environment to Balance Control in Patients with Chronic Sequels of Stroke",2015,"ACM International Conference Proceeding Series","01-02-October-2015",,,"100","104",,1,"10.1145/2838944.2838969","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959262666&doi=10.1145%2f2838944.2838969&partnerID=40&md5=c9314008eda325534cdb8f240c4262e5","Department of Physical Therapy, Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Brazil; Institute of Psychology, University of São Paulo, Brazil","Miranda, C.S., Department of Physical Therapy, Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Brazil; De Paula Oliveira, T., Department of Physical Therapy, Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Brazil; De Gouvêa, J.X.M., Institute of Psychology, University of São Paulo, Brazil; Perez, D.B., Institute of Psychology, University of São Paulo, Brazil; Marques, A.P., Department of Physical Therapy, Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Brazil; Piemonte, M.E.P., Department of Physical Therapy, Speech Therapy and Occupational Therapy, Faculty of Medicine, University of São Paulo, Brazil, Institute of Psychology, University of São Paulo, Brazil","Objectives: Despite the recent enlargement in the usage of Virtual Reality environments for rehabilitation in Stroke, the potential for transference/generalization of gains to similar task performed in real environments remains uncertain. Thus, the purpose of this study was to verify the transference/generalization of gains obtained by training in Virtual Reality environments (VR) to similar balance tasks in real environment in patients with chronic sequels of Stroke. Participants: Twenty-nine chronic stroke patients. Interventions: Three sessions of balance training in VR using five games from Nintendo Wii FitTM for experimental group (EG). Verbal orientation about falls preventions for control group (CG). Main outcome measures: The transference/generalization of gains obtained in VR training was assessed through performance in four balance tests with similar demand than games using a force plate in two assessment time points: at baseline (BA) and at end of study (EA). Results: The ANOVA for repeated measure showed that there were statistically significant improvements for all trained games after the training. However, there were no statistical significant differences in the balance tests performance between BA and EA, for both groups. Conclusions: Patients with chronic sequels with stroke were unable to transfer/generalize the gains obtained in VR to similar balance tasks performed in real environment. © 2015 ACM.","Learning; Postural balance; Virtual reality exposure therapy","Electronic medical equipment; Interactive computer graphics; Virtual reality; Balance training; Experimental groups; Learning; Postural balance; Real environments; Repeated measures; Virtual reality exposure therapies; Virtual-reality environment; Patient rehabilitation",Conference Paper,"Final","",Scopus,2-s2.0-84959262666
"Vaughan N., Dubey V.N., Wainwright T.W., Middleton R.G.","55345677800;56243741100;24342473500;21644110000;","Does virtual-reality training on orthopaedic simulators improve performance in the operating room?",2015,"Proceedings of the 2015 Science and Information Conference, SAI 2015",,, 7237125,"51","54",,6,"10.1109/SAI.2015.7237125","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957809956&doi=10.1109%2fSAI.2015.7237125&partnerID=40&md5=a1beac849bf9a08361e051493d14b23f","Faculty of Science and Technology, Bournemouth University (BU), Bournemouth, United Kingdom; Department of Orthopaedics, Royal Bournemouth Hospital NHS Foundation Trust, Bournemouth, United Kingdom","Vaughan, N., Faculty of Science and Technology, Bournemouth University (BU), Bournemouth, United Kingdom; Dubey, V.N., Faculty of Science and Technology, Bournemouth University (BU), Bournemouth, United Kingdom; Wainwright, T.W., Department of Orthopaedics, Royal Bournemouth Hospital NHS Foundation Trust, Bournemouth, United Kingdom; Middleton, R.G., Department of Orthopaedics, Royal Bournemouth Hospital NHS Foundation Trust, Bournemouth, United Kingdom","This paper summarises recent validation studies and evidence demonstrating whether training on virtual reality (VR) simulators directly relates to improved performance in-vivo for orthopaedic surgical procedures. This research provides a summary of transfer validity on virtual reality orthopaedic simulators. This covers studies which have shown validation of simulators and have shown the transfer of simulator-acquired skill to the operating room. The findings of this study are that there are 6 studies showing transfer of skill for VR to in-vivo However more studies assessing efficacy and transfer validity are required to conclusively quantify the transfer validity of VR orthopaedic simulators. However there is a popular positive opinion for the ability of VR training to convert into better in-vivo performance. © 2015 IEEE.","Efficacy; Orthopeadic; Performance; Simulator; Surgery; Testing; Transfer validity","E-learning; Operating rooms; Simulators; Surgery; Testing; Virtual reality; Efficacy; Improve performance; Orthopaedic surgical procedures; Orthopeadic; Performance; Transfer validity; Validation study; Virtual reality training; Surgical equipment",Conference Paper,"Final","",Scopus,2-s2.0-84957809956
"Qidwai U., Ajimsha M.S.","6602234511;36935923900;","Can immersive type of Virtual Reality bring EMG pattern changes post facial palsy?",2015,"Proceedings of the 2015 Science and Information Conference, SAI 2015",,, 7237227,"756","760",,,"10.1109/SAI.2015.7237227","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957837199&doi=10.1109%2fSAI.2015.7237227&partnerID=40&md5=35218ea6df1ae0cac754bc35808d59db","KINDI Lab for Computing Research, Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Physiotherapy Specialist, Dept. of Physical Therapy, Hamad Medical Corporation, Doha, Qatar","Qidwai, U., KINDI Lab for Computing Research, Department of Computer Science and Engineering, Qatar University, Doha, Qatar; Ajimsha, M.S., Physiotherapy Specialist, Dept. of Physical Therapy, Hamad Medical Corporation, Doha, Qatar","The loss of facial expression via facial paralysis is a devastating condition, both functionally and aesthetically. However, given the life-long plasticity of the brain one could assume that recovery could be facilitated by the harnessing of mechanisms underlying neuronal reorganization. Currently it is not clear how this reorganization can be mobilized. Novel technology based neurorehabilitation techniques hold promise to address this issue. In this paper an immersive Virtual Reality (VR) based system is presented that is based on a number of hypotheses related to the neural structures targeted for recovery/reorganization, the structure of training system, and the role of individualization. The purpose of this paper is to examine the effects of an immersive type virtual reality (VR) intervention on activation of facial upper quadrant muscles following facial palsy in comparison with a control program. The key components of an immersive Virtual Reality (VR) based system and its effectiveness on facial palsy rehabilitation has been described in the form of experimental findings. Experimental trial was performed on an individual with facial upper quadrant muscles weakness due to facial palsy in a crossover study methodology with and without VR. EMG patterns from the facial upper quadrant muscles were recorded and analyzed for results. This trial has plotted a positive relationship between VR and facial upper quadrant muscles activation following a neurological impetus. The results reported here also show a consistent transfer of movement kinematics between physical and virtual tasks. EMG analysis has shown progressing improvement in the muscle activation in response to the challenging and impulsive activities in the virtual environment provided by the immersive VR devise. © 2015 IEEE.","EMG-based measurements; Facial palsy; Impulsive impetus; Virtual Reality","Activation analysis; Chemical activation; Muscle; Experimental trials; Facial Expressions; Facial palsy; Immersive virtual reality; Impulsive impetus; Movement kinematics; Neural structures; Neurorehabilitation; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84957837199
"Katz B.F.G., Felinto D.Q., Touraine D., Poirier-Quinot D., Bourdot P.","35557015800;54788920100;6506895230;55613431100;14051447300;","BlenderVR: Open-source framework for interactive and immersive VR",2015,"2015 IEEE Virtual Reality Conference, VR 2015 - Proceedings",,, 7223366,"203","204",,12,"10.1109/VR.2015.7223366","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954548555&doi=10.1109%2fVR.2015.7223366&partnerID=40&md5=9cd4b67baa192a1ea65bdcc275d8639b","LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France","Katz, B.F.G., LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; Felinto, D.Q., LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; Touraine, D., LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; Poirier-Quinot, D., LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France; Bourdot, P., LIMSI-CNRS, Campus Universitaire d'Orsay, Orsay, France","BlenderVR is an open-source project framework for interactive and immersive applications based on an extension of the Blender Game Engine to Virtual Reality applications. BlenderVR is a generalization of the BlenderCAVE project, accounting for alternate platforms (e.g., HMD, video-walls). The goal is to provide a flexible and easy to use framework for the creation of VR applications for various platforms, making use of the existing power of the BGE's graphics rendering and physics engine. Compatible with 3 major Operating Systems, BlenderVR has been developed by VR researchers with support from the Blender Community. BlenderVR currently handles multi-screen/multi-user tracked stereoscopic rendering through efficient low-level master/slave synchronization process with multimodal interactions via OSC and VRPN protocols. © 2015 IEEE.","H.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realities; I.3.2 [Graphics Systems]: Distributed/network graphics","Blending; Computer graphics; Stereo image processing; Three dimensional computer graphics; Virtual reality; Distributed/network graphics; H.5.1 [multimedia information systems]: artificial , augmented , and virtual realities; Immersive application; Multi-Modal Interactions; Open source frameworks; Open source projects; Stereoscopic renderings; Synchronization process; Rendering (computer graphics)",Conference Paper,"Final","",Scopus,2-s2.0-84954548555
"Moore A.G., Herrera N.S., Hurst T.C., McMahan R.P., Poeschl S.","56779368700;56779769000;57062163600;18037514200;55211397600;","The effects of olfaction on training transfer for an assembly task",2015,"2015 IEEE Virtual Reality Conference, VR 2015 - Proceedings",,, 7223383,"237","238",,2,"10.1109/VR.2015.7223383","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954534828&doi=10.1109%2fVR.2015.7223383&partnerID=40&md5=71bbca6644f2ae3585ba301e072012ab","FIVE Lab, University of Texas at Dallas, United States; Ilmenau University of Technology, Germany","Moore, A.G., FIVE Lab, University of Texas at Dallas, United States; Herrera, N.S., FIVE Lab, University of Texas at Dallas, United States; Hurst, T.C., FIVE Lab, University of Texas at Dallas, United States; McMahan, R.P., FIVE Lab, University of Texas at Dallas, United States; Poeschl, S., Ilmenau University of Technology, Germany","Context-dependent memory studies have indicated that olfaction, the sense of smell, has a special odor memory that can significantly improve recall in some cases. Virtual reality (VR), which has been investigated as a training tool, could feasibly benefit from odor memory by incorporating olfactory stimuli. There have been a few studies on this concept for semantic learning, but not for procedural training. To address this gap in knowledge, we investigated the effects of olfaction on the transfer of knowledge from training to next-day execution for building a complex LEGO jet-plane model. Our results indicate that the pleasantness of an odor significantly affects training transfer more than whether the encoding and recall contexts match. © 2015 IEEE.","Olfactory fidelity; training transfer","Knowledge management; Virtual reality; Assembly tasks; Context-dependent memory; Olfactory fidelity; Plane model; Semantic learning; Training tools; Transfer of knowledge; Training aircraft",Conference Paper,"Final","",Scopus,2-s2.0-84954534828
"Rousset T., Bourdin C., Goulon C., Monnoyer J., Vercher J.-L.","57063135900;6603566648;26535970800;57063170900;7004221343;","Does virtual reality affect visual perception of egocentric distance?",2015,"2015 IEEE Virtual Reality Conference, VR 2015 - Proceedings",,, 7223403,"277","278",,3,"10.1109/VR.2015.7223403","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954502515&doi=10.1109%2fVR.2015.7223403&partnerID=40&md5=7108f93a962da5ba619a2614530680f4","Aix Marseille Université, CNRS, ISM UMR 7287, Marseille, 13288, France; PSA Peugeot Citroën, Velizy Villacoublay, France","Rousset, T., Aix Marseille Université, CNRS, ISM UMR 7287, Marseille, 13288, France; Bourdin, C., Aix Marseille Université, CNRS, ISM UMR 7287, Marseille, 13288, France; Goulon, C., Aix Marseille Université, CNRS, ISM UMR 7287, Marseille, 13288, France; Monnoyer, J., PSA Peugeot Citroën, Velizy Villacoublay, France; Vercher, J.-L., Aix Marseille Université, CNRS, ISM UMR 7287, Marseille, 13288, France","Virtual reality (driving simulators) tends to generalize for the study of human behavior in mobility. It is thus crucial to ensure that perception of space and motion is little or not affected by the virtual environment (VE). The aim of this study was to determine a metrics of distance perception in VEs and whether this metrics depends on interactive factors: stereoscopy and motion parallax. After a training session, participants were asked, while driving, to estimate the relative location (5 to 80 m) of a car on the same road. The overall results suggest that distance perception in this range does not depend on interactive factors. In average, as generally reported, subjects underestimated the distances whatever the vision conditions. However, the study revealed a large interpersonal variability: two profiles of participants were defined, those who quite accurately perceived distances in VR and those who underestimated distances as usually reported. Overall, this classification was correlated to the level of performance of participants during the training phase. Furthermore, learning performance is predictive of the behavior of participants. © 2015 IEEE.","distance perception; Driving simulation; parallax; stereoscopy; variability","Behavioral research; Depth perception; Geometrical optics; Stereo image processing; Distance perception; Driving simulation; Driving simulator; Learning performance; parallax; Perceived distances; Relative location; variability; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84954502515
"Bertrand J., Brickler D., Babu S., Madathil K., Zelaya M., Wang T., Wagner J., Gramopadhye A., Luo J.","55858839700;57063224300;9039004700;37075253800;24345548300;55858602500;55693743100;7005569103;57217336220;","The role of dimensional symmetry on bimanual psychomotor skills education in immersive virtual environments",2015,"2015 IEEE Virtual Reality Conference, VR 2015 - Proceedings",,, 7223317,"3","10",,13,"10.1109/VR.2015.7223317","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954500994&doi=10.1109%2fVR.2015.7223317&partnerID=40&md5=d705a74c3695a12bc56f14ec051c3cba","Clemson University, United States","Bertrand, J., Clemson University, United States; Brickler, D., Clemson University, United States; Babu, S., Clemson University, United States; Madathil, K., Clemson University, United States; Zelaya, M., Clemson University, United States; Wang, T., Clemson University, United States; Wagner, J., Clemson University, United States; Gramopadhye, A., Clemson University, United States; Luo, J., Clemson University, United States","The need for virtual reality applications for education and training involving bimanual dexterous activities has been increasing in recent years. However, it is unclear how the amount of correspondence between a virtual interaction metaphor to the real-world equivalent, otherwise known as dimensional symmetry, affects bimanual pscyhomotor skills training and how skills learned in the virtual simulation transfer to the real world. How does the number of degrees of freedom enhance or hinder the learning process? Does the increase in dimensional symmetry affect cognitive load? In an empirical evaluation, we compare the effectiveness of a natural 6-DOF interaction metaphor to a simplified 3-DOF metaphor. Our simulation interactively educates users in the step-by-step process of taking a precise measurement using calipers and micrometers in a simulated technical workbench environment. We conducted a usability study to evaluate the user experience and pedagogical benefits using measures including a pre and post cognition questionnaire over all levels of Bloom's taxonomy, workload assessment, system usability, and real world psychomotor assessment tasks. Results from the pre and post cognition questionnaires suggest that learning outcomes improved throughout all levels of Bloom's taxonomy for both conditions, and trends in the data suggest that the 6-DOF metaphor was more effective in real-world skill transference compared to the 3-DOF metaphor. © 2015 IEEE.","Bimanual interaction; dimensional symmetry; psychomotor skills education","Blooms (metal); Degrees of freedom (mechanics); Education; Human computer interaction; Personnel training; Surveys; Taxonomies; Virtual reality; Bi-manual interaction; Education and training; Empirical evaluations; Immersive virtual environments; Interaction metaphors; Number of degrees of freedom; Precise measurements; Virtual interactions; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-84954500994
"Hochreiter J., Daher S., Nagendran A., Gonzalez L., Welch G.","55821444200;57062307400;26768151000;32667638800;35572266400;","Touch sensing on non-parametric rear-projection surfaces: A physical-virtual head for hands-on healthcare training",2015,"2015 IEEE Virtual Reality Conference, VR 2015 - Proceedings",,, 7223326,"69","74",,4,"10.1109/VR.2015.7223326","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954496838&doi=10.1109%2fVR.2015.7223326&partnerID=40&md5=b931f185c4f065c4af22ada031f13d17","University of Central Florida, United States","Hochreiter, J., University of Central Florida, United States; Daher, S., University of Central Florida, United States; Nagendran, A., University of Central Florida, United States; Gonzalez, L., University of Central Florida, United States; Welch, G., University of Central Florida, United States","We demonstrate a generalizable method for unified multitouch detection and response on a human head-shaped surface with a rear-projection animated 3D face. The method helps achieve hands-on touch-sensitive training with dynamic physical-virtual patient behavior. The method, which is generalizable to other non-parametric rear-projection surfaces, requires one or more infrared (IR) cameras, one or more projectors, IR light sources, and a rear-projection surface. IR light reflected off of human fingers is captured by cameras with matched IR pass filters, allowing for the localization of multiple finger touch events. These events are tightly coupled with the rendering system to produce auditory and visual responses on the animated face displayed using the projector(s), resulting in a responsive, interactive experience. We illustrate the applicability of our physical prototype in a medical training scenario. © 2015 IEEE.","H.5.1 [Information Interfaces and Presentation]: Multimedia Information Systems - Animations, Artificial, Augmented, and Virtual Realities; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism - Virtual Reality; I.3.8 [Computer Graphics]: Applications","Cameras; Computer graphics; Light sources; Matched filters; Virtual reality; I.3.7 [computer graphics]: three-dimensional graphics and realism - virtual realities; I.3.8 [computer graphics]: Applications; Infrared cameras; Medical training; Multimedia Information Systems - Animations; Rendering system; Tightly-coupled; Virtual patients; Three dimensional computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-84954496838
"Andrews S., Vincent J.B., McCormick J.","57185000800;57184835300;57197554028;","Duet: Improvising spatial dialogues with an artificially intelligent agent",2015,"SUI 2015 - Proceedings of the 3rd ACM Symposium on Spatial User Interaction",,,,"57","60",,,"10.1145/2788940.2788952","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961205751&doi=10.1145%2f2788940.2788952&partnerID=40&md5=217ef1efc54e66e4387fe530c4afaac3","Deakin University, 221 Burwood Highway, Burwood, VIC  3125, Australia","Andrews, S., Deakin University, 221 Burwood Highway, Burwood, VIC  3125, Australia; Vincent, J.B., Deakin University, 221 Burwood Highway, Burwood, VIC  3125, Australia; McCormick, J., Deakin University, 221 Burwood Highway, Burwood, VIC  3125, Australia","This paper presents an experimental framework for a virtual reality artwork, Duet, that employs a combination of live, full body motion capture and Oculus Rift HMD to construct an experience through which a human User can spatially interact with an artificially intelligent Agent. The project explores conceptual notions of embodied knowledge transfer, shared poetics of movement and distortions of the body schema. Within this context, both the User and the Agent become performers, constructing an intimate and spontaneously generated proximal space. The project generates a visualization of the relationship between the User and the Agent without the context of a fixed VR landscape or architecture. The Agent's ability to retain and accumulate movement knowledge in a way that mimics human learning transforms an interactive experience into a collaborative one. The virtual representation of both performers is distorted and amplified in a dynamic manner, enhancing the potential for creative dialogue between the Agent and the User. © 2015 ACM.","Aesthetic Interaction; Agents and Intelligent Systems; Embodiment; Performance; Virtual Reality","Intelligent agents; Intelligent systems; Knowledge management; Virtual reality; Aesthetic Interaction; Embodied knowledge; Embodiment; Full-body motions; Human learning; Performance; Proximal spaces; Virtual representations; Intelligent virtual agents",Conference Paper,"Final","",Scopus,2-s2.0-84961205751
"Senanayake R., Goonetilleke R.S., Hoffmann E.R.","57212145761;6701533131;7201369859;","Targeted-Tracking With Pointing Devices",2015,"IEEE Transactions on Human-Machine Systems","45","4", 7072531,"431","441",,6,"10.1109/THMS.2015.2408260","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027934312&doi=10.1109%2fTHMS.2015.2408260&partnerID=40&md5=acdc793faee80000433fa08374db3dde","Department of Industrial Engineering and Logistics Management, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong, Hong Kong","Senanayake, R., Department of Industrial Engineering and Logistics Management, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong, Hong Kong; Goonetilleke, R.S., Department of Industrial Engineering and Logistics Management, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong, Hong Kong; Hoffmann, E.R., Department of Industrial Engineering and Logistics Management, Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong, Hong Kong","Targeting and tracking in graphical user interfaces have been widely studied, but attempts to model targeted-tracking are few. Targeted-tracking is essentially a two component task of tracking followed by targeting, where either or both components may dominate depending on the levels of difficulty in each component. The applicability of an empirical model based on computer mouse use is unknown with respect to other devices. In order to confirm the model validity for other input devices, experiments were carried out using a mouse, a pen mouse, a touch screen, and a graphics tablet. Fourteen participants were tested on 48 experimental conditions that included four difficulty levels and 12 conditions with varying track width (P), track length (D), and target width (W). Movement time, error rate, index of performance, and throughput were compared. Repeated-measures ANOVA indicated that factors in the targeted-tracking model were significant (p &lt; 0.05) and movement time data were a good fit (R2 &gt; 0.8) to the model, confirming the generality of the model. A principal component analysis showed that a mouse is relatively superior in terms of both movement time and error rate. Thus, the targeted-tracking model is an effective way to compare and evaluate input devices. © 2013 IEEE.","Fitts' law; human performance model; human-computer interface; input device evaluation; targeted-tracking","Graphical user interfaces; Human computer interaction; Knobs; Mammals; Touch screens; User interfaces; Experimental conditions; Fitts' law; Human computer interfaces; Human performance model; Input device evaluation; Pointing devices; Repeated measures; Tracking models; Principal component analysis",Article,"Final","",Scopus,2-s2.0-85027934312
"Chebat D.-R., Maidenbaum S., Amedi A.","11140655700;54585718400;6506450805;","Navigation using sensory substitution in real and virtual mazes",2015,"PLoS ONE","10","6", e0126307,"","",,44,"10.1371/journal.pone.0126307","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931275709&doi=10.1371%2fjournal.pone.0126307&partnerID=40&md5=faf18acfbaa35df5bc2e6c8bea3d8507","Department of Medical Neurobiology, Faculty of Medicine, Hebrew University of Jerusalem, Hadassah Ein-Kerem, Jerusalem, Israel; Edmond and Lily Safra Center for Brain Research, Hebrew University of Jerusalem, Hadassah Ein-Kerem, Jerusalem, Israel; Department of Behavioral Sciences, Ariel University, Ariel, Israel","Chebat, D.-R., Department of Medical Neurobiology, Faculty of Medicine, Hebrew University of Jerusalem, Hadassah Ein-Kerem, Jerusalem, Israel, Edmond and Lily Safra Center for Brain Research, Hebrew University of Jerusalem, Hadassah Ein-Kerem, Jerusalem, Israel, Department of Behavioral Sciences, Ariel University, Ariel, Israel; Maidenbaum, S., Department of Medical Neurobiology, Faculty of Medicine, Hebrew University of Jerusalem, Hadassah Ein-Kerem, Jerusalem, Israel, Edmond and Lily Safra Center for Brain Research, Hebrew University of Jerusalem, Hadassah Ein-Kerem, Jerusalem, Israel; Amedi, A., Department of Medical Neurobiology, Faculty of Medicine, Hebrew University of Jerusalem, Hadassah Ein-Kerem, Jerusalem, Israel, Edmond and Lily Safra Center for Brain Research, Hebrew University of Jerusalem, Hadassah Ein-Kerem, Jerusalem, Israel","Under certain specific conditions people who are blind have a perception of space that is equivalent to that of sighted individuals. However, in most cases their spatial perception is impaired. Is this simply due to their current lack of access to visual information or does the lack of visual information throughout development prevent the proper integration of the neural systems underlying spatial cognition? Sensory Substitution devices (SSDs) can transfer visual information via other senses and provide a unique tool to examine this question. We hypothesize that the use of our SSD (The EyeCane: a device that translates distance information into sounds and vibrations) can enable blind people to attain a similar performance level as the sighted in a spatial navigation task. We gave fifty-six participants training with the EyeCane. They navigated in real life-size mazes using the EyeCane SSD and in virtual renditions of the same mazes using a virtual-EyeCane. The participants were divided into four groups according to visual experience: congenitally blind, low vision & late blind, blind-folded sighted and sighted visual controls. We found that with the EyeCane participants made fewer errors in the maze, had fewer collisions, and completed the maze in less time on the last session compared to the first. By the third session, participants improved to the point where individual trials were no longer significantly different from the initial performance of the sighted visual group in terms of errors, time and collision. © 2015 Chebat et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.",,"adult; analytical error; Article; clinical article; congenital blindness; controlled study; female; general device; human; low vision; male; maze test; sensory substitution; sensory substitution device; sound; spatial orientation; task performance; vibration; virtual reality; blindness; clinical trial; computer interface; depth perception; middle aged; orientation; pathophysiology; Adult; Blindness; Female; Humans; Male; Maze Learning; Middle Aged; Orientation; Space Perception; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84931275709
"Pan J.J., Chang J., Yang X., Liang H., Zhang J.J., Qureshi T., Howell R., Hickish T.","55459051800;55514990300;55683846400;55742830800;55912086700;50061751400;57196842311;7003268270;","Virtual reality training and assessment in laparoscopic rectum surgery",2015,"International Journal of Medical Robotics and Computer Assisted Surgery","11","2",,"194","209",,26,"10.1002/rcs.1582","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930178534&doi=10.1002%2frcs.1582&partnerID=40&md5=cacaaa3fcb00d3a3553728465ec51f1a","State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; National Centre for Computer Animation, Media School, Bournemouth University, Poole, United Kingdom; Poole Hospital, Poole, United Kingdom; The Royal Bournemouth and Christchurch Hospitals, Bournemouth, United Kingdom; School of Animation, Communication University of China, Beijing, China","Pan, J.J., State Key Laboratory of Virtual Reality Technology and Systems, Beihang University, Beijing, China; Chang, J., National Centre for Computer Animation, Media School, Bournemouth University, Poole, United Kingdom; Yang, X., National Centre for Computer Animation, Media School, Bournemouth University, Poole, United Kingdom; Liang, H., School of Animation, Communication University of China, Beijing, China; Zhang, J.J., National Centre for Computer Animation, Media School, Bournemouth University, Poole, United Kingdom; Qureshi, T., Poole Hospital, Poole, United Kingdom; Howell, R., The Royal Bournemouth and Christchurch Hospitals, Bournemouth, United Kingdom; Hickish, T., The Royal Bournemouth and Christchurch Hospitals, Bournemouth, United Kingdom","Background: Virtual-reality (VR) based simulation techniques offer an efficient and low cost alternative to conventional surgery training. This article describes a VR training and assessment system in laparoscopic rectum surgery. Methods: To give a realistic visual performance of interaction between membrane tissue and surgery tools, a generalized cylinder based collision detection and a multi-layer mass-spring model are presented. A dynamic assessment model is also designed for hierarchy training evaluation. Results: With this simulator, trainees can operate on the virtual rectum with both visual and haptic sensation feedback simultaneously. The system also offers surgeons instructions in real time when improper manipulation happens. The simulator has been tested and evaluated by ten subjects. Conclusions: This prototype system has been verified by colorectal surgeons through a pilot study. They believe the visual performance and the tactile feedback are realistic. It exhibits the potential to effectively improve the surgical skills of trainee surgeons and significantly shorten their learning curve. © 2014 John Wiley & Sons, Ltd..","Collision detection; Dissection simulation; Dynamic assessment; Evaluation; Laparoscopic rectum surgery","Article; cancer surgery; computer simulation; controlled study; human; laparoscopic surgery; rectum cancer; rectum surgery; simulator; surgical approach; surgical training; surgical ward; virtual reality; abdominal surgery; anatomic model; anatomy and histology; computer interface; computer simulation; education; evaluation study; laparoscopy; learning curve; medical education; pilot study; procedures; rectum; surgery; Computer Simulation; Digestive System Surgical Procedures; Education, Medical, Continuing; Humans; Laparoscopy; Learning Curve; Models, Anatomic; Pilot Projects; Rectum; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84930178534
"Carlson P., Peters A., Gilbert S.B., Vance J.M., Luse A.","55211819500;39062047500;14041448900;57209452002;24776050400;","Virtual training: Learning transfer of assembly tasks",2015,"IEEE Transactions on Visualization and Computer Graphics","21","6", 7014246,"770","782",,43,"10.1109/TVCG.2015.2393871","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928953556&doi=10.1109%2fTVCG.2015.2393871&partnerID=40&md5=52638cc89410113748eb702d400853b6","Department of Human-Computer Interaction (HCI), Iowa State University, Ames, IA  5001, United States; Department of Industrial and Manufacturing Systems Engineering, Iowa State University, Ames, IA  5001, United States; Department of Mechanical Engineering, Iowa State University, Ames, IA  5001, United States; Department of Management Science and Information Systems, Oklahoma State University, Stillwater, OK, United States","Carlson, P., Department of Human-Computer Interaction (HCI), Iowa State University, Ames, IA  5001, United States; Peters, A., Department of Human-Computer Interaction (HCI), Iowa State University, Ames, IA  5001, United States; Gilbert, S.B., Department of Industrial and Manufacturing Systems Engineering, Iowa State University, Ames, IA  5001, United States; Vance, J.M., Department of Mechanical Engineering, Iowa State University, Ames, IA  5001, United States; Luse, A., Department of Management Science and Information Systems, Oklahoma State University, Stillwater, OK, United States","In training assembly workers in a factory, there are often barriers such as cost and lost productivity due to shutdown. The use of virtual reality (VR) training has the potential to reduce these costs. This research compares virtual bimanual haptic training versus traditional physical training and the effectiveness for learning transfer. In a mixed experimental design, participants were assigned to either virtual or physical training and trained by assembling a wooden burr puzzle as many times as possible during a twenty minute time period. After training, participants were tested using the physical puzzle and were retested again after two weeks. All participants were trained using brightly colored puzzle pieces. To examine the effect of color, testing involved the assembly of colored physical parts and natural wood colored physical pieces. Spatial ability as measured using a mental rotation test, was shown to correlate with the number of assemblies they were able to complete in the training. While physical training outperformed virtual training, after two weeks the virtually trained participants actually improved their test assembly times. The results suggest that the color of the puzzle pieces helped the virtually trained participants in remembering the assembly process. © 2015 IEEE.","assembly; Haptics; Learning transfer; training; virtual reality","Assembly; Personnel training; Plant shutdowns; Virtual reality; Assembly process; Assembly workers; Haptics; Learning Transfer; Lost productivities; Physical training; Spatial abilities; Virtual training; E-learning",Article,"Final","",Scopus,2-s2.0-84928953556
"Thomsen A.S.S., Subhi Y., Kiilgaard J.F., La Cour M., Konge L.","56530286900;55805141800;6602384350;7004692457;36704959000;","Update on simulation-based surgical training and assessment in ophthalmology: A systematic review",2015,"Ophthalmology","122","6",,"1111","1130.e1",,45,"10.1016/j.ophtha.2015.02.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930041430&doi=10.1016%2fj.ophtha.2015.02.028&partnerID=40&md5=9f4a4000b6f088a0534cbca1e45a2ec0","Department of Ophthalmology, Glostrup University Hospital, Ndr. Ringvej 57, Glostrup, DK-2600, Denmark; Centre for Clinical Education, Centre for HR, Capital Region of Denmark, Copenhagen, Denmark","Thomsen, A.S.S., Department of Ophthalmology, Glostrup University Hospital, Ndr. Ringvej 57, Glostrup, DK-2600, Denmark, Centre for Clinical Education, Centre for HR, Capital Region of Denmark, Copenhagen, Denmark; Subhi, Y., Centre for Clinical Education, Centre for HR, Capital Region of Denmark, Copenhagen, Denmark; Kiilgaard, J.F., Department of Ophthalmology, Glostrup University Hospital, Ndr. Ringvej 57, Glostrup, DK-2600, Denmark; La Cour, M., Department of Ophthalmology, Glostrup University Hospital, Ndr. Ringvej 57, Glostrup, DK-2600, Denmark; Konge, L., Centre for Clinical Education, Centre for HR, Capital Region of Denmark, Copenhagen, Denmark","Topic This study reviews the evidence behind simulation-based surgical training of ophthalmologists to determine (1) the validity of the reported models and (2) the ability to transfer skills to the operating room. Clinical Relevance Simulation-based training is established widely within ophthalmology, although it often lacks a scientific basis for implementation. Methods We conducted a systematic review of trials involving simulation-based training or assessment of ophthalmic surgical skills among health professionals. The search included 5 databases (PubMed, EMBASE, PsycINFO, Cochrane Library, and Web of Science) and was completed on March 1, 2014. Overall, the included trials were divided into animal, cadaver, inanimate, and virtual-reality models. Risk of bias was assessed using the Cochrane Collaboration's tool. Validity evidence was evaluated using a modern validity framework (Messick's). Results We screened 1368 reports for eligibility and included 118 trials. The most common surgery simulated was cataract surgery. Most validity trials investigated only 1 or 2 of 5 sources of validity (87%). Only 2 trials (48 participants) investigated transfer of skills to the operating room; 4 trials (65 participants) evaluated the effect of simulation-based training on patient-related outcomes. Because of heterogeneity of the studies, it was not possible to conduct a quantitative analysis. Conclusions The methodologic rigor of trials investigating simulation-based surgical training in ophthalmology is inadequate. To ensure effective implementation of training models, evidence-based knowledge of validity and efficacy is needed. We provide a useful tool for implementation and evaluation of research in simulation-based training. © 2015 American Academy of Ophthalmology.",,"cadaver; cataract extraction; clinical assessment; data base; human; nonhuman; operating room; ophthalmologist; ophthalmology; outcome assessment; priority journal; quantitative analysis; randomized controlled trial (topic); Review; risk factor; simulation; skill; surgical training; systematic review; validity; virtual reality; animal model; clinical competence; computer interface; computer simulation; education; eye surgery; factual database; ophthalmology; procedures; standards; teaching; Cadaver; Clinical Competence; Computer Simulation; Computer-Assisted Instruction; Databases, Factual; Humans; Models, Animal; Ophthalmologic Surgical Procedures; Ophthalmology; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84930041430
"Parijat P., Lockhart T.E., Liu J.","24833394100;7004975783;55705866300;","Effects of Perturbation-Based Slip Training Using a Virtual Reality Environment on Slip-induced Falls",2015,"Annals of Biomedical Engineering","43","4",,"958","967",,24,"10.1007/s10439-014-1128-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926187937&doi=10.1007%2fs10439-014-1128-z&partnerID=40&md5=144d81d9dcb0dcd13bfb2462148f812b","School of Biomedical Engineering and Science, Virginia Tech, Blacksburg, VA, United States; School of Biological and Health Systems Engineering, Arizona State University, Tempe, AZ, United States; Division of Applied Science and Technology, Marshall University, One John Marshall Drive, CB 212, Huntington, WV  25755, United States","Parijat, P., School of Biomedical Engineering and Science, Virginia Tech, Blacksburg, VA, United States; Lockhart, T.E., School of Biological and Health Systems Engineering, Arizona State University, Tempe, AZ, United States; Liu, J., Division of Applied Science and Technology, Marshall University, One John Marshall Drive, CB 212, Huntington, WV  25755, United States","The purpose of the current study was to design and evaluate the effectiveness of virtual reality training in improving recovery reactions and reducing fall frequency in older adults. Twenty-four older adults were recruited and randomly assigned to two groups (virtual reality training and control). Both groups underwent three sessions including baseline slip, training and transfer of training on slippery surface. Both groups experienced two slips, one during baseline and the other during the transfer of training trial. The training group underwent 12 simulated slips using a visual perturbation induced by tilting a virtual reality scene while walking on the treadmill and the control group performed normal walking during the training session. Kinematic and kinetic data were collected during all the sessions. Results demonstrated a reduced incidence of falls in the training group during the transfer of training trial as compared to the control group. The training group was able to transfer reactive control strategies learned during training to the second slip trial. The reactive adjustments included reduced slip distance. Additionally, gait parameters reflective of gait instability (stride length, step width, variability in stride velocity) reduced after walking in the VR environment for 15–20 min. The results indicated a beneficial effect of the virtual reality training in reducing slip severity and recovery kinematics in healthy older adults. © 2014, Biomedical Engineering Society.","Biomechanics; Elderly; Fall prevention training; Falls; Virtual reality","Accident prevention; Biomechanics; Gait analysis; Kinematics; Virtual reality; Beneficial effects; Elderly; Fall prevention; Falls; Recovery reactions; Transfer of trainings; Virtual reality training; Virtual-reality environment; E-learning; accident prevention; aged; Article; biomechanics; controlled clinical trial; controlled study; falling; female; gait; ground reaction force; human; kinematics; kinetics; male; movement therapy; normal human; priority journal; treadmill; virtual reality; virtual reality training; biological model; clinical trial; comparative study; computer interface; falling; prevention and control; very elderly; walking; Accidental Falls; Aged; Aged, 80 and over; Biomechanical Phenomena; Female; Humans; Male; Models, Biological; User-Computer Interface; Walking",Article,"Final","",Scopus,2-s2.0-84926187937
"Sun G., Muneesawang P., Kyan M., Li H., Zhong L., Dong N., Elder B., Guan L.","36810742400;6603438525;6506086351;36440061500;56659631800;7005861053;16244749200;55679853000;","An advanced computational intelligence system for training of ballet dance in a cave virtual reality environment",2015,"Proceedings - 2014 IEEE International Symposium on Multimedia, ISM 2014",,, 7033015,"159","166",,7,"10.1109/ISM.2014.55","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930464608&doi=10.1109%2fISM.2014.55&partnerID=40&md5=4a5fc1c22ef0e6601101aa353616f80b","Communication University of China, China; Naresuan University, Thailand; Ryerson University, Canada; Guangdong University of Technology, China","Sun, G., Communication University of China, China; Muneesawang, P., Naresuan University, Thailand; Kyan, M., Ryerson University, Canada; Li, H., Communication University of China, China; Zhong, L., Guangdong University of Technology, China; Dong, N., Ryerson University, Canada; Elder, B., Ryerson University, Canada; Guan, L., Ryerson University, Canada","This paper presents a computer-based system for assessment and training of ballet dance in a CAVE virtual reality environment. The system utilizes Kinect sensor to capture student's dance and extracts features from skeleton joints. This system depends on a structured posture space, which comprises a set of dance elements that represent key moments - 'postures', that typically will be so briefly held as to experience as a fleeting moment in a flux - in the dance movements whose performance we are attempting to assess. The recording captured from the Kinect allows the parsing of dance movement into a structured posture space using the spherical self-organizing map (SSOM). From this, a unique descriptor can be obtained by following gesture trajectories through posture space on the SSOM, which appropriately reflects the subtleties of ballet dance movements. Consequently, the system can recognize the category of movement the student is attempting, and this allows us make a quantitative assessment of individual movements. Based on the experimental results, the proposed system appears to be very effective for recognition and offering generalization across instances of movement. Thus, it is possible for the construction of assessment and visualization of ballet dance movements performed by the student in an instructional, virtual reality setting. © 2014 IEEE.","CAVE virtual reality environment; dance assesment; dance traning system; gesture recognition; spherical-self-organizing map","Caves; Conformal mapping; E-learning; Gesture recognition; Self organizing maps; Students; Assesment; Computer-based system; dance traning system; Gesture trajectories; Kinect sensors; Quantitative assessments; Skeleton joints; Virtual-reality environment; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84930464608
"Parijat P., Lockhart T.E., Liu J.","24833394100;7004975783;55705866300;","EMG and kinematic responses to unexpected slips after slip training in virtual reality",2015,"IEEE Transactions on Biomedical Engineering","62","2", 6915881,"593","599",,12,"10.1109/TBME.2014.2361324","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921488714&doi=10.1109%2fTBME.2014.2361324&partnerID=40&md5=e432932fd1aa41a758618af69b02bd5c","School of Biomedical Engineering and Science, Virginia Tech, Blacksburg, VA  24060, United States; School of Biological and Health Systems Engineering, Arizona State University, Tempe, AZ  85287, United States; Division of Applied Science and Technology, Marshall University, Huntington, WV  25755, United States","Parijat, P., School of Biomedical Engineering and Science, Virginia Tech, Blacksburg, VA  24060, United States; Lockhart, T.E., School of Biological and Health Systems Engineering, Arizona State University, Tempe, AZ  85287, United States; Liu, J., Division of Applied Science and Technology, Marshall University, Huntington, WV  25755, United States","The objective of the study was to design a virtual reality (VR) training to induce perturbation in older adults similar to a slip and examine the effect of the training on kinematic and muscular responses in older adults. Twenty-four older adults were involved in a laboratory study and randomly assigned to two groups (VR training and control). Both groups went through three sessions including baseline slip, training, and transfer of training on slippery surface. The training group experienced 12 simulated slips using a visual perturbation induced by tilting a VR scene while walking on the treadmill and the control group completed normal walking during the training session. Kinematic, kinetic, and electromyography data were collected during all the sessions. Results demonstrated the proactive adjustments such as increased trunk flexion at heel contact after training. Reactive adjustments included reduced time to peak activations of knee flexors, reduced knee coactivation, reduced time to trunk flexion, and reduced trunk angular velocity after training. In conclusion, the study findings indicate that the VR training was able to generate a perturbation in older adults that evoked recovery reactions and such motor skill can be transferred to the actual slip trials. © 2014 IEEE.","Elderly; electromyography (EMG); fall prevention training; falls; virtual reality (VR)","Accident prevention; E-learning; Electromyography; Kinematics; Virtual reality; Elderly; Fall prevention; falls; Kinematic response; Laboratory studies; Recovery reactions; Training sessions; Transfer of trainings; Physiological models; adult; Article; controlled study; electromyogram; electromyography; female; human; human experiment; kinematics; knee function; male; normal human; randomized controlled trial; surface property; tilting; treadmill; velocity; virtual reality; walking; aged; body equilibrium; computer interface; falling; gait; muscle contraction; photostimulation; physiology; prevention and control; procedures; psychomotor performance; psychophysiology; stimulation; treatment outcome; virtual reality exposure therapy; Accidental Falls; Aged; Biofeedback, Psychology; Electromyography; Female; Gait; Humans; Male; Muscle Contraction; Photic Stimulation; Physical Stimulation; Postural Balance; Psychomotor Performance; Treatment Outcome; User-Computer Interface; Virtual Reality Exposure Therapy",Article,"Final","",Scopus,2-s2.0-84921488714
"Freina L., Canessa A.","26665429300;57210766595;","Immersive vs desktop virtual reality in game based learning",2015,"Proceedings of the European Conference on Games-based Learning","2015-January",,,"195","202",,10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955151400&partnerID=40&md5=f62727021ff0a306eef5ab32c8a4bce7","CNR-ITD, Genova, Italy; BioLab - DIBRIS, Università degli Studi di Genova, Italy","Freina, L., CNR-ITD, Genova, Italy; Canessa, A., BioLab - DIBRIS, Università degli Studi di Genova, Italy","Virtual environments are recognized as more effective than other digital approaches for the acquisition of several abilities. This is because the brain recognizes the virtual world as real and this facilitates the transfer of the newly acquired skills to the real world. In this paper, we present a game that has been designed and developed with the aim of teaching spatial orientation abilities to teenagers with mild intellectual impairments. In particular, the game focuses on the training of two basic skills: Perspective taking and mental rotation. Perspective taking refers to the ability of imagining how the world looks like from another person's point of view, while mental rotation is the ability to mentally represent and manipulate physical objects in one's mind. The game, which takes place in a virtual environment, shows the player a scene with some objects on the table. The player has to choose among four provided alternatives, the one that shows how the scene would look like from a different side of the table. The game was first developed to be used with either a desktop pc monitor or an interactive touch table. In this case, a virtual world is represented, but the player is not completely immersed in it, he just looks at the scene from outside. A second version of the same game has then been developed using a Head Mounted Display (HMD), which makes the player feel immersed in the virtual environment, where he can freely move around just as if it was real. In this paper, we discuss both advantages and disadvantages of the immersive Virtual Reality (VR) compared to the desktop VR. In fact, on the one hand, having the possibility to ""dive"" into the virtual world allows the player to: Better build a mental model of the scene and the involved objects by freely moving around the table and examining the objects from all the possible perspectives; Manage by himself the amount of help needed: It is always possible, at any time of the game, to move to the other side of the table and see what the scene looks like. Increase his involvement in the game by exploring the virtual world as he pleases. Have a better learning transfer thanks to the similarities between the virtual and the real worlds. On the other hand, using a HMD can be tiring and cause sickness to some players. Furthermore, the presence of a complete environment in which to move and explore, can draw the attention away from the main task of the game and therefore influence learning negatively. Experiments are planned to verify the foreseen advantages and disadvantages involving young adults with mild intellective disabilities.","Innovative games-based learning; Mental rotation; Perspective taking; Virtual worlds","Helmet mounted displays; Interactive computer graphics; Personnel training; Sensory perception; Desktop virtual reality; Head mounted displays; Immersive virtual reality; Innovative games-based learning; Mental rotation; Perspective taking; Spatial orientations; Virtual worlds; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84955151400
"Chapoulie E., Tsandilas T., Oehlberg L., MacKay W., Drettakis G.","38662242200;6507282888;23991094100;7102699682;6603449604;","Finger-based manipulation in immersive spaces and the real world",2015,"2015 IEEE Symposium on 3D User Interfaces, 3DUI 2015 - Proceedings",,, 7131734,"109","116",,6,"10.1109/3DUI.2015.7131734","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939200619&doi=10.1109%2f3DUI.2015.7131734&partnerID=40&md5=e2a02c5e045bd8cb1a45d08de3dc4280","Inria, Univ Paris-Sud, France","Chapoulie, E., Inria, Univ Paris-Sud, France; Tsandilas, T., Inria, Univ Paris-Sud, France; Oehlberg, L., Inria, Univ Paris-Sud, France; MacKay, W., Inria, Univ Paris-Sud, France; Drettakis, G., Inria, Univ Paris-Sud, France","Immersive environments that approximate natural interaction with physical 3D objects are designed to increase the user's sense of presence and improve performance by allowing users to transfer existing skills and expertise from real to virtual environments. However, limitations of current Virtual Reality technologies, e.g., low-fidelity real-time physics simulations and tracking problems, make it difficult to ascertain the full potential of finger-based 3D manipulation techniques. This paper decomposes 3D object manipulation into the component movements, taking into account both physical constraints and mechanics. We fabricate five physical devices that simulate these movements in a measurable way under experimental conditions. We then implement the devices in an immersive environment and conduct an experiment to evaluate direct finger-based against ray-based object manipulation. The key contribution of this work is the careful design and creation of physical and virtual devices to study physics-based 3D object manipulation in a rigorous manner in both real and virtual setups. © 2015 IEEE.","Finger-based manipulation; Immersive Cube-like Displays; Real/virtual world comparison","Virtual reality; 3D object manipulations; Experimental conditions; Finger-based manipulation; Immersive; Immersive environment; Physical constraints; Real/virtual world comparison; Virtual reality technology; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-84939200619
"Nabioyuni M., Bowman D.A.","57218219407;7202508735;","An Evaluation of the Effects of Hyper-Natural Components of Interaction Fidelity on Locomotion Performance in Virtual Reality",2015,"International Conference on Artificial Reality and Telexistence and Eurographics Symposium on Virtual Environments, ICAT-EGVE 2015",,,,"167","174",,8,"10.2312/egve.20151325","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994865676&doi=10.2312%2fegve.20151325&partnerID=40&md5=f3db2d10ac35041de78cf07da799959e","Instittue Center for Human-Computer Interaction, Department of Computer Science, Virginia Tech, United States","Nabioyuni, M., Instittue Center for Human-Computer Interaction, Department of Computer Science, Virginia Tech, United States; Bowman, D.A., Instittue Center for Human-Computer Interaction, Department of Computer Science, Virginia Tech, United States","Virtual reality (VR) locomotion techniques that approximate real-world walking often have lower performance than fully natural real walking due to moderate interaction fidelity. Other techniques with moderate fidelity, however, are intentionally designedto enhance users'abilities beyond whatis possible in the realworld. We compared such hyper-natural techniques to their natural counterparts on a wide range of locomotion tasks for a variety of measures. The evaluation also considered two independent components of interaction fidelity: bio-mechanics and transfer function. The results show that hyper-natural transfer functions can improve locomotion speed and some aspects of user satisfaction, although this can come at the expense of accuracy for complicated path-following tasks. On the other hand, hyper-natural techniques designed to provide biomechanical assistance had lower performance and user acceptance than those based on natural walking movements. These results contribute to a deeper understanding of the effects of interaction fidelity and designer intent for VR interaction techniques. © The Eurographics Association 2015.",,"Biomechanics; Function evaluation; Transfer functions; Virtual reality; Independent components; Interaction techniques; Locomotion technique; Natural components; Path following; User acceptance; User satisfaction; Walking movements; Walking aids",Conference Paper,"Final","",Scopus,2-s2.0-84994865676
"Loukas C., Lahanas V., Kanakis M., Georgiou E.","6603074122;51461624800;22934670600;7004603021;","The Effect of Mixed-Task Basic Training in the Acquisition of Advanced Laparoscopic Skills",2015,"Surgical Innovation","22","4",,"418","425",,4,"10.1177/1553350614556365","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937032825&doi=10.1177%2f1553350614556365&partnerID=40&md5=77f5bdb1f5e8edf986df4077a4170cdd","Medical Physics Lab-Simulation Center, School of Medicine, University of Athens, Mikras Asias 75 Str, Athens, 11527, Greece","Loukas, C., Medical Physics Lab-Simulation Center, School of Medicine, University of Athens, Mikras Asias 75 Str, Athens, 11527, Greece; Lahanas, V., Medical Physics Lab-Simulation Center, School of Medicine, University of Athens, Mikras Asias 75 Str, Athens, 11527, Greece; Kanakis, M., Medical Physics Lab-Simulation Center, School of Medicine, University of Athens, Mikras Asias 75 Str, Athens, 11527, Greece; Georgiou, E., Medical Physics Lab-Simulation Center, School of Medicine, University of Athens, Mikras Asias 75 Str, Athens, 11527, Greece","The aim of this study was to assess whether mixed practice of basic tasks on a virtual reality (VR) simulator improves the performance of advanced tasks on the same device used for training as well as on a video trainer (VT). Thirty-six novices were allocated into 3 equal groups. Each group practiced on different combinations of basic tasks on a VR simulator: (A) peg transfer, (B) peg transfer and clipping, and (C) peg transfer, clipping, and cutting. Before and after training, each group performed a laparoscopic cholecystectomy (LC) scenario on the simulator and intracorporeal knot tying (KT) on a VT. Assessment metrics included time, instruments path length, penalty score, and hand motion synchronization. Results showed that for the common training tasks, plateau values were statistically equivalent for most assessment metrics (P >.05). For LC, all groups showed significant performance improvement (P <.05). For KT, group C improved significantly in pathlength (P <.005), penalty score (P <.05), and hand motion synchronization (P <.05); the other groups failed to show an improvement (P >.05). In conclusion, training on different VR tasks seems to have no effect on the performance of more demanding tasks on the same device. However, the number of different tasks practiced on the VR simulator seems to favorably affect the performance of advanced tasks on the VT. © The Author(s) 2014.","simulation; surgical training; virtual reality","Article; cholecystectomy; clinical article; controlled study; hand movement; human; intracorporeal knot tying; medical student; needle holder; punishment; randomized controlled trial; rigid endoscope; surgical equipment; surgical technique; surgical training; task performance; virtual reality; virtual reality laparoscopic simulator; computer interface; computer simulation; education; equipment design; laparoscopy; Computer Simulation; Equipment Design; Humans; Laparoscopy; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84937032825
"Tahriri F., Mousavi M., Yap H.J., Siti Zawiah M.D., Taha Z.","36618278700;56673713600;35319362200;36782839400;7004562426;","Optimizing the robot arm movement time using virtual reality robotic teaching system",2015,"International Journal of Simulation Modelling","14","1",,"28","38",,16,"10.2507/IJSIMM14(1)3.273","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930681484&doi=10.2507%2fIJSIMM14%281%293.273&partnerID=40&md5=5a478432dd121ee4b5e7d518ffd4f207","Department of Mechanical Engineering, University of Malaya, Kuala Lumpur, 50603, Malaysia; Universiti Malaysia Pahang, Pekan, Pahang Darul Makmur  26600, Malaysia","Tahriri, F., Department of Mechanical Engineering, University of Malaya, Kuala Lumpur, 50603, Malaysia; Mousavi, M., Department of Mechanical Engineering, University of Malaya, Kuala Lumpur, 50603, Malaysia; Yap, H.J., Department of Mechanical Engineering, University of Malaya, Kuala Lumpur, 50603, Malaysia; Siti Zawiah, M.D., Department of Mechanical Engineering, University of Malaya, Kuala Lumpur, 50603, Malaysia; Taha, Z., Universiti Malaysia Pahang, Pekan, Pahang Darul Makmur  26600, Malaysia","Robots play an important role in performing operations such as welding, drilling and screwing parts in manufacturing. Optimizing the robot arm movement time between different points is an important task which will minimize the make-span and maximize the production rate. But robot programming is a complex task whereby the user needs to teach and control the robot in order to perform a desired action. In order to address the above problem, an integrated 3-dimensional (3D) simulation software and virtual reality (VR) system is developed to simplify and speed up tasks and therefore enhance the quality of manufacturing processes. This system has the capability to communicate, transfer, optimize and test the data obtained from the VR and 3D environment to the real robot in a fast and efficient manner. In addition, this system eliminates the need for robot programming, and thus it is easily implemented by users with limited engineering knowledge. The optimization model is tested on a test case, in which the data are extracted from the VR system. The results show an increase in production rate and a decrease in cycle time when the make-span is minimized. The virtual reality robotic teaching system (VRRTS) offers several benefits to users, and will therefore surpass complex and time-intensive conventional robot programming methods. © 2015, Vienna University of Technology. All rights reserved.","Flexible manufacturing system; Optimization; Robot traveling time; Robotics; Teaching system; Virtual reality",,Article,"Final","",Scopus,2-s2.0-84930681484
"Silva W.H.S., Lopes G.L.B., Yano K.M., Tavares N.S.A., Rego I.A.O., Da Costa Cavalcanti F.A.","56865512600;56865589600;56865302400;56865818800;56866000000;57000087100;","Effect of a rehabilitation program using virtual reality for balance and functionality of chronic stroke patients",2015,"Motriz. Revista de Educacao Fisica","21","3",,"237","243",,6,"10.1590/S1980-65742015000300003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942080414&doi=10.1590%2fS1980-65742015000300003&partnerID=40&md5=8d318783732c5e6789c6e5378611c22a","Department of Physical Therapy, Brazil Universidade Federal do Rio Grande do Norte, Av. Senador Salgado Filho 3000, Natal, Rio Grande do Norte, 59072-970, Brazil; 150 Rue St. Norbert, Montreal, QC  H2X1G6, Canada","Silva, W.H.S., Department of Physical Therapy, Brazil Universidade Federal do Rio Grande do Norte, Av. Senador Salgado Filho 3000, Natal, Rio Grande do Norte, 59072-970, Brazil, 150 Rue St. Norbert, Montreal, QC  H2X1G6, Canada; Lopes, G.L.B., Department of Physical Therapy, Brazil Universidade Federal do Rio Grande do Norte, Av. Senador Salgado Filho 3000, Natal, Rio Grande do Norte, 59072-970, Brazil; Yano, K.M., Department of Physical Therapy, Brazil Universidade Federal do Rio Grande do Norte, Av. Senador Salgado Filho 3000, Natal, Rio Grande do Norte, 59072-970, Brazil; Tavares, N.S.A., Department of Physical Therapy, Brazil Universidade Federal do Rio Grande do Norte, Av. Senador Salgado Filho 3000, Natal, Rio Grande do Norte, 59072-970, Brazil; Rego, I.A.O., Department of Physical Therapy, Brazil Universidade Federal do Rio Grande do Norte, Av. Senador Salgado Filho 3000, Natal, Rio Grande do Norte, 59072-970, Brazil; Da Costa Cavalcanti, F.A., Department of Physical Therapy, Brazil Universidade Federal do Rio Grande do Norte, Av. Senador Salgado Filho 3000, Natal, Rio Grande do Norte, 59072-970, Brazil","This study aimed to investigate the effect of a rehabilitation program using virtual reality (VR) in addition to conventional therapy for improvement of balance (BERG scale) and functional independence (FIM scale) in chronic stroke patients. Ten individuals, mean age of 51.4 (± 6.7 years), participated of eight 60-minute sessions comprising kinesiotherapy (15min), Nintendo Wii (30min) and Learning transfer (15min) exercises. After training, nonparametric statistical analysis showed significant improvement in total FIM (p = .01) and BERG scores (p = .00), and in some of their subitems: FIM - dressing lower body (p = .01), transfer to bathtub/shower (p = .02) and locomotion: stairs (p = .03); BERG - reaching forward with outstretched arm (p = .01), retrieving object from the floor (p = .04), turning 360 (p = .01), placing alternate foot on step (p < .01), standing with one foot in front (p = .01), and one leg stand (p = .03). These findings suggest a positive influence of virtual reality exercises adjunct to conventional therapy on rehabilitation of balance and functionality post stroke, and indicate the feasibility of the proposed VR-based rehabilitation program.","Daily living activities; Postural balance; Rehabilitation; Virtual reality",,Article,"Final","",Scopus,2-s2.0-84942080414
"Alfred M., Neyens D.M., Gramopadhye A.K.","56901101700;15045355400;7005569103;","The impact of training method on skill acquisition and transfer",2015,"Proceedings of the Human Factors and Ergonomics Society","2015-January",,,"1563","1567",,1,"10.1177/1541931215591338","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84981717478&doi=10.1177%2f1541931215591338&partnerID=40&md5=ad531b4a2ae5b19f89fd2b1bfa2e7b04","Clemson University, United States","Alfred, M., Clemson University, United States; Neyens, D.M., Clemson University, United States; Gramopadhye, A.K., Clemson University, United States","Technology, such as simulations and virtual reality (VR), can be used for training students and employees. Using these tools may have implications for skills development and retention, specifically related to individual differences and technology's effectiveness as a learning tool. To explore this issue, a pilot study was used to evaluate how an individual's performance on a task (i.e., the building an electrical circuit), differs depending on the physical fidelity of the learning environment. In addition, this study examined the effects of cognitive ability and goal orientation on task performance. Specifically this study investigated different methods for practicing the building of electrical circuits using a 2D breadboard simulation, a 3D virtual breadboard, and a physical breadboard. The preliminary results of this pilot study found that physical fidelity of learning environment was a significant predictor of construction time and circuit accuracy. Cognitive ability and learning goal orientation were significant predictors of gain scores and diagram accuracy. Copyright 2015 Human Factors and Ergonomics Society.",,"Computer aided instruction; Electric network parameters; Ergonomics; Human engineering; Networks (circuits); Reconfigurable hardware; Virtual reality; Cognitive ability; Construction time; Electrical circuit; Individual Differences; Learning environments; Skill acquisition and transfers; Skills development; Virtual breadboards; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-84981717478
"Mestre D.R.","7004066310;","On the usefulness of the concept of presence in Virtual Reality applications",2015,"Proceedings of SPIE - The International Society for Optical Engineering","9392",, 93920J,"","",,5,"10.1117/12.2075798","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928473664&doi=10.1117%2f12.2075798&partnerID=40&md5=c601907e8f7dda5bc906c334bb8df603","Aix-Marseille University, CNRS, Institute of Movement Sciences, Marseilles, France","Mestre, D.R., Aix-Marseille University, CNRS, Institute of Movement Sciences, Marseilles, France","Virtual Reality (VR) leads to realistic experimental situations, while enabling researchers to have deterministic control on these situations, and to precisely measure participants' behavior. However, because more realistic and complex situations can be implemented, important questions arise, concerning the validity and representativeness of the observed behavior, with reference to a real situation. One example is the investigation of a critical (virtually dangerous) situation, in which the participant knows that no actual threat is present in the simulated situation, and might thus exhibit a behavioral response that is far from reality. This poses serious problems, for instance in training situations, in terms of transfer of learning to a real situation. Facing this difficult question, it seems necessary to study the relationships between three factors: immersion (physical realism), presence (psychological realism) and behavior. We propose a conceptual framework, in which presence is a necessary condition for the emergence of a behavior that is representative of what is observed in real conditions. Presence itself depends not only on physical immersive characteristics of the Virtual Reality setup, but also on contextual and psychological factors. © 2015 SPIE-IS&T.","Behavior; Immersion; Presence; Virtual Reality","Optical engineering; Behavior; Behavioral response; Conceptual frameworks; Immersion; Presence; Psychological factors; Psychological realisms; Transfer of learning; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84928473664
"Lu X., Davis S.R.","57157731400;7405958602;","How sounds influence people's safety decisions-human interaction with a virtual reality simulator",2015,"32nd International Symposium on Automation and Robotics in Construction and Mining: Connected to the Future, Proceedings",,,,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962811937&partnerID=40&md5=f03b03cdd1cb514a9a2b53d47faef246","School of Civil and Environmental Engineering, University of New South Wales, Australia","Lu, X., School of Civil and Environmental Engineering, University of New South Wales, Australia; Davis, S.R., School of Civil and Environmental Engineering, University of New South Wales, Australia","Safety decisions made by construction workers on-site directly affect the rate of accidents and injuries. Virtual Reality safety simulators have been created for training workers in site safety. This paper examines the effect that sound has on the realism of virtual reality simulators and the effect that virtual reality training has on subsequent behavior in the physical world. A Virtual Reality environment was built for the tests. Tests involved maneuvering a wheelbarrow around a construction site. Safe and unsafe routes were available. Participants were divided into two groups, those with background sounds in their simulation and those without. A physical environment was built to investigate if use of the virtual reality environment resulted in behavior changes. Participants also completed questionnaires after the tests to discover why participants acted the way they did. The paper is unique in testing users with and without sound in a construction safety simulator. Preliminary study results show that people are likely to perceive more risks when there is no background sound which results in fewer accidents. Results of the paper are useful for those creating virtual reality simulators. Limitations of the research are that it applies to a very specific problem and results need to be generalized over a larger set of problems. Future research is also required to determine what sound range (in terms of decibels) is best for virtual reality training.","Construction sounds; Safety decision; Virtual reality simulator","Accidents; Behavioral research; E-learning; Occupational risks; Robotics; Safety engineering; Safety testing; Simulators; Surveys; Construction safety; Construction sites; Construction workers; Human interactions; Physical environments; Virtual reality simulator; Virtual reality training; Virtual-reality environment; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84962811937
"Serino S., Morganti F., Di Stefano F., Riva G.","54910848200;35509559400;56688297800;56962750600;","Detecting early egocentric and allocentric impairments deficits in Alzheimer's disease: An experimental study with virtual reality",2015,"Frontiers in Aging Neuroscience","7","MAY", 88,"","",,49,"10.3389/fnagi.2015.00088","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931260335&doi=10.3389%2ffnagi.2015.00088&partnerID=40&md5=cc13601823828a09b3b5375c5a2a9ba8","Applied Technology for Neuro-Psychology Lab, Istituto Auxologico Italiano, Milan, Italy; Department of Human and Social Sciences, University of Bergamo, Bergamo, Italy; Ospedale Castelli Verbania, Verbania, Italy; Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy","Serino, S., Applied Technology for Neuro-Psychology Lab, Istituto Auxologico Italiano, Milan, Italy; Morganti, F., Department of Human and Social Sciences, University of Bergamo, Bergamo, Italy; Di Stefano, F., Ospedale Castelli Verbania, Verbania, Italy; Riva, G., Applied Technology for Neuro-Psychology Lab, Istituto Auxologico Italiano, Milan, Italy, Department of Psychology, Università Cattolica del Sacro Cuore, Milan, Italy","Several studies have pointed out that egocentric and allocentric spatial impairments are one of the earliest manifestations of Alzheimer's Disease (AD). It is less clear how a break in the continuous interaction between these two representations may be a crucial marker to detect patients who are at risk to develop dementia. The main objective of this study is to compare the performances of participants suffering from amnestic mild cognitive impairment (aMCI group), patients with AD (AD group) and a control group (CG), using a virtual reality (VR)-based procedure for assessing the abilities in encoding, storing and syncing different spatial representations. In the first task, participants were required to indicate on a real map the position of the object they had memorized, while in the second task they were invited to retrieve its position from an empty version of the same virtual room, starting from a different position. The entire procedure was repeated across three different trials, depending on the object location in the encoding phase. Our finding showed that aMCI patients performed significantly more poorly in the third trial of the first task, showing a deficit in the ability to encode and store an allocentric viewpoint independent representation. On the other hand, AD patients performed significantly more poorly when compared to the CG in the second task, indicating a specific impairment in storing an allocentric viewpoint independent representation and then syncing it with the allocentric viewpoint dependent representation. Furthermore, data suggested that these impairments are not a product of generalized cognitive decline or of general decay in spatial abilities, but instead may reflect a selective deficit in the spatial organization Overall, these findings provide an initial insight into the cognitive underpinnings of amnestic impairment in aMCI and AD patient exploiting the potentiality of VR. © 2015 Serino, Morganti, Di Stefano and Riva.","Allocentric representation; Alzheimer's disease; Egocentric representation; Mild cognitive impairment; Virtual reality","aged; Alzheimer disease; Article; clinical article; controlled study; Corsi BlockTest; depth perception; disease severity; female; human; Judgement of Line Orientation; long term memory; male; Manikin Test; mental test; mild cognitive impairment; Money Road Map; short term memory; spatial memory; spatial memory test; spatial orientation; virtual reality",Article,"Final","",Scopus,2-s2.0-84931260335
"Josan P.K., Singh-Derewa C., De Leon P., Inada B., Srivastava P.","57191542339;56287831300;16315695800;57191538742;57191545841;","Enhancing the human-machine interface using visr-An interactive 3d visualization/ desens1tization training tool in a variable gravity model",2015,"Proceedings of the International Astronautical Congress, IAC","6",,,"4205","4216",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991489707&partnerID=40&md5=929faade94c2cfb432e6c706c34b5eec","Department of Space Studies, University of North Dakota, United States; Systems Engineering Division, NASA-JPL, United States; University of North Dakota, United States; User Research and Interaction Design, NASA-JPL, United States; University of Michigan, Ann Arbor, United States","Josan, P.K., Department of Space Studies, University of North Dakota, United States; Singh-Derewa, C., Systems Engineering Division, NASA-JPL, United States; De Leon, P., University of North Dakota, United States; Inada, B., User Research and Interaction Design, NASA-JPL, United States; Srivastava, P., University of Michigan, Ann Arbor, United States","The human body is used to a 1-G environment and behaves differently in lower gravity. Mars gravity is about l/3rd of Earth's, asteroid and dwarf planets even less. Training for Extra Vehicular Activities (EVA) using rovers and spacesuits is challenging at best. Lower gravity planetary environments with distinctive terrain require trained space explorers with interactive human-machine compatibilities. Current visualization methods, such as Virtual Reality (VR) goggles, can be adapted to display a generalized view of planetary surface featuring a visual 3-D interface, yet lack a high-fidelity, immersive environment. Limited terrain mapping and limited methods for reflecting the variable gravitational conditions are two of the primary limitations. In order to better understand human behavior in alternate environments, it is important to study the psycho-physiological components of a subject in a near-Actual simulations. With the potential to augment planetary EVA procedures and address vital human factors associated with space planetary exploration, our team in partnership with the University of North Dakota (UND) and the Jet Propulsion Laboratory (JPL) have developed the concept of VISR (Visual Immersion for Simulated Robotics) system. VISR provides an immersive 3-D planetary Virtual Reality model utilizing high performance computing, image processing, 3-D rendering, powered by an expansive referential database. The software manipulates image processing speed with a variable gravity parameter as an input. VISR is compatible with multiple planetary bodies and asteroids whereas the current system applications are limited to the space station and Mars. VISR assists in the study of psycho-physiological effects (human limbs - eye coordination) associated with deep-space travel and low- gravity environments. VISR can be utilized to facilitate short range tele-robotic operation during actual missions. Mars has a vast, geologically complex terrain with existing environments models allowing topographical visualization. Image composition draws upon the significant wealth of information accumulated at JPL over 50 years interacting with solar system bodies. VISR users experience these features in an immersive and interactive environment enhancing human performance in real situations, and assisting scientists and mission planners in system and mission design. VISR integrates the UND developed planetary suit NDX-2, currently used as a simulation tool for 'astronaut training', the LEGACY database for planetary bodies at JPL, human factors and related Psychophysiological studies. The VISR system development will has seen different phases such as development of terrain maps, and their integration with visual device sensor, integration of the LEGACY terrain sysml model which can identify and import relevant physical parameters from available planetary databases, varying the speed of image output to the user by manipulating the gravity parameter, and integrating it with already developed terrain models. This device can be further used to feed real-Time physiological performance data to a separate sensor based system, and study the related effects on human subjects. VISR will be an effective tool which would equip the researchers, mission planners and space travelers for a future planetary manned mission.",,"Asteroids; Database systems; Fighter aircraft; Gravitation; Human computer interaction; Human engineering; Image processing; Interplanetary spacecraft; Landforms; Liquid sloshing; Manned space flight; Physiology; Planets; Planning; Reconfigurable hardware; Robotics; Space stations; Spacecraft; Three dimensional computer graphics; Training aircraft; Virtual reality; Visualization; Extravehicular activity; High performance computing; Human Machine Interface; Interactive 3d visualizations; Interactive Environments; Jet Propulsion Laboratory; University of North Dakota; Virtual reality modeling; Behavioral research",Conference Paper,"Final","",Scopus,2-s2.0-84991489707
"Wae-Hayee M., Tekasakul P., Eiamsa-Ard S., Nuntadusit C.","54581708300;6602214176;8309843000;6506467024;","Flow and heat transfer characteristics of in-line impinging jets with cross-flow at short jet-to-plate distance",2015,"Experimental Heat Transfer","28","6",,"511","530",,21,"10.1080/08916152.2014.913091","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84914126870&doi=10.1080%2f08916152.2014.913091&partnerID=40&md5=ca4b431398c1b13218915072cb2088c8","Department of Mechanical Engineering, Faculty of Engineering, Prince of Songkla University, Hat Yai, Songkhla, Thailand; Department of Mechanical Engineering, Faculty of Engineering, Mahanakorn University of Technology, CheumSam Rd., Bangkok, 10530, Thailand","Wae-Hayee, M., Department of Mechanical Engineering, Faculty of Engineering, Prince of Songkla University, Hat Yai, Songkhla, Thailand; Tekasakul, P., Department of Mechanical Engineering, Faculty of Engineering, Prince of Songkla University, Hat Yai, Songkhla, Thailand; Eiamsa-Ard, S., Department of Mechanical Engineering, Faculty of Engineering, Mahanakorn University of Technology, CheumSam Rd., Bangkok, 10530, Thailand; Nuntadusit, C., Department of Mechanical Engineering, Faculty of Engineering, Prince of Songkla University, Hat Yai, Songkhla, Thailand, Department of Mechanical Engineering, Faculty of Engineering, Mahanakorn University of Technology, CheumSam Rd., Bangkok, 10530, Thailand","The aim of this research is to numerically and experimentally study the flow and heat transfer characteristics of in-line impinging jets in cross-flow. The jets from a row of round orifices are perpendicularly impinged on the inner surface of a rectangular wind tunnel at a short distance between the orifice plate and impinged surface (H) of 2D, where D is a diameter of the orifice. The jet velocity was fixed corresponding to Re = 13,400 for all experiments, and the cross-flow velocity was varied at three different velocity ratios (velocity ratio, jet velocity/cross-flow velocity) of 3, 5, and 7. The heat transfer characteristic was visualized using a thermochromic liquid crystal sheet, and the Nusselt number distribution was evaluated by an image processing technique. The flow pattern on the impinged surface was also visualized by an oil film technique. The numerical simulation was used to explore a flow interaction between the impinging jets and cross-flow. The results indicated that Nusselt number peak increased by the increasing cross-flow velocity for short jet-to-plate distance. For the range determined, the maximum local Nusselt number peak was obtained at VR = 3 as the consequence of high velocity and high turbulence kinetic energy of jet impingement. © 2015 © Taylor & Francis Group, LLC.","cross-flow; heat transfer; impinging jets; inline arrangement; numerical simulation; thermochromic liquid crystal","Computer simulation; Flow patterns; Flow velocity; Heat transfer; Image processing; Kinetic energy; Kinetics; Liquid crystals; Numerical models; Nusselt number; Orifices; Wind tunnels; Cross flows; Heat transfer characteristics; Image processing technique; Impinging jet; In-line arrangement; Nusselt number distribution; Thermochromic liquid crystal sheets; Thermochromic liquid crystals; Velocity",Article,"Final","",Scopus,2-s2.0-84914126870
"Probst A., Pcytavf G.G., Nakath D., Schattel A., Rachuy C., Langef P., Clemens J., Echim M., Schwarting V., Srinivas A., Gadzicki K., Fdrstner R., Eissfeller B., Schill K., Biiskens C., Zachmann G.","57191525833;57191524198;55648238600;57191528420;36447921500;57191529826;55972025700;57191525289;57191531608;57191524766;35483742900;57191528844;6603546304;6603857707;57191524387;6603062795;","IAC-15-A3.IP.15 Kanaria: Identifying the challenges for cognitive autonomous navigation and guidance for missions to small planetary bodies",2015,"Proceedings of the International Astronautical Congress, IAC","2",,,"1393","1406",,10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991408360&partnerID=40&md5=3c72b9a8f2640eb95e1e0476c8651bc4","Space Technology Dept., Institute of Space Technology and Applications, Bundeswehr University, Munich, Germany; Navigation Dept., Institute of Space Technology and Applications, Bundeswehr University, Munich, Germany; Sensor Fusion Group, Cognitive Neuroinformatics, University of Bremen, Germany; Working group Optimization and Optimal Control, University of Bremen, Germany; Autonomy Group, Cognitive Neuroinformatics, University of Bremen, Germany; Computer Graphics and Virtual Reality, University of Bremen, Germany","Probst, A., Space Technology Dept., Institute of Space Technology and Applications, Bundeswehr University, Munich, Germany; Pcytavf, G.G., Navigation Dept., Institute of Space Technology and Applications, Bundeswehr University, Munich, Germany; Nakath, D., Sensor Fusion Group, Cognitive Neuroinformatics, University of Bremen, Germany; Schattel, A., Working group Optimization and Optimal Control, University of Bremen, Germany; Rachuy, C., Autonomy Group, Cognitive Neuroinformatics, University of Bremen, Germany; Langef, P., Computer Graphics and Virtual Reality, University of Bremen, Germany; Clemens, J., Sensor Fusion Group, Cognitive Neuroinformatics, University of Bremen, Germany; Echim, M., Working group Optimization and Optimal Control, University of Bremen, Germany; Schwarting, V., Autonomy Group, Cognitive Neuroinformatics, University of Bremen, Germany; Srinivas, A., Navigation Dept., Institute of Space Technology and Applications, Bundeswehr University, Munich, Germany; Gadzicki, K., Autonomy Group, Cognitive Neuroinformatics, University of Bremen, Germany; Fdrstner, R., Space Technology Dept., Institute of Space Technology and Applications, Bundeswehr University, Munich, Germany; Eissfeller, B., Navigation Dept., Institute of Space Technology and Applications, Bundeswehr University, Munich, Germany; Schill, K., Sensor Fusion Group, Cognitive Neuroinformatics, University of Bremen, Germany, Autonomy Group, Cognitive Neuroinformatics, University of Bremen, Germany; Biiskens, C., Working group Optimization and Optimal Control, University of Bremen, Germany; Zachmann, G., Computer Graphics and Virtual Reality, University of Bremen, Germany","Problems and the calculation of trajectory sensitivities for on-board stability analysis as well as real-time optimal control are explained. Bringing cognitive autonomy to a spacecraft requires an on-board computational module as a central spacecraft component. This module is responsible for state evaluation, mission planning and decision-making regarding selection of potential targets, trajectory selection and FD1R. A knowledge-base serves as a database for decision making processes. With the aim to validate and test our methods, we create a virtual environment in which humans can interact with the simulation of the mission. In order to achieve real-time performance, we propose a massively-parallel software system architecture, which enables very efficient and easily adaptable communication between concurrent software modules within KaNaRiA.,With the rapid evolution of space technologies and increasing thirst for knowledge about the origin of life and the universe, the need for deep space missions as well as for autonomous solutions for complex, time-critical mission operations becomes urgent. Within this context, the project KaNaRiA aims at technology development tailored to the ambitious task of space resource mining on small planetary bodies using increased autonomy for on-board mission planning, navigation and guidance. This paper focuses on the specific challenges as well as first solutions and results corresponding to the KaNaRiA mission phases (1) interplanetary cruise, (2) target identification and characterization and (3) proximity operations. Based on the KaNaRiA asteroid mining mission objectives, initially, a mission reference scenario as well as a reference mission architecture are described in this paper. KaNaRiA has been proposed as a multi-spacecraft mission to the asteroid main belt. Composed of a flock of prospective scout spacecraft, a mother ship carrying the mining payload and several service modules placed on a 2.8 AU parking orbit around the Sun, KaNaRiA intends to characterize main belt asteroid properties, identify targets for mining and perform a soft-landing for in-situ characterization and mining. Subsequently, the autonomous navigation system design of KaNaRiA for the interplanetary cruise is presented. The navigation challenges, which arise in phases (1) to (3), are discussed. Particular attention is given to the sensor- technology readiness-level, accuracy, applicability range, mass and power budgets. In order to navigate in the vicinity of an asteroid, an information fusion algorithm is required that aggregates multi-sensor data as well as a- priori knowledge and solves the task known as simultaneous localization and mapping (SLAM). In order to deal with uncertain and inconsistent information and to explicitly represent different dimensions of uncertainty, a belief- function-based SLAM approach is used, which is a generalization of the popular FastSLAM algorithm. The objective of the guidance task is the autonomous planning of optimal transfer trajectories according to mission driving criteria, e.g. transfer time and fuel consumption. Optimal control,. © Copyright 2015 by International Astronautical Federation. All rights reserved.",,"Asteroids; Budget control; Concurrency control; Control theory; Decision making; Interplanetary flight; Knowledge based systems; Navigation systems; Planets; Reconfigurable hardware; Robotics; Sensor data fusion; Space flight; Spacecraft; Spacecraft landing; Trajectories; Uncertainty analysis; Virtual reality; Autonomous navigation and guidance; Autonomous navigation systems; In-situ characterization; Inconsistent information; Information fusion algorithm; Multi-spacecraft mission; Real time optimal control; Simultaneous localization and mapping; Orbits",Conference Paper,"Final","",Scopus,2-s2.0-84991408360
"Stein G., Gonzalez A.J.","35372116000;7404585054;","Building and Improving Tactical Agents in Real Time through a Haptic-Based Interface",2015,"Journal of Intelligent Systems","24","4",,"383","403",,1,"10.1515/jisys-2014-0126","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943640569&doi=10.1515%2fjisys-2014-0126&partnerID=40&md5=81955b1caf88a819cdcacde1939e8a2c","Primal Innovation, 201 Tech Drive, Sanford, FL, United States; Intelligent Systems Laboratory, University of Central Florida, 4000 Central Florida Boulevard, Orlando, FL  32816-2362, United States","Stein, G., Primal Innovation, 201 Tech Drive, Sanford, FL, United States; Gonzalez, A.J., Intelligent Systems Laboratory, University of Central Florida, 4000 Central Florida Boulevard, Orlando, FL  32816-2362, United States","This article describes and evaluates an approach to create and/or improve tactical agents through direct human interaction in real time through a force-feedback haptic device. This concept takes advantage of a force-feedback joystick to enhance motor skill and decision-making transfer from the human to the agent in real time. Haptic devices have been shown to have high bandwidth and sensitivity. Experiments are described for this new approach, named Instructional Learning. It is used both as a way to build agents from scratch as well as to improve and/or correct agents built through other means. The approach is evaluated through experiments that involve three applications of increasing complexity-chasing a fleer (Chaser), shepherding a flock of sheep into a pen (Sheep), and driving a virtual automobile (Car) through a simulated road network. The results indicate that in some instances, instructional learning can successfully create agents under some circumstances. However, instructional learning failed to build and/or improve agents in other instances. The Instructional Learning approach, the experiments, and their results are described and extensively discussed. © 2015 by De Gruyter.","Haptics; instructional learning; multimodal machine learning; tactical agents","Artificial intelligence; Complex networks; Decision making; Learning systems; Force feedback joystick; Haptic devices; Haptics; High bandwidth; Human interactions; instructional learning; Learning approach; Multi-modal; Haptic interfaces",Article,"Final","",Scopus,2-s2.0-84943640569
"Gobat N., Kinnersley P., Gregory J.W., Pickles T., Hood K., Robling M.","56593233700;7004522623;7402520206;36560197900;7005611219;6701809350;","Measuring clinical skills in agenda-mapping (EAGL-I)",2015,"Patient Education and Counseling","98","10",,"1214","1221",,3,"10.1016/j.pec.2015.06.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84941314398&doi=10.1016%2fj.pec.2015.06.018&partnerID=40&md5=fa213e3901f3bd63064c91ac11a82f41","Cochrane Institute of Primary Care and Public Health, Cardiff University, Cardiff, United Kingdom; Institute of Medical Education, Cardiff University, Cardiff, United Kingdom; Institute of Molecular and Experimental Medicine, Cardiff University, Cardiff, United Kingdom; South East Wales Trials Unit, Cardiff University, Cardiff, United Kingdom","Gobat, N., Cochrane Institute of Primary Care and Public Health, Cardiff University, Cardiff, United Kingdom; Kinnersley, P., Institute of Medical Education, Cardiff University, Cardiff, United Kingdom; Gregory, J.W., Institute of Molecular and Experimental Medicine, Cardiff University, Cardiff, United Kingdom; Pickles, T., South East Wales Trials Unit, Cardiff University, Cardiff, United Kingdom; Hood, K., South East Wales Trials Unit, Cardiff University, Cardiff, United Kingdom; Robling, M., South East Wales Trials Unit, Cardiff University, Cardiff, United Kingdom","Objective: To develop and validate the Evaluation of AGenda-mapping skilL Instrument (EAGL-I). Methods: EAGL-I was constructed after a literature review and piloting. Simulated consultation recordings were collected in a workshop with third-year medical students at three time points: once pre-teaching, twice post-teaching. Three raters used EAGL-I to assess student agenda-mapping. We examined reliability, ability to detect change and predict full expression of patients' agendas. Results: EAGL-I scores represented reliable assessment of agenda-mapping (Ep2=0.832; ϕ=0.675). Generalizability coefficients across items (Ep2=0.836) and raters (ϕ=0.797 two raters) were acceptable. A one-way repeated measure ANOVA with post hoc analysis found a statistically significant difference between the pre-teaching occasion of measurement and each post-teaching occasion (p<0.001) and no significant difference between the two post-teaching occasions (p=0.085). Multilevel logistic regression show scores predict expression of scripted hidden agendas irrespective of occasions, or patient scenario (n=60, p=0.005). Conclusion: Evidence of measure validation is shown. Reliability is optimised when two or more raters use EAGL-I and agenda-mapping has been taught. EAGL-I appears sensitive to change. Higher scores predict the likelihood that a patient will disclose their full agenda in a simulated environment. Practice implications: A validated tool for measuring agenda-mapping in teaching and research is now available. © 2015 Elsevier Ireland Ltd.","Agenda-mapping; Establish focus; Measure development; Measure validation; Skills assessment; Teaching","Article; evaluation of agenda mapping skill instrument; human; interrater reliability; measurement error; medical education; medical student; primary medical care; priority journal; rating scale; scoring system; undergraduate student; validity; clinical competence; devices; education; female; human relation; male; medical information; multilevel analysis; psychometry; reproducibility; simulation training; statistical model; teaching; Clinical Competence; Educational Measurement; Female; Health Communication; Humans; Logistic Models; Male; Multilevel Analysis; Professional-Patient Relations; Psychometrics; Reproducibility of Results; Simulation Training; Students, Medical; Teaching",Article,"Final","",Scopus,2-s2.0-84941314398
"Vélaz Y., Arce J.R., Gutiérrez T., Lozano-Rodero A., Suescun A.","36662969400;57194191682;18036923100;35090084900;24282105300;","The influence of interaction technology on the learning of assembly tasks using virtual reality",2014,"Journal of Computing and Information Science in Engineering","14","4", 041007,"","",,24,"10.1115/1.4028588","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907830996&doi=10.1115%2f1.4028588&partnerID=40&md5=5bff1b3e24e502112ce9273c861e09e8","Department of Mechanical Engineering, CEIT and TECNUN, University of Navarra, Manuel Lardizabal 15, San-Sebastián, 20018, Spain; Industry and Transport Division, C/Geldo-Parque Tecnologico de Bizkaia, Edificio 700, Derio, 48160, Spain; TECNALIA, San-Sebastián, 20009, Spain","Vélaz, Y., Department of Mechanical Engineering, CEIT and TECNUN, University of Navarra, Manuel Lardizabal 15, San-Sebastián, 20018, Spain; Arce, J.R., Department of Mechanical Engineering, CEIT and TECNUN, University of Navarra, Manuel Lardizabal 15, San-Sebastián, 20018, Spain; Gutiérrez, T., Industry and Transport Division, C/Geldo-Parque Tecnologico de Bizkaia, Edificio 700, Derio, 48160, Spain, TECNALIA, San-Sebastián, 20009, Spain; Lozano-Rodero, A., Department of Mechanical Engineering, CEIT and TECNUN, University of Navarra, Manuel Lardizabal 15, San-Sebastián, 20018, Spain; Suescun, A., Department of Mechanical Engineering, CEIT and TECNUN, University of Navarra, Manuel Lardizabal 15, San-Sebastián, 20018, Spain","This paper focuses on the use of virtual reality (VR) systems for teaching industrial assembly tasks and studies the influence of the interaction technology on the learning process. The experiment conducted follows a between-subjects design with 60 participants distributed in five groups. Four groups were trained on the target assembly task with a VR system, but each group used a different interaction technology: mouse-based, Phantom Omni® haptic, and two configurations of the Markerless Motion Capture (Mmocap) system (with 2D or 3D tracking of hands). The fifth group was trained with a video tutorial. A post-training test carried out the day after evaluated performance in the real task. The experiment studies the efficiency and effectiveness of each interaction technology for learning the task, taking in consideration both quantitative measures (such as training time, real task performance, evolution from the virtual task to real one), and qualitative data (user feedback from a questionnaire). Results show that there were no significant differences in the final performance among the five groups. However, users trained under mouse and 2D-tracking Mmocap systems took significantly less training time than the rest of the virtual modalities. This brings out two main outcomes: (1) the perception of collisions using haptics does not increase the learning transfer of procedural tasks demanding low motor skills and (2) Mmocap-based interactions can be valid for training this kind of tasks. Copyright © 2014 by ASME.","assembly training; haptic devices; knowledge transfer; learning; motion capture; virtual reality","Assembly trainings; Haptic devices; Knowledge transfer; learning; Motion capture; Virtual reality",Article,"Final","",Scopus,2-s2.0-84907830996
"Bric J., Connolly M., Kastenmeier A., Goldblatt M., Gould J.C.","56215447100;57216277008;6507237990;6701703048;24736664300;","Proficiency training on a virtual reality robotic surgical skills curriculum",2014,"Surgical Endoscopy","28","12",,"3343","3348",,25,"10.1007/s00464-014-3624-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84931374502&doi=10.1007%2fs00464-014-3624-5&partnerID=40&md5=e9fde3a5f6a09dbaa7c0038c124485a2","Division of General Surgery, Department of Surgery, Medical College of Wisconsin, 9200 W Wisconsin Avenue, Milwaukee, WI  53226, United States","Bric, J., Division of General Surgery, Department of Surgery, Medical College of Wisconsin, 9200 W Wisconsin Avenue, Milwaukee, WI  53226, United States; Connolly, M., Division of General Surgery, Department of Surgery, Medical College of Wisconsin, 9200 W Wisconsin Avenue, Milwaukee, WI  53226, United States; Kastenmeier, A., Division of General Surgery, Department of Surgery, Medical College of Wisconsin, 9200 W Wisconsin Avenue, Milwaukee, WI  53226, United States; Goldblatt, M., Division of General Surgery, Department of Surgery, Medical College of Wisconsin, 9200 W Wisconsin Avenue, Milwaukee, WI  53226, United States; Gould, J.C., Division of General Surgery, Department of Surgery, Medical College of Wisconsin, 9200 W Wisconsin Avenue, Milwaukee, WI  53226, United States","Methods: 25 medical students with no prior robotic surgery experience were recruited. Prior to VR training, subjects performed 2 FLS tasks 3 times each (Peg Transfer, Intracorporeal Knot Tying) using the daVinci Surgical System™ docked to a video trainer box. Task performance for the FLS tasks was scored objectively. Subjects then practiced on the VR simulator (daVinci Skills Simulator) until proficiency levels on all 5 tasks were achieved before completing a post-training assessment of the 2 FLS tasks on the daVinci Surgical System™ in the video trainer box.Introduction: The clinical application of robotic surgery is increasing. The skills necessary to perform robotic surgery are unique from those required in open and laparoscopic surgery. A validated laparoscopic surgical skills curriculum (Fundamentals of Laparoscopic Surgery or FLS™) has transformed the way surgeons acquire laparoscopic skills. There is a need for a similar skills training and assessment tool for robotic surgery. Our research group previously developed and validated a robotic training curriculum in a virtual reality (VR) simulator. We hypothesized that novice robotic surgeons could achieve proficiency levels defined by more experienced robotic surgeons on the VR robotic curriculum, and that this would result in improved performance on the actual daVinci Surgical System™.Results: All subjects to complete the study (1 dropped out) reached proficiency levels on all VR tasks in an average of 71 (± 21.7) attempts, accumulating 164.3 (± 55.7) minutes of console training time. There was a significant improvement in performance on the robotic FLS tasks following completion of the VR training curriculum.Conclusions: Novice robotic surgeons are able to attain proficiency levels on a VR simulator. This leads to improved performance in the daVinci surgical platform on simulated tasks. Training to proficiency on a VR robotic surgery simulator is an efficient and viable method for acquiring robotic surgical skills. © 2014, Springer Science+Business Media New York.","Fundamentals of laparoscopic surgery; Proficiency training; Robotic surgery; Simulation; Virtual reality","clinical competence; clinical trial; computer interface; computer simulation; curriculum; education; educational model; human; laparoscopy; medical education; medical student; procedures; robotics; task performance; United States; Clinical Competence; Computer Simulation; Curriculum; Education, Medical, Undergraduate; Humans; Laparoscopy; Models, Educational; Robotics; Students, Medical; Task Performance and Analysis; United States; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84931374502
"Chellali A., Zhang L., Sankaranarayanan G., Arikatla V.S., Ahn W., Derevianko A., Schwaitzberg S.D., Jones D.B., DeMoya M., Cao C.G.L.","26767578800;37076447700;15623319200;26654027600;9334513400;36893032600;7007036892;55387240300;57208993340;25957557800;","Validation of the VBLaST peg transfer task: a first step toward an alternate training standard",2014,"Surgical Endoscopy","28","10",,"2856","2862",,12,"10.1007/s00464-014-3538-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936111555&doi=10.1007%2fs00464-014-3538-2&partnerID=40&md5=275bd2100968f7dc0ddd99297a4eeaff","Department of Surgery, Cambridge Health Alliance, Harvard Medical School, Cambridge, MA, United States; Department of Computer Engineering, University of Evry, IBISC Laboratory, Evry, France; Department of Mechanical Engineering, Tufts University, Medford, MA, United States; Center for Modeling, Simulation and Imaging in Medicine, Rensselaer Polytechnic Institute, Troy, NY, United States; Department of Surgery, Massachusetts General Hospital, Boston, MA, United States; Department of Surgery, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; Department of Biomedical, Industrial and Human Factors Engineering, Wright State University, 207 Russ Engineering Center, 3640 Colonel Glenn Hwy, Dayton, OH  45435, United States","Chellali, A., Department of Surgery, Cambridge Health Alliance, Harvard Medical School, Cambridge, MA, United States, Department of Computer Engineering, University of Evry, IBISC Laboratory, Evry, France; Zhang, L., Department of Mechanical Engineering, Tufts University, Medford, MA, United States; Sankaranarayanan, G., Center for Modeling, Simulation and Imaging in Medicine, Rensselaer Polytechnic Institute, Troy, NY, United States; Arikatla, V.S., Center for Modeling, Simulation and Imaging in Medicine, Rensselaer Polytechnic Institute, Troy, NY, United States; Ahn, W., Center for Modeling, Simulation and Imaging in Medicine, Rensselaer Polytechnic Institute, Troy, NY, United States; Derevianko, A., Department of Surgery, Massachusetts General Hospital, Boston, MA, United States; Schwaitzberg, S.D., Department of Surgery, Cambridge Health Alliance, Harvard Medical School, Cambridge, MA, United States; Jones, D.B., Department of Surgery, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; DeMoya, M., Department of Surgery, Massachusetts General Hospital, Boston, MA, United States; Cao, C.G.L., Department of Biomedical, Industrial and Human Factors Engineering, Wright State University, 207 Russ Engineering Center, 3640 Colonel Glenn Hwy, Dayton, OH  45435, United States","Background: The FLS trainer lacks objective and automated assessments of laparoscopic performance and requires a large supply of relatively expensive consumables. Virtual reality simulation has a great potential as a training and assessment tool of laparoscopic skills and can overcome some limitations of the FLS trainer. This study was carried out to assess the value of our Virtual Basic Laparoscopic Surgical Trainer (VBLaST©) in the peg transfer task compared to the FLS trainer and its ability to differentiate performance between novice, intermediate, and expert groups. Methods: Thirty subjects were divided into three groups: novices (PGY1-2, n = 10), intermediates (PGY3-4, n = 10), and experts (PGY5, surgical fellows and attendings, n = 10). All subjects performed ten trials of the peg transfer task on each simulator. Assessment of laparoscopic performance was based on FLS scoring while a questionnaire was used for subjective evaluation. Results: The performance scores in the two simulators were correlated, though subjects performed significantly better in the FLS trainer. Experts performed better than novices only on the FLS trainer while no significant differences were observed between the other groups. Moreover, a significant learning effect was found on both trainers, with a greater improvement of performance on the VBLaST©. Finally, 82.6 % of the subjects preferred the FLS over the VBLaST© for surgical training which could be attributed to the novelty of the VR technology and existing deficiencies of the user interface for the VBLaST©. Conclusion: This study demonstrated that the VBLaST© reproduced faithfully some aspects of the FLS peg transfer task (such as color, size, and shape of the peg board, etc.) while other aspects require additional development. Future improvement of the user interface and haptic feedback will enhance the value of the system as an alternative to the FLS as the standard training tool for laparoscopic surgery skills. © 2014, Springer Science+Business Media New York.","Force feedback; Fundamentals of Laparoscopic Skills (FLS); Surgical training; Virtual Basic Laparoscopic Surgical Trainer (VBLaST); Virtual reality (VR)","adult; Article; clinical article; controlled study; eye hand coordination; feedback system; female; health care personnel; human; laparoscopic surgery; male; outcome assessment; priority journal; psychomotor performance; questionnaire; surgical training; task performance; virtual basic laparoscopic surgical trainer; virtual reality; clinical competence; computer interface; computer simulation; education; laparoscopy; middle aged; validation study; Adult; Clinical Competence; Computer Simulation; Feedback; Female; Humans; Laparoscopy; Male; Middle Aged; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84936111555
"Arikatla V.S., Ahn W., Sankaranarayanan G., De S.","26654027600;9334513400;15623319200;7202304567;","Towards virtual FLS: Development of a peg transfer simulator",2014,"International Journal of Medical Robotics and Computer Assisted Surgery","10","3",,"344","355",,8,"10.1002/rcs.1534","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908293801&doi=10.1002%2frcs.1534&partnerID=40&md5=50454b1c40156f225271110ab5e874e9","Department of Mechanical, Aerospace and Nuclear Engineering, Rensselaer Polytechnic Institute, Troy, United States","Arikatla, V.S., Department of Mechanical, Aerospace and Nuclear Engineering, Rensselaer Polytechnic Institute, Troy, United States; Ahn, W., Department of Mechanical, Aerospace and Nuclear Engineering, Rensselaer Polytechnic Institute, Troy, United States; Sankaranarayanan, G., Department of Mechanical, Aerospace and Nuclear Engineering, Rensselaer Polytechnic Institute, Troy, United States; De, S., Department of Mechanical, Aerospace and Nuclear Engineering, Rensselaer Polytechnic Institute, Troy, United States","Background: Peg transfer is one of five tasks in the Fundamentals of Laparoscopic Surgery (FLS), program. This paper reports the development and validation of a Virtual Basic Laparoscopic Skill Trainer-Peg Transfer (VBLaST-PT) simulator for automatic real-time scoring and objective quantification of performance. Methods: New techniques have been introduced in order to allow bi-manual manipulation of pegs and automatic scoring/evaluation while maintaining high quality of simulation. A preliminary face and construct validation study was performed with 22 subjects divided into two groups: experts (PGY 4-5, fellow and practicing surgeons) and novice (PGY 1-3). Results: Face validation shows high scores for all aspects of the simulation. Two-tailed Mann-Whitney U-test scores showed significant differences between the two groups on completion time (P=0.003), FLS score (P=0.002) and the VBLaST-PT; score (P=0.006). Conclusions: VBLaST-PT is a high quality virtual simulator that showed both face and construct validity. © 2013 John Wiley & Sons, Ltd.","Construct validation; Face validation; Haptics; Minimally invasive surgery; Physics-based simulation; Surgical simulation; Virtual reality","Article; computer interface; construct validity; controlled study; face validity; human; mathematical model; simulation training; simulator; surgeon; surgical training; validation study; virtual basic laparoscopic skill trainer peg transfer simulator; virtual reality; algorithm; clinical competence; computer; computer simulation; education; equipment design; hand strength; laparoscopy; procedures; reproducibility; robotic surgical procedure; robotics; task performance; touch; Algorithms; Clinical Competence; Computer Simulation; Computers; Equipment Design; Hand Strength; Humans; Laparoscopy; Reproducibility of Results; Robotic Surgical Procedures; Robotics; Task Performance and Analysis; Touch; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84908293801
"Powell W., Simmonds M.J.","35243433300;7103093809;","Virtual reality and musculoskeletal pain: Manipulating sensory cues to improve motor performance during walking",2014,"Cyberpsychology, Behavior, and Social Networking","17","6",,"390","396",,5,"10.1089/cyber.2014.0061","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901952361&doi=10.1089%2fcyber.2014.0061&partnerID=40&md5=fd3741a64568e340ca0b65eba687d83d","University of Portsmouth, School of Creative Technologies, Eldon Building, Winston Churchill Avenue, Portsmouth P01 2DJ, United Kingdom; University of Texas HSC, San Antonio, TX, United States","Powell, W., University of Portsmouth, School of Creative Technologies, Eldon Building, Winston Churchill Avenue, Portsmouth P01 2DJ, United Kingdom; Simmonds, M.J., University of Texas HSC, San Antonio, TX, United States","Musculoskeletal pain (MSP) is the most expensive nonmalignant health problem and the most common reason for activity limitation. Treatment approaches to improve movement without aggravating pain are urgently needed. Virtual reality (VR) can decrease acute pain, as well as influence movement speed. It is not clear whether VR can improve movement speed in individuals with MSP without aggravating pain. This study investigated the extent to which different audio and optic flow cues in a VR environment influenced walking speed in people with and without MSP. A total of 36 subjects participated, 19 with MSP and 17 controls. All walked on a motorized self-paced treadmill interfaced with a three-dimensional virtual walkway. The audio tempo was scaled (75%, 100%, and 125%) from baseline cadence, and optic flow was either absent, or scaled to 50% or 100% of preferred walking speed. Gait speed was measured during each condition, and pain was measured before and after the experiment. Repeated measures analysis of variance showed that audio tempo above baseline cadence significantly increased walking speed in both groups, F(3, 99)=10.41, p<0.001. Walking speed increases of more than 25% occurred in both groups in the 125% audio tempo condition, without any significant increase in pain. There was also a trend toward increased walking speeds with the use of optic flow, but the results in this study did not achieve significance at the p<0.05 level, F(2, 66)=2.01, p=0.14. Further research is needed to establish the generalizability of increasing movement speed across different physical performance tasks in VR. © Copyright 2014, Mary Ann Liebert, Inc. 2014.",,"adult; article; association; controlled clinical trial; controlled study; female; gait; human; male; methodology; middle aged; motor performance; musculoskeletal pain; psychological aspect; virtual reality exposure therapy; walking; Adult; Cues; Female; Gait; Humans; Male; Middle Aged; Motor Skills; Musculoskeletal Pain; Virtual Reality Exposure Therapy; Walking",Article,"Final","",Scopus,2-s2.0-84901952361
"Thurley K., Henke J., Hermann J., Ludwig B., Tatarau C., Wätzig A., Herz A.V.M., Grothe B., Leibold C.","24177446700;56106309600;36741578100;57197120229;56105501500;56106394000;56105419100;7003374577;6603862645;","Mongolian gerbils learn to navigate in complex virtual spaces",2014,"Behavioural Brain Research","266",,,"161","168",,8,"10.1016/j.bbr.2014.03.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897829904&doi=10.1016%2fj.bbr.2014.03.007&partnerID=40&md5=6c59580c3a3b80bd59168e65206ec8cd","Department Biologie II, Ludwig-Maximilians-Universität München, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany; Bernstein Center for Computational Neuroscience Munich, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany","Thurley, K., Department Biologie II, Ludwig-Maximilians-Universität München, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany, Bernstein Center for Computational Neuroscience Munich, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany; Henke, J., Department Biologie II, Ludwig-Maximilians-Universität München, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany; Hermann, J., Department Biologie II, Ludwig-Maximilians-Universität München, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany, Bernstein Center for Computational Neuroscience Munich, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany; Ludwig, B., Department Biologie II, Ludwig-Maximilians-Universität München, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany; Tatarau, C., Department Biologie II, Ludwig-Maximilians-Universität München, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany; Wätzig, A., Department Biologie II, Ludwig-Maximilians-Universität München, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany; Herz, A.V.M., Department Biologie II, Ludwig-Maximilians-Universität München, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany, Bernstein Center for Computational Neuroscience Munich, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany; Grothe, B., Department Biologie II, Ludwig-Maximilians-Universität München, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany, Bernstein Center for Computational Neuroscience Munich, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany; Leibold, C., Department Biologie II, Ludwig-Maximilians-Universität München, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany, Bernstein Center for Computational Neuroscience Munich, Großhaderner Str. 2, 82152 Planegg-Martinsried, Germany","Virtual reality (VR) environments are increasingly used to study spatial navigation in rodents. So far behavioral paradigms in virtual realities have been limited to linear tracks or open fields. However, little is known whether rodents can learn to navigate in more complex virtual spaces. We used a VR setup with a spherical treadmill but no head-fixation, which permits animals not only to move in a virtual environment but also to freely rotate around their vertical body axis. We trained Mongolian gerbils to perform spatial tasks in virtual mazes of different complexity. Initially the animals learned to run back and forth between the two ends of a virtual linear track for food reward. Performance, measured as path length and running time between the virtual reward locations, improved to asymptotic performance within about five training sessions. When more complex mazes were presented after this training epoch, the animals generalized and explored the new environments already at their first exposure. In a final experiment, the animals also learned to perform a two-alternative forced choice task in a virtual Y-maze. Our data thus shows that gerbils can be trained to solve spatial tasks in virtual mazes and that this behavior can be used as a readout for psychophysical measurements. © 2014 Elsevier B.V.","Mongolian gerbil; Spatial learning; Spatial navigation; Virtual reality","animal behavior; animal experiment; article; circular maze; comparative study; complex virtual reality; controlled study; decision making; exploratory behavior; feedback system; female; learning; male; maze test; Meriones unguiculatus; nonhuman; parameters; path length; priority journal; psychophysiology; reward; running time; simulation; task performance; U shaped maze; velocity; virtual reality; virtual spatial behavior; visual stimulation; Y-maze test; analysis of variance; animal; association; computer interface; depth perception; gerbil; learning; physiology; rotation; spatial learning; spatial orientation; Analysis of Variance; Animals; Cues; Female; Gerbillinae; Learning; Male; Rotation; Space Perception; Spatial Learning; Spatial Navigation; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84897829904
"Connors E.C., Chrastil E.R., Sánchez J., Merabet L.B.","55363650600;36935391000;7403997772;6603146795;","Virtual environments for the transfer of navigation skills in the blind: A comparison of directed instruction vs. video game based learning approaches",2014,"Frontiers in Human Neuroscience","8","MAY", 223,"","",,34,"10.3389/fnhum.2014.00223","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899692409&doi=10.3389%2ffnhum.2014.00223&partnerID=40&md5=1b8c46d74a0cb5d4ae6dfc55b2edb3e7","The Laboratory for Visual Neuroplasticity, Department of Ophthalmology, Massachusetts Eye and Ear Infirmary, Harvard Medical School, Boston, MA, United States; Department of Psychology, Center for Memory and Brain, Boston University, Boston, MA, United States; Department of Computer Science, Center for Advanced Research in Education, University of Chile, Santiago, Chile","Connors, E.C., The Laboratory for Visual Neuroplasticity, Department of Ophthalmology, Massachusetts Eye and Ear Infirmary, Harvard Medical School, Boston, MA, United States; Chrastil, E.R., Department of Psychology, Center for Memory and Brain, Boston University, Boston, MA, United States; Sánchez, J., Department of Computer Science, Center for Advanced Research in Education, University of Chile, Santiago, Chile; Merabet, L.B., The Laboratory for Visual Neuroplasticity, Department of Ophthalmology, Massachusetts Eye and Ear Infirmary, Harvard Medical School, Boston, MA, United States","For profoundly blind individuals, navigating in an unfamiliar building can represent a significant challenge. We investigated the use of an audio-based, virtual environment called Audio-based Environment Simulator (AbES) that can be explored for the purposes of learning the layout of an unfamiliar, complex indoor environment. Furthermore, we compared two modes of interaction with AbES. In one group, blind participants implicitly learned the layout of a target environment while playing an exploratory, goal-directed video game. By comparison, a second group was explicitly taught the same layout following a standard route and instructions provided by a sighted facilitator. As a control, a third group interacted with AbES while playing an exploratory, goal-directed video game however, the explored environment did not correspond to the target layout. Following interaction with AbES, a series of route navigation tasks were carried out in the virtual and physical building represented in the training environment to assess the transfer of acquired spatial information. We found that participants from both modes of interaction were able to transfer the spatial knowledge gained as indexed by their successful route navigation performance. This transfer was not apparent in the control participants. Most notably, the game-based learning strategy was also associated with enhanced performance when participants were required to find alternate routes and short cuts within the target building suggesting that a ludic-based training approach may provide for a more flexible mental representation of the environment. Furthermore, outcome comparisons between early and late blind individuals suggested that greater prior visual experience did not have a significant effect on overall navigation performance following training. Finally, performance did not appear to be associated with other factors of interest such as age, gender, and verbal memory recall. We conclude that the highly interactive and immersive exploration of the virtual environment greatly engages a blind user to develop skills akin to positive near transfer of learning. Learning through a game play strategy appears to confer certain behavioral advantages with respect to how spatial information is acquired and ultimately manipulated for navigation. © 2014 Connors, Chrastil, Sánchez and Merabet.","Early blind; Games for learning; Late blind; Navigation; Near transfer of learning; Spatial cognition; Videogames; Virtual environment","adult; article; blindness; clinical article; cognition; comparative study; computer program; controlled study; explicit memory; female; human; male; navigation; recreation; self evaluation; simulation; spatial learning; task performance; verbal memory; virtual reality",Article,"Final","",Scopus,2-s2.0-84899692409
"Zhou X., Liu Y., Ma J., Sui T., Ge Y., Cao X.","55998796500;55999542900;53980238400;55972372800;34770469600;8963608700;","Extradural nerve anastomosis technique for bladder reinnervation in spinal cord injury: Anatomical feasibility study in human cadavers",2014,"Spine","39","8",,"635","641",,9,"10.1097/BRS.0000000000000208","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84921983322&doi=10.1097%2fBRS.0000000000000208&partnerID=40&md5=64dcfccc547a0dc96499f680cf086dd5","Department of Orthopedics, First Affiliated Hospital of Nanjing Medical University, 300 Guangzhou Road, Nanjing, Jiangsu Province, 210029, China; Department of Orthopedics, People's Hospital of Suqian, Drum Tower Hospital Group of Nanjing, Jiangsu Province, China; Department of Physiology, Nanjing Medical University, 140 Hanzhong Rd, Nanjing, Jiangsu, 210029, China","Zhou, X., Department of Orthopedics, First Affiliated Hospital of Nanjing Medical University, 300 Guangzhou Road, Nanjing, Jiangsu Province, 210029, China; Liu, Y., Department of Orthopedics, First Affiliated Hospital of Nanjing Medical University, 300 Guangzhou Road, Nanjing, Jiangsu Province, 210029, China; Ma, J., Department of Orthopedics, People's Hospital of Suqian, Drum Tower Hospital Group of Nanjing, Jiangsu Province, China; Sui, T., Department of Orthopedics, First Affiliated Hospital of Nanjing Medical University, 300 Guangzhou Road, Nanjing, Jiangsu Province, 210029, China; Ge, Y., Department of Physiology, Nanjing Medical University, 140 Hanzhong Rd, Nanjing, Jiangsu, 210029, China; Cao, X., Department of Orthopedics, First Affiliated Hospital of Nanjing Medical University, 300 Guangzhou Road, Nanjing, Jiangsu Province, 210029, China","Study Design. An anatomic study of extradural spinal root in 9 embalmed cadavers. Objective. To ascertain the anatomical parameters of the extradural spinal root and to demonstrate the feasibility of spinal root anastomoses without opening the spinal dura mater. Summary of Background Data. Intradural anastomosis of the spinal root has made breakthrough progress in treating neurogenic bladder in spinal cord injury. However, because of the complex surgical procedures and extensive bony destruction, its clinical use is not widely promoted. Methods. Nine formalin-fixed cadavers were used. The distance between the nerve root outlet and ganglion center, the neighboring nerve root-outlet distance, and the gross anatomy of the extradural spinal root were measured with a surgical microscope. The number of nerve fibers from the T7 to S4 ventral roots (VRs) was calculated by immunohistochemical staining. Results. The longest and shortest lengths of the extradural spinal root were observed at the S4 and T7 levels, with average values of 33.29 and 6.06 mm, respectively. The longest distance between the adjacent nerve root outlets was observed at L1-L2 (mean, 29.16 mm), and shortest at S3-S4 (mean, 11.79 mm). After leaving the dural sac, the spinal root descends in the spinal canal until reaching the corresponding intervertebral foramina, and the motor nerve roots still lie ventrally to the sensory nerve roots. The largest and smallest numbers of nerve fibers were observed at the L3 and S4 levels (mean, 9169 and 1356, respectively). Conclusion. The dorsal roots and VRs can both be successfully harvested and identified outside the dural sac. The S1 VR can be anastomosed to the S2 VR extradurally without nerve grafts. For extradural neuroanastomosis of the thoracic VRs to the S2 VR, a nerve graft is required. In addition, there are a sufficient number of nerve fibers for functional bladder recovery at the T7-T12 and S1 levels. This study supports the feasibility of extradural spinal root anastomosis as a modified surgical method for treating neurogenic bladder. Copyright © 2014 Lippincott Williams &Wilkins.","Bladder reinnervation; Modified nerve transfer; Spinal cord injury (SCI).","formaldehyde; adult; aged; Article; bladder innervation; cadaver; clinical article; dorsal root; dura mater; embalming; feasibility study; female; ganglion; histology; human; human tissue; immunohistochemistry; lumbar spinal cord; male; nerve anastomosis; nerve root; neurogenic bladder; priority journal; reinnervation; sensory nerve; spinal cord injury; spinal cord surgery; spinal root; surgical anatomy; surgical microscope; ventral root; vertebral canal; anastomosis; anatomic landmark; anatomy and histology; bladder; chemistry; complication; convalescence; evaluation study; innervation; middle aged; neurosurgery; pathophysiology; plastic surgery; spinal cord injury; spinal root; surgery; Urinary Bladder, Neurogenic; Aged; Anastomosis, Surgical; Anatomic Landmarks; Cadaver; Feasibility Studies; Female; Humans; Immunohistochemistry; Male; Middle Aged; Neurosurgical Procedures; Reconstructive Surgical Procedures; Recovery of Function; Spinal Cord Injuries; Spinal Nerve Roots; Urinary Bladder; Urinary Bladder, Neurogenic",Article,"Final","",Scopus,2-s2.0-84921983322
"Connors E.C., Chrastil E.R., Sánchez J., Merabet L.B.","55363650600;36935391000;7403997772;6603146795;","Action video game play and transfer of navigation and spatial cognition skills in adolescents who are blind",2014,"Frontiers in Human Neuroscience","8","MAR", 133,"","",,36,"10.3389/fnhum.2014.00133","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896989398&doi=10.3389%2ffnhum.2014.00133&partnerID=40&md5=04eb798757de38dc99f74a8326380b0f","The Laboratory for Visual Neuroplasticity, Department of Ophthalmology, Massachusetts Eye and Ear Infirmary, Harvard Medical School, Boston, MA, United States; Department of Psychological and Brain Sciences, Center for Memory and Brain, Boston University, Boston, MA, United States; Department of Computer Science, Center for Advanced Research in Education, University of Chile, Santiago, Chile","Connors, E.C., The Laboratory for Visual Neuroplasticity, Department of Ophthalmology, Massachusetts Eye and Ear Infirmary, Harvard Medical School, Boston, MA, United States; Chrastil, E.R., Department of Psychological and Brain Sciences, Center for Memory and Brain, Boston University, Boston, MA, United States; Sánchez, J., Department of Computer Science, Center for Advanced Research in Education, University of Chile, Santiago, Chile; Merabet, L.B., The Laboratory for Visual Neuroplasticity, Department of Ophthalmology, Massachusetts Eye and Ear Infirmary, Harvard Medical School, Boston, MA, United States","For individuals who are blind, navigating independently in an unfamiliar environment represents a considerable challenge. Inspired by the rising popularity of video games, we have developed a novel approach to train navigation and spatial cognition skills in adolescents who are blind. Audio-based Environment Simulator (AbES) is a software application that allows for the virtual exploration of an existing building set in an action video game metaphor. Using this ludic-based approach to learning, we investigated the ability and efficacy of adolescents with early onset blindness to acquire spatial information gained from the exploration of a target virtual indoor environment. Following game play, participants were assessed on their ability to transfer and mentally manipulate acquired spatial information on a set of navigation tasks carried out in the real environment. Success in transfer of navigation skill performance was markedly high suggesting that interacting with AbES leads to the generation of an accurate spatial mental representation. Furthermore, there was a positive correlation between success in game play and navigation task performance. The role of virtual environments and gaming in the development of mental spatial representations is also discussed. We conclude that this game based learning approach can facilitate the transfer of spatial knowledge and further, can be used by individuals who are blind for the purposes of navigation in real-world environments. © 2014 Connors, Chrastil, Sánchez and Merabet.","Adolescent; Early blind; Gaming for learning; Navigation; Serious videogames; Spatial cognition; Virtual environment","adolescent; article; Audio based Environment Simulator; blindness; clinical article; cognition; computer program; controlled study; data analysis software; female; game; human; neuronavigation; nonhuman; perception; social interaction; spatial learning; task performance; video game; virtual reality; working memory",Article,"Final","",Scopus,2-s2.0-84896989398
"Schmuker M., Pfeil T., Nawrot M.P.","6507693639;55339892000;7004343639;","A neuromorphic network for generic multivariate data classification",2014,"Proceedings of the National Academy of Sciences of the United States of America","111","6",,"2081","2086",,53,"10.1073/pnas.1303053111","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893861508&doi=10.1073%2fpnas.1303053111&partnerID=40&md5=5758c8062476126cb2d1c9f57369f207","Institute for Biology, Department of Biology Chemistry and Pharmacy, Freie Universität Berlin, 14195 Berlin, Germany; Bernstein Center for Computational Neuroscience Berlin, 10119 Berlin, Germany; Kirchhoff-Institute for Physics, Heidelberg University, 69120 Heidelberg, Germany","Schmuker, M., Institute for Biology, Department of Biology Chemistry and Pharmacy, Freie Universität Berlin, 14195 Berlin, Germany, Bernstein Center for Computational Neuroscience Berlin, 10119 Berlin, Germany; Pfeil, T., Kirchhoff-Institute for Physics, Heidelberg University, 69120 Heidelberg, Germany; Nawrot, M.P., Institute for Biology, Department of Biology Chemistry and Pharmacy, Freie Universität Berlin, 14195 Berlin, Germany, Bernstein Center for Computational Neuroscience Berlin, 10119 Berlin, Germany","Computational neuroscience has uncovered a number of computational principles used by nervous systems. At the same time, neuromorphic hardware has matured to a state where fast silicon implementations of complex neural networks have become feasible. En route to future technical applications of neuromorphic computing the current challenge lies in the identification and implementation of functional brain algorithms. Taking inspiration from the olfactory system of insects, we constructed a spiking neural network for the classification of multivariate data, a common problem in signal and data analysis. In this model, real-valued multivariate data are converted into spike trains using virtual receptors (VRs). Their output is processed by lateral inhibition and drives a winner-take-all circuit that supports supervised learning. VRs are conveniently implemented in software, whereas the lateral inhibition and classification stages run on accelerated neuromorphic hardware. When trained and tested on real-world datasets, we find that the classification performance is on par with a naïve Bayes classifier. An analysis of the network dynamics shows that stable decisions in output neuron populations are reached within less than 100 ms of biological time, matching the time-to-decision reported for the insect nervous system. Through leveraging a population code, the network tolerates the variability of neuronal transfer functions and trial-totrial variation that is inevitably present on the hardware system. Our work provides a proof of principle for the successful implementation of a functional spiking neural network on a configurable neuromorphic hardware system that can readily be applied to realworld computing problems.","Bioinspired computing; Machine learning; Multivariate classification; Spiking networks","bioinspired computing; machine learning; multivariate classification; spiking networks; Algorithms; Bayes Theorem; Brain; Learning; Multivariate Analysis; Neural Networks (Computer)",Article,"Final","",Scopus,2-s2.0-84893861508
"Covaci A., Olivier A.-H., Multon F.","56419559200;15761037000;6602128151;","Third person view and guidance for more natural motor behaviour in immersive basketball playing",2014,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,,,"55","64",,19,"10.1145/2671015.2671023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911165254&doi=10.1145%2f2671015.2671023&partnerID=40&md5=96d2c2541f6beaa265768ac7208a6e8b","Middlesex University London, United Kingdom; Inria, France; M2S Lab, University Rennes2, Inria, France","Covaci, A., Middlesex University London, United Kingdom; Olivier, A.-H., Inria, France; Multon, F., M2S Lab, University Rennes2, Inria, France","The use of Virtual Reality (VR) in sports training is now widely studied with the perspective to transfer motor skills learned in virtual environments (VEs) to real practice. However precision motor tasks that require high accuracy have been rarely studied in the context of VE, especially in Large Screen Image Display (LSID) platforms. An example of such a motor task is the basketball free throw, where the player has to throw a ball in a 46cm wide basket placed at 4.2m away from her. In order to determine the best VE training conditions for this type of skill, we proposed and compared three training paradigms. These training conditions were used to compare the combinations of different user perspectives: first (1PP) and third-person (3PP) perspectives, and the effectiveness of visual guidance. We analysed the performance of eleven amateur subjects who performed series of free throws in a real and immersive 1:1 scale environment under the proposed conditions. The results show that ball speed at the moment of the release in 1PP was significantly lower compared to real world, supporting the hypothesis that distance is underestimated in large screen VEs. However ball speed in 3PP condition was more similar to the real condition, especially if combined with guidance feedback. Moreover, when guidance information was proposed, the subjects released the ball at higher - and closer to optimal - position (5-7% higher compared to no-guidance conditions). This type of information contributes to better understand the impact of visual feedback on the motor performance of users who wish to train motor skills using immersive environments. Moreover, this information can be used by exergames designers who wish to develop coaching systems to transfer motor skills learned in VEs to real practice. Copyright © 2014 by the Association for Computing Machinery, Inc (ACM).","Basketball training; Immersive room; Perception of distance in VR; Performance; Visual feedback","Virtual reality; Visual communication; Guidance feedbacks; Guidance information; Immersive; Immersive environment; Motor performance; Performance; Training conditions; Visual feedback; Sports",Conference Paper,"Final","",Scopus,2-s2.0-84911165254
"Falah J., Khan S., Alfalah T., Alfalah S.F.M., Chan W., Harrison D.K., Charissis V.","55350011200;55869080000;56410895700;55583479900;55471377200;7403545546;22733653900;","Virtual Reality medical training system for anatomy education",2014,"Proceedings of 2014 Science and Information Conference, SAI 2014",,, 6918271,"752","758",,28,"10.1109/SAI.2014.6918271","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84909594509&doi=10.1109%2fSAI.2014.6918271&partnerID=40&md5=48368b5ac00dfd3e6a7d06f299067683","School of Engineering and Built Environment, Glasgow Caledonian University, Cowcaddens Road, Glasgow, G4 0BA, United Kingdom; School of Business, Applied Science University, Amman, Jordan; King Abdullah II School for Information Technology, University of Jordan, Amman, Jordan","Falah, J., School of Engineering and Built Environment, Glasgow Caledonian University, Cowcaddens Road, Glasgow, G4 0BA, United Kingdom; Khan, S., School of Engineering and Built Environment, Glasgow Caledonian University, Cowcaddens Road, Glasgow, G4 0BA, United Kingdom; Alfalah, T., School of Business, Applied Science University, Amman, Jordan; Alfalah, S.F.M., King Abdullah II School for Information Technology, University of Jordan, Amman, Jordan; Chan, W., School of Engineering and Built Environment, Glasgow Caledonian University, Cowcaddens Road, Glasgow, G4 0BA, United Kingdom; Harrison, D.K., School of Engineering and Built Environment, Glasgow Caledonian University, Cowcaddens Road, Glasgow, G4 0BA, United Kingdom; Charissis, V., School of Engineering and Built Environment, Glasgow Caledonian University, Cowcaddens Road, Glasgow, G4 0BA, United Kingdom","Medical education is a dynamic field that witnesses continuous evolution and development. The employment of Virtual Reality (VR) based visualization and training environments in the delivery of anatomy teaching transfers the learning experience from one that involves memorising the structures without a true understanding of the 3-Dimensional (3D) relations, to a process that involves a thorough understanding of the structure based on visualisation rather than memorising, which makes the learning process more efficient and enjoyable, and less time consuming. This paper describes the development of a Virtual Reality and 3D visualisation system for anatomy teaching. The developed system offers a real-time 3D representation of the heart in an interactive VR environment that provides self-directed learning and assessment tools through a variety of interfaces and functionalities. To ensure the accuracy and precision of the developed system it was evaluated by a group of medical professionals. © 2014 The Science and Information (SAI) Organization.","3D; Anatomy; Heart; Medical Education; Virtual Reality","Heart; Medical education; Three dimensional computer graphics; Virtual reality; Visualization; 3D; 3d representations; Accuracy and precision; Anatomy; Learning experiences; Medical professionals; Medical training system; Self-directed learning; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-84909594509
"Gruber L., Langlotz T., Sen P., Hoherer T., Schmalstieg D.","57197371956;8250843500;7402920249;56159602900;55101019100;","Efficient and robust radiance transfer for probeless photorealistic augmented reality",2014,"Proceedings - IEEE Virtual Reality",,, 6802044,"15","20",,22,"10.1109/VR.2014.6802044","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900535157&doi=10.1109%2fVR.2014.6802044&partnerID=40&md5=ac44806520e5403714f1820be9b679e1","Graz University of Technology, Austria; University of California, Santa Barbara, United States","Gruber, L., Graz University of Technology, Austria; Langlotz, T., Graz University of Technology, Austria; Sen, P., University of California, Santa Barbara, United States; Hoherer, T., University of California, Santa Barbara, United States; Schmalstieg, D., Graz University of Technology, Austria","Photorealistic Augmented Reality (AR) requires knowledge of the scene geometry and environment lighting to compute photometric registration. Recent work has introduced probeless photometric registration, where environment lighting is estimated directly from observations of reflections in the scene rather than through an invasive probe such as a reflective ball. However, computing the dense radiance transfer of a dynamically changing scene is computationally challenging. In this work, we present an improved radiance transfer sampling approach, which combines adaptive sampling in image and visibility space with robust caching of radiance transfer to yield real time framerates for photorealistic AR scenes with dynamically changing scene geometry and environment lighting. © 2014 IEEE.","Augmented reality; photometric registration; radiance transfer","Computational geometry; Lighting; Photometry; Virtual reality; Adaptive sampling; Environment lighting; Photo-realistic; Photometric registration; Radiance transfer; Real time; Augmented reality",Conference Paper,"Final","",Scopus,2-s2.0-84900535157
"Araujo S.E.A., Delaney C.P., Seid V.E., Imperiale A.R., Bertoncini A.B., Nahas S.C., Cecconello I.","55788278900;7103378404;6506919015;6604032220;54681643900;7004706439;54979488500;","Short-duration virtual reality simulation training positively impacts performance during laparoscopic colectomy in animal model: Results of a single-blinded randomized trial - VR warm-up for laparoscopic colectomy",2014,"Surgical Endoscopy","28","9",,"2547","2554",,11,"10.1007/s00464-014-3500-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84906937962&doi=10.1007%2fs00464-014-3500-3&partnerID=40&md5=90d44c151ec09287a2901d4632bc9429","Department of Gastroenterology, University of Sao Paulo Medical School, São Paulo, Brazil; Colorectal Surgery Division, University of Sao Paulo Medical Center, São Paulo, SP, Brazil; Av. Dr. Eneas de Carvalho Aguiar, 255, São Paulo, SP 05403-000, Brazil; Case Western Reserve University Center for Skills and Simulation, Cleveland, OH, United States; Digestive Health Institute University Hospitals Case Medical Center, Case Western Reserve University, Cleveland, OH, United States; Digestive Surgery Division, University of Sao Paulo Medical Center, São Paulo, SP, Brazil","Araujo, S.E.A., Department of Gastroenterology, University of Sao Paulo Medical School, São Paulo, Brazil, Colorectal Surgery Division, University of Sao Paulo Medical Center, São Paulo, SP, Brazil, Av. Dr. Eneas de Carvalho Aguiar, 255, São Paulo, SP 05403-000, Brazil; Delaney, C.P., Case Western Reserve University Center for Skills and Simulation, Cleveland, OH, United States, Digestive Health Institute University Hospitals Case Medical Center, Case Western Reserve University, Cleveland, OH, United States; Seid, V.E., Colorectal Surgery Division, University of Sao Paulo Medical Center, São Paulo, SP, Brazil; Imperiale, A.R., Colorectal Surgery Division, University of Sao Paulo Medical Center, São Paulo, SP, Brazil; Bertoncini, A.B., Colorectal Surgery Division, University of Sao Paulo Medical Center, São Paulo, SP, Brazil; Nahas, S.C., Department of Gastroenterology, University of Sao Paulo Medical School, São Paulo, Brazil, Colorectal Surgery Division, University of Sao Paulo Medical Center, São Paulo, SP, Brazil; Cecconello, I., Department of Gastroenterology, University of Sao Paulo Medical School, São Paulo, Brazil, Digestive Surgery Division, University of Sao Paulo Medical Center, São Paulo, SP, Brazil","Background: Several studies have demonstrated skills transfer after virtual reality (VR) simulation training in laparoscopic surgery. However, the impact of VR simulation training on transfer of skills related to laparoscopic colectomy remains not investigated. The present study aimed at determining the impact of VR simulation warm-up on performance during laparoscopic colectomy in the porcine model. Methods: Fourteen residents naive to laparoscopic colectomy as surgeons were randomly assigned in block to two groups. Seven trainees completed a 2-h VR simulator training in the laparoscopic sigmoid colectomy module (study group). The remaining seven surgeons (control group) underwent no intervention. On the same day, all participants performed a sigmoid colectomy with anastomosis on a pig. All operations were video recorded. Two board-certified expert colorectal surgeons independently assessed performance during the colectomy on the swine. Examiners were blinded to group assignment. The two examiners used a previously validated clinical instrument specific to laparoscopic colectomy. The primary outcome was the generic and specific skills score values. Results: Surgeons undergoing short-duration training on the VR simulator performed significantly better during laparoscopic colectomy on the pig regarding general and specific technical skills evaluation. The average score of generic skills was 17.2 (16.5-18) for the control group and 20.1 (16.5-22) for the study group (p = 0.002). The specific skills average score for the control group was 20.2 (19-21.5) and 24.2 (21-27.5) for the study group (p = 0.001). There was acceptable concordance (Kendall's W) regarding the video assessment of generic (W = 0.78) and specific skills (W = 0.84) between the two examiners. Conclusions: A single short-duration VR simulator practice positively impacted surgeons' generic and specific skills performance required to accomplish laparoscopic colectomy in the swine model. © 2014 Springer Science+Business Media.","Clinical skills; Colectomy; Colonic neoplasms; Credentialing; Education; Laparoscopy","article; clinical assessment tool; colon resection; control group; controlled study; human; laparoscopic colectomy; laparoscopic surgery; medical student; nonhuman; performance; porcine model; priority journal; randomized controlled trial; resident; simulation; simulator; single blind procedure; skill; surgeon; surgical training; teaching; videorecording; virtual reality; warm up; animal; animal model; clinical competence; colon resection; computer interface; computer simulation; education; female; laparoscopy; male; procedures; swine; time; Animals; Clinical Competence; Colectomy; Computer Simulation; Female; Humans; Laparoscopy; Male; Models, Animal; Single-Blind Method; Swine; Time Factors; User-Computer Interface; Video Recording",Article,"Final","",Scopus,2-s2.0-84906937962
"Rus-Calafell M., Gutiérrez-Maldonado J., Ribas-Sabaté J.","35094538900;9334173600;51562528400;","A virtual reality-integrated program for improving social skills in patients with schizophrenia: A pilot study",2014,"Journal of Behavior Therapy and Experimental Psychiatry","45","1",,"81","89",,67,"10.1016/j.jbtep.2013.09.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884755111&doi=10.1016%2fj.jbtep.2013.09.002&partnerID=40&md5=3fe06085fe1cfd90d8d00cda727a7ad0","Department of Personality, Assessment and Psychological Treatments, University of Barcelona, Passeig de la Vall d'Hebrón, 171, 08035 Barcelona, Spain; Department of Psychiatry and Mental Health, Igualada General Hospital, Avinguda Catalunya, 11, 08700 Igualada, Spain","Rus-Calafell, M., Department of Personality, Assessment and Psychological Treatments, University of Barcelona, Passeig de la Vall d'Hebrón, 171, 08035 Barcelona, Spain, Department of Psychiatry and Mental Health, Igualada General Hospital, Avinguda Catalunya, 11, 08700 Igualada, Spain; Gutiérrez-Maldonado, J., Department of Personality, Assessment and Psychological Treatments, University of Barcelona, Passeig de la Vall d'Hebrón, 171, 08035 Barcelona, Spain; Ribas-Sabaté, J., Department of Psychiatry and Mental Health, Igualada General Hospital, Avinguda Catalunya, 11, 08700 Igualada, Spain","Background and objectives: Social skills training (SST) intervention has shown its efficacy to improve social dysfunction in patients with psychosis; however the implementation of new skills into patients' everyday functioning is difficult to achieve. In this study, we report results from the application of a virtual reality (VR) integrated program as an adjunct technique to a brief social skills intervention for patients with schizophrenia. It was predicted that the intervention would improve social cognition and performance of patients as well as generalisation of the learned responses into patient's daily life. Methods: Twelve patients with schizophrenia or schizoaffective disorder completed the study. They attended sixteen individual one-hour sessions, and outcome assessments were conducted at pre-treatment, post-treatment and four-month follow-up. Results: The results of a series of repeated measures ANOVA revealed significant improvement in negative symptoms, psychopathology, social anxiety and discomfort, avoidance and social functioning. Objective scores obtained through the use of the VR program showed a pattern of learning in emotion perception, assertive behaviours and time spent in a conversation. Most of these gains were maintained at four-month follow-up. Limitations: The reported results are based on a small, uncontrolled pilot study. Although there was an independent rater for the self-reported and informant questionnaires, assessments were not blinded. Conclusions The results showed that the intervention may be effective for improving social dysfunction. The use of the VR program contributed to the generalisation of new skills into the patient's everyday functioning. © 2013 Elsevier Ltd. All rights reserved.","Psychopathology; Schizophrenia; Social skills training; Virtual reality (VR)","atypical antipsychotic agent; neuroleptic agent; article; assertiveness; avoidance behavior; behavior; clinical article; emotion; female; follow up; human; male; negative syndrome; outcome assessment; pilot study; Positive and Negative Syndrome Scale; reinforcement; schizoaffective psychosis; schizophrenia; social adaptation; social cognition; social interaction; social phobia; virtual reality; Psychopathology; Schizophrenia; Social skills training; Virtual reality (VR); Activities of Daily Living; Adolescent; Adult; Analysis of Variance; Female; Follow-Up Studies; Humans; Male; Middle Aged; Pilot Projects; Psychiatric Status Rating Scales; Schizophrenia; Schizophrenic Psychology; Self Report; Social Behavior Disorders; Treatment Outcome; Virtual Reality Exposure Therapy; Young Adult",Article,"Final","",Scopus,2-s2.0-84884755111
"Trojan J., Diers M., Fuchs X., Bach F., Bekrater-Bodmann R., Foell J., Kamping S., Rance M., Maaß H., Flor H.","56262402900;6603232814;56154824700;55695210800;42260980200;44760992500;6507437083;36791108000;7005301066;7006743137;","An augmented reality home-training system based on the mirror training and imagery approach",2014,"Behavior Research Methods","46","3",,"634","640",,28,"10.3758/s13428-013-0412-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904767056&doi=10.3758%2fs13428-013-0412-4&partnerID=40&md5=fe577624a9748b6fbfbe2bdb194b15b8","Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany; Department of Psychology, University of Koblenz-Landau, Landau, Germany; Institute of Applied Computer Science, Karlsruhe Institute of Technology, Karlsruhe, Germany; Department of Psychology, Florida State University, Tallahassee, FL, United States","Trojan, J., Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany, Department of Psychology, University of Koblenz-Landau, Landau, Germany; Diers, M., Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany; Fuchs, X., Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany; Bach, F., Institute of Applied Computer Science, Karlsruhe Institute of Technology, Karlsruhe, Germany; Bekrater-Bodmann, R., Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany; Foell, J., Department of Psychology, Florida State University, Tallahassee, FL, United States; Kamping, S., Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany; Rance, M., Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany; Maaß, H., Institute of Applied Computer Science, Karlsruhe Institute of Technology, Karlsruhe, Germany; Flor, H., Department of Cognitive und Clinical Neuroscience, Central Institute of Mental Health, Heidelberg University, J 5, 68159 Mannheim, Germany","Mirror training and movement imagery have been demonstrated to be effective in treating several clinical conditions, such as phantom limb pain, stroke-induced hemiparesis, and complex regional pain syndrome. This article presents an augmented reality home-training system based on the mirror and imagery treatment approaches for hand training. A head-mounted display equipped with cameras captures one hand held in front of the body, mirrors this hand, and displays it in real time in a set of four different training tasks: (1) flexing fingers in a predefined sequence, (2) moving the hand into a posture fitting into a silhouette template, (3) driving a ""Snake"" video game with the index finger, and (4) grasping and moving a virtual ball. The system records task performance and transfers these data to a central server via the Internet, allowing monitoring of training progress. We evaluated the system by having 7 healthy participants train with it over the course of ten sessions of 15-min duration. No technical problems emerged during this time. Performance indicators showed that the system achieves a good balance between relatively easy and more challenging tasks and that participants improved significantly over the training sessions. This suggests that the system is well suited to maintain motivation in patients, especially when it is used for a prolonged period of time. © 2013 The Author(s).","Augmented reality; Complex regional pain syndrome; Imagery; Mirror training; Phantom limb pain; Rehabilitation; Stroke; Virtual reality","adult; agnosia; article; cerebrovascular accident; complex regional pain syndrome; equipment design; female; finger; hand; hand strength; human; male; middle aged; movement (physiology); paresis; physiology; psychotherapy; recreation; reproducibility; young adult; Adult; Complex Regional Pain Syndromes; Equipment Design; Female; Fingers; Hand; Hand Strength; Humans; Imagery (Psychotherapy); Male; Middle Aged; Movement; Paresis; Phantom Limb; Reproducibility of Results; Stroke; Video Games; Young Adult",Article,"Final","",Scopus,2-s2.0-84904767056
"Ganier F., Hoareau C., Tisseau J.","6507178310;55975572000;6603486416;","Evaluation of procedural learning transfer from a virtual environment to a real situation: A case study on tank maintenance training",2014,"Ergonomics","57","6",,"828","843",,36,"10.1080/00140139.2014.899628","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901692802&doi=10.1080%2f00140139.2014.899628&partnerID=40&md5=d3e64acf6619d1cb4b87e64de8cc64fe","Lab-STICC, UMR 6285 CNRS, Université Européenne de Bretagne, Université de Bretagne Occidentale, European Center for Virtual Reality, Plouzané, France; Lab-STICC, UMR 6285 CNRS, Université Européenne de Bretagne, École Nationale d'Ingénieurs de Brest, European Center for Virtual Reality, Plouzané, France","Ganier, F., Lab-STICC, UMR 6285 CNRS, Université Européenne de Bretagne, Université de Bretagne Occidentale, European Center for Virtual Reality, Plouzané, France; Hoareau, C., Lab-STICC, UMR 6285 CNRS, Université Européenne de Bretagne, Université de Bretagne Occidentale, European Center for Virtual Reality, Plouzané, France; Tisseau, J., Lab-STICC, UMR 6285 CNRS, Université Européenne de Bretagne, École Nationale d'Ingénieurs de Brest, European Center for Virtual Reality, Plouzané, France","Virtual reality opens new opportunities for operator training in complex tasks. It lowers costs and has fewer constraints than traditional training. The ultimate goal of virtual training is to transfer knowledge gained in a virtual environment to an actual real-world setting. This study tested whether a maintenance procedure could be learnt equally well by virtual-environment and conventional training. Forty-two adults were divided into three equally sized groups: virtual training (GVT® [generic virtual training]), conventional training (using a real tank suspension and preparation station) and control (no training). Participants then performed the procedure individually in the real environment. Both training types (conventional and virtual) produced similar levels of performance when the procedure was carried out in real conditions. Performance level for the two trained groups was better in terms of success and time taken to complete the task, time spent consulting job instructions and number of times the instructor provided guidance. Practitioner Summary: A key issue for virtual environments for training (VETs) is the transfer of skills to real situations. An experiment investigated whether skills acquired in a VET could be applied in a real situation. Results suggest that a procedure can be successfully transferred from the virtual to the real. © 2014 © 2014 Taylor & Francis.","knowledge transfer; maintenance; procedural learning; virtual environments for training (VET); virtual reality","E-learning; Knowledge management; Maintenance; Tanks (containers); Virtual reality; Knowledge transfer; Maintenance procedures; Maintenance training; Operator training; Performance level; Procedural learning; Real environments; Virtual training; Personnel training; adult; comparative study; computer simulation; computer-assisted instruction; Female; Humans; Inservice Training; Maintenance; Male; Manufacturing Industry; methods; Teaching; Transfer (Psychology); User-Computer Interface; Weapons; Young Adult; Adult; Computer Simulation; Computer-Assisted Instruction; Female; Humans; Inservice Training; Maintenance; Male; Manufacturing Industry; Teaching; Transfer (Psychology); User-Computer Interface; Weapons; Young Adult",Article,"Final","",Scopus,2-s2.0-84901692802
"Gutiérrez-Maldonado J., Ferrer-Garcia M., Pla J., Andrés-Pueyo A.","9334173600;13405944200;56040715100;6602452514;","Virtual humans and formative assessment to train diagnostic skills in bulimia nervosa",2014,"Annual Review of CyberTherapy and Telemedicine","12",,,"30","34",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019770155&partnerID=40&md5=870857652d82ae1b43c2859b4d1aeae1","University of Barcelona, Spain","Gutiérrez-Maldonado, J., University of Barcelona, Spain; Ferrer-Garcia, M., University of Barcelona, Spain; Pla, J., University of Barcelona, Spain; Andrés-Pueyo, A., University of Barcelona, Spain","Carrying out a diagnostic interview requires skills that need to be taught in a controlled environment. Virtual Reality (VR) environments are increasingly used in the training of professionals, as they offer the most realistic alternative while not requiring students to face situations for which they are yet unprepared. The results of the training of diagnostic skills can also be generalized to any other situation in which effective communication skills play a major role. Our aim with this study has been to develop a procedure of formative assessment in order to increment the effectiveness of virtual learning simulation systems and then to assess their efficacy. © 2014, Virtual reality med institute. All rights reserved.","Bulimia nervosa; Formative assessment; Medical education; Psychological education; Psychopathological exploration; Virtual humans","Article; bulimia; clinical article; communication skill; controlled study; human; skill; training; virtual reality",Article,"Final","",Scopus,2-s2.0-85019770155
"Gutiérrez-Maldonado J., Ferrer-Garcia M., Pla J., Andrés-Pueyo A.","9334173600;13405944200;56040715100;6602452514;","Virtual humans and formative assessment to train diagnostic skills in bulimia nervosa",2014,"Studies in Health Technology and Informatics","199",,,"30","34",,1,"10.3233/978-1-61499-401-5-30","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84928053013&doi=10.3233%2f978-1-61499-401-5-30&partnerID=40&md5=896116a61e395aac56cb04cd3345f51f","University of Barcelona, Spain","Gutiérrez-Maldonado, J., University of Barcelona, Spain; Ferrer-Garcia, M., University of Barcelona, Spain; Pla, J., University of Barcelona, Spain; Andrés-Pueyo, A., University of Barcelona, Spain","Carrying out a diagnostic interview requires skills that need to be taught in a controlled environment. Virtual Reality (VR) environments are increasingly used in the training of professionals, as they offer the most realistic alternative while not requiring students to face situations for which they are yet unprepared. The results of the training of diagnostic skills can also be generalized to any other situation in which effective communication skills play a major role. Our aim with this study has been to develop a procedure of formative assessment in order to increment the effectiveness of virtual learning simulation systems and then to assess their efficacy. © 2014 The authors and IOS Press.","bulimia nervosa; formative assessment; medical education; psychological education; psychopathological exploration; Virtual humans","Diagnosis; Diseases; Medical education; bulimia nervosa; Controlled environment; Diagnostic skills; Effective communication; Formative assessment; Virtual humans; Virtual learning; Virtual reality; bulimia; forecasting; human; medical education; procedures; simulation training; teaching; trends; virtual reality; Bulimia Nervosa; Computer-Assisted Instruction; Education, Medical; Forecasting; Humans; Simulation Training; Virtual Reality",Article,"Final","",Scopus,2-s2.0-84928053013
"Stelzer R., Steindecker E., Arndt S., Steger W.","26636710000;55820360600;56577560600;7007055664;","Expanding VRPN to tasks in virtual engineering",2014,"Proceedings of the ASME Design Engineering Technical Conference","1B",,,"","",,8,"10.1115/DETC201434277","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961296501&doi=10.1115%2fDETC201434277&partnerID=40&md5=28647ff11b1edd0430e72bf6c5794cec","Technische Universität Dresden, Faculty of Mechanical Engineering, Department of Engineering Design and CAD, Dresden, D-01062, Germany","Stelzer, R., Technische Universität Dresden, Faculty of Mechanical Engineering, Department of Engineering Design and CAD, Dresden, D-01062, Germany; Steindecker, E., Technische Universität Dresden, Faculty of Mechanical Engineering, Department of Engineering Design and CAD, Dresden, D-01062, Germany; Arndt, S., Technische Universität Dresden, Faculty of Mechanical Engineering, Department of Engineering Design and CAD, Dresden, D-01062, Germany; Steger, W., Technische Universität Dresden, Faculty of Mechanical Engineering, Department of Engineering Design and CAD, Dresden, D-01062, Germany","A high variety of peripherals for the interaction between human and computer is available (e.g. Mouse, Touch and Camera). Therefore the peripherals communicate in different ways with the computer and its applications. The library VRPN is a common, generalized interface between peripherals and VR applications to reduce the development effort. Its main advantages are the system independent client-server architecture with real-time capability and the easy implementation of new peripheral devices. The proposed paper describes the adaption and extension of the VRPN concept to address the challenges of engineering like modeling, evaluation, simulation and modification. Innovative interaction devices have the capability to enhance engineering applications with comparatively small effort but great benefit. As an example a VRPN client is implemented into the CAD application SolidWorks. This enables the use of any interaction device which is supported by VRPN. For example, the designer can control the model view by human movement via tracking device like the Microsoft Kinect or the Geomagic Touch. The data transfer can be either established in a synchronous or in an asynchronous manner. Regarding synchronous transfer, the server-client architecture was implemented in different applications (e.g. CAD, VR). In order to realize a time shifted asynchronous transfer a recorder-player middleware was developed. Copyright © 2014 by ASME.",,"Client server computer systems; Computer aided design; Computer peripheral equipment; Data transfer; Design; Human computer interaction; Middleware; CAD applications; Client-server architectures; Engineering applications; Interaction devices; ITS applications; Peripheral devices; Real time capability; Virtual engineering; Interfaces (computer)",Conference Paper,"Final","",Scopus,2-s2.0-84961296501
"Zhang Z., Zhang M., Chang Y., Esche S.K., Chassapis C.","55858936500;55859014100;55501373900;6603892215;7004391468;","An efficient method for creating virtual spaces for virtual reality",2014,"ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)","5",,,"","",,8,"10.1115/IMECE2014-37149","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84926381647&doi=10.1115%2fIMECE2014-37149&partnerID=40&md5=b5aa8fe03dd6ab9d308e4587187e4c7c","Stevens Institute of Technology, Hoboken, IN, United States","Zhang, Z., Stevens Institute of Technology, Hoboken, IN, United States; Zhang, M., Stevens Institute of Technology, Hoboken, IN, United States; Chang, Y., Stevens Institute of Technology, Hoboken, IN, United States; Esche, S.K., Stevens Institute of Technology, Hoboken, IN, United States; Chassapis, C., Stevens Institute of Technology, Hoboken, IN, United States","A virtual space (VS) is an indispensable component of a virtual environment (VE) in virtual reality (VR). Usually, it is created using general tools and skills that are independent of the users' specific applications and intents. Creating a VS by surveying the real world with traditional measuring tools or creating virtual features with CAD software involves many steps and thus is time consuming and complicated. This renders the construction of VEs difficult, impairs their flexibility and hampers their widespread usage. In this paper, an efficient method for creating VSs with a handheld camera is introduced. In this approach, the camera is used as a measuring tool that scans the real scene and obtains the corresponding surface information. This information is then used to generate a virtual 3D model through a series of data processing procedures. Firstly, the camera's pose is traced in order to locate the points of the scene's surface, whereby these surface points form a point cloud. Then, this point cloud is meshed and the mesh elements are textured automatically one by one. Unfortunately, the virtual 3D model resulting from this procedure represents an impenetrable solid and thus collision detection would prevent the avatars from entering into this VS. Therefore, an approach for eliminating this restriction is proposed here. Finally, a game-based virtual laboratory (GBVL) for an undergraduate mechanical engineering class was developed to demonstrate the feasibility of the proposed methodology. The model format used in Garry's Mod (GMod) is also found in other VEs, and therefore the method proposed here can be straightforwardly generalized to other VE implementations. Copyright © 2014 by ASME.","GBVL; GMod; Kinect; VR","Cameras; Data handling; Three dimensional computer graphics; Virtual reality; Collision detection; GBVL; GMod; Kinect; Processing procedures; Surface information; Virtual laboratories; VR; Computer aided design",Conference Paper,"Final","",Scopus,2-s2.0-84926381647
"Jalink M.B., Goris J., Heineman E., Pierie J.P.E.N., Hoedemaker H.O.T.C.","56107478500;55841755100;7005529702;8656937000;55470561000;","Construct and concurrent validity of a Nintendo Wii video game made for training basic laparoscopic skills",2014,"Surgical Endoscopy","28","2",,"537","542",,22,"10.1007/s00464-013-3199-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899478909&doi=10.1007%2fs00464-013-3199-6&partnerID=40&md5=cad21a9dbdee0a93fac5828d9fd05461","Department of Surgery, University Medical Center Groningen, University of Groningen, De Brug, P.O. Box 30 001, 9700 RB Groningen, Netherlands; Wenckebach Institute, University Medical Center Groningen, University of Groningen, Groningen, Netherlands; Department of Surgery, University Medical Center Groningen, University of Groningen, Groningen, Netherlands; Postgraduate School of Medicine, University Medical Center Groningen, University of Groningen, Groningen, Netherlands; Department of Surgery, Medical Center Leeuwarden, Leeuwarden, Netherlands; Leeuwarden Institute for Minimally Invasive Surgery, Medical Center Leeuwarden, Leeuwarden, Netherlands","Jalink, M.B., Department of Surgery, University Medical Center Groningen, University of Groningen, De Brug, P.O. Box 30 001, 9700 RB Groningen, Netherlands; Goris, J., Wenckebach Institute, University Medical Center Groningen, University of Groningen, Groningen, Netherlands; Heineman, E., Department of Surgery, University Medical Center Groningen, University of Groningen, Groningen, Netherlands; Pierie, J.P.E.N., Postgraduate School of Medicine, University Medical Center Groningen, University of Groningen, Groningen, Netherlands, Department of Surgery, Medical Center Leeuwarden, Leeuwarden, Netherlands, Leeuwarden Institute for Minimally Invasive Surgery, Medical Center Leeuwarden, Leeuwarden, Netherlands; Hoedemaker, H.O.T.C., Wenckebach Institute, University Medical Center Groningen, University of Groningen, Groningen, Netherlands, Department of Surgery, University Medical Center Groningen, University of Groningen, Groningen, Netherlands","Background: Virtual reality (VR) laparoscopic simulators have been around for more than 10 years and have proven to be cost- and time-effective in laparoscopic skills training. However, most simulators are, in our experience, considered less interesting by residents and are often poorly accessible. Consequently, these devices are rarely used in actual training. In an effort to make a low-cost and more attractive simulator, a custom-made Nintendo Wii game was developed. This game could ultimately be used to train the same basic skills as VR laparoscopic simulators ought to. Before such a video game can be implemented into a surgical training program, it has to be validated according to international standards. Methods: The main goal of this study was to test construct and concurrent validity of the controls of a prototype of the game. In this study, the basic laparoscopic skills of experts (surgeons, urologists, and gynecologists, n = 15) were compared to those of complete novices (internists, n = 15) using the Wii Laparoscopy (construct validity). Scores were also compared to the Fundamentals of Laparoscopy (FLS) Peg Transfer test, an already established assessment method for measuring basic laparoscopic skills (concurrent validity). Results: Results showed that experts were 111% faster (P = 0.001) on the Wii Laparoscopy task than novices. Also, scores of the FLS Peg Transfer test and the Wii Laparoscopy showed a significant, high correlation (r = 0.812, P < 0.001). Conclusions: The prototype setup of the Wii Laparoscopy possesses solid construct and concurrent validity. © Springer Science+Business Media 2013.","Education; Laparoscopy; Simulator; Video games","adult; article; concurrent validity; construct validity; controlled study; education program; female; gynecologist; human; laparoscopic surgery; laparoscopic surgical instrument; male; motor performance; priority journal; recreation; simulator; skill; surgeon; surgical training; task performance; urologist; virtual reality; clinical competence; computer interface; computer simulation; education; laparoscopy; medical education; physician; procedures; standards; validation study; Clinical Competence; Computer Simulation; Education, Medical, Continuing; Humans; Laparoscopy; Physicians; User-Computer Interface; Video Games",Article,"Final","",Scopus,2-s2.0-84899478909
"Wong Sarver N., Beidel D.C., Spitalnick J.S.","55897023000;7006749171;23480308700;","The Feasibility and Acceptability of Virtual Environments in the Treatment of Childhood Social Anxiety Disorder",2014,"Journal of Clinical Child and Adolescent Psychology","43","1",,"63","73",,30,"10.1080/15374416.2013.843461","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892480783&doi=10.1080%2f15374416.2013.843461&partnerID=40&md5=25af832fdacd7b2a6c0a7f6a8144bc08","Department of Psychology, University of Central Florida, United States; Virtually Better, Inc., United States","Wong Sarver, N., Department of Psychology, University of Central Florida, United States; Beidel, D.C., Department of Psychology, University of Central Florida, United States; Spitalnick, J.S., Virtually Better, Inc., United States","Two significant challenges for the dissemination of social skills training programs are the need to assure generalizability and provide sufficient practice opportunities. In the case of social anxiety disorder, virtual environments may provide one strategy to address these issues. This study evaluated the utility of an interactive virtual school environment for the treatment of social anxiety disorder in preadolescent children. Eleven children with a primary diagnosis of social anxiety disorder between 8 to 12 years old participated in this initial feasibility trial. All children were treated with Social Effectiveness Therapy for Children, an empirically supported treatment for children with social anxiety disorder. However, the in vivo peer generalization sessions and standard parent-assisted homework assignments were substituted by practice in a virtual environment. Overall, the virtual environment programs were acceptable, feasible, and credible treatment components. Both children and clinicians were satisfied with using the virtual environment technology, and children believed it was a high-quality program overall. In addition, parents were satisfied with the virtual environment augmented treatment and indicated that they would recommend the program to family and friends. Findings indicate that the virtual environments are viewed as acceptable and credible by potential recipients. Furthermore, they are easy to implement by even novice users and appear to be useful adjunctive elements for the treatment of childhood social anxiety disorder. © 2014 Copyright Taylor and Francis Group, LLC.",,"article; behavior disorder; child; feasibility study; female; human; male; parent; patient satisfaction; phobia; program evaluation; psychological aspect; treatment outcome; virtual reality exposure therapy; Child; Child Behavior Disorders; Feasibility Studies; Female; Humans; Male; Parents; Patient Satisfaction; Phobic Disorders; Program Evaluation; Treatment Outcome; Virtual Reality Exposure Therapy",Article,"Final","",Scopus,2-s2.0-84892480783
"Luo M.-S., Xie H.-Z., Xie L., Cai P., Gu L.-X.","56416998600;32267720700;7402590591;35812886000;13604940900;","Robust and real-time guidewire simulation based on Kirchhoff elastic rod for vascular intervention training",2014,"Journal of Shanghai Jiaotong University (Science)","19","5",,"624","629",,,"10.1007/s12204-014-1551-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919676052&doi=10.1007%2fs12204-014-1551-1&partnerID=40&md5=904914f1c071a28806540ee5fa127449","School of Biomedical Engineering, Shanghai Jiaotong University, Shanghai, 200240, China; Department of Cardiac Intervention, Beijing Union Medical College Hospital, Beijing, 100110, China; Institute of Forming Technology & Equipment, Shanghai Jiaotong University, Shanghai, 200240, China; School of Electronic Information and Electrical Engineering, Shanghai Jiaotong University, Shanghai, 200240, China","Luo, M.-S., School of Biomedical Engineering, Shanghai Jiaotong University, Shanghai, 200240, China; Xie, H.-Z., Department of Cardiac Intervention, Beijing Union Medical College Hospital, Beijing, 100110, China; Xie, L., Institute of Forming Technology & Equipment, Shanghai Jiaotong University, Shanghai, 200240, China; Cai, P., School of Electronic Information and Electrical Engineering, Shanghai Jiaotong University, Shanghai, 200240, China; Gu, L.-X., School of Biomedical Engineering, Shanghai Jiaotong University, Shanghai, 200240, China","Virtual reality (VR) based vascular intervention training is a fascinating innovation, which helps trainees develop skills in safety remote from patients. The vascular intervention training involves the use of flexible tipped guidewires to advance diagnostic or therapeutic catheters into a patient’s vascular anatomy. In this paper, a real-time physically-based modeling approach is proposed to simulate complicated behaviors of guidewires and catheters based on Kirchhoff elastic rod. The slender body of guidewire and catheter is simulated using more efficient special case of naturally straight, isotropic Kirchhoff rods, and the short flexible tip composed of straight or angled design is modeled using more complex generalized Kirchhoff rods. We derive the equations of motion for guidewire and catheter with continuous elastic energy, and then they were discretized using a linear implicit scheme that guarantees stability and robustness. In addition, we apply a fast-projection method to enforce the inextensibility of guidewire and catheter, while an adaptive sampling algorithm is implemented to improve the simulation efficiency without reducing accuracy. Experimental results reveal that our guidewire simulation method is both robust and efficient in a real-time performance. © 2014, Shanghai Jiaotong University and Springer-Verlag Berlin Heidelberg.","guidewire and catheter; Kirchhoff elastic rod; physically based simulation; vascular intervention","Catheters; Diagnosis; Equations of motion; Virtual reality; Adaptive sampling algorithms; Elastic rod; Guide-wire; Physically based modeling; Physically-based simulation; Real time performance; Stability and robustness; Vascular interventions; Patient treatment",Article,"Final","",Scopus,2-s2.0-84919676052
"Zollmann S., Hoppe C., Langlotz T., Reitmayr G.","8250843400;53163755900;8250843500;6602277577;","FlyAR: Augmented reality supported micro aerial vehicle navigation",2014,"IEEE Transactions on Visualization and Computer Graphics","20","4", 6777462,"560","568",,31,"10.1109/TVCG.2014.24","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897370709&doi=10.1109%2fTVCG.2014.24&partnerID=40&md5=f983e7194988d8162c44ef8f383a2e7d","Graz University of Technology, Austria; Graz University of Technology, University of Otago, Austria","Zollmann, S., Graz University of Technology, Austria; Hoppe, C., Graz University of Technology, Austria; Langlotz, T., Graz University of Technology, University of Otago, Austria; Reitmayr, G., Graz University of Technology, Austria","Micro aerial vehicles equipped with high-resolution cameras can be used to create aerial reconstructions of an area of interest. In that context automatic flight path planning and autonomous flying is often applied but so far cannot fully replace the human in the loop, supervising the flight on-site to assure that there are no collisions with obstacles. Unfortunately, this workflow yields several issues, such as the need to mentally transfer the aerial vehicle&amp;#146;s position between 2D map positions and the physical environment, and the complicated depth perception of objects flying in the distance. Augmented Reality can address these issues by bringing the flight planning process on-site and visualizing the spatial relationship between the planned or current positions of the vehicle and the physical environment. In this paper, we present Augmented Reality supported navigation and flight planning of micro aerial vehicles by augmenting the user's view with relevant information for flight planning and live feedback for flight supervision. Furthermore, we introduce additional depth hints supporting the user in understanding the spatial relationship of virtual waypoints in the physical world and investigate the effect of these visualization techniques on the spatial understanding. © 2014 IEEE.","Augmented reality; Micro aerial vehicles; Visualization","Augmented reality; Depth perception; Flow visualization; Micro air vehicle (MAV); Motion planning; Planning; Area of interest; Automatic flight; High resolution camera; Human-in-the-loop; Micro aerial vehicle; Physical environments; Spatial relationships; Visualization technique; Physical addresses; aircraft; computer interface; depth perception; devices; human; man machine interaction; miniaturization; orientation; physiology; procedures; three dimensional imaging; Aircraft; Depth Perception; Humans; Imaging, Three-Dimensional; Man-Machine Systems; Miniaturization; Orientation; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84897370709
"Matsuda Y., Fushimi S., Terashima K.","56413873300;55941312300;55826255600;","Development of training simulator for sway suppression skills on shipboard rotary cranes",2014,"ICINCO 2014 - Proceedings of the 11th International Conference on Informatics in Control, Automation and Robotics","1",,,"429","440",,1,"10.5220/0005008104330440","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910093215&doi=10.5220%2f0005008104330440&partnerID=40&md5=04aa7dd2eb89957f44bdd92334c2eea1","Toyohashi University of Technology, Mechanical Engineering Department, System and Control Laboratory, Hibarigaoka 1-1, Tempaku Town, Toyohashi City, Japan","Matsuda, Y., Toyohashi University of Technology, Mechanical Engineering Department, System and Control Laboratory, Hibarigaoka 1-1, Tempaku Town, Toyohashi City, Japan; Fushimi, S., Toyohashi University of Technology, Mechanical Engineering Department, System and Control Laboratory, Hibarigaoka 1-1, Tempaku Town, Toyohashi City, Japan; Terashima, K., Toyohashi University of Technology, Mechanical Engineering Department, System and Control Laboratory, Hibarigaoka 1-1, Tempaku Town, Toyohashi City, Japan","In this paper, we develop the operational training system by teaching control input to crane operators. In particular, it is applied to the sway suppression control of load, by utilizing optimal control input. If crane operators can replicate its control input, they can operate crane suppressing the load sway, and hope the advance of training effect. Firstly, we build a shipboard rotary crane simulator, and verify the validity of the training simulator by transfer simulation. Nextly, it presents a sway suppression control method to obtain control input for crane operators, and proposes the training system to teach its control input to operators. Finally, the crane simulator integrates this training system, and the proposed training system verifies the validity by subjects experiments.","Human-machine interface; Industrial control; Ship control; Teaching; Training; Virtual reality","Cranes; Robotics; Ships; Simulators; Teaching; Virtual reality; Human Machine Interface; Industrial controls; Operational training; Optimal controls; Ship control; Suppression control; Training simulator; Transfer simulations; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-84910093215
"Luo M., Xie H., Xie L., Cai P., Gu L.","56416998600;32267720700;7402590591;35812886000;13604940900;","A robust and real-time vascular intervention simulation based on Kirchhoff elastic rod",2014,"Computerized Medical Imaging and Graphics","38","8",,"735","743",,16,"10.1016/j.compmedimag.2014.08.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910626458&doi=10.1016%2fj.compmedimag.2014.08.002&partnerID=40&md5=3ca8fb8ebc79de945dadff425614799b","School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Cardiac Intervention, Beijing Union Medical College Hospital, Beijing, China; Institute of Forming Technology and Equipment, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China","Luo, M., School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; Xie, H., Department of Cardiac Intervention, Beijing Union Medical College Hospital, Beijing, China; Xie, L., Institute of Forming Technology and Equipment, Shanghai Jiao Tong University, Shanghai, China; Cai, P., School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University, Shanghai, China; Gu, L., School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China","A virtual reality (VR) based vascular intervention simulation system is introduced in this paper, which helps trainees develop surgical skills and experience complications in safety remote from patients. The system simulates interventional radiology procedures, in which flexible tipped guidewires are employed to advance diagnostic or therapeutic catheters into vascular anatomy of a patient. A real-time physically-based modeling approach ground on Kirchhoff elastic rod is proposed to simulate complicated behaviors of guidewires and catheters. The slender body of guidewire and catheter is modeled using more efficient special case of naturally straight, isotropic Kirchhoff rods, and the shorter flexible tip composed of straight or angled design is modeled using more complex generalized Kirchhoff rods. The motion equations for guidewire and catheter were derived with continuous elastic energy, followed by a discretization using a linear implicit scheme that guarantees stability and robustness. In addition, we used a fast-projection method to enforce the inextensibility of guidewire and catheter. An adaptive sampling algorithm was also implemented to improve the simulation efficiency without decrease of accuracy. Experimental results revealed that our system is both robust and efficient in a real-time performance. © 2014 Elsevier Ltd.","Guidewire and catheter; Kirchhoff elastic rod; Physically based simulation; Vascular intervention","Catheters; Diagnosis; Equations of motion; Virtual reality; Adaptive sampling algorithms; Elastic rod; Guide-wire; Interventional radiology; Physically based modeling; Physically-based simulation; Stability and robustness; Vascular interventions; Patient treatment; Article; computer simulation; energy; human; interventional cardiovascular procedure; interventional radiology; intravascular catheter; medical student; patient safety; percutaneous coronary intervention; real time vascular intervention; simulation; surgical training; tactile feedback; vascular guide wire; anatomy and histology; artery; biological model; catheter; catheterization; computer interface; computer simulation; computer system; physiology; procedures; teaching; Young modulus; Arteries; Catheterization, Peripheral; Catheters; Computer Simulation; Computer Systems; Computer-Assisted Instruction; Elastic Modulus; Humans; Models, Cardiovascular; Radiography, Interventional; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84910626458
"Pucher P.H., Batrick N., Taylor D., Chaudery M., Cohen D., Darzi A.","50162336700;18133430500;55851945195;16244070000;57214762952;14633357600;","Virtual-world hospital simulation for real-world disaster response: Design and validation of a virtual reality simulator for mass casualty incident management",2014,"Journal of Trauma and Acute Care Surgery","77","2",,"315","321",,29,"10.1097/TA.0000000000000308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905016019&doi=10.1097%2fTA.0000000000000308&partnerID=40&md5=536e68d549b8bb166c60a53d0a104048","Departments of Surgery and Cancer, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom; Emergency Medicine, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom","Pucher, P.H., Departments of Surgery and Cancer, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom; Batrick, N., Departments of Surgery and Cancer, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom, Emergency Medicine, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom; Taylor, D., Departments of Surgery and Cancer, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom; Chaudery, M., Departments of Surgery and Cancer, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom; Cohen, D., Departments of Surgery and Cancer, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom; Darzi, A., Departments of Surgery and Cancer, St Mary's Hospital Major Trauma Centre, Imperial College London, London, United Kingdom","BACKGROUND: Mass casualty incidents are unfortunately becoming more common. The coordination of mass casualty incident response is highly complex. Currently available options for training, however, are limited by either lack of realism or prohibitive expense and by a lack of assessment tools. Virtual worlds represent a potentially cost-effective, immersive, and easily accessible platform for training and assessment. The aim of this study was to assess feasibility of a novel virtual-worlds-based system for assessment and training in major incident response. METHODS: Clinical areas were modeled within a virtual, online hospital. A major incident, incorporating virtual casualties, allowed multiple clinicians to simultaneously respond with appropriate in-world management and transfer plans within limits of the hospital's available resources. Errors, delays, and completed actions were recorded, as well as Trauma-NOnTECHnical Skills (T-NOTECHS) score. Performance was compared between novice and expert clinician groups. RESULTS: Twenty-one subjects participated in three simulations: pilot (n = 7), novice (n = 8), and expert groups (n = 6). The novices committed more critical events than the experts, 11 versus 3, p = 0.006; took longer to treat patients, 560 (299) seconds versus 339 (321) seconds, p = 0.026; and achieved poorer T-NOTECHS scores, 14 (2) versus 21.5 (3.7), p = 0.003, and technical skill, 2.29 (0.34) versus 3.96 (0.69), p = 0.001. One hundred percent of the subjects thought that the simulation was realistic and superior to existing training options. CONCLUSION: A virtual-worlds-based model for the training and assessment of major incident response has been designed and validated. The advantages of customizability, reproducibility, and recordability combined with the low cost of implementation suggest that this potentially represents a powerful adjunct to existing training methods and may be applicable to further areas of surgery as well. © 2014 Lippincott Williams & Wilkins.","Distributed; Online; Simulation; Trauma; Virtual","article; clinical decision making; computer interface; computer program; disaster planning; emergency health service; emergency medicine; emergency treatment; emergency ward; female; general surgery; human; intensive care; intensive care unit; male; mass disaster; medical education; online system; operating room; performance measurement system; priority journal; questionnaire; reproducibility; resident; resource management; resuscitation; simulation; simulator; skill; training; traumatology; validation study; virtual reality; Disaster Medicine; Disaster Planning; Hospitalization; Humans; Mass Casualty Incidents; Reproducibility of Results; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84905016019
"Akhtar K.S.N., Chen A., Standfield N.J., Gupte C.M.","24173166800;57216316518;6602620965;6602169843;","The role of simulation in developing surgical skills",2014,"Current Reviews in Musculoskeletal Medicine","7","2",,"155","160",,34,"10.1007/s12178-014-9209-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905733244&doi=10.1007%2fs12178-014-9209-z&partnerID=40&md5=c5174e2d116b3f1596460dfbd4a1258b","Orthopaedic Surgery, Imperial College, Charing Cross Hospital, Fulham Palace Road, Hammersmith, London W6 8RP, United Kingdom","Akhtar, K.S.N., Orthopaedic Surgery, Imperial College, Charing Cross Hospital, Fulham Palace Road, Hammersmith, London W6 8RP, United Kingdom; Chen, A., Orthopaedic Surgery, Imperial College, Charing Cross Hospital, Fulham Palace Road, Hammersmith, London W6 8RP, United Kingdom; Standfield, N.J., Orthopaedic Surgery, Imperial College, Charing Cross Hospital, Fulham Palace Road, Hammersmith, London W6 8RP, United Kingdom; Gupte, C.M., Orthopaedic Surgery, Imperial College, Charing Cross Hospital, Fulham Palace Road, Hammersmith, London W6 8RP, United Kingdom","Surgical training has followed the masterapprentice model for centuries but is currently undergoing a paradigm shift. The traditional model is inefficient with no guarantee of case mix, quality, or quantity. There is a growing focus on competency-based medical education in response to restrictions on doctors' working hours and the traditional mantra of ""see one, do one, teach one"" is being increasingly questioned. The medical profession is subject to more scrutiny than ever before and is facingmounting financial, clinical, and political pressures. Simulation may be a means of addressing these challenges. It provides a way for trainees to practice technical tasks in a protected environment without putting patients at risk and helps to shorten the learning curve. The evidence for simulation-based training in orthopedic surgery using synthetic models, cadavers, and virtual reality simulators is constantly developing, though further work is needed to ensure the transfer of skills to the operating theatre. © Springer Science+Business Media 2014.","Arthroscopy; Assessment; Boot camp; Cadaver; Competency; Education; Feedback; Patient safety; Phantom; Proficiency; Psychomotor; Simulation; Skills; Surgical training; Task performance; Training; Virtual reality","article; cadaver; clinical competence; clinical practice; disease model; evidence based medicine; human; learning curve; nonhuman; operating room; operation duration; orthopedic surgery; patient safety; phantom; priority journal; psychomotor performance; simulation; skill retention; surgical training; task performance; virtual reality; visual feedback; working time",Article,"Final","",Scopus,2-s2.0-84905733244
"Rivard J.D., Vergis A.S., Unger B.J., Hardy K.M., Andrew C.G., Gillman L.M., Park J.","24169358700;19640882300;7007030226;55930167100;8633327600;14043435000;35320426600;","Construct validity of individual and summary performance metrics associated with a computer-based laparoscopic simulator",2014,"Surgical Endoscopy","28","6",,"1921","1928",,11,"10.1007/s00464-013-3414-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903584638&doi=10.1007%2fs00464-013-3414-5&partnerID=40&md5=a8228370b96c943a70cabc41c53d200b","Department of Surgery, St. Boniface General Hospital, University of Manitoba, Z-Block, Winnipeg, MB R2H 2A6, Canada; Department of Medical Education, University of Manitoba, Winnipeg, MB, Canada","Rivard, J.D., Department of Surgery, St. Boniface General Hospital, University of Manitoba, Z-Block, Winnipeg, MB R2H 2A6, Canada; Vergis, A.S., Department of Surgery, St. Boniface General Hospital, University of Manitoba, Z-Block, Winnipeg, MB R2H 2A6, Canada; Unger, B.J., Department of Medical Education, University of Manitoba, Winnipeg, MB, Canada; Hardy, K.M., Department of Surgery, St. Boniface General Hospital, University of Manitoba, Z-Block, Winnipeg, MB R2H 2A6, Canada; Andrew, C.G., Department of Surgery, St. Boniface General Hospital, University of Manitoba, Z-Block, Winnipeg, MB R2H 2A6, Canada; Gillman, L.M., Department of Surgery, St. Boniface General Hospital, University of Manitoba, Z-Block, Winnipeg, MB R2H 2A6, Canada; Park, J., Department of Surgery, St. Boniface General Hospital, University of Manitoba, Z-Block, Winnipeg, MB R2H 2A6, Canada","Background: Computer-based surgical simulators capture a multitude of metrics based on different aspects of performance, such as speed, accuracy, and movement efficiency. However, without rigorous assessment, it may be unclear whether all, some, or none of these metrics actually reflect technical skill, which can compromise educational efforts on these simulators. We assessed the construct validity of individual performance metrics on the LapVR simulator (Immersion Medical, San Jose, CA, USA) and used these data to create task-specific summary metrics. Methods: Medical students with no prior laparoscopic experience (novices, N = 12), junior surgical residents with some laparoscopic experience (intermediates, N = 12), and experienced surgeons (experts, N = 11) all completed three repetitions of four LapVR simulator tasks. The tasks included three basic skills (peg transfer, cutting, clipping) and one procedural skill (adhesiolysis). Results: We selected 36 individual metrics on the four tasks that assessed six different aspects of performance, including speed, motion path length, respect for tissue, accuracy, task-specific errors, and successful task completion. Four of seven individual metrics assessed for peg transfer, six of ten metrics for cutting, four of nine metrics for clipping, and three of ten metrics for adhesiolysis discriminated between experience levels. Time and motion path length were significant on all four tasks. We used the validated individual metrics to create summary equations for each task, which successfully distinguished between the different experience levels. Conclusion: Educators should maintain some skepticism when reviewing the plethora of metrics captured by computer-based simulators, as some but not all are valid. We showed the construct validity of a limited number of individual metrics and developed summary metrics for the LapVR. The summary metrics provide a succinct way of assessing skill with a single metric for each task, but require further validation. © 2014 Springer Science+Business Media.","Education; Evaluation; Laparoscopic surgery; Simulation; Validation; Virtual reality","adult; article; computer based laparoscopic simulator; construct validity; female; human; laparoscopic surgery; male; medical student; priority journal; resident; simulator; surgeon; surgical training; virtual reality; computer assisted surgery; computer interface; computer simulation; devices; education; equipment design; evaluation study; laparoscopy; medical education; operation duration; procedures; standards; task performance; validation study; Adult; Computer Simulation; Equipment Design; Female; Humans; Internship and Residency; Laparoscopy; Male; Operative Time; Students, Medical; Surgery, Computer-Assisted; Task Performance and Analysis; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84903584638
"Rauter G., Sigrist R., Koch C., Crivelli F., Van Raai M., Riener R., Wolf P.","26423348100;37073446800;56024522400;55633747400;16305180100;7003404145;55627877036;","Transfer of complex skill learning from virtual to real rowing",2013,"PLoS ONE","8","12", e82145,"","",,24,"10.1371/journal.pone.0082145","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893381578&doi=10.1371%2fjournal.pone.0082145&partnerID=40&md5=9f70db43e46ed8e315c51becb818a422","Sensory-Motor Systems (SMS) Lab, Institute of Robotics and Intelligent Systems (IRIS), ETH Zurich, Zurich, Switzerland; Medical Faculty, University of Zurich, Zurich, Switzerland","Rauter, G., Sensory-Motor Systems (SMS) Lab, Institute of Robotics and Intelligent Systems (IRIS), ETH Zurich, Zurich, Switzerland, Medical Faculty, University of Zurich, Zurich, Switzerland; Sigrist, R., Sensory-Motor Systems (SMS) Lab, Institute of Robotics and Intelligent Systems (IRIS), ETH Zurich, Zurich, Switzerland, Medical Faculty, University of Zurich, Zurich, Switzerland; Koch, C., Sensory-Motor Systems (SMS) Lab, Institute of Robotics and Intelligent Systems (IRIS), ETH Zurich, Zurich, Switzerland, Medical Faculty, University of Zurich, Zurich, Switzerland; Crivelli, F., Sensory-Motor Systems (SMS) Lab, Institute of Robotics and Intelligent Systems (IRIS), ETH Zurich, Zurich, Switzerland, Medical Faculty, University of Zurich, Zurich, Switzerland; Van Raai, M., Sensory-Motor Systems (SMS) Lab, Institute of Robotics and Intelligent Systems (IRIS), ETH Zurich, Zurich, Switzerland, Medical Faculty, University of Zurich, Zurich, Switzerland; Riener, R., Sensory-Motor Systems (SMS) Lab, Institute of Robotics and Intelligent Systems (IRIS), ETH Zurich, Zurich, Switzerland, Medical Faculty, University of Zurich, Zurich, Switzerland; Wolf, P., Sensory-Motor Systems (SMS) Lab, Institute of Robotics and Intelligent Systems (IRIS), ETH Zurich, Zurich, Switzerland, Medical Faculty, University of Zurich, Zurich, Switzerland","Simulators are commonly used to train complex tasks. In particular, simulators are applied to train dangerous tasks, to save costs, and to investigate the impact of different factors on task performance. However, in most cases, the transfer of simulator training to the real task has not been investigated. Without a proof for successful skill transfer, simulators might not be helpful at all or even counter-productive for learning the real task. In this paper, the skill transfer of complex technical aspects trained on a scull rowing simulator to sculling on water was investigated. We assume if a simulator provides high fidelity rendering of the interactions with the environment even without augmented feedback, training on such a realistic simulator would allow similar skill gains as training in the real environment. These learned skills were expected to transfer to the real environment. Two groups of four recreational rowers participated. One group trained on water, the other group trained on a simulator. Within two weeks, both groups performed four training sessions with the same licensed rowing trainer. The development in performance was assessed by quantitative biomechanical performance measures and by a qualitative video evaluation of an independent, blinded trainer. In general, both groups could improve their performance on water. The used biomechanical measures seem to allow only a limited insight into the rowers' development, while the independent trainer could also rate the rowers' overall impression. The simulator quality and naturalism was confirmed by the participants in a questionnaire. In conclusion, realistic simulator training fostered skill gains to a similar extent as training in the real environment and enabled skill transfer to the real environment. In combination with augmented feedback, simulator training can be further exploited to foster motor learning even to a higher extent, which is subject to future work. © 2013 Rauter et al.",,"adult; article; biomechanics; controlled study; feedback system; human; human experiment; learning; motor performance; normal human; rowing; simulator; skill transfer; virtual reality; computer interface; computer simulation; female; male; middle aged; questionnaire; ship; task performance; videorecording; Adult; Biomechanical Phenomena; Computer Simulation; Female; Humans; Learning; Male; Middle Aged; Questionnaires; Ships; Task Performance and Analysis; User-Computer Interface; Video Recording",Article,"Final","",Scopus,2-s2.0-84893381578
"Robles-García V., Arias P., Sanmartín G., Espinosa N., Flores J., Grieve K.L., Cudeiro J.","36083210000;36815267300;54897990100;16678192900;56817822000;7003958119;6701665552;","Motor facilitation during real-time movement imitation in Parkinson's disease: A virtual reality study",2013,"Parkinsonism and Related Disorders","19","12",,"1123","1129",,18,"10.1016/j.parkreldis.2013.08.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889090295&doi=10.1016%2fj.parkreldis.2013.08.005&partnerID=40&md5=8ff9462f5fcc886021abce3965f8e137","Neuroscience and Motor Control Group (NEUROcom), Department of Medicine, INEF-Galicia and Institute of Biomedical Research of Coruña (INIBIC), University of A Coruña, 15006 A Coruña, Spain; Instituto de Investigacións Tecnolóxicas, University of Santiago de Compostela, Spain; Faculty of Life Sciences, University of Manchester, Manchester M13 9PT, United Kingdom","Robles-García, V., Neuroscience and Motor Control Group (NEUROcom), Department of Medicine, INEF-Galicia and Institute of Biomedical Research of Coruña (INIBIC), University of A Coruña, 15006 A Coruña, Spain; Arias, P., Neuroscience and Motor Control Group (NEUROcom), Department of Medicine, INEF-Galicia and Institute of Biomedical Research of Coruña (INIBIC), University of A Coruña, 15006 A Coruña, Spain; Sanmartín, G., Instituto de Investigacións Tecnolóxicas, University of Santiago de Compostela, Spain; Espinosa, N., Neuroscience and Motor Control Group (NEUROcom), Department of Medicine, INEF-Galicia and Institute of Biomedical Research of Coruña (INIBIC), University of A Coruña, 15006 A Coruña, Spain; Flores, J., Instituto de Investigacións Tecnolóxicas, University of Santiago de Compostela, Spain; Grieve, K.L., Faculty of Life Sciences, University of Manchester, Manchester M13 9PT, United Kingdom; Cudeiro, J., Neuroscience and Motor Control Group (NEUROcom), Department of Medicine, INEF-Galicia and Institute of Biomedical Research of Coruña (INIBIC), University of A Coruña, 15006 A Coruña, Spain","Background: Impaired temporal stability and poor motor unit recruitment are key impairments in Parkinsonian motor control during a whole spectrum of rhythmic movements, from simple finger tapping to gait. Therapies based on imitation can be designed for patients with motor impairments and virtual-reality (VR) offers a new perspective. Motor actions are known to depend upon the dopaminergic system, whose involvement in imitation is unknown. We sought to understand this role and the underlying possibilities for motor rehabilitation, by observing the execution of different motor-patterns during imitation in a VR environment in subjects with and without dopaminergic deficits. Methods: 10 OFF-dose idiopathic Parkinson's Disease patients (PD), 9 age-matched and 9 young-subjects participated. Subjects performed finger-tapping at their ""comfort"" and ""slow-comfort"" rates, while immersed in VR presenting their ""avatar"" in 1st person perspective. Imitation was evaluated by asking subjects to replicate finger-tapping patterns different to their natural one. The finger-pattern presented matched their comfort and comfort-slow rates, but without a pause on the table (continuously moving). Results: Patients were able to adapt their finger-tapping correctly, showing that in comparison with the control groups, the dopaminergic deficiency of PD did not impair imitation. During imitation the magnitude of EMG increased and the temporal variability of movement decreased. Conclusions: PD-patients have unaltered ability to imitate instructed motor-patterns, suggesting that a fully-functional dopaminergic system is not essential for such imitation. It should be further investigated if imitation training over a period of time induces positive off-line motor adaptations with transfer to non-imitation tasks. © 2013 Elsevier Ltd.","Imitative behavior; Movement; Parkinson's disease; Virtual environment","adaptation; aged; article; clinical article; comfort self paced tapping rate; comparative study; contact time; controlled study; disease severity; dopaminergic system; electromyogram; facilitation; finger tapping; human; imitation; motor control; motor facilitation; motor performance; movement (physiology); Parkinson disease; priority journal; slow comfort self paced tapping rate; time series analysis; velocity; virtual reality; Imitative behavior; Movement; Parkinson's disease; Virtual environment; Adult; Aged; Female; Humans; Imitative Behavior; Male; Movement; Parkinson Disease; Psychomotor Performance; Virtual Reality Exposure Therapy",Article,"Final","",Scopus,2-s2.0-84889090295
"Endo T., Kobayashi M., Kawasaki H.","36195618000;55966240400;7403230258;","A finger skill transfer system using a multi-fingered haptic interface robot and a hand motion image",2013,"Robotica","31","8",,"1251","1261",,7,"10.1017/S0263574713000465","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890357455&doi=10.1017%2fS0263574713000465&partnerID=40&md5=eb565a6a526b77f8f335cc0907be1a32","Faculty of Engineering, Gifu University, 1-1 Yanagido, Gifu 501-1193, Japan","Endo, T., Faculty of Engineering, Gifu University, 1-1 Yanagido, Gifu 501-1193, Japan; Kobayashi, M., Faculty of Engineering, Gifu University, 1-1 Yanagido, Gifu 501-1193, Japan; Kawasaki, H., Faculty of Engineering, Gifu University, 1-1 Yanagido, Gifu 501-1193, Japan","The teaching of how to exert fingertip forces and how to move the fingers is essential for transferring skill using the fingers to perform fine motor tasks. In this paper we accomplish the transfer of fingertip forces and positions in three-dimensional space by combining a multi-fingered haptic interface robot, which can measure and present the three-dimensional forces and positions at five fingertips, and an image display system that records a trainer's hand image and displays it to a trainee. Several experimental results show a high fingertip force and position transferability and the great potential of our proposed transfer system. Copyright © Cambridge University Press 2013.","Fine motor skill in fingers; Hand motion image; Haptic interfaces; Man-machine systems; Skill transfer; Virtual reality","Fine motors; Hand motion; Haptic interface robots; Image display; Multi-fingered; Skill transfer; Three dimensional space; Transfer systems; Display devices; Haptic interfaces; Interactive computer systems; Three dimensional; Virtual reality; Personnel training",Article,"Final","",Scopus,2-s2.0-84890357455
"Gehring S., Hartz E., Löchtefeld M., Krüger A.","36095852400;55876830800;34881899600;35264048900;","The media façade toolkit: Prototyping and simulating interaction with media façades",2013,"UbiComp 2013 - Proceedings of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing",,,,"763","772",,15,"10.1145/2493432.2493471","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885230036&doi=10.1145%2f2493432.2493471&partnerID=40&md5=f8f15c2906a0cadbe2bb229041d9785d","German Research Center for Artificial Intelligence (DFKI), Campus D3, 2, Saarbrücken, Germany","Gehring, S., German Research Center for Artificial Intelligence (DFKI), Campus D3, 2, Saarbrücken, Germany; Hartz, E., German Research Center for Artificial Intelligence (DFKI), Campus D3, 2, Saarbrücken, Germany; Löchtefeld, M., German Research Center for Artificial Intelligence (DFKI), Campus D3, 2, Saarbrücken, Germany; Krüger, A., German Research Center for Artificial Intelligence (DFKI), Campus D3, 2, Saarbrücken, Germany","Digital technologies are rapidly finding their way into urban spaces. One prominent example is media façades. Due to their size, visibility and their technical capabilities, they offer great potential for interaction and for becoming the future displays of public spaces. To explore their potential, researchers have recently started to develop interactive applications for various media façades. Existing development tools are mostly tailored to one specific media façade in one specific setting. They usually provide limited means to incorporate interaction by a user, and the applications developed are limited to running on only one particular media façade. In this paper, we present a flexible, generalized media façade toolkit, which is capable of mimicking arbitrary media façade installations. The toolkit is capable of running interactive applications on media façades with different form factors, sizes and technical capabilities. Furthermore, it ensures application portability between different media façades and offers the possibility of providing interactivity by enabling user input with different modalities and different interaction devices. Copyright © 2013 ACM.","Interfaces; Media façades; Prototyping; Simulation","Application portability; Development tools; Digital technologies; Interaction devices; Interactive applications; Interactivity; Simulation; Technical capabilities; Interfaces (materials); Software prototyping; Ubiquitous computing; Interactive devices",Conference Paper,"Final","",Scopus,2-s2.0-84885230036
"Umakatsu A., Mashita T., Kiyokawa K., Takernura H.","45261534100;14319405900;7005065755;55869055000;","Pinch-n-Paste: Direct texture transfer interaction in augmented reality",2013,"Proceedings - IEEE Virtual Reality",,, 6549369,"73","74",,,"10.1109/VR.2013.6549369","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884877577&doi=10.1109%2fVR.2013.6549369&partnerID=40&md5=7d7963e7b9ed03ab4f4ef35a2b738a1f","Osaka University, Japan","Umakatsu, A., Osaka University, Japan; Mashita, T., Osaka University, Japan; Kiyokawa, K., Osaka University, Japan; Takernura, H., Osaka University, Japan","Our Pinch-n-Paste allows a user to touch or pinch one part of an object, copy and move its texture, and paste it onto another object, directly with his or her hand, in an augmented reality environment. To transfer texture appropriately from one part of an object to another, two texture images are generated by the Least Square Conformal Map (LSCM) technique. Two regions in the texture images corresponding to source and target areas of interest are then obtained using cross-boundary brushes. Target texel values are sampled from corresponding source texels by Moving Least Squares (MLS), and are finally mapped onto the target object. In this poster, we will describe the basic idea, implementation details, and example interaction results and a preliminary user study. © 2013 IEEE.","3D physics interaction; Augmented Reality; texture transfer","3D physics interaction; Conformal map; Least Square; Moving least squares; Target object; Texture image; Texture transfer; User study; Augmented reality; Conformal mapping; Textures; Virtual reality; Image texture",Conference Paper,"Final","",Scopus,2-s2.0-84884877577
"Zmuda M.A., Wonser J.L., Bachmann E.R., Hodgson E.","55905032400;35729733600;7005745121;14053915200;","Optimizing constrained-environment redirected walking instructions using search techniques",2013,"IEEE Transactions on Visualization and Computer Graphics","19","11", 6520845,"1872","1884",,37,"10.1109/TVCG.2013.88","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84884554083&doi=10.1109%2fTVCG.2013.88&partnerID=40&md5=091fedd90ee3852d2e41955d41a5eb1f","Department of Computer Science and Software Engineering, Miami University, 201D Benton Hall, Oxford, OH 45056, United States; Department of Psychology, Miami University, Oxford, OH 45056, United States","Zmuda, M.A., Department of Computer Science and Software Engineering, Miami University, 201D Benton Hall, Oxford, OH 45056, United States; Wonser, J.L., Department of Computer Science and Software Engineering, Miami University, 201D Benton Hall, Oxford, OH 45056, United States; Bachmann, E.R., Department of Computer Science and Software Engineering, Miami University, 201D Benton Hall, Oxford, OH 45056, United States; Hodgson, E., Department of Psychology, Miami University, Oxford, OH 45056, United States","A goal of redirected walking (RDW) is to allow large virtual worlds to be explored within small tracking areas. Generalized steering algorithms, such as steer-to-center, simply move the user toward locations that are considered to be collision free in most cases. The algorithm developed here, FORCE, identifies collision-free paths by using a map of the tracking area's shape and obstacles, in addition to a multistep, probabilistic prediction of the user's virtual path through a known virtual environment. In the present implementation, the path predictions describe a user's possible movements through a virtual store with aisles. Based on both the user's physical and virtual location/orientation, a search-based optimization technique identifies the optimal steering instruction given the possible user paths. Path prediction uses the map of the virtual world; consequently, the search may propose steering instructions that put the user close to walls if the user's future actions eventually lead away from the wall. Results from both simulated and real users are presented. FORCE identifies collision-free paths in 55.0 percent of the starting conditions compared to 46.1 percent for generalized methods. When considering only the conditions that result in different outcomes, redirection based on FORCE produces collision-free path 94.5 percent of the time. © 2013 IEEE.","Backtracking; motion compression; redirected walking; virtual reality","Backtracking; Collision-free paths; Generalized method; Motion compression; Optimization techniques; Probabilistic prediction; Redirected walkings; Steering algorithms; Algorithms; Interactive computer graphics; Virtual reality; Optimization; adult; algorithm; computer graphics; computer interface; computer simulation; environment; human; male; orientation; physiology; procedures; three dimensional imaging; walking; article; methodology; three dimensional imaging; walking; Adult; Algorithms; Computer Graphics; Computer Simulation; Environment; Humans; Imaging, Three-Dimensional; Male; Orientation; User-Computer Interface; Walking; Adult; Algorithms; Computer Graphics; Computer Simulation; Environment; Humans; Imaging, Three-Dimensional; Male; Orientation; User-Computer Interface; Walking",Article,"Final","",Scopus,2-s2.0-84884554083
"Deutsch J.E., Myslinski M.J., Kafri M., Ranky R., Sivak M., Mavroidis C., Lewis J.A.","7201985389;12769194300;55914359900;36081179400;36106349000;7005291566;8693257800;","Feasibility of virtual reality augmented cycling for health promotion of people poststroke",2013,"Journal of Neurologic Physical Therapy","37","3",,"118","124",,13,"10.1097/NPT.0b013e3182a0a078","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883449764&doi=10.1097%2fNPT.0b013e3182a0a078&partnerID=40&md5=0e04fa87326d124dffc295478d0a4240","Research in Virtual Environments and Rehabilitation Sciences Laboratory, Department of Rehabilitation and Movement Sciences, Rutgers University 65, Bergen Street, Newark, NJ 07103, United States; Biomedical Mechatronics Laboratory, Northeastern University, Boston, MA, United States; VRehab LLC, Jersey City, NJ, United States","Deutsch, J.E., Research in Virtual Environments and Rehabilitation Sciences Laboratory, Department of Rehabilitation and Movement Sciences, Rutgers University 65, Bergen Street, Newark, NJ 07103, United States, VRehab LLC, Jersey City, NJ, United States; Myslinski, M.J., Research in Virtual Environments and Rehabilitation Sciences Laboratory, Department of Rehabilitation and Movement Sciences, Rutgers University 65, Bergen Street, Newark, NJ 07103, United States; Kafri, M., Research in Virtual Environments and Rehabilitation Sciences Laboratory, Department of Rehabilitation and Movement Sciences, Rutgers University 65, Bergen Street, Newark, NJ 07103, United States; Ranky, R., Biomedical Mechatronics Laboratory, Northeastern University, Boston, MA, United States; Sivak, M., Biomedical Mechatronics Laboratory, Northeastern University, Boston, MA, United States; Mavroidis, C., Biomedical Mechatronics Laboratory, Northeastern University, Boston, MA, United States; Lewis, J.A., VRehab LLC, Jersey City, NJ, United States","BACKGROUND AND PURPOSE:: A virtual reality (VR) augmented cycling kit (VRACK) was developed to address motor control and fitness deficits of individuals with chronic stroke. In this article, we report on the safety, feasibility, and efficacy of using the VR augmented cycling kit to improve cardiorespiratory (CR) fitness of individuals in the chronic phase poststroke. METHODS:: Four individuals with chronic stroke (47-65 years old and ≥3 years poststroke), with residual lower extremity impairments (Fugl-Meyer 24-26/34), who were limited community ambulators (gait speed range 0.56-1.1 m/s) participated in this study. Safety was defined as the absence of adverse events. Feasibility was measured using attendance, total exercise time, and ""involvement"" measured with the presence questionnaire (PQ). Efficacy of CR fitness was evaluated using a submaximal bicycle ergometer test before and after an 8-week training program. RESULTS:: The intervention was safe and feasible with participants having 1 adverse event, 100% adherence, achieving between 90 and 125 minutes of cycling each week, and a mean PQ score of 39 (SD 3.3). There was a statistically significant (13%; P = 0.035) improvement in peak VO2, with a range of 6% to 24.5%. DISCUSSION AND CONCLUSION:: For these individuals, poststroke, VR augmented cycling, using their heart rate to set their avatarÊs speed, fostered training of sufficient duration and intensity to promote CR fitness. In addition, there was a transfer of training from the bicycle to walking endurance. VR augmented cycling may be an addition to the therapistÊs tools for concurrent training of mobility and health promotion of individuals poststroke. Copyright © 2013 Neurology Section, APTA.","fitness; health promotion; mobility; stroke; virtual reality","aged; article; bicycle; cerebrovascular accident; computer interface; feasibility study; female; fitness; health promotion; human; male; middle aged; pathophysiology; physiology; treatment outcome; Aged; Bicycling; Feasibility Studies; Female; Health Promotion; Humans; Male; Middle Aged; Physical Fitness; Stroke; Treatment Outcome; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84883449764
"Duarte R.J., Cury J., Oliveira L.C.N., Srougi M.","7005370698;36338774200;35574498800;7006308114;","Establishing the minimal number of virtual reality simulator training sessions necessary to develop basic laparoscopic skills competence: Evaluation of the learning curve",2013,"International Braz J Urol","39","5",,"712","719",,8,"10.1590/S1677-5538.IBJU.2013.05.14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891641710&doi=10.1590%2fS1677-5538.IBJU.2013.05.14&partnerID=40&md5=889f58bf7a18bcb605bf31713db3925d","Sao Paulo University Medical School, CEPEC Vicky Safra, Department of Urology, Sao Paulo, Brazil","Duarte, R.J., Sao Paulo University Medical School, CEPEC Vicky Safra, Department of Urology, Sao Paulo, Brazil; Cury, J., Sao Paulo University Medical School, CEPEC Vicky Safra, Department of Urology, Sao Paulo, Brazil; Oliveira, L.C.N., Sao Paulo University Medical School, CEPEC Vicky Safra, Department of Urology, Sao Paulo, Brazil; Srougi, M., Sao Paulo University Medical School, CEPEC Vicky Safra, Department of Urology, Sao Paulo, Brazil","Introduction: Medical literature is scarce on information to define a basic skills training program for laparoscopic surgery (peg and transferring, cutting, clipping). The aim of this study was to determine the minimal number of simulator sessions of basic laparoscopic tasks necessary to elaborate an optimal virtual reality training curriculum. Materials and Methods: Eleven medical students with no previous laparoscopic experience were spontaneously enrolled. They were submitted to simulator training sessions starting at level 1 (Immersion Lap VR, San Jose, CA), including sequentially camera handling, peg and transfer, clipping and cutting. Each student trained twice a week until 10 sessions were completed. The score indexes were registered and analyzed. The total of errors of the evaluation sequences (camera, peg and transfer, clipping and cutting) were computed and thereafter, they were correlated to the total of items evaluated in each step, resulting in a success percent ratio for each student for each set of each completed session. Thereafter, we computed the cumulative success rate in 10 sessions, obtaining an analysis of the learning process. By non-linear regression the learning curve was analyzed. Results: By the non-linear regression method the learning curve was analyzed and a r2 = 0.73 (p &lt; 0.001) was obtained, being necessary 4.26 (~five sessions) to reach the plateau of 80% of the estimated acquired knowledge, being that 100% of the students have reached this level of skills. From the fifth session till the 10th, the gain of knowledge was not significant, although some students reached 96% of the expected improvement. Conclusions: This study revealed that after five simulator training sequential sessions the students' learning curve reaches a plateau. The forward sessions in the same difficult level do not promote any improvement in laparoscopic basic surgical skills, and the students should be introduced to a more difficult training tasks level.","Aptitude; General surgery; Laparoscopy; Methods [subheading]; Teaching","article; chi square distribution; clinical competence; computer interface; computer simulation; education; evaluation study; female; human; laparoscopy; learning curve; male; medical student; reference value; reproducibility; task performance; time; utilization review; Chi-Square Distribution; Clinical Competence; Computer Simulation; Female; Humans; Laparoscopy; Learning Curve; Male; Reference Values; Reproducibility of Results; Students, Medical; Task Performance and Analysis; Time Factors; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84891641710
"Chavez-Gamboa M., Herrera-Aguilar I., Sandoval-Gonzalez O., Malagon-Gonzalez F., Jacinto-Villegas J.M.","55811826400;34167892600;25031570600;55811873100;57192265005;","Anthropomorphic robotic system with 6 DOF for space positioning in the virtual reality applications for human machine interaction",2013,"23rd International Conference on Electronics, Communications and Computing, CONIELECOMP 2013",,, 6525788,"212","217",,,"10.1109/CONIELECOMP.2013.6525788","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881042480&doi=10.1109%2fCONIELECOMP.2013.6525788&partnerID=40&md5=c6c17a064e55f35c37b5b4a8f8a5204f","Technological Institute of Orizaba, Electronics Department, Orizaba, Veracruz, Mexico","Chavez-Gamboa, M., Technological Institute of Orizaba, Electronics Department, Orizaba, Veracruz, Mexico; Herrera-Aguilar, I., Technological Institute of Orizaba, Electronics Department, Orizaba, Veracruz, Mexico; Sandoval-Gonzalez, O., Technological Institute of Orizaba, Electronics Department, Orizaba, Veracruz, Mexico; Malagon-Gonzalez, F., Technological Institute of Orizaba, Electronics Department, Orizaba, Veracruz, Mexico; Jacinto-Villegas, J.M., Technological Institute of Orizaba, Electronics Department, Orizaba, Veracruz, Mexico","This paper presents a spatial hand tracking system using a 6 DOF anthropomorphic robot applied in human machine interaction. The main objective of this mechatronic system is to obtain information about the spatial position of a user's hand movements in order to be used like a skills trainer to accelerate the skills transfer from the machine to the human by integrating the laws of physics of virtual objects and adapting different design techniques and use of computer software for three-dimensional virtual reality © 2013 IEEE.","computational design; DOF; physical human-computer interaction; skills transfer; upper limbs; virtual reality","Computational design; Design technique; DOF; Human machine interaction; Mechatronic systems; skills transfer; Spatial positions; Upper limbs; Human computer interaction; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84881042480
"Leeb R., Lancelle M., Kaiser V., Fellner D.W., Pfurtscheller G.","9940938400;53881535800;30467896100;6603799372;7103106088;","Thinking penguin: Multimodal brain-computer interface control of a VR game",2013,"IEEE Transactions on Computational Intelligence and AI in Games","5","2", 6418003,"117","128",,49,"10.1109/TCIAIG.2013.2242072","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879354288&doi=10.1109%2fTCIAIG.2013.2242072&partnerID=40&md5=5e3f109ac0827b40ece1c83d173b7f10","Center for Neuroprosthetics, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne CH-1015, Switzerland; Nanyang Technological University, Singapore 639798, Singapore; Institute of Computer Graphics and Knowledge Visualization, Graz University of Technology, Graz A-8010, Austria; ETH Zürich, Zürich 8006, Switzerland; Laboratory of Brain Computer Interfaces, Institute for Knowledge Discovery, Graz University of Technology, Graz A-8010, Austria; Interactive Graphics Systems Group (GRIS), Technical University Darmstadt, Darmstadt 64289, Germany; Fraunhofer Institute for Applied Research in Visual Computing (IGD), Darmstadt 64283, Germany","Leeb, R., Center for Neuroprosthetics, École Polytechnique Fédérale de Lausanne (EPFL), Lausanne CH-1015, Switzerland; Lancelle, M., Nanyang Technological University, Singapore 639798, Singapore, Institute of Computer Graphics and Knowledge Visualization, Graz University of Technology, Graz A-8010, Austria, ETH Zürich, Zürich 8006, Switzerland; Kaiser, V., Laboratory of Brain Computer Interfaces, Institute for Knowledge Discovery, Graz University of Technology, Graz A-8010, Austria; Fellner, D.W., Institute of Computer Graphics and Knowledge Visualization, Graz University of Technology, Graz A-8010, Austria, Interactive Graphics Systems Group (GRIS), Technical University Darmstadt, Darmstadt 64289, Germany, Fraunhofer Institute for Applied Research in Visual Computing (IGD), Darmstadt 64283, Germany; Pfurtscheller, G., Laboratory of Brain Computer Interfaces, Institute for Knowledge Discovery, Graz University of Technology, Graz A-8010, Austria","In this paper, we describe a multimodal brain-computer interface (BCI) experiment, situated in a highly immersive CAVE. A subject sitting in the virtual environment controls the main character of a virtual reality game: a penguin that slides down a snowy mountain slope. While the subject can trigger a jump action via the BCI, additional steering with a game controller as a secondary task was tested. Our experiment profits from the game as an attractive task where the subject is motivated to get a higher score with a better BCI performance. A BCI based on the so-called brain switch was applied, which allows discrete asynchronous actions. Fourteen subjects participated, of which 50% achieved the required performance to test the penguin game. Comparing the BCI performance during the training and the game showed that a transfer of skills is possible, in spite of the changes in visual complexity and task demand. Finally and most importantly, our results showed that the use of a secondary motor task, in our case the joystick control, did not deteriorate the BCI performance during the game. Through these findings, we conclude that our chosen approach is a suitable multimodal or hybrid BCI implementation, in which the user can even perform other tasks in parallel. © 2013 IEEE.","brain switch; Brain-computer interfaces (BCI); game; hybrid BCI; multimodal; multitasking; virtual reality (VR)","game; Hybrid bci; Joystick control; Mountain slopes; Multi-modal; Secondary tasks; Virtual environment control; Visual complexity; Experiments; Interfaces (computer); Multitasking; Profitability; Virtual reality; Brain computer interface",Article,"Final","",Scopus,2-s2.0-84879354288
"Krogh C.L., Konge L., Bjurström J., Ringsted C.","6602944781;36704959000;55338419400;7003334846;","Training on a new, portable, simple simulator transfers to performance of complex bronchoscopy procedures",2013,"Clinical Respiratory Journal","7","3",,"237","244",,5,"10.1111/j.1752-699X.2012.00311.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880153923&doi=10.1111%2fj.1752-699X.2012.00311.x&partnerID=40&md5=36d3dec5ba1220379ca649d112d6e81c","Centre for Clinical Education, University of Copenhagen and Capital Region of Denmark, Copenhagen, Denmark","Krogh, C.L., Centre for Clinical Education, University of Copenhagen and Capital Region of Denmark, Copenhagen, Denmark; Konge, L., Centre for Clinical Education, University of Copenhagen and Capital Region of Denmark, Copenhagen, Denmark; Bjurström, J., Centre for Clinical Education, University of Copenhagen and Capital Region of Denmark, Copenhagen, Denmark; Ringsted, C., Centre for Clinical Education, University of Copenhagen and Capital Region of Denmark, Copenhagen, Denmark","Introduction: Virtual-reality (VR) simulation provides a safe and effective learning environment prior to practicing on patients. However, existing bronchoscopy simulators are expensive and not easily portable. Objectives: The aim of this study was to assess the effect of self-directed training on a new, portable, simple simulator measured by transfer of skills to performance of more complex bronchoscopy procedures on an advanced VR simulator. Methods: Twenty medical students participated in the study. After a general introduction to bronchoscopy, they were randomised into two groups, receiving either self-directed bronchoscopy training using a portable, simple simulator or no manual training. Subsequently, all participants were tested on complex scenarios in an advanced VR simulator using a validated bronchoscopy quality test. Bronchoscopy quality scores were compared using independent samples t-test and correlated with a previously established pass-fail standard. Results: The intervention group spent an average of 71-min training on the new simulator. The intervention group performed significantly better than the control group, mean bronchoscopy quality score 0.55 [standard deviation (SD) 0.16] vs 0.36 (SD 0.10), P=0.005, effect size=1.47. Eight out of 10 participants in the intervention group passed the test compared with only 1 out of 10 in the control group. Conclusion: The effect of a brief, self-directed training session using a portable, simple simulator was substantial and transferred to performance of more complex skills. © 2012 John Wiley & Sons Ltd.","bronchoscopy; Education; Simulation; Transfer of learning; Virtual reality","adult; article; bronchoscopy; controlled study; experimental study; female; human; male; medical education; medical student; normal human; outcome assessment; performance; priority journal; scoring system; simulator; bronchoscopy; education; simulation; transfer of learning; virtual reality; Adult; Bronchoscopy; Competency-Based Education; Computer Simulation; Computer-Assisted Instruction; Education, Medical, Graduate; Education, Medical, Undergraduate; Female; Humans; Male; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84880153923
"Konge L., Annema J., Clementsen P., Minddal V., Vilmann P., Ringsted C.","36704959000;6601992141;54918162400;55744814200;35473385900;7003334846;","Using virtual-reality simulation to assess performance in endobronchial ultrasound",2013,"Respiration","86","1",,"59","65",,57,"10.1159/000350428","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880571132&doi=10.1159%2f000350428&partnerID=40&md5=28c7c080c4585a317cb748d4f96d7d4a","Centre for Clinical Education, University of Copenhagen and the Capital Region of Denmark, Blegdamsvej 9, DK-2100 Copenhagen, Denmark; Department of Pulmonology, Gentofte Hospital, University of Copenhagen, Hellerup, Denmark; Department of Surgical Gastroenterology, Copenhagen University Hospital Herlev, Herlev, Denmark; Department of Pulmonolgy, Leiden University Medical Center, Leiden, Netherlands; Department of Pulmonolgy, Academic Medical Center, Amsterdam, Netherlands; Department of Anesthesia, University of Toronto, Toronto, ON, Canada","Konge, L., Centre for Clinical Education, University of Copenhagen and the Capital Region of Denmark, Blegdamsvej 9, DK-2100 Copenhagen, Denmark; Annema, J., Department of Pulmonolgy, Leiden University Medical Center, Leiden, Netherlands, Department of Pulmonolgy, Academic Medical Center, Amsterdam, Netherlands; Clementsen, P., Department of Pulmonology, Gentofte Hospital, University of Copenhagen, Hellerup, Denmark; Minddal, V., Department of Pulmonology, Gentofte Hospital, University of Copenhagen, Hellerup, Denmark; Vilmann, P., Department of Surgical Gastroenterology, Copenhagen University Hospital Herlev, Herlev, Denmark; Ringsted, C., Department of Anesthesia, University of Toronto, Toronto, ON, Canada","Background: For optimal treatment of patients with non-small cell lung carcinoma, it is essential to have physicians with competence in endobronchial ultrasound-guided transbronchial needle aspiration (EBUS-TBNA). EBUS training and certification requirements are under discussion and the establishment of basic competence should be based on an objective assessment of performance. Objectives: The aims of this study were to design an evidence-based and credible EBUS certification based on a virtual-reality (VR) EBUS simulator test. Methods: Twenty-two respiratory physicians were divided into 3 groups: experienced EBUS operators (group 1, n = 6), untrained novices (group 2, n = 8) and simulator-trained novices (group 3, n = 8). Each physician performed two standardized simulated EBUS-TBNA procedures. Simulator metrics with discriminatory ability were identified and reliability was explored. Finally, the contrasting-groups method was used to establish a pass/fail standard, and the consequences of this standard were explored. Results: Successfully sampled lymph nodes and procedure time were the only simulator metrics that showed statistically significant differences of p = 0.047 and p = 0.002, respectively. The resulting quality score (QS, i.e. sampled lymph nodes per minute) showed an acceptable reliability and a generalizability coefficient of 0.67. Reliability of 0.8 could be obtained by testing in 4 procedures. Median QS was 0.24 (range 0.21-0.26) and 0.098 (range 0.04-0.21) for groups 1 and 2, respectively (p = 0.001). The resulting pass/fail standard was 0.19. Group 3 had a median posttraining QS of 0.11 (range 0-0.17). None of them met the pass/fail standard. Conclusions: With careful design of standardized tests, a credible standard setting and appropriate transfer studies, VR simulators could be an important first line in credentialing before proceeding to supervised performance on patients. Copyright © 2013 S. Karger AG, Basel.","Endobronchial ultrasound; Transbronchial needle aspiration; Virtual-reality simulator","article; certification; clinical article; clinical practice; endobronchial ultrasonography; evidence based practice; female; human; male; medical education; physician; priority journal; simulation; task performance; virtual reality; work experience; aged; Article; clinical assessment; lymph node; normal human; operator; personal experience; respiratory physician; simulator; task performance; training; transbronchial aspiration; Biopsy, Needle; Bronchoscopy; Carcinoma, Non-Small-Cell Lung; Clinical Competence; Educational Measurement; Endosonography; Humans; Image-Guided Biopsy; Ultrasonography, Interventional; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84880571132
"Sodhi R., Poupyrev I., Glisson M., Israr A.","26424844100;6603553340;55347042000;15022614400;","AIREAL: Interactive tactile experiences in free air",2013,"ACM Transactions on Graphics","32","4", 134,"","",,172,"10.1145/2461912.2462007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84880776379&doi=10.1145%2f2461912.2462007&partnerID=40&md5=7130f7d61e77b4ba44170aedef5f0b43","Disney Research, Pittsburgh, United States; University of Illinois, United States","Sodhi, R., Disney Research, Pittsburgh, United States, University of Illinois, United States; Poupyrev, I., Disney Research, Pittsburgh, United States; Glisson, M., Disney Research, Pittsburgh, United States; Israr, A., Disney Research, Pittsburgh, United States","AIREAL is a novel haptic technology that delivers effective and expressive tactile sensations in free air, without requiring the user to wear a physical device. Combined with interactive computers graphics, AIREAL enables users to feel virtual 3D objects, experience free air textures and receive haptic feedback on gestures performed in free space. AIREAL relies on air vortex generation directed by an actuated flexible nozzle to provide effective tactile feedback with a 75 degrees field of view, and within an 8.5cm resolution at 1 meter. AIREAL is a scalable, inexpensive and practical free air haptic technology that can be used in a broad range of applications, including gaming, mobile applications, and gesture interaction among many others. This paper reports the details of the AIREAL design and control, experimental evaluations of the device's performance, as well as an exploration of the application space of free air haptic displays. Although we used vortices, we believe that the results reported are generalizable and will inform the design of haptic displays based on alternative principles of free air tactile actuation. Copyright © ACM. Copyright © ACM 2013.","3D interfaces; Augmented reality; Augmented surfaces; Haptics; Tactile displays; Tangible interfaces; Touch interaction.","3D interface; Haptics; Tactile display; Tangible interfaces; Touch interaction; Augmented reality; Display devices; Haptic interfaces; Human computer interaction; Vortex flow",Article,"Final","",Scopus,2-s2.0-84880776379
"Gallagher A.G., Seymour N.E., Jordan-Black J.-A., Bunting B.P., McGlade K., Satava R.M.","7101915089;7004355854;15750790300;7003531889;6602177321;7006711764;","Prospective, randomized assessment of transfer of training (ToT) and transfer effectiveness ratio (TER) of virtual reality simulation training for laparoscopic skill acquisition",2013,"Annals of Surgery","257","6",,"1025","1031",,93,"10.1097/SLA.0b013e318284f658","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879104286&doi=10.1097%2fSLA.0b013e318284f658&partnerID=40&md5=3a0fb0955c67ac50cdd1499eb3dae4f1","School of Medicine, Brookfield Health Sciences Complex, University College Cork, College Road, Cork, Ireland; Department of Surgery, Tufts University, School of Medicine, Springfield, MA, United States; School of Psychology, Queen's University, Belfast, Northern Ireland, United Kingdom; School of Psychology, University of Ulster, Derry, Northern Ireland, United Kingdom; School of Medicine, Dentistry and Biomedical Sciences, Queen's University, Belfast, Northern Ireland, United Kingdom; Department of Surgery, University of Washington, Medical Center, Seattle, WA, United States","Gallagher, A.G., School of Medicine, Brookfield Health Sciences Complex, University College Cork, College Road, Cork, Ireland; Seymour, N.E., Department of Surgery, Tufts University, School of Medicine, Springfield, MA, United States; Jordan-Black, J.-A., School of Psychology, Queen's University, Belfast, Northern Ireland, United Kingdom; Bunting, B.P., School of Psychology, University of Ulster, Derry, Northern Ireland, United Kingdom; McGlade, K., School of Medicine, Dentistry and Biomedical Sciences, Queen's University, Belfast, Northern Ireland, United Kingdom; Satava, R.M., Department of Surgery, University of Washington, Medical Center, Seattle, WA, United States","Objectives: We assessed the effectiveness of ToT from VR laparoscopic simulation training in 2 studies. In a second study, we also assessed the TER. ToT is a detectable performance improvement between equivalent groups, and TER is the observed percentage performance differences between 2 matched groups carrying out the same task but with 1 group pretrained on VR simulation. Concordance between simulated and in-vivo procedure performance was also assessed. Design: Prospective, randomized, and blinded. Participants: In Study 1, experienced laparoscopic surgeons (n = 195) and in Study 2 laparoscopic novices (n = 30) were randomized to either train on VR simulation before completing an equivalent real-world task or complete the real-world task only. Results: Experienced laparoscopic surgeons and novices who trained on the simulator performed significantly better than their controls, thus demonstrating ToT. Their performance showed a TER between 7% and 42% from the virtual to the real tasks. Simulation training impacted most on procedural error reduction in both studies (32-42%). The correlation observed between the VR and real-world task performance was r > 0·96 (Study 2). Conclusions: VR simulation training offers a powerful and effective platform for training safer skills. Copyright © 2013 by Lippincott Williams and Wilkins.","Operating room (OR); Simulation; Transfer effectiveness ratio (TER); Transfer of training (ToT); Virtual reality (VR)","adolescent; adult; aged; article; controlled study; female; human; in vivo study; laparoscopy; major clinical study; male; priority journal; prospective study; randomized controlled trial; simulation; task performance; training; virtual reality; Adolescent; Adult; Analysis of Variance; Clinical Competence; Computer Simulation; Female; Humans; Laparoscopy; Male; Prospective Studies; Transfer (Psychology); User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84879104286
"Saleh G.M., Lamparter J., Sullivan P.M., O'Sullivan F., Hussain B., Athanasiadis I., Litwin A.S., Gillan S.N.","12779593000;35090265600;7402033170;57206301011;7003941657;19639956200;16042735100;54945134600;","The international forum of ophthalmic simulation: Developing a virtual reality training curriculum for ophthalmology",2013,"British Journal of Ophthalmology","97","6",,"789","792",,31,"10.1136/bjophthalmol-2012-302764","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878015632&doi=10.1136%2fbjophthalmol-2012-302764&partnerID=40&md5=1bee65603d78d15664ae99707037c212","National Institute of Health Research Biomedical Research Centre, Moorfields Eye Hospital NHS Foundation Trust, UCL Institute of Ophthalmology, 162 City Road, London EC1V 2PD, United Kingdom; Moorfields Eye Hospital, London, United Kingdom; School of Ophthalmology, London Deanery, London, United Kingdom; Department of Ophthalmology, University Medical Centre, Mainz, Germany; Ophthalmologiko Iatreio, Thessaloniki, Greece","Saleh, G.M., National Institute of Health Research Biomedical Research Centre, Moorfields Eye Hospital NHS Foundation Trust, UCL Institute of Ophthalmology, 162 City Road, London EC1V 2PD, United Kingdom, Moorfields Eye Hospital, London, United Kingdom, School of Ophthalmology, London Deanery, London, United Kingdom; Lamparter, J., Moorfields Eye Hospital, London, United Kingdom, Department of Ophthalmology, University Medical Centre, Mainz, Germany; Sullivan, P.M., Moorfields Eye Hospital, London, United Kingdom; O'Sullivan, F., School of Ophthalmology, London Deanery, London, United Kingdom; Hussain, B., Moorfields Eye Hospital, London, United Kingdom; Athanasiadis, I., Moorfields Eye Hospital, London, United Kingdom, Ophthalmologiko Iatreio, Thessaloniki, Greece; Litwin, A.S., Moorfields Eye Hospital, London, United Kingdom; Gillan, S.N., Moorfields Eye Hospital, London, United Kingdom","Background: To investigate the effect of a structured, supervised, cataract simulation programme on ophthalmic surgeons in their first year of training, and to evaluate the level of skill transfer. Methods: Trainees with minimal intraocular and simulator experience in their first year of ophthalmology undertook a structured, sequential, customised, virtual reality (VR) cataract training programme developed through the International Forum of Ophthalmic Simulation. A set of one-handed, bimanual, static and dynamic tasks were evaluated before and after the course and scores obtained. Statistical significance was evaluated with the Wilcoxon sign-rank test. Results: The median precourse score of 101.50/400 (IQR 58.75-145.75) was significantly improved after completing the training programme ((postcourse score: 302/400, range: 266.25-343), p<0.001). While improvement was evident and found to be statistically significant in all parameters, greatest improvements were found for capsulorhexis and antitremor training ((Capsulorhexis: precourse score=0/100, range 0-4.5; postcourse score=81/100, range 13-87.75; p=0.002), (antitremor training: precourse score=0/100, range 0-0; postcourse score=80/100, range 60.25-91.50; p=0.001)). Conclusions: Structured and supervised VR training can offer a significant level of skills transfer to novice ophthalmic surgeons. VR training at the earliest stage of ophthalmic surgical training may, therefore, be of benefit.",,"article; capsulorhexis; cataract; cohort analysis; human; ophthalmology; priority journal; prospective study; scoring system; simulation; simulator; surgeon; surgical training; task performance; virtual reality; Eye (Globe); Lens and zonules; Medical Education; Optics and Refraction; Treatment Surgery; Capsulorhexis; Cataract Extraction; Competency-Based Education; Computer-Assisted Instruction; Curriculum; Education, Medical, Graduate; Humans; Ophthalmology; Prospective Studies",Article,"Final","",Scopus,2-s2.0-84878015632
"Lendvay T.S., Brand T.C., White L., Kowalewski T., Jonnadula S., Mercer L.D., Khorsand D., Andros J., Hannaford B., Satava R.M.","14319319500;14039907700;36081406500;7006132582;55645674800;42161891600;55645521300;55645382400;7005603758;7006711764;","Virtual reality robotic surgery warm-up improves task performance in a dry laboratory environment: A prospective randomized controlled study",2013,"Journal of the American College of Surgeons","216","6",,"1181","1192",,63,"10.1016/j.jamcollsurg.2013.02.012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878108010&doi=10.1016%2fj.jamcollsurg.2013.02.012&partnerID=40&md5=66f57f8f125ca98dba55ff5555edb4cc","Department of Urology, University of Washington, School of Medicine, Seattle, WA, United States; Department of Surgery, University of Washington, School of Medicine, Seattle, WA, United States; Department of Bioengineering, University of Washington, Seattle, WA, United States; Department of Electrical Engineering, University of Washington, Seattle, WA, United States; Core for Biomedical Statistics, Seattle Children's Research Institute, Seattle, WA, United States; Madigan Army Medical Center, US Army, Tacoma, WA, United States","Lendvay, T.S., Department of Urology, University of Washington, School of Medicine, Seattle, WA, United States; Brand, T.C., Madigan Army Medical Center, US Army, Tacoma, WA, United States; White, L., Department of Bioengineering, University of Washington, Seattle, WA, United States; Kowalewski, T., Department of Electrical Engineering, University of Washington, Seattle, WA, United States; Jonnadula, S., Department of Surgery, University of Washington, School of Medicine, Seattle, WA, United States; Mercer, L.D., Core for Biomedical Statistics, Seattle Children's Research Institute, Seattle, WA, United States; Khorsand, D., Department of Surgery, University of Washington, School of Medicine, Seattle, WA, United States; Andros, J., Department of Surgery, University of Washington, School of Medicine, Seattle, WA, United States; Hannaford, B., Department of Electrical Engineering, University of Washington, Seattle, WA, United States; Satava, R.M., Department of Surgery, University of Washington, School of Medicine, Seattle, WA, United States","Background: Preoperative simulation warm-up has been shown to improve performance and reduce errors in novice and experienced surgeons, yet existing studies have only investigated conventional laparoscopy. We hypothesized that a brief virtual reality (VR) robotic warm-up would enhance robotic task performance and reduce errors. Study Design: In a 2-center randomized trial, 51 residents and experienced minimally invasive surgery faculty in General Surgery, Urology, and Gynecology underwent a validated robotic surgery proficiency curriculum on a VR robotic simulator and on the da Vinci surgical robot (Intuitive Surgical Inc). Once they successfully achieved performance benchmarks, surgeons were randomized to either receive a 3- to 5-minute VR simulator warm-up or read a leisure book for 10 minutes before performing similar and dissimilar (intracorporeal suturing) robotic surgery tasks. The primary outcomes compared were task time, tool path length, economy of motion, technical, and cognitive errors. Results: Task time (-29.29 seconds, p = 0.001; 95% CI, -47.03 to -11.56), path length (-79.87 mm; p = 0.014; 95% CI, -144.48 to -15.25), and cognitive errors were reduced in the warm-up group compared with the control group for similar tasks. Global technical errors in intracorporeal suturing (0.32; p = 0.020; 95% CI, 0.06-0.59) were reduced after the dissimilar VR task. When surgeons were stratified by earlier robotic and laparoscopic clinical experience, the more experienced surgeons (n = 17) demonstrated significant improvements from warm-up in task time (-53.5 seconds; p = 0.001; 95% CI, -83.9 to -23.0) and economy of motion (0.63 mm/s; p = 0.007; 95% CI, 0.18-1.09), and improvement in these metrics was not statistically significantly appreciated in the less-experienced cohort (n = 34). Conclusions: We observed significant performance improvement and error reduction rates among surgeons of varying experience after VR warm-up for basic robotic surgery tasks. In addition, the VR warm-up reduced errors on a more complex task (robotic suturing), suggesting the generalizability of the warm-up. © 2013 by the American College of Surgeons.","FLS; Fundamentals of Laparoscopic Surgery; ICC; interclass correlations; minimally invasive surgery; MIS; operating room; OR; virtual reality; VR","adult; article; controlled study; female; human; laparoscopic surgery; male; minimally invasive surgery; outcome assessment; priority journal; prospective study; randomized controlled trial; robotic surgery; robotics; simulation; surgical error; task performance; virtual reality; Adult; Clinical Competence; Computer Simulation; Curriculum; Equipment Design; Female; Follow-Up Studies; Humans; Learning Curve; Male; Operating Rooms; Prospective Studies; Robotics; Specialties, Surgical; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84878108010
"Taylor G.S., Barnett J.S.","25958441300;7201378608;","Evaluation of wearable simulation interface for military training",2013,"Human Factors","55","3",,"672","690",,17,"10.1177/0018720812466892","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878072143&doi=10.1177%2f0018720812466892&partnerID=40&md5=f36f9b5c70a6e8abbbcf6ba1db8eea25","University of Central Florida, Orlando FL, United States; U.S. Army Research Institute, ATTN: DAPE-ARI-IF, 12350 Research Parkway, Orlando FL 32826-3276, United States","Taylor, G.S., University of Central Florida, Orlando FL, United States; Barnett, J.S., U.S. Army Research Institute, ATTN: DAPE-ARI-IF, 12350 Research Parkway, Orlando FL 32826-3276, United States","Objective: This research evaluated the training effectiveness of a novel simulation interface, a wearable computer integrated into a soldier's load-bearing equipment. Background: Military teams often use game-based simulators on desktop computers to train squad-level procedures. A wearable computer interface that mimics the soldier's equipment was expected to provide better training through increased realism and immersion. Method: A heuristic usability evaluation and two experiments were conducted. Eight evaluators interacted with both wearable and desktop interfaces and completed a usability survey. The first experiment compared the training retention of the wearable interface with a desktop simulator and interactive training video. The second experiment compared the training transfer of the wearable and desktop simulators with a live training environment. Results: Results indicated the wearable interface was more difficult to use and elicited stronger symptoms of simulator sickness. There was no significant difference in training retention between the wearable, desktop, or interactive video training methods. The live training used in the second experiment provided superior training transfer than the simulator conditions, with no difference between the desktop and wearable. Conclusion: The wearable simulator interface did not provide better training than the desktop computer interface. It also had poorer usability and caused worse simulator sickness. Therefore, it was a less effective training tool. Application: This research illustrates the importance of conducting empirical evaluations of novel training technologies. New and innovative technologies are always coveted by users, but new does not always guarantee improvement.","computer interface; simulator; training; training effectiveness; training transfer; usability; wearable simulation interface","Empirical evaluations; Innovative technology; Interactive training; Significant differences; Training effectiveness; usability; Usability evaluation; Wearable interfaces; Experiments; Heuristic methods; Interfaces (computer); Personnel training; Wearable computers; Simulators; adult; article; computer interface; controlled clinical trial; controlled study; equipment design; female; human; learning; male; middle aged; military phenomena; randomized controlled trial; videorecording; Adult; Equipment Design; Female; Humans; Male; Middle Aged; Military Science; Transfer (Psychology); User-Computer Interface; Video Recording; Young Adult",Article,"Final","",Scopus,2-s2.0-84878072143
"Arambula D., Wong W., Medhekar B.A., Guo H., Gingery M., Czornyj E., Liu M., Dey S., Ghosh P., Miller J.F.","55704972500;55706034100;21739582900;7404403700;6602564008;54881249300;7406300697;57199712489;39660981600;35237764000;","Surface display of a massively variable lipoprotein by a legionella diversity-generating retroelement",2013,"Proceedings of the National Academy of Sciences of the United States of America","110","20",,"8212","8217",,31,"10.1073/pnas.1301366110","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877846517&doi=10.1073%2fpnas.1301366110&partnerID=40&md5=485b0cce32bc37a032c9377ddc3aa184","Departments of Microbiology Immunology and Molecular Genetics, University of California, Los Angeles, CA 90095, United States; Department of Internal Medicine, Yale University, School of Medicine, New Haven, CT 06511, United States; Chemistry and Biochemistry, University of California, Los Angeles, CA 90095, United States; Department of Chemistry and Biochemistry, University of California at San Diego, San Diego, CA 92093, United States; Molecular Biology Institute, University of California, Los Angeles, CA 90095, United States; California NanoSystems Institute, University of California, Los Angeles, CA 90095, United States","Arambula, D., Departments of Microbiology Immunology and Molecular Genetics, University of California, Los Angeles, CA 90095, United States; Wong, W., Departments of Microbiology Immunology and Molecular Genetics, University of California, Los Angeles, CA 90095, United States; Medhekar, B.A., Department of Internal Medicine, Yale University, School of Medicine, New Haven, CT 06511, United States; Guo, H., Departments of Microbiology Immunology and Molecular Genetics, University of California, Los Angeles, CA 90095, United States; Gingery, M., Chemistry and Biochemistry, University of California, Los Angeles, CA 90095, United States; Czornyj, E., Departments of Microbiology Immunology and Molecular Genetics, University of California, Los Angeles, CA 90095, United States; Liu, M., Departments of Microbiology Immunology and Molecular Genetics, University of California, Los Angeles, CA 90095, United States; Dey, S., Department of Chemistry and Biochemistry, University of California at San Diego, San Diego, CA 92093, United States; Ghosh, P., Department of Chemistry and Biochemistry, University of California at San Diego, San Diego, CA 92093, United States; Miller, J.F., Departments of Microbiology Immunology and Molecular Genetics, University of California, Los Angeles, CA 90095, United States, Molecular Biology Institute, University of California, Los Angeles, CA 90095, United States, California NanoSystems Institute, University of California, Los Angeles, CA 90095, United States","Diversity-generating retroelements (DGRs) are a unique family of retroelements that confer selective advantages to their hosts by facilitating localized DNA sequence evolution through a specialized error-prone reverse transcription process. We characterized a DGR in Legionella pneumophila, an opportunistic human pathogen that causes Legionnaires disease. The L. pneumophila DGR is found within a horizontally acquired genomic island, and it can theoretically generate 1026 unique nucleotide sequences in its target gene, legionella determinent target A (ldtA), creating a repertoire of 1019 distinct proteins. Expression of the L. pneumophila DGR resulted in transfer of DNA sequence information from a template repeat to a variable repeat (VR) accompanied by adenine-specific mutagenesis of progeny VRs at the 3'end of ldtA. ldtA encodes a twin-arginine translocated lipoprotein that is anchored in the outer leaflet of the outer membrane, with its C-terminal variable region surface exposed. Related DGRs were identified in L. pneumophila clinical isolates that encode unique target proteins with homologous VRs, demonstrating the adaptability of DGR components. This work characterizes a DGR that diversifies a bacterial protein and confirms the hypothesis that DGR-mediated mutagenic homing occurs through a conserved mechanism. Comparative bioinformatics predicts that surface display of massively variable proteins is a defining feature of a subset of bacterial DGRs.","Accelerated evolution; Bacterial surface display; TAT","bacterial protein; cis acting element; legionella determinent target A protein; lipoprotein; trans acting factor; unclassified drug; amino terminal sequence; anatomy; article; bacterial cell; bacterial chromosome; bacterial genome; bacterial outer membrane; Bacteroides fragilis; Bacteroides thetaiotaomicron; carboxy terminal sequence; consensus sequence; controlled study; diversity generating retroelement; DNA sequence; gene targeting; genomic island; Legionella pneumophila; legionnaire disease; mutagenesis; nonhuman; nucleotide sequence; priority journal; progeny; protein expression; protein function; retroposon; Shewanella; Treponema denticola; type IV secretion system; Vibrio; accelerated evolution; bacterial surface display; TAT; Bacterial Proteins; Base Sequence; Cell Membrane; Genomic Islands; Legionella pneumophila; Lipoproteins; Molecular Sequence Data; Mutagenesis; Open Reading Frames; Protein Structure, Tertiary; Retroelements; Sequence Analysis, DNA; Surface Properties; Virulence",Article,"Final","",Scopus,2-s2.0-84877846517
"Chellali A., Dumas C., Milleville-Pennel I.","26767578800;16645562300;16242282200;","Haptic communication to support biopsy procedures learning in virtual environments",2013,"Presence: Teleoperators and Virtual Environments","22","1",,"470","489",,10,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876983959&partnerID=40&md5=f0460885116fe5644323776da9a61ae8","Robotics Research Group, IRCCyN Ecole des Mines de Nantes, France; Cambridge Health Alliance, Department of Surgery Research Group, Cambridge, MA 02139, United States; Biomedical Imaging Team, CSIRO, Australia; PsyCoTech Research Group, IRCCyN-CNRS, France","Chellali, A., Robotics Research Group, IRCCyN Ecole des Mines de Nantes, France, Cambridge Health Alliance, Department of Surgery Research Group, Cambridge, MA 02139, United States; Dumas, C., Robotics Research Group, IRCCyN Ecole des Mines de Nantes, France, Biomedical Imaging Team, CSIRO, Australia; Milleville-Pennel, I., PsyCoTech Research Group, IRCCyN-CNRS, France","In interventional radiology, physicians require high haptic sensitivity and fine motor skills development because of the limited real-time visual feedback of the surgical site. The transfer of this type of surgical skill to novices is a challenging issue. This paper presents a study on the design of a biopsy procedure learning system. Our methodology, based on a task-centered design approach, aims to bring out new design rules for virtual learning environments. A new collaborative haptic training paradigm is introduced to support human-haptic interaction in a virtual environment. The interaction paradigm supports haptic communication between two distant users to teach a surgical skill. In order to evaluate this paradigm, a user experiment was conducted. Sixty volunteer medical students participated in the study to assess the influence of the teaching method on their performance in a biopsy procedure task. The results show that to transfer the skills, the combination of haptic communication with verbal and visual communications improves the novices' performance compared to conventional teaching methods. Furthermore, the results show that, depending on the teaching method, participants developed different needle insertion profiles. We conclude that our interaction paradigm facilitates expert-novice haptic communication and improves skills transfer; and new skills acquisition depends on the availability of different communication channels between experts and novices. Our findings indicate that the traditional fellowship methods in surgery should evolve to an off-patient collaborative environment that will continue to support visual and verbal communication, but also haptic communication, in order to achieve a better and more complete skills training. © 2012 by the Massachusetts Institute of Technology.",,"Collaborative environments; Design approaches; Haptic communications; Interaction paradigm; Interventional radiology; Skills acquisition; Verbal communications; Virtual learning environments; Biopsy; Computer aided instruction; Haptic interfaces; Radiology; Surgery; Teaching; Virtual reality; Visual communication; Personnel training",Article,"Final","",Scopus,2-s2.0-84876983959
"Farra S., Miller E., Timm N., Schafer J.","54921506600;7404491434;16311140300;56545149400;","Improved Training for Disasters Using 3-D Virtual Reality Simulation",2013,"Western Journal of Nursing Research","35","5",,"655","671",,44,"10.1177/0193945912471735","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875670675&doi=10.1177%2f0193945912471735&partnerID=40&md5=a22f0258cd46e23cf434ae56cd42ab8e","Miami University Oxford, OH, United States; University of Cincinnati, OH, United States","Farra, S., Miami University Oxford, OH, United States; Miller, E., University of Cincinnati, OH, United States; Timm, N., University of Cincinnati, OH, United States; Schafer, J., University of Cincinnati, OH, United States","The purpose of this study was to examine the effects of virtual reality simulation (VRS) on learning outcomes and retention of disaster training. The study used a longitudinal experimental design using two groups and repeated measures. A convenience sample of associate degree nursing students enrolled in a disaster course was randomized into two groups; both groups completed web-based modules; the treatment group also completed a virtually simulated disaster experience. Learning was measured using a 20-question multiple-choice knowledge assessment pre/post and at 2 months following training. Results were analyzed using the generalized linear model. Independent and paired t tests were used to examine the between- and within-participant differences. The main effect of the virtual simulation was strongly significant (p&.0001). The VRS effect demonstrated stability over time. In this preliminary examination, VRS is an instructional method that reinforces learning and improves learning retention. © The Author(s) 2012.","disaster planning; education; mass casualty training; virtual reality","article; controlled clinical trial; controlled study; disaster planning; in service training; longitudinal study; nursing student; organization and management; randomized controlled trial; Disaster Planning; Inservice Training; Longitudinal Studies; Students, Nursing",Article,"Final","",Scopus,2-s2.0-84875670675
"Kirkman M.A.","15831567800;","Deliberate practice, domain-specific expertise, and implications for surgical education in current climes",2013,"Journal of Surgical Education","70","3",,"309","317",,27,"10.1016/j.jsurg.2012.11.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876664367&doi=10.1016%2fj.jsurg.2012.11.011&partnerID=40&md5=22c90e6e6349ea4b59f6b5e59bd09aef","Victor Horsley Department of Neurosurgery, National Hospital for Neurology and Neurosurgery, Queen Square, London WC1N 3BG, United Kingdom; Department of Surgery and Cancer, Imperial College London, St Mary's Hospital Campus, London, United Kingdom","Kirkman, M.A., Victor Horsley Department of Neurosurgery, National Hospital for Neurology and Neurosurgery, Queen Square, London WC1N 3BG, United Kingdom, Department of Surgery and Cancer, Imperial College London, St Mary's Hospital Campus, London, United Kingdom","Background and Objectives: Within surgery, recent years have witnessed increasing focus on patient safety, accountability, and surgical performance. In addition to these factors, increasing subspecialisation and reductions to working hours among junior doctors most notably in the United States of America and Europe mandate the need for surgeons to develop expertise. However, surgical expertise as a concept is poorly defined. The aim of this review is to (i) define surgical expertise, (ii) discuss the literature analyzing how expertise is attained, and (iii) highlight the concept of domain-specific expertise. Methods: A review was performed of literature pertinent to expertise both within and external to medicine and surgery. Additional literature concerning deliberate practice, simulation, and transfer of learning was also reviewed. Results: A remarkable repertoire of literature demonstrates that in many domains expertise: (i) is developed after 10 years of deliberate practice (defined as repeated practice in motivated individuals receiving feedback) - the '10-year rule,' and (ii) is highly domain specific. Conclusions: Surgical expertise is domain (procedure and context) specific. If the '10-year rule' is true for surgery, restrictions on doctors' working hours will likely delay surgical expertise acquisition. Conversely, the trend to increasing subspecialisation may facilitate surgical expertise acquisition. So, too, may simulation, as long as appropriate transfer of learning to clinical practice occurs. Further work is required to better understand surgical expertise and provide solutions to accelerate expertise acquisition in surgical trainees, with the aim of improving postgraduate training programs and optimizing patient outcomes. © 2013 Association of Program Directors in Surgery. Published by Elsevier Inc. All rights reserved.","ACGME duty hours; deliberate practice; domain-specific exper- tise; European working time directive; surgical education","article; clinical assessment; clinical practice; communication skill; experiential learning; human; learning; patient safety; patient satisfaction; priority journal; professionalism; surgical mortality; surgical technique; surgical training; working time; Clinical Competence; Europe; Feedback; General Surgery; Humans; Motivation; Patient Safety; Time Factors; United States; Workload",Article,"Final","",Scopus,2-s2.0-84876664367
"Dai C.-Y., Huang Y.-H., Chou L.-W., Wu S.-C., Wang R.-Y., Lin L.-C.","55651483900;7501570030;24773457800;14625561000;35201891600;57149136000;","Effects of primary caregiver participation in vestibular rehabilitation for unilateral neglect patients with right hemispheric stroke: A randomized controlled trial",2013,"Neuropsychiatric Disease and Treatment","9",,,"477","484",,16,"10.2147/NDT.S42426","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876177041&doi=10.2147%2fNDT.S42426&partnerID=40&md5=9a65fc28eaa96ba26dee6e0108bdcc32","School of Nursing, National Yang Ming University, Taipei, Taiwan; Department of Nursing, Central Taiwan University of Science and Technology, Taichung, Taiwan; Department of Physical Medicine and Rehabilitation, Chung Shan Medical University Hospital, Taichung, Taiwan; School of Medicine, Chung Shan Medical University, Taichung, Taiwan; Department of Physical Medicine and Rehabilitation, China Medical University Hospital, Taichung, Taiwan; School of Chinese Medicine, College of Chinese Medicine, China Medical University, Taichung, Taiwan; Institute of Health and Welfare Policy, National Yang-Ming University, Taipei, Taiwan; Department of Physical Therapy and Assistive Technology, National Yang-Ming University, Taipei, Taiwan; Institute of Clinical and Community Health Nursing, National Yang-Ming University, 155 Li-Nong Street, Sec 2, Beitou District, Taipei City 11221, Taiwan","Dai, C.-Y., School of Nursing, National Yang Ming University, Taipei, Taiwan, Department of Nursing, Central Taiwan University of Science and Technology, Taichung, Taiwan; Huang, Y.-H., Department of Physical Medicine and Rehabilitation, Chung Shan Medical University Hospital, Taichung, Taiwan, School of Medicine, Chung Shan Medical University, Taichung, Taiwan; Chou, L.-W., Department of Physical Medicine and Rehabilitation, China Medical University Hospital, Taichung, Taiwan, School of Chinese Medicine, College of Chinese Medicine, China Medical University, Taichung, Taiwan; Wu, S.-C., Institute of Health and Welfare Policy, National Yang-Ming University, Taipei, Taiwan; Wang, R.-Y., Department of Physical Therapy and Assistive Technology, National Yang-Ming University, Taipei, Taiwan; Lin, L.-C., Institute of Clinical and Community Health Nursing, National Yang-Ming University, 155 Li-Nong Street, Sec 2, Beitou District, Taipei City 11221, Taiwan","Introduction: The current study aims to investigate the effects of primary caregiver participation in vestibular rehabilitation (VR) on improving the measures of neglect, activities of daily living (ADL), balance, and falls of unilateral neglect (UN) patients. Methods: This study is a single-blind randomized controlled trial. Both experimental (n = 24) and control groups (n = 24) received conventional rehabilitation. The experimental group undertook VR for a month. During the first and second weeks, a registered nurse trained the experimental group in VR. The primary caregivers in the experimental group supervised and guided their patients in VR during the third and fourth weeks. The outcome measures were neglect, ADL, balance, and falls. Results: The two groups of UN patients showed a significant improvement in neglect, ADL, and balance over time. Based on the generalized estimating equations model, an interaction was observed between groups and times. Significant interactions were observed between the VR group at days 14 and 28 in the areas of neglect, ADL, and balance. No significant difference was observed between the two groups in the number of falls. Conclusion: Neglect, ADL, and balance among UN patients with right hemispheric stroke can be improved through the participation of primary caregivers in VR. Trained informal caregivers were recommended to provide VR guidance and supervision to patients who suffer from UN. © 2013 Dai et al, publisher and licensee Dove Medical Press Ltd.","Balance; Caregiver; Falls; Neglect; Vestibular rehabilitation","adult; aged; article; body equilibrium; caregiver; cerebrovascular accident; clinical article; clinical effectiveness; controlled study; daily life activity; falling; female; human; intermethod comparison; male; neglect; nurse patient relationship; occupational therapy; outcome assessment; physiotherapy; primary health care; randomized controlled trial; registered nurse; rehabilitation; right hemisphere; single blind procedure; therapy effect; vestibular rehabilitation",Article,"Final","",Scopus,2-s2.0-84876177041
"Chien J.H., Suh I.H., Park S.-H., Mukherjee M., Oleynikov D., Siu K.-C.","36542283700;26654525700;36543101600;26654285000;35474063300;57192938181;","Enhancing fundamental robot-assisted surgical proficiency by using a portable virtual simulator",2013,"Surgical Innovation","20","2",,"198","203",,6,"10.1177/1553350612458545","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875534734&doi=10.1177%2f1553350612458545&partnerID=40&md5=95e9747aa189a1d24a48636165ce2268","University of Nebraska Medical Center, Omaha, NE, United States; University of Nebraska at Omaha, 6001 Dodge St, HPER 202, Omaha, NE 68182, United States; Yuhan University, Gyeonggi-do, South Korea","Chien, J.H., University of Nebraska Medical Center, Omaha, NE, United States, University of Nebraska at Omaha, 6001 Dodge St, HPER 202, Omaha, NE 68182, United States; Suh, I.H., University of Nebraska Medical Center, Omaha, NE, United States; Park, S.-H., Yuhan University, Gyeonggi-do, South Korea; Mukherjee, M., University of Nebraska at Omaha, 6001 Dodge St, HPER 202, Omaha, NE 68182, United States; Oleynikov, D., University of Nebraska Medical Center, Omaha, NE, United States; Siu, K.-C., University of Nebraska Medical Center, Omaha, NE, United States, University of Nebraska at Omaha, 6001 Dodge St, HPER 202, Omaha, NE 68182, United States","Background. The development of a virtual reality (VR) training platform provides an affordable interface. The learning effect of VR and the capability of skill transfer from the VR environment to clinical tasks require more investigation. Methods. Here, 14 medical students performed 2 fundamental surgical tasks - bimanual carrying (BC) and peg transfer (PT) - in actual and virtual environments. Participants in the VR group received VR training, whereas participants in the control group played a 3D game. The learning effect was examined by comparing kinematics between pretraining and posttraining in the da Vinci Surgical System. Differences between VR and playing the 3D game were also examined. Results. Those who were trained with the VR simulator had significantly better performance in both actual PT (P =.002) and BC (P <.001) tasks. The time to task completion and the total distance traveled were significantly decreased in both surgical tasks in the VR group compared with the 3D game group. However, playing the 3D game showed no significant enhancement of fundamental surgical skills in the actual PT task. The difference between pretraining and posttraining was significantly larger in the VR group than in the 3D game group in both the time to task completion (P =.002) and the total distance traveled (P =.027) for the actual PT task. Participants who played the 3D game seemed to perform even worse in posttraining. Conclusions. Training with the portable VR simulator improved robot-assisted surgical skill proficiency in comparison to playing a 3D game. © The Author(s) 2012.","da Vinci surgical system; game; virtual reality","article; computer assisted surgery; controlled study; game; human; human experiment; medical student; normal human; robotics; simulation; task performance; training; virtual reality; Education, Medical; Humans; Imaging, Three-Dimensional; Laparoscopy; Robotics; Students, Medical; Surgery, Computer-Assisted; User-Computer Interface; Video Games",Article,"Final","",Scopus,2-s2.0-84875534734
"Hayes A.T., Straub C.L., Dieker L.A., Hughes C.E., Hynes M.C.","55904744300;55925439900;8352122200;7401857048;36728914300;","Ludic learning: Exploration of TLE TeachLivE™ and effective teacher training",2013,"International Journal of Gaming and Computer-Mediated Simulations","5","2",,"20","33",,18,"10.4018/jgcms.2013040102","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887453745&doi=10.4018%2fjgcms.2013040102&partnerID=40&md5=4921bfb4e153c1c8e6fed8cbe71588c3","University of Central Florida, Orlando, FL, United States","Hayes, A.T., University of Central Florida, Orlando, FL, United States; Straub, C.L., University of Central Florida, Orlando, FL, United States; Dieker, L.A., University of Central Florida, Orlando, FL, United States; Hughes, C.E., University of Central Florida, Orlando, FL, United States; Hynes, M.C., University of Central Florida, Orlando, FL, United States","New and emerging technology in the field of virtual environments has permitted a certain malleability of learning milieus. These emerging environments allow learning and transfer through interactions that have been intentionally designed to be pleasurable experiences. TLE TeachLivE™ is just such an emerging environment that engages teachers in practice on pedagogical and content aspects of teaching in a simulator. The sense of presence, engagement, and ludus of TLE TeachLivE™ are derived from the compelling Mixed Reality that includes components of off-the shelf and emerging technologies. Some of the noted features that have been identified relevant to the ludic nature of TeachLivE include the flow, fidelity, unpredicability, suspension of disbelief, social presence, and gamelike elements. This article explores TLE TeachLivE™ in terms of the ludology, paideic user experience, the source of the ludus, and outcomes of the ludic nature of the experience. Copyright © 2013, IGI Global.","Engagement; Fidelity; Ludic Simulation; Mixed Reality; Serious Games; Suspension of Disbelief; Teacher Education; Virtual Environment","Engagement; Fidelity; Ludic Simulation; Mixed reality; Serious games; Teacher education; Personnel training; Suspensions (fluids); Virtual reality; Teaching",Article,"Final","",Scopus,2-s2.0-84887453745
"Sofronia R.E., Knott T., Davidescu A., Savii G.G., Kuhlen T., Gerressen M.","36195968600;34881741500;10240743400;10241173300;6602984500;8579214900;","Failure mode and effects analysis in designing a virtual reality-based training simulator for bilateral sagittal split osteotomy",2013,"International Journal of Medical Robotics and Computer Assisted Surgery","9","1",,"e1","e9",,8,"10.1002/rcs.1483","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874978458&doi=10.1002%2frcs.1483&partnerID=40&md5=fa4b8401e9a02e82ba5dc67bbf97fa6a","Department of Mechatronics, Politehnica University of Timisoara, Timisoara, Romania; Virtual Reality Group, RWTH Aachen University, Aachen, Germany; Department of Oral, Maxillofacial and Plastic Facial Surgery, University Hospital of the Aachen University (RWTH), Aachen, Germany","Sofronia, R.E., Department of Mechatronics, Politehnica University of Timisoara, Timisoara, Romania; Knott, T., Virtual Reality Group, RWTH Aachen University, Aachen, Germany; Davidescu, A., Department of Mechatronics, Politehnica University of Timisoara, Timisoara, Romania; Savii, G.G., Department of Mechatronics, Politehnica University of Timisoara, Timisoara, Romania; Kuhlen, T., Virtual Reality Group, RWTH Aachen University, Aachen, Germany; Gerressen, M., Department of Oral, Maxillofacial and Plastic Facial Surgery, University Hospital of the Aachen University (RWTH), Aachen, Germany","Background: Virtual reality-based simulators offer a cost-effective and efficient alternative to traditional medical training and planning. Developing a simulator that enables the training of medical skills and also supports recognition of errors made by the trainee is a challenge. The first step in developing such a system consists of error identification in the real procedure, in order to ensure that the training environment covers the most significant errors that can occur. This paper focuses on identifying the main system requirements for an interactive simulator for training bilateral sagittal split osteotomy (BSSO). Methods: An approach is proposed based on failure mode and effects analysis (FMEA), a risk analysis method that is well structured and already an approved technique in other domains. Results: Based on the FMEA results, a BSSO training simulator is currently being developed, which centres upon the main critical steps of the procedure (sawing and splitting) and their main errors. Conclusions: FMEA seems to be a suitable tool in the design phase of developing medical simulators. Herein, it serves as a communication medium for knowledge transfer between the medical experts and the system developers. The method encourages a reflective process and allows identification of the most important elements and scenarios that need to be trained. © 2013 John Wiley & Sons, Ltd.","Bilateral sagittal split osteotomy; Error analysis; Medical simulators; Orthognathic surgery; System design; Virtual reality","article; bilateral sagittal split osteotomy; bleeding; facial nerve injury; fracture fixation; fracture nonunion; infection; lingual nerve injury; malocclusion; osteotomy; relapse; risk assessment; simulator; virtual reality; wound closure; Clinical Competence; Computer Simulation; Computer-Assisted Instruction; Equipment Design; Equipment Failure Analysis; Humans; Medical Errors; Models, Biological; Osteotomy, Sagittal Split Ramus; Robotics; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84874978458
"Rankouhi S., Waugh L.M.","56743224400;14629800800;","A literature review on the comparison role of virtual reality and augmented reality technologies in the AEC industry",2013,"Proceedings, Annual Conference - Canadian Society for Civil Engineering","2","January",,"1359","1368",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938271063&partnerID=40&md5=c5308f2cb214207b60bb14aee5f09c9e","Department of Civil Engineering, University of New Brunswick, Canada","Rankouhi, S., Department of Civil Engineering, University of New Brunswick, Canada; Waugh, L.M., Department of Civil Engineering, University of New Brunswick, Canada","The application of Virtual Reality (VR) and Augmented Reality (AR) technologies in the Architecture, Engineering, and Construction industry has tremendously increased. These technologies play various roles in different stages of the construction projects, such as simulating construction performance, comparing as-built and as-planned statuses of projects, pre-empting schedule disputes, improving collaboration opportunities, and training for similar projects. This article provides an extended foundation for future research by presenting a review of the comparison role of virtual reality and augmented reality technologies. The review is based on articles found within four well-known journals in the AEC industry for the period 2000 to 2011 inclusive. The selected journal articles are classified in different comparison categories e.g., comparison modes, comparison by project phase, comparison purpose, comparison performer, comparison tools and techniques. The number of articles found to match each of these dimensions is used to identify emerging trends in the literature as well as to synthesize the current state-of-the-art of comparison role of VR and AR research in the construction industry. In summary, the literature has focused on the comparison role and its prominent purpose such as progress monitoring in the construction phases of a project; in parallel, the literature addresses issues faced by on-site individual audiences such as project managers and workers/technicians.",,"Augmented reality; Construction industry; Human resource management; Technology transfer; Virtual reality; Architecture , engineering , and constructions; Augmented reality technology; Construction performance; Construction phasis; Construction projects; Literature reviews; State of the art; Tools and techniques; Project management",Conference Paper,"Final","",Scopus,2-s2.0-84938271063
"Levac D., Missiuna C., Wishart L., Dematteo C., Wright V.","25937323900;6701510600;6603522141;19834525300;7202487712;","The motor learning strategy instrument: Interrater reliability within usual and virtual reality physical therapy interventions",2013,"Pediatric Physical Therapy","25","1",,"53","60",,6,"10.1097/PEP.0b013e3182750c28","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873097562&doi=10.1097%2fPEP.0b013e3182750c28&partnerID=40&md5=2432d03f381102cbb14b14c82215ce2a","School of Rehabilitation Science, Institute for Applied Health Science, McMaster University, 1400 Main St W, Hamilton, ON L8S 1C7, Canada; CanChild Centre for Childhood Disability Research, McMaster University, Hamilton, ON, Canada; Bloorview Research Institute, Toronto, ON, Canada; Department of Physical Therapy, University of Toronto, Toronto, ON, Canada","Levac, D., School of Rehabilitation Science, Institute for Applied Health Science, McMaster University, 1400 Main St W, Hamilton, ON L8S 1C7, Canada; Missiuna, C., School of Rehabilitation Science, Institute for Applied Health Science, McMaster University, 1400 Main St W, Hamilton, ON L8S 1C7, Canada, CanChild Centre for Childhood Disability Research, McMaster University, Hamilton, ON, Canada; Wishart, L., School of Rehabilitation Science, Institute for Applied Health Science, McMaster University, 1400 Main St W, Hamilton, ON L8S 1C7, Canada; Dematteo, C., School of Rehabilitation Science, Institute for Applied Health Science, McMaster University, 1400 Main St W, Hamilton, ON L8S 1C7, Canada, CanChild Centre for Childhood Disability Research, McMaster University, Hamilton, ON, Canada; Wright, V., School of Rehabilitation Science, Institute for Applied Health Science, McMaster University, 1400 Main St W, Hamilton, ON L8S 1C7, Canada, CanChild Centre for Childhood Disability Research, McMaster University, Hamilton, ON, Canada, Bloorview Research Institute, Toronto, ON, Canada, Department of Physical Therapy, University of Toronto, Toronto, ON, Canada","Purpose: To evaluate and compare the interrater reliability of the Motor Learning Strategy Rating Instrument (MLSRI) within usual and virtual reality (VR) interventions for children with acquired brain injury. Methods: Two intervention sessions for each of 11 children (total, 22) were videotaped; sessions were provided by 4 physical therapists. Videotapes were divided into usual and VR components and rated by 2 observers using the MLSRI. A generalizability theory approach was used to determine interrater reliability for each intervention. Results: Interrater reliability for usual interventions was high for the MLSRI total score (g-coefficient, 0.81), whereas it was low for the VR total score (g-coefficient, 0.28); MLSRI category g-coefficients varied from 0.35 to 0.65 for usual and from 0.17 to 0.72 for VR interventions. Conclusion: Adequate reliability was achieved within ratings of usual interventions; however, challenges related to MLSRI use to rate VR-based interventions require further evaluation. © 2013 Wolters Kluwer Health | Lippincott Williams Wilkins.","adolescent; brain injuries/rehabilitation; child; clinical decision making; disabled children/rehabilitation; motor skills; physical therapy modalities; psychomotor performance; reproducibility of results; sensory feedback; therapy/computer assisted methods","adolescent; article; brain injury; child; computer interface; computer system; disability; equipment; evaluation; female; human; male; motor performance; observer variation; physiology; physiotherapy; reproducibility; virtual reality exposure therapy; Adolescent; Brain Injuries; Child; Computer Systems; Disability Evaluation; Female; Humans; Male; Motor Skills; Observer Variation; Physical Therapy Modalities; Reproducibility of Results; User-Computer Interface; Virtual Reality Exposure Therapy",Article,"Final","",Scopus,2-s2.0-84873097562
"Brinkman W.M., Tjiam I.M., Buzink S.N.","57023425700;36623066000;14064457800;","Assessment of basic laparoscopic skills on virtual reality simulator or box trainer",2013,"Surgical Endoscopy","27","10",,"3584","3590",,11,"10.1007/s00464-013-2930-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885173472&doi=10.1007%2fs00464-013-2930-7&partnerID=40&md5=605a4c04af59f6efdbfd078dd3714473","Department of Urology, Catharina Hospital Eindhoven, Michelangelolaan 2, 5623 EJ Eindhoven, Netherlands; Faculty of Industrial Design Engineering, Delft University of Technology, Landbergstraat 15, 2628 CE Delft, Netherlands; Department of Education and Research, Catharina Hospital Eindhoven, Michelangelolaan 2, 5623 EJ Eindhoven, Netherlands","Brinkman, W.M., Department of Urology, Catharina Hospital Eindhoven, Michelangelolaan 2, 5623 EJ Eindhoven, Netherlands; Tjiam, I.M., Department of Urology, Catharina Hospital Eindhoven, Michelangelolaan 2, 5623 EJ Eindhoven, Netherlands; Buzink, S.N., Faculty of Industrial Design Engineering, Delft University of Technology, Landbergstraat 15, 2628 CE Delft, Netherlands, Department of Education and Research, Catharina Hospital Eindhoven, Michelangelolaan 2, 5623 EJ Eindhoven, Netherlands","Introduction: We investigated whether the peg transfer task is interchangeable between a VR simulator and a box trainer. Our research questions: (1) Are scores of the box trainer interchangeable with the virtual equivalent of the exercise; (2) does training on the box affect performance on the VR simulator and vice versa; and (3) which system is preferred? Methods: Experienced laparoscopists and medical interns were randomly assigned to one of two groups (V or B). They performed eight repetitions of the peg transfer task (4 on each simulator system) following a crossover study design. Group B started on the box trainer and group V started on the VR simulator. Opinion of participants was evaluated by a questionnaire. Results: A significant correlation was found between time to complete the task on the box and the VR simulator. The comparison of the performances per system showed that group B (N = 14) performed the peg transfer task on the VR simulator in significantly less time than group V (N = 14; p = 0.014). Overall, the box was preferred over the VR simulator. Conclusions: Although performances on the box trainer and VR simulator were correlated, they were not interchangeable. The results also imply that assessment on the VR simulator after pretraining on the box is acceptable, whereas VR simulator training alone might not suffice to pass an assessment on a box trainer. More research is needed to validate the use of the VR simulator as a FLS and PLUS assessment instrument. © 2013 Springer Science+Business Media New York.","Laparoscopy training virtual reality PLUS","adult; article; box trainer; controlled study; educational technology; endoscopist; female; human; laparoscopic surgery; male; priority journal; questionnaire; resident; surgeon; surgical training; task performance; urologist; virtual reality simulator; Adult; Clinical Competence; Computer Simulation; Consumer Satisfaction; Female; Functional Laterality; General Surgery; Humans; Laparoscopy; Male; Operative Time; Task Performance and Analysis; Urology; User-Computer Interface; Young Adult",Article,"Final","",Scopus,2-s2.0-84885173472
"Sedda A., Borghese N.A., Ronchetti M., Mainetti R., Pasotti F., Beretta G., Bottini G.","35410398900;7003727657;6603848972;50061562900;50061782200;55571263300;7003788458;","Using virtual reality to rehabilitate neglect",2013,"Behavioural Neurology","26","3",,"183","185",,12,"10.3233/BEN-2012-129006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872904466&doi=10.3233%2fBEN-2012-129006&partnerID=40&md5=9dd0493c948240dfb0e84817a5518451","Humanistic Studies Department, Psychology Section, University of Pavia, Pavia, Italy; AIS Lab, Computer Science Department, University of Milan, Milan, Italy; Cognitive Neuropsychology Center, Niguarda Ca' Granda Hospital, Milan, Italy; Neurorehabilitation and Rehabilitative Medecine, Niguarda Ca' Granda Hospital, Milan, Italy","Sedda, A., Humanistic Studies Department, Psychology Section, University of Pavia, Pavia, Italy; Borghese, N.A., AIS Lab, Computer Science Department, University of Milan, Milan, Italy; Ronchetti, M., AIS Lab, Computer Science Department, University of Milan, Milan, Italy; Mainetti, R., AIS Lab, Computer Science Department, University of Milan, Milan, Italy; Pasotti, F., Humanistic Studies Department, Psychology Section, University of Pavia, Pavia, Italy, Cognitive Neuropsychology Center, Niguarda Ca' Granda Hospital, Milan, Italy; Beretta, G., Neurorehabilitation and Rehabilitative Medecine, Niguarda Ca' Granda Hospital, Milan, Italy; Bottini, G., Humanistic Studies Department, Psychology Section, University of Pavia, Pavia, Italy, Cognitive Neuropsychology Center, Niguarda Ca' Granda Hospital, Milan, Italy","Purpose: Virtual Reality (VR) platforms gained a lot of attention in the rehabilitation field due to their ability to engage patients and the opportunity they offer to use real world scenarios. As neglect is characterized by an impairment in exploring space that greatly affects daily living, VR could be a powerful tool compared to classical paper and pencil tasks and computer training. Nevertheless, available platforms are costly and obstructive. Here we describe a low cost platform for neglect rehabilitation, that using consumer equipments allows the patient to train at home in an intensive fashion. Method: We tested the platform on IB, a chronic neglect patient, who did not benefit from classical rehabilitation. Results: Our results show that IB improved both in terms of neglect and attention. Importantly, these ameliorations lasted at a follow up evaluation 5 months after the last treatment session and generalized to everyday life activities. Conclusions: VR platforms built using equipment technology and following theoretical principles on brain functioning may induce greater ameliorations in visuo-spatial deficits than classical paradigms possibly thanks to the real world scenarios in association with the «visual feedback» of the patient's own body operating in the virtual environment. © 2013 - IOS Press and the authors. All rights reserved.","grasping; neglect rehabilitation; neural plasticity; neuropsychological rehabilitation; Virtual reality","adult; attention; cognitive rehabilitation; conference paper; daily life activity; follow up; home care; human; mini mental state examination; neglect; neuropsychological test; priority journal; task performance; virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84872904466
"Xuewen C., Yuqing L., Ming A., Fuchao H.","9337925200;55298260900;56288630600;56288096800;","Astronaut operating simulation in space station based on virtual reality",2013,"Proceedings of the International Astronautical Congress, IAC","6",,,"4666","4677",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904673323&partnerID=40&md5=1e3975a7b5915cf4a0300cd388765612","China Astronaut Research and Training Center, National Key Laboratory of Human Factors Engineering, Beijing, China","Xuewen, C., China Astronaut Research and Training Center, National Key Laboratory of Human Factors Engineering, Beijing, China; Yuqing, L., China Astronaut Research and Training Center, National Key Laboratory of Human Factors Engineering, Beijing, China; Ming, A., China Astronaut Research and Training Center, National Key Laboratory of Human Factors Engineering, Beijing, China; Fuchao, H., China Astronaut Research and Training Center, National Key Laboratory of Human Factors Engineering, Beijing, China","Astronaut operating simulation system was widely applied to verification of project design and operation training for mission preparation. The hardware and software framework of the virtual reality (VR) system, the method to simulate the virtual scene and human, the flow of simulation for operating were given. Three operations which complete the process of obtaining food from cupboard and heating food in a microwave oven, and three types of objects in degree of freedom(DOF) were given detailed analysis. The three operations are: grasp-transfer-release free object, push/pop drawer, open/close cabinet door. The three types of objects are: 6 DOF objects which can be moved to any position and orientation, cabinet door which can be rotated around a fixed axis within a range of angle, drawer which can be moved along a direction within a range of distance. The algorithm and C++ code to implement the operation on the three types of objects using the VR system were given. The operation system was applied successfully to the verification of design for the cupboard in the space kitchen of the future long-term manned spacecraft. The results showed that the operation system was a real-time system, could be used to all operations in spacecraft, and was a useful system for verification of designs in developing and training for mission preparation. Copyright© (2013) by the International Astronautical Federation.",,"Computer programming; Manned space flight; Real time systems; Space stations; Thermal processing (foods); Virtual reality; Hardware and software; Manned spacecraft; Mission preparations; Operation system; Position and orientations; Project designs; Simulation systems; Virtual scenes; C++ (programming language)",Conference Paper,"Final","",Scopus,2-s2.0-84904673323
"Alaraj A., Charbel F.T., Birk D., Tobin M., Luciano C., Banerjee P.P., Rizzi S., Sorenson J., Foley K., Slavin K., Roitberg B.","15838807800;16945837000;14120930700;55550172100;7004699651;35580367600;16310730600;8690246600;7102856392;7006065355;33968027300;","Role of cranial and spinal virtual and augmented reality simulation using immersive touch modules in neurosurgical training",2013,"Neurosurgery","72","SUPPL. 1",,"A115","A123",,64,"10.1227/NEU.0b013e3182753093","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872064481&doi=10.1227%2fNEU.0b013e3182753093&partnerID=40&md5=b9581c8c6bde510488311acc4dda173d","Department of Neurosurgery, College of Medicine, University of Illinois at Chicago, 912 S Wood St, Chicago, IL 60612-7329, United States; Department of Mechanical and Industrial Engineering, University of Illinois at Chicago, College of Engineering, Chicago, IL, United States; Section of Neurosurgery, University of Chicago, Chicago, IL, United States; Medical Education and Research Institute, Memphis, TN, United States","Alaraj, A., Department of Neurosurgery, College of Medicine, University of Illinois at Chicago, 912 S Wood St, Chicago, IL 60612-7329, United States; Charbel, F.T., Department of Neurosurgery, College of Medicine, University of Illinois at Chicago, 912 S Wood St, Chicago, IL 60612-7329, United States; Birk, D., Department of Neurosurgery, College of Medicine, University of Illinois at Chicago, 912 S Wood St, Chicago, IL 60612-7329, United States; Tobin, M., Department of Neurosurgery, College of Medicine, University of Illinois at Chicago, 912 S Wood St, Chicago, IL 60612-7329, United States; Luciano, C., Department of Mechanical and Industrial Engineering, University of Illinois at Chicago, College of Engineering, Chicago, IL, United States; Banerjee, P.P., Department of Mechanical and Industrial Engineering, University of Illinois at Chicago, College of Engineering, Chicago, IL, United States, Section of Neurosurgery, University of Chicago, Chicago, IL, United States; Rizzi, S., Department of Mechanical and Industrial Engineering, University of Illinois at Chicago, College of Engineering, Chicago, IL, United States; Sorenson, J., Medical Education and Research Institute, Memphis, TN, United States; Foley, K., Medical Education and Research Institute, Memphis, TN, United States; Slavin, K., Department of Neurosurgery, College of Medicine, University of Illinois at Chicago, 912 S Wood St, Chicago, IL 60612-7329, United States; Roitberg, B., Section of Neurosurgery, University of Chicago, Chicago, IL, United States","Recent studies have shown that mental script-based rehearsal and simulation-based training improve the transfer of surgical skills in various medical disciplines. Despite significant advances in technology and intraoperative techniques over the last several decades, surgical skills training on neurosurgical operations still carries significant risk of serious morbidity or mortality. Potentially avoidable technical errors are well recognized as contributing to poor surgical outcome. Surgical education is undergoing overwhelming change, as a result of the reduction of work hours and current trends focusing on patient safety and linking reimbursement with clinical outcomes. Thus, there is a need for adjunctive means for neurosurgical training, which is a recent advancement in simulation technology. ImmersiveTouch is an augmented reality system that integrates a haptic device and a high-resolution stereoscopic display. This simulation platform uses multiple sensory modalities, re-creating many of the environmental cues experienced during an actual procedure. Modules available include ventriculostomy, bone drilling, percutaneous trigeminal rhizotomy, and simulated spinal modules such as pedicle screw placement, vertebroplasty, and lumbar puncture. We present our experience with the development of such augmented reality neurosurgical modules and the feedback from neurosurgical residents. Copyright © 2012 by the Congress of Neurological Surgeons.","Neurosurgical training; Spinal instrumentation; Surgical Simulation; Ventriculostomy; Virtual reality","anastomosis; article; bone drilling; human; lumbar puncture; neurosurgery; pedicle screw; percutaneous trigeminal rhizotomy; percutaneous vertebroplasty; priority journal; rhizotomy; skull surgery; surgical training; virtual reality; Central Nervous System Diseases; Competency-Based Education; Computer Simulation; Craniotomy; Education, Medical, Graduate; Feedback; Humans; Imaging, Three-Dimensional; Internship and Residency; Medical Errors; Neurosurgical Procedures; Rhizotomy; Spinal Fusion; Spinal Puncture; Touch; Trigeminal Neuralgia; User-Computer Interface; Ventriculostomy; Vertebroplasty",Article,"Final","",Scopus,2-s2.0-84872064481
"Mac Dowell N., Samsatli N.J., Shah N.","35775476400;6603189628;56846290400;","Dynamic modelling and analysis of an amine-based post-combustion CO2 capture absorption column",2013,"International Journal of Greenhouse Gas Control","12",,,"247","258",,77,"10.1016/j.ijggc.2012.10.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871369555&doi=10.1016%2fj.ijggc.2012.10.013&partnerID=40&md5=e8731e35e47b8fae1bd03dfed79e41f0","Centre for Process Systems Engineering, Department of Chemical Engineering, Imperial College London, South Kensington Campus, London SW7 2AZ, United Kingdom","Mac Dowell, N., Centre for Process Systems Engineering, Department of Chemical Engineering, Imperial College London, South Kensington Campus, London SW7 2AZ, United Kingdom; Samsatli, N.J., Centre for Process Systems Engineering, Department of Chemical Engineering, Imperial College London, South Kensington Campus, London SW7 2AZ, United Kingdom; Shah, N., Centre for Process Systems Engineering, Department of Chemical Engineering, Imperial College London, South Kensington Campus, London SW7 2AZ, United Kingdom","A dynamic, non-equilibrium model of a packed column for the chemisorption of CO2 from dilute gas streams using a monoethanolamine solvent has been proposed. The model uses the SAFT-VR equation of state to describe the thermophysical properties and fluid-phase behaviour of this process. The SAFT-VR equation-of-state is used to account for all of the inter-species interactions in the fluid, including the reactions. In this way, we avoid the use of enhancement factors. Further it is not necessary to include a detailed description of the reaction mechanisms or the reaction products. Steady state validation of the proposed model is performed using pilot plant data. The position and extent of the mass transfer zone is found to be a function of competing interphase fluxes of H2O and CO2. We evaluate through dynamic simulation the effect of changing the lean solvent flowrate and thermodynamic state on column behaviour. The influence of flue gas humidity on the position and shape of the mass transfer zone is also highlighted and discussed. © 2012 Elsevier Ltd.","CO2 capture; Dynamic process modelling; Flexibility; SAFT-VR","Absorption columns; Dilute gas; Dynamic process; Enhancement factor; Equation of state; Flexibility; Flue gas humidity; Fluid-phase; Monoethanolamine solvent; Nonequilibrium model; Packed column; Post-combustion; Reaction mechanism; SAFT-VR; Steady state; Thermodynamic state; Chemisorption; Computer simulation; Mass transfer; Pilot plants; Thermodynamic properties; Carbon dioxide; absorption; carbon dioxide; carbon sequestration; combustion; equation of state; solvent; steady-state equilibrium; transfer zone",Article,"Final","",Scopus,2-s2.0-84871369555
"Medeiros D., Teixeira L., Carvalho F., Santos I., Raposo A.","55428540900;57212518247;23396260500;7102671754;6603721426;","A tablet-based 3D interaction tool for virtual engineering environments",2013,"Proceedings - VRCAI 2013: 12th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry",,,,"211","218",,14,"10.1145/2534329.2534349","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891519598&doi=10.1145%2f2534329.2534349&partnerID=40&md5=fac54922eb295c032efdb5293a9c8806","Tecgraf/PUC-Rio, Brazil; Petrobras, Brazil","Medeiros, D., Tecgraf/PUC-Rio, Brazil; Teixeira, L., Tecgraf/PUC-Rio, Brazil; Carvalho, F., Tecgraf/PUC-Rio, Brazil; Santos, I., Petrobras, Brazil; Raposo, A., Tecgraf/PUC-Rio, Brazil","Three-dimensional computer-aided design (3D CAD) modeling and reviewing is one of the most common engineering project tools. Interaction in these environments is characterized by the need for a high precision level to execute specific tasks. Generally this kind of task uses specific interaction devices with 4 or more degrees of freedom, such as 3D mice. Currently applications involving 3D interaction use interaction devices for object modeling or for the implementation of navigation, selection and manipulation techniques in a virtual environment. A related problem is the need to control naturally non-immersive tasks, such as symbolic input (e.g., text, photos). In addition, the steep learning curve to handle such non-conventional devices is a recurring problem. The addition of sensors and the popularization of smart-phones and tablets, allowed the use of such devices in virtual engineering environments. These devices, differs to other devices by the possibility of including additional information and performing naturally non-immersive tasks. This work presents a 3D interaction tablet-based tool, which allows the aggregation of all major 3D interaction topics, such as navigation, selection, manipulation, system control and symbolic input. To validate the proposed tool, the SimUEP-Ambsim application was chosen, an oil and gas simulator that has the complexity needed and which allows the use of all techniques implemented. Then, the tool was tested in another application, a photo-voltaic solar plant simulator, in order to evaluate the generality of this work concept. © 2013 ACM.","3D interaction; mobile devices; virtual engineering environments; virtual reality","Computer aided design; Interactive computer graphics; Mobile devices; Tools; Virtual reality; 3D interactions; Engineering project; Interaction devices; Manipulation techniques; Specific interaction; Specific tasks; Steep learning curve; Virtual engineering; Three dimensional",Conference Paper,"Final","",Scopus,2-s2.0-84891519598
"Sandy N.S., Da Cruz J.A.S., Passerotti C.C., Nguyen H., Dos Reis S.T., Gouveia E.M., Duarte R.J., Bruschini H., Srougi M.","35786587900;36342181400;14007212500;7403322087;26432175700;55019988400;7005370698;6701853811;7006308114;","Can the learning of laparoscopic skills be quantified by the measurements of kill parameters performed in a virtual reality simulator?",2013,"International Braz J Urol","39","3",,"371","376",,2,"10.1590/S1677-5538.IBJU.2013.03.17","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881530865&doi=10.1590%2fS1677-5538.IBJU.2013.03.17&partnerID=40&md5=b90f84323e3d581a254b23b09a1b3402","Urology Department, University of Sao Paulo Medical School, Sao Paulo, Brazil; Laboratory of Medical Investigation (LIM55), Urology Department, University of Sao Paulo Medical School, Sao Paulo, Brazil; Urology Department, Nove de Julho University (UNINOVE), Sao Paulo, Brazil; Urology Department, Children's Hospital Boston, Boston, MA, United States","Sandy, N.S., Urology Department, University of Sao Paulo Medical School, Sao Paulo, Brazil; Da Cruz, J.A.S., Urology Department, University of Sao Paulo Medical School, Sao Paulo, Brazil; Passerotti, C.C., Urology Department, University of Sao Paulo Medical School, Sao Paulo, Brazil, Laboratory of Medical Investigation (LIM55), Urology Department, University of Sao Paulo Medical School, Sao Paulo, Brazil, Urology Department, Nove de Julho University (UNINOVE), Sao Paulo, Brazil; Nguyen, H., Urology Department, Children's Hospital Boston, Boston, MA, United States; Dos Reis, S.T., Laboratory of Medical Investigation (LIM55), Urology Department, University of Sao Paulo Medical School, Sao Paulo, Brazil; Gouveia, E.M., Urology Department, University of Sao Paulo Medical School, Sao Paulo, Brazil; Duarte, R.J., Urology Department, University of Sao Paulo Medical School, Sao Paulo, Brazil; Bruschini, H., Urology Department, University of Sao Paulo Medical School, Sao Paulo, Brazil; Srougi, M., Urology Department, University of Sao Paulo Medical School, Sao Paulo, Brazil","Purpose: To ensure patient safety and surgical efficiency, much emphasis has been placed on the training of laparoscopic skills using virtual reality simulators. The purpose of this study was to determine whether laparoscopic skills can be objectively quantified by measuring specific skill parameters during training in a virtual reality surgical simulator (VRSS).Materials and Methods: Ten medical students (with no laparoscopic experience) and ten urology residents (PGY3-5 with limited laparoscopic experience) were recruited to participate in a ten-week training course in basic laparoscopic skills (camera, cutting, peg transfer and clipping skills) on a VRSS. Data were collected from the training sessions. The time that individuals took to complete each task and the errors that they made were analyzed independently. Results: The mean time that individuals took to complete tasks was significantly different between the groups (p < 0.05), with the residents being faster than the medical students. The residents' group also completed the tasks with fewer errors. The majority of the subjects in both groups exhibited a significant improvement in their task completion time and error rate. Conclusion: The findings in this study demonstrate that laparoscopic skills can be objectively measured in a VRSS based on quantified skill parameters, including the time spent to complete skill tasks and the associated error rate. We conclude that a VRSS is a feasible tool for training and assessing basic laparoscopic skills.","Education; Laparoscopy; Virtual reality exposure therapy",,Article,"Final","",Scopus,2-s2.0-84881530865
"Moya S., Grau S., Tost D.","36091427300;24337715400;6602117681;","Assisted navigation for 3D serious games training",2013,"Actas del XIV Congreso Internacional de Interaccion Persona-Ordenador, INTERACCION 2013",,,,"3","9",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088699580&partnerID=40&md5=449ddbc86a82d5073b41361a3e71dcc4","CREB-UPC, Spain","Moya, S., CREB-UPC, Spain; Grau, S., CREB-UPC, Spain; Tost, D., CREB-UPC, Spain","Serious games in 3D virtual environments are becoming a popular tool for professional training activities as well as for rehabilitation. Navigation in 3D is recognized as one of the activity which is more difficult to master in this envi- ronments. In particular, elder users, less familiar with 3D games often do not know how to walk through these envi- ronments. They get puzzled without having been able to address the real purpose of the game. In this paper, we pro- pose different enhancement methods to make navigation in 3D easier, and we describe the design and implementation of an automatic navigation mode, usable when navigation is needed to reach objects in the 3D world but is not a goal of the game by itself. We compare the results of an eval- uation test of these different methods. We conclude that, for non-usual gamers, automatic navigation is the faster and preferred mode, whereas gamers prefer to control navigation themselves. For non-automatic navigation, the performance is better when the cursor is fixed in the view center point during locomotion. On the contrary, for still positions, a free cursor is preferable. Finally, restriction of the pitch an- gle in a solid angle that encompasses the objects related to the task is better than a free pitch angle rotation for still positions. During locomotion, fixing the pitch angle at the horizontal level enhances the navigation. © 2013 Actas del XIV Congreso Internacional de Interaccion Persona-Ordenador, INTERACCION 2013. All rights reserved.","Camera Control; Navigation; Usability; Virtual Worlds","Human computer interaction; Navigation; Technology transfer; 3-D virtual environment; Assisted navigations; Automatic navigation; Center points; Design and implementations; Pitch angle; Professional training; Solid angle; Serious games",Conference Paper,"Final","",Scopus,2-s2.0-85088699580
"Van Bruwaene S., Schijven M.P., Miserez M.","26536965100;6602492995;6603926707;","Maintenance training for laparoscopic suturing: The quest for the perfect timing and training model: A randomized trial",2013,"Surgical Endoscopy","27","10",,"3823","3829",,12,"10.1007/s00464-013-2981-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885188934&doi=10.1007%2fs00464-013-2981-9&partnerID=40&md5=0ed4eee05932ade53082eefc4d86ca9e","Center for Surgical Technologies, Leuven, Belgium; Department of Urology, University Hospitals, Herestraat 49, 3000 Leuven, Belgium; Department of Surgery, Academic Medical Center, Amsterdam, Netherlands; Department of Abdominal Surgery, University Hospitals, Leuven, Belgium","Van Bruwaene, S., Center for Surgical Technologies, Leuven, Belgium, Department of Urology, University Hospitals, Herestraat 49, 3000 Leuven, Belgium; Schijven, M.P., Department of Surgery, Academic Medical Center, Amsterdam, Netherlands; Miserez, M., Center for Surgical Technologies, Leuven, Belgium, Department of Abdominal Surgery, University Hospitals, Leuven, Belgium","Background: Although excellent training programs exist for acquiring the challenging skill required in laparoscopic suturing, without subsequent reinforcement, performance is prone to decay. Therefore, maintenance training is proposed to ensure better skill retention. This study aimed to elucidate the ideal timing and frequency of maintenance training as well as the best model to be used for this training. Methods: After completing a proficiency-based laparoscopic suturing training, 39 medical students attended different maintenance programs represented by four groups: a control group without additional training (group 1), a massed training group with one supervised training session (150 min) after 2.5 months (group 2), and two distributed training groups with five monthly unsupervised training sessions of 30 min on a box trainer (group 3) or the LapMentor® (group 4). Retention testing, after 5 months, included suturing on a box trainer and on a cadaver porcine Nissen model. Performance scores (time and errors) were expressed in seconds. Afterward, time needed to regain proficiency was measured. Results: On the box trainer, the median performance scores were 233 s (interquartile range [IQR] 27 s) for group 1, 180 s (IQR 55 s) for group 2, 169 s (IQR 26 s) for group 3, and 226 s (IQR 66 s) for group 4 (p = 0.03). No difference was seen between groups 2 and 3, both of which significantly outperformed groups 1 and 4. On the porcine Nissen model, no differences were detected between the groups (p = 0.53). Group 3 reached proficiency more quickly than the other groups. Conclusions: Maintenance training is a valuable and necessary addendum to proficiency-based training programs for laparoscopic suturing. A maintenance-training interval of 1 month with unsupervised training sessions on simple box trainers seems ideal. The LapMentor® did not show any benefit. Performance differences between groups did not translate to a clinically relevant model, indicating that transfer of training is not perfect. © 2013 Springer Science+Business Media New York.","Laparoscopy; Maintenance; Suturing; Training; Virtual simulation","adult; article; controlled study; educational model; female; human; human experiment; laparoscopic suturing; male; medical student; model; normal human; priority journal; questionnaire; randomized controlled trial; scoring system; surgical training; suturing method; virtual reality; Animals; Education, Medical, Undergraduate; Educational Measurement; Female; Fundoplication; Humans; Laparoscopy; Learning Curve; Male; Models, Structural; Students, Medical; Suture Techniques; Swine; Task Performance and Analysis; User-Computer Interface; Young Adult",Article,"Final","",Scopus,2-s2.0-84885188934
"Neuenhaus D.H.-J.F., Geßler U.J., Feldmann M.","6602226398;7006489375;55940349300;","Using multibody-system modeling to make accurate predictions of vehicle impacts on road restraint systems",2013,"International Journal of Non-Linear Mechanics","53",,,"24","31",,7,"10.1016/j.ijnonlinmec.2012.10.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897602042&doi=10.1016%2fj.ijnonlinmec.2012.10.011&partnerID=40&md5=c0f7b6afef39ff9298999a0877252608","Im Hole 39, 44791 Bochum, Germany; RWTH Aachen University, Institute for Steel Structures, Mies-van-der-Rohe-Straße 1, 52074 Aachen, Germany","Neuenhaus, D.H.-J.F., Im Hole 39, 44791 Bochum, Germany; Geßler, U.J., RWTH Aachen University, Institute for Steel Structures, Mies-van-der-Rohe-Straße 1, 52074 Aachen, Germany; Feldmann, M., RWTH Aachen University, Institute for Steel Structures, Mies-van-der-Rohe-Straße 1, 52074 Aachen, Germany","Road restraint systems have the aim to prevent vehicles from leaving the road, thus to elude obstacles (lightening posts etc), to protect the environment (water protection areas etc) or to prevent fall hazards at bridges (protecting people and housing underneath bridges). With regard to these different protective aims, the European standard EN 1317 classifies vehicle restraint systems (VRS) into different containment levels for 'temporary', 'normal' or 'higher containment'. To classify and certify a VRS to these levels, EN 1317 requires carrying out standardized full-scale impact tests, causing substantial expenses. To reduce such costs, EN 1317-part 5 explicitly allows replacing those full-scale impact tests by computational simulations under certain limitations, in particular if a VRS is only subject to modifications. Due to the high requirements on reproducing the real impact tests by simulations, the modeling of the VRS as well as of the vehicle demands for great accuracy and high skills. Already minor changes on the model of the VRS or vehicle may cause significant changes in results. While it seems at the moment that FEM models are the preferred choice for this, the paper will show that the method of MBS provides an equally or even better simulation approach. The MBS models are assembled using macro-objects from former experience [e.g. Neuenhaus et al. 2007 [12]] offering simulations with comparably short runtime. In particular favorable for parametric studies, the use of MBS models allows the modification of system parameters directly by changing viscoelastic element parameters. To illustrate the potential and possible accuracy of using MBS, the results from real full-scale impact tests are faced with the results from simulation runs. To show the generality of the method, one of the examples represents a rather flexible (soft) VRS, and the other one represents a much more stiff construction. © 2012 Elsevier Ltd. All rights reserved.","EN 1317; Full-scale test; Guardrails; Multibody systems (MBS); Simulation; Vehicle impact; Vehicle restraint system (VRS)","Guard rails; Roads and streets; Transportation; Vehicles; EN 1317; Full scale tests; Multibody system; Simulation; Vehicle impact; Vehicle restraint system; Crashworthiness",Article,"Final","",Scopus,2-s2.0-84897602042
"Antonya C.","22133383000;","Hybrid dynamic model for haptic systems with planar mechanisms",2013,"IEEE Conference on Robotics, Automation and Mechatronics, RAM - Proceedings",,, 6758579,"174","178",,1,"10.1109/RAM.2013.6758579","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84898021585&doi=10.1109%2fRAM.2013.6758579&partnerID=40&md5=f0c7588fb03be44335bba2c68b26b86c","Automotive and Transportation Department, Faculty of Mechanical Engineering, Transilvania University of Brasov, 29 Eroilor Blvd, Brasov, 500036, Romania","Antonya, C., Automotive and Transportation Department, Faculty of Mechanical Engineering, Transilvania University of Brasov, 29 Eroilor Blvd, Brasov, 500036, Romania","The aim of this paper is to present a new partitioning method for solving the equation of motion of a planar mechanism with more than one degree of freedom, using a hybrid dynamic model. The procedure is according to the Newton-Euler formalism with Lagrange equations and can be used in the case that some of the applied forces acting on the elements of the mechanism are unknown, but the time history of generalized coordinate variation (acceleration) of the same elements are imposed. The resulting equations can be used for real time simulations whenever some of the external forces are unknown (but the motion of the same elements are tracked or imposed) and when a high rate of update is expected. For example virtual prototyping with haptic systems needs a very fast haptic rendering loop and forces developed by the user are unknown. Fast simulation makes possible the expansion of the frequency of aliased harmonics of the generated forces in the haptic system, so that it can better mechanically filter them, allowing a wider bandwidth of force. Haptic interaction with an accurate and fast dynamic simulation provides unique insights into the behaviors of the virtual prototype. The proposed partitioning method can be used only in these special circumstances and enforce dynamic consistency over time. © 2013 IEEE.",,"Computer simulation; Dynamic models; Equations of motion; Haptic interfaces; Dynamic consistencies; Equation of motion; Generalized coordinates; Haptic interactions; Hybrid dynamic modeling; Partitioning methods; Real time simulations; Virtual prototyping; Robotics",Conference Paper,"Final","",Scopus,2-s2.0-84898021585
"Nehme J., Sodergren M.H., Sugden C., Aggarwal R., Gillen S., Feussner H., Yang G.-Z., Darzi A.","37031585700;25929707800;26632563200;8616911800;8159952600;56048375900;55539304100;14633357600;","A randomized controlled trial evaluating endoscopic and laparoscopic training in skills transfer for novices performing a simulated NOTES task",2013,"Surgical Innovation","20","6",,"631","638",,5,"10.1177/1553350613480854","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894538098&doi=10.1177%2f1553350613480854&partnerID=40&md5=d8f19a6f76b8132cd3758912d7f02ed1","Department of Biosurgery and Surgical Technology, Imperial College, London, St Mary's Hospital, South Wharf Road, London, W2 1NY, United Kingdom; Klinikum Rechts der Isar, Technische Universität Munich, Germany","Nehme, J., Department of Biosurgery and Surgical Technology, Imperial College, London, St Mary's Hospital, South Wharf Road, London, W2 1NY, United Kingdom; Sodergren, M.H., Department of Biosurgery and Surgical Technology, Imperial College, London, St Mary's Hospital, South Wharf Road, London, W2 1NY, United Kingdom; Sugden, C., Department of Biosurgery and Surgical Technology, Imperial College, London, St Mary's Hospital, South Wharf Road, London, W2 1NY, United Kingdom; Aggarwal, R., Department of Biosurgery and Surgical Technology, Imperial College, London, St Mary's Hospital, South Wharf Road, London, W2 1NY, United Kingdom; Gillen, S., Klinikum Rechts der Isar, Technische Universität Munich, Germany; Feussner, H., Klinikum Rechts der Isar, Technische Universität Munich, Germany; Yang, G.-Z., Department of Biosurgery and Surgical Technology, Imperial College, London, St Mary's Hospital, South Wharf Road, London, W2 1NY, United Kingdom; Darzi, A., Department of Biosurgery and Surgical Technology, Imperial College, London, St Mary's Hospital, South Wharf Road, London, W2 1NY, United Kingdom","Background. The NOSCAR white paper lists training as an important step to the safe clinical application of natural orifice translumenal endoscopic surgery (NOTES). The aim of this randomized controlled trial was to evaluate whether training novices in either a laparoscopic or endoscopic simulator curriculum would affect performance in a NOTES simulator task. Methods. A total of 30 third-year medical undergraduates were recruited. They were randomized to 3 groups: no training (control; n = 10), endoscopy training on a validated colonoscopy simulator protocol (n = 10), and training on a validated laparoscopy simulator curriculum (n = 10). All participants subsequently completed a simulated NOTES task, consisting of 7 steps, on the ELITE (endoscopic- laparoscopic interdisciplinary training entity) model. Performance was assessed as time taken to complete individual steps, overall task time, and number of errors. Results. The endoscopy group was significantly faster than the control group at accessing the peritoneal cavity through the gastric incision (median 27 vs 78 s; P =.015), applying diathermy to the base of the appendix (median 103.5 vs 173 s; P =.014), and navigating to the gallbladder (median 76 vs 169.5 s; P =.049). Endoscopy participants completed the full NOTES procedure in a shorter time than the laparoscopy group (median 863 vs 2074 s; P <.001). Conclusion. This study highlights the importance of endoscopic training for a simulated NOTES task that involves both navigation and resection with operative maneuvers. Although laparoscopic training confers some benefit for operative steps such as applying diathermy to the gallbladder fossa, this was not as beneficial as training in endoscopy. © The Author(s) 2013.","ergonomics and/or human factors study; flexible endoscopy; NOTES; simulation","adult; appendix; article; clinical article; clip; controlled study; diathermy; education program; endoscopy; error; female; gallbladder; gastroscope; human; incision; intermethod comparison; laparoscopy; male; natural orifice transluminal endoscopic surgery; needle; operation duration; performance; peritoneal cavity; randomized controlled trial; simulation; simulator; skill; surgical training; young adult; ergonomics and/or human factors study; flexible endoscopy; NOTES; simulation; Adult; Clinical Competence; Colonoscopy; Computer Simulation; Education, Medical, Continuing; Female; Human Engineering; Humans; Laparoscopy; Male; Natural Orifice Endoscopic Surgery; Task Performance and Analysis; Young Adult",Article,"Final","",Scopus,2-s2.0-84894538098
"Larrue F., Sauzéon H., Aguilova L., Lotte F., Hachet M., Kaoua B.N.","36139685200;7801452039;55546691500;12801085400;10140643700;35334502000;","Brain computer interface vs walking interface in VR: The impact of motor activity on spatial transfer",2012,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,,,"113","120",,6,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871967464&partnerID=40&md5=b48cae25c8b792e08b8fd3f09cd17f75","University of Bordeaux, LaBRI, UMR 5800, F-33400 Talence, France; CNRS, LaBRI, UMR 5800, 33400 Talence, France; University of Bordeaux Victor Segalen, EA 4136, Handicap and Système Nerveux, 33076 Bordeaux Cedex, France; INRIA, F-33400 Talence, France","Larrue, F., University of Bordeaux, LaBRI, UMR 5800, F-33400 Talence, France, CNRS, LaBRI, UMR 5800, 33400 Talence, France, University of Bordeaux Victor Segalen, EA 4136, Handicap and Système Nerveux, 33076 Bordeaux Cedex, France, INRIA, F-33400 Talence, France; Sauzéon, H., CNRS, LaBRI, UMR 5800, 33400 Talence, France; Aguilova, L., CNRS, LaBRI, UMR 5800, 33400 Talence, France; Lotte, F., University of Bordeaux, LaBRI, UMR 5800, F-33400 Talence, France, CNRS, LaBRI, UMR 5800, 33400 Talence, France, INRIA, F-33400 Talence, France; Hachet, M., University of Bordeaux, LaBRI, UMR 5800, F-33400 Talence, France, CNRS, LaBRI, UMR 5800, 33400 Talence, France, INRIA, F-33400 Talence, France; Kaoua, B.N., CNRS, LaBRI, UMR 5800, 33400 Talence, France","The goal of this study is to explore new navigation methods in Virtual Reality (VR) and to understand the impact of motor activity on spatial cognition, and more precisely the question of the spatial learning transfer. We present a user study comparing two interfaces with different motor activities: the first one, a walking interface (a treadmill with rotation) gives the user a high level of sensorimotor activity (especially body-based and vestibular information). The second one, a brain computer interface (BCI), enables the user to navigate in a virtual environment (VE) without any motor activity, by using brain activity only. The task consisted in learning a path in a virtual city built from a 3D model of a real city with either one of these two interfaces (named treadmill condition and BCI condition), or in the real city directly (the real condition). Then, participants had to recall spatial knowledge, according to six different tasks assessing spatial memory and transfer. We also evaluated the ergonomics of these two interfaces and the presence felt by participants. Surprisingly, contrary to expectations, our results showed similar performances whatever the spatial restitution tasks or the interfaces used, very close to that of the real condition, which tends to indicate that motor activity is not essential to learn and transfer spatial knowledge. Even if BCI seems to be less natural to use than the treadmill, our study suggests that BCI is a promising interface for studying spatial cognition. Copyright 2012 ACM.","Brain Computer Interface; Interfaces; Navigation; Spatial Cognition; Treadmill; User Study; Virtual Reality","3D models; Brain activity; Motor activity; Navigation methods; Sensorimotor activities; Spatial cognition; Spatial knowledge; Spatial learning; Spatial memory; User study; Virtual cities; Ergonomics; Exercise equipment; Interfaces (materials); Navigation; Sporting goods; Virtual reality; Brain computer interface",Conference Paper,"Final","",Scopus,2-s2.0-84871967464
"Hoang T.N., Thomas B.H.","14819594500;55467685600;","Distance-based modeling and manipulation techniques using ultrasonic gloves",2012,"ISMAR 2012 - 11th IEEE International Symposium on Mixed and Augmented Reality 2012, Science and Technology Papers",,, 6402577,"287","288",,5,"10.1109/ISMAR.2012.6402577","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873560024&doi=10.1109%2fISMAR.2012.6402577&partnerID=40&md5=46ed206868e0dba0c80160c16cade270","Wearable Computer Lab., University of South Australia, Australia","Hoang, T.N., Wearable Computer Lab., University of South Australia, Australia; Thomas, B.H., Wearable Computer Lab., University of South Australia, Australia","We present a set of distance-based interaction techniques for modeling and manipulation, enabled by a new input device called the ultrasonic gloves. The ultrasonic gloves are built upon the original design of the pinch glove device for virtual reality systems with a tilt sensor and a pair of ultrasonic transducers in the palms of the gloves. The transducers are distance-ranging sensors that allow the user to specify a range of distances by natural gestures such as facing the palms towards each other or towards other surfaces. The user is able to create virtual models of physical objects by specifying their dimensions with hand gestures. We combine the reported distance with the tilt orientation data to construct virtual models. We also map the distance data to create a set of affine transformation techniques, including relative and fixed scaling, translation, and rotation. Our techniques can be generalized to different sensor technologies. © 2012 IEEE.","distance-based techniques; manipulation; modeling; ultrasonic gloves","Affine transformations; Distance datum; Distance-based; Hand gesture; Input devices; Interaction techniques; manipulation; Manipulation techniques; Orientation data; Original design; Physical objects; Sensor technologies; Tilt sensor; Virtual models; Virtual reality system; Augmented reality; Models; Sensors; Transducers; Ultrasonic transducers; Virtual reality; Ultrasonic testing",Conference Paper,"Final","",Scopus,2-s2.0-84873560024
"Lou X., Zhang Q., Wu B., Zhou C.Q., Heim J.E.","56008147000;56007622700;55479844500;7403347472;56007759500;","Development of a virtual power plant boiler for training",2012,"ASME 2012 Heat Transfer Summer Conf. Collocated with the ASME 2012 Fluids Engineering Div. Summer Meeting and the ASME 2012 10th Int. Conf. on Nanochannels, Microchannels and Minichannels, HT 2012","1",,,"1085","1091",,4,"10.1115/HT2012-58426","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892658776&doi=10.1115%2fHT2012-58426&partnerID=40&md5=bccf9710c40285d8130058ef8f3bb402","Center for Innovation through Visualization and Simulation (CIVS), Purdue University Calumet, Hammond, IN, 46323, United States; Northern Indiana Public Service Company (NIPSCO), 721 Zigler Rd., LaPorte, IN 46350, United States","Lou, X., Center for Innovation through Visualization and Simulation (CIVS), Purdue University Calumet, Hammond, IN, 46323, United States; Zhang, Q., Center for Innovation through Visualization and Simulation (CIVS), Purdue University Calumet, Hammond, IN, 46323, United States; Wu, B., Center for Innovation through Visualization and Simulation (CIVS), Purdue University Calumet, Hammond, IN, 46323, United States; Zhou, C.Q., Center for Innovation through Visualization and Simulation (CIVS), Purdue University Calumet, Hammond, IN, 46323, United States; Heim, J.E., Northern Indiana Public Service Company (NIPSCO), 721 Zigler Rd., LaPorte, IN 46350, United States","A power plant boiler is widely used as a heat source for generating steam through fuel combustion. Operations trainees at NIPSCO coal-fired power stations receive short-term training in boiler operation procedures and are given 2D, non-scaled representations of the plant's steam, coal cycle, and limited key components. This study focused on pursuing a more efficient way of representation by using a three-dimensional (3D) numerical model of the power plant boiler and a Virtual Reality platform. Coal and air are injected into ten cyclones of the boiler to undergo violent combustion and release the heat to the tubes along both cyclone and furnace walls. In order to obtain a better understanding of the boiler operation process, which cannot be achieved in reality, Computational Fluid Dynamics (CFD) was employed to simulate the boiler components and the entire combustion procedure. Simulation results presented detailed transient flow characteristics and temperature gradients inside cyclones and the furnace to achieve a thorough understanding of the internal gas flow pattern. Also, the Virtual Reality (VR) platform of a power plant boiler was developed by combining the simulation data inside the boiler and visualization of model image outside the boiler to provide a vivid 3D representation for trainees. Copyright © 2012 by ASME.","Boiler; CFD; Combustion; Flow characteristics; Virtual Reality","3d representations; Coal-fired power stations; Flow charac-teristics; Internal gas flows; Power plant boiler; Three dimensional (3D) numerical models; Transient flow characteristics; Virtual power plants; Coal combustion; Combustion; Computational fluid dynamics; Fossil fuel power plants; Fuels; Heat transfer; Microchannels; Steam power plants; Storms; Three dimensional; Three dimensional computer graphics; Virtual reality; Boilers",Conference Paper,"Final","",Scopus,2-s2.0-84892658776
"Martin K.D., Cameron K., Belmont Jr. P.J., Schoenfeld A., Owens B.D.","54406996500;7102930668;6701737430;35235131300;7102230541;","Shoulder arthroscopy simulator performance correlates with resident and shoulder arthroscopy experience",2012,"Journal of Bone and Joint Surgery - Series A","94","21",,"e160.1","e160.5",,56,"10.2106/JBJS.L.00072","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869142865&doi=10.2106%2fJBJS.L.00072&partnerID=40&md5=ee2942beeada908f2c39a3252d270f50","William Beaumont Army Medical Center, 5005 North Piedras Street, El Paso, TX 79920, United States; Keller Army Hospital, 900 Washington Road, West Point, NY 10996, United States","Martin, K.D., William Beaumont Army Medical Center, 5005 North Piedras Street, El Paso, TX 79920, United States; Cameron, K., Keller Army Hospital, 900 Washington Road, West Point, NY 10996, United States; Belmont Jr., P.J., William Beaumont Army Medical Center, 5005 North Piedras Street, El Paso, TX 79920, United States; Schoenfeld, A., William Beaumont Army Medical Center, 5005 North Piedras Street, El Paso, TX 79920, United States; Owens, B.D., Keller Army Hospital, 900 Washington Road, West Point, NY 10996, United States","Background: The technical skills required to perform arthroscopy are multifaceted and require supervised training and repetition. Obtaining this basic arthroscopic skill set can be costly and time-consuming. Simulation may represent a viable training source for basic arthroscopic skills. Our goal was to evaluate the correlation between timed task performance on an arthroscopic shoulder simulator and both resident experience and shoulder arthroscopy experience. Methods: Twenty-seven residents were voluntarily recruited from an orthopaedic residency program. Each subject was tested annually for three consecutive years on an arthroscopic shoulder simulator and objectively scored on time to completion of a standardized object localization task. Each subject's total number of shoulder arthroscopies, all arthroscopies, and cases were calculated according to postgraduate year from their Accreditation Council for Graduate Medical Education (ACGME) case log. Generalized estimating equation multivariate regression analysis was performed to determine the correlation between simulation performance and total numbers of shoulder arthroscopies, all arthroscopies, and cases. Results: Univariate analyses revealed that postgraduate year, total number of shoulder arthroscopies, total number of arthroscopies of any joint, and total number of surgical cases performed during residency training prior to testing were associated with the mean time required to complete the simulator task. The number of prior shoulder arthroscopies performed (r = 0.55) and postgraduate year in training (r = 0.60) correlated most strongly with simulator basic task performance. In the multivariate analysis, the number of prior shoulder arthroscopies and postgraduate year remained independent predictors of faster completion of the simulator task. For every additional postgraduate year, there was a sixteen-second improvement in the time required to complete the simulator task (p < 0.005). Similarly, after controlling for the influence of postgraduate year, there was a twelve-second decrease in the time to complete the simulator task for every additional fifty shoulder arthroscopies performed during residency training (p < 0.008). Conclusions: These results showed a significant relationship between performance of basic arthroscopic tasks in a simulator model and the number of shoulder arthroscopies performed. The data confirmed our hypothesis that simulator performance is representative of both resident experience and shoulder arthroscopy experience. Clinical Relevance: This study suggests that greater resident clinical experience and shoulder arthroscopy experience are both reflected in improved performance of basic tasks on a shoulder simulator. These findings warrant further investigation to determine if training on a validated arthroscopic shoulder simulator would improve clinical arthroscopic skills. Copyright © 2012 By the Journal of Bone and Joint Surgery, Incorporated.",,"accreditation; adult; article; clinical article; correlational study; female; human; male; outcome assessment; priority journal; professional competence; residency education; resident; shoulder arthroscopy; simulator; task performance; time; work experience; Adult; Arthroscopy; Clinical Competence; Computer Simulation; Education, Medical, Graduate; Educational Measurement; Female; Humans; Internship and Residency; Male; Orthopedics; Psychomotor Performance; Shoulder; Young Adult",Article,"Final","",Scopus,2-s2.0-84869142865
"Mobach M.P.","6601956127;","Interactive facility management, design and planning",2012,"International Journal on Interactive Design and Manufacturing","6","4",,"241","250",,4,"10.1007/s12008-012-0154-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868524533&doi=10.1007%2fs12008-012-0154-z&partnerID=40&md5=3058a71f7b9e27460af147b5225d5a08","Wageningen University, Box 8130, 6700 EW Wageningen, Netherlands; Hanze University of Applied Sciences, Box 3037, 9701 DA Groningen, Netherlands; University of Groningen, Box 800, 9700 AV Groningen, Netherlands","Mobach, M.P., Wageningen University, Box 8130, 6700 EW Wageningen, Netherlands, Hanze University of Applied Sciences, Box 3037, 9701 DA Groningen, Netherlands, University of Groningen, Box 800, 9700 AV Groningen, Netherlands","Societal developments show that future demands for visualization can be expected to grow. In many areas of organized human activities organizations may turn away from textual and numerical flatlands, and rely on the convenient and multidimensional digital worlds. Virtual worlds for facility management, design, and planning are no exception, it has an enormous potential to help organizations finding the right spaces that fit the human activities they perform. However, a major take-up of virtual worlds in this context allowing a comparison between present and future, is yet to come. Perhaps such applications, interweaving virtual and real worlds in order to design better facilities are at its beginning stages. One thing is clear: sophisticated applications may have remained absent until today, but it will come to us. Digital worlds start to normalize and the design of organizational spaces can benefit from that development. In this current article the effects of the proposed integration of visualization with facilities were studied in a case study design. It was assessed whether the participants would actually change the design, without data on the organizational performance, and to what extent this affected staff satisfaction. This study however showed no design changes and no statistically significant changes in the affective responses of participants between pre-test and post-test stages. However, in this current case the sample size may have been too small for generalization purposes. The connection of virtual worlds with organizational data, which were not applied in this current case but were in fact applied in our earlier studies, may be vital for the efficacy of interactive facility management, design, and planning. It is concluded that data on organizational performance serve as a linking pin between facility management and virtual worlds. Interaction can thus be improved by using organizational data as 'subtitles' which stimulate a more active use of the visualization. © 2012 The Author(s).","Facility management; Organization; Participation; Virtual worlds; Visualization","Affective response; Design and planning; Design change; Digital world; Facility management; Human activities; Organizational performance; Participation; Sample sizes; Study design; Virtual worlds; Design; Flow visualization; Management; Office buildings; Societies and institutions; Stages; Virtual reality; Visualization; Data visualization",Article,"Final","",Scopus,2-s2.0-84868524533
"Ju R., Chang P.L., Buckley A.P., Wang K.C.","55587386400;55331762300;55624882800;55624946500;","Comparison of Nintendo Wii and PlayStation2 for enhancing laparoscopic skills",2012,"Journal of the Society of Laparoendoscopic Surgeons","16","4",,"612","618",,11,"10.4293/108680812X13462882737294","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875082632&doi=10.4293%2f108680812X13462882737294&partnerID=40&md5=94a4e85fef3b4ca30635ecda47635553","Department of Obstetrics and Gynecology, The University of North Carolina: Chapel Hill, UNC Hospitals, 3031 Old Clinic, Building CB: 7570, 101 Manning Drive, Chapel Hill, NC 27514, United States; Department of Obstetrics and Gynecology, Beth Israel Medical Center, Baird Hall, New York, NY, United States; Department of Obstetrics and Gynecology, Brigham and Women's Hospital, Boston, MA, United States","Ju, R., Department of Obstetrics and Gynecology, The University of North Carolina: Chapel Hill, UNC Hospitals, 3031 Old Clinic, Building CB: 7570, 101 Manning Drive, Chapel Hill, NC 27514, United States; Chang, P.L., Department of Obstetrics and Gynecology, Beth Israel Medical Center, Baird Hall, New York, NY, United States; Buckley, A.P., Department of Obstetrics and Gynecology, Beth Israel Medical Center, Baird Hall, New York, NY, United States; Wang, K.C., Department of Obstetrics and Gynecology, Brigham and Women's Hospital, Boston, MA, United States","Background and Objective: The increase in laparoscopic surgery has led to a growing need to train residents in this skill. Virtual reality simulators and box trainers have been used as educational tools outside of the operating room, but both approaches have advantages and disadvantages. Video games have been an area of interest in the search for other modalities to train residents. Experience with the traditional single controller unit video games have been correlated with better surgical skill acquisition. In 2006, Nintendo introduced the Wii, a novel gaming modality that mimics movements in laparoscopy better than traditional games do. Our objective was to compare the Nintendo Wii and PlayStation2 for enhancing laparoscopy skills. Methods: The study included stratified randomization of 23 less experienced (<12 laparoscopy cases per year) and 19 more experienced (>12 per year) physicians, residents, and medical students to 30 min of Wii versus PlayStation2 in a university-affiliated hospital Department of Obstetrics and Gynecology. Pre- and posttest bead transfer and suturing scores were obtained. Results: Baseline characteristics were similar for both video game groups. Participants assigned to Wii and PlayStation2 both demonstrated significant improvement in bead transfer. Neither Wii nor PlayStation2 participants improved in suturing scores. The Wii group improved more in bead transfer scores when compared to the PlayStation2 group (60 points vs. 40 points, respectively), but this difference was not statistically significant. Conclusions: Both Wii and PlayStation2 significantly improved laparoscopic skills in bead transfer. These video games may be inexpensive alternatives to laparoscopy training simulators. © 2012 by JSLS, Journal of the Society of Laparoendoscopic Surgeons.","Education; Laparoscopy; Surgical; Video games","adult; article; clinical competence; comparative study; computer simulation; controlled clinical trial; controlled study; education; female; gynecologic surgery; gynecology; human; laparoscopy; male; medical education; medical student; methodology; obstetric operation; obstetrics; randomized controlled trial; recreation; Adult; Clinical Competence; Computer Simulation; Female; Gynecologic Surgical Procedures; Gynecology; Humans; Internship and Residency; Laparoscopy; Male; Obstetric Surgical Procedures; Obstetrics; Students, Medical; Video Games",Article,"Final","",Scopus,2-s2.0-84875082632
"Hseino H., Nugent E., Lee M.J., Hill A.D.K., Neary P., Tierney S., Moneley D., Given M.","36666490600;36141331600;22971842000;35467984400;55250427800;7005249790;6507860045;7005334435;","Skills transfer after proficiency-based simulation training in superficial femoral artery angioplasty",2012,"Simulation in Healthcare","7","5",,"274","281",,25,"10.1097/SIH.0b013e31825b6308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84867214550&doi=10.1097%2fSIH.0b013e31825b6308&partnerID=40&md5=a60a023fd152caf988c5aec7f5f53f63","Department of Surgical Training, Royal College of Surgeons in Ireland, 121 St Stephen's Green, Dublin 2, Ireland; Division of Vascular Surgery, Beaumont Hospital, Dublin, Ireland; Department of Surgery, Beaumont Hospital, Dublin, Ireland","Hseino, H., Department of Surgical Training, Royal College of Surgeons in Ireland, 121 St Stephen's Green, Dublin 2, Ireland; Nugent, E., Department of Surgical Training, Royal College of Surgeons in Ireland, 121 St Stephen's Green, Dublin 2, Ireland; Lee, M.J., Department of Surgery, Beaumont Hospital, Dublin, Ireland; Hill, A.D.K., Department of Surgical Training, Royal College of Surgeons in Ireland, 121 St Stephen's Green, Dublin 2, Ireland; Neary, P., Department of Surgical Training, Royal College of Surgeons in Ireland, 121 St Stephen's Green, Dublin 2, Ireland; Tierney, S., Department of Surgical Training, Royal College of Surgeons in Ireland, 121 St Stephen's Green, Dublin 2, Ireland; Moneley, D., Division of Vascular Surgery, Beaumont Hospital, Dublin, Ireland; Given, M., Department of Surgery, Beaumont Hospital, Dublin, Ireland","INTRODUCTION: The purpose of this study was to explore whether basic endovascular skills acquired using proficiency-based simulation training in superficial femoral artery (SFA) angioplasty translate to real-world performance. METHODS: Five international experts were invited to evaluate a preliminary 28-item rating scale for SFA angioplasty using a modified Delphi study. To test the procedural scale, 4 experts and 11 final-year medical students then performed 2 SFA angioplasties each on the vascular intervention simulation trainer simulator. Thereafter, 10 general surgical residents (novices) received didactic training in SFA angioplasty. Trainees were then randomized with 5 trainees receiving further training on the vascular intervention simulation trainer simulator up to proficiency level. All 10 trainees then performed 1 SFA angioplasty on a patient within 5 days of training. The trainees' performance was assessed by 1 attending consultant blinded to the trainees' training status, using the developed procedural scale and a global rating scale. RESULTS: Four items were eliminated from the procedural scale after the Delphi study. There were significant differences in the procedural scale scores between the experts and the students in the first trial [mean (SD), 94.25 (2.22) vs. 74.90 (8.79), P = 0.001] and the second trial [95.25 (0.50) vs. 76.82 (9.44), P < 0.001]. Simulation-trained trainees scored higher than the controls on the procedural scale [86.8 (5.4) vs. 67.6 (6), P = 0.001] and the global rating scale [37.2 (4.1) vs. 24.4 (5.3), P = 0.003]. CONCLUSIONS: Basic endovascular skills acquired using proficiency-based simulation training in SFA angioplasty do translate to real-world performance. Copyright © 2012 Society for Simulation in Healthcare.","Angioplasty; Delphi; Endovascular; SFA; Simulator; VIST","adult; angioplasty; article; clinical competence; computer interface; computer simulation; controlled clinical trial; controlled study; Delphi study; education; female; femoral artery; human; Ireland; male; medical education; medical staff; medical student; randomized controlled trial; standard; Adult; Angioplasty; Clinical Competence; Computer Simulation; Delphi Technique; Education, Medical, Graduate; Female; Femoral Artery; Humans; Ireland; Male; Medical Staff, Hospital; Students, Medical; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84867214550
"Tausch T.J., Kowalewski T.M., White L.W., McDonough P.S., Brand T.C., Lendvay T.S.","21234661700;7006132582;36081406500;47261410700;14039907700;14319319500;","Content and construct validation of a robotic surgery curriculum using an electromagnetic instrument tracker",2012,"Journal of Urology","188","3",,"919","923",,38,"10.1016/j.juro.2012.05.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864954290&doi=10.1016%2fj.juro.2012.05.005&partnerID=40&md5=eeb64501e2ffe871cdd3727107f7bf9e","Madigan Health Care System, 1120 Cliff Ave., No. 510, Tacoma, WA 98402, United States; University of Washington, Seattle, WA, United States; Seattle Children's Hospital, Seattle, WA, United States","Tausch, T.J., Madigan Health Care System, 1120 Cliff Ave., No. 510, Tacoma, WA 98402, United States; Kowalewski, T.M., University of Washington, Seattle, WA, United States; White, L.W., University of Washington, Seattle, WA, United States; McDonough, P.S., Madigan Health Care System, 1120 Cliff Ave., No. 510, Tacoma, WA 98402, United States; Brand, T.C., Madigan Health Care System, 1120 Cliff Ave., No. 510, Tacoma, WA 98402, United States; Lendvay, T.S., Seattle Children's Hospital, Seattle, WA, United States","Purpose: Rapid adoption of robot-assisted surgery has outpaced our ability to train novice roboticists. Objective metrics are required to adequately assess robotic surgical skills and yet surrogates for proficiency, such as economy of motion and tool path metrics, are not readily accessible directly from the da Vinci® robot system. The trakSTAR™ Tool Tip Tracker is a widely available, cost-effective electromagnetic position sensing mechanism by which objective proficiency metrics can be quantified. We validated a robotic surgery curriculum using the trakSTAR device to objectively capture robotic task proficiency metrics. Materials and Methods: Through an institutional review board approved study 10 subjects were recruited from 2 surgical experience groups (novice and experienced). All subjects completed 3 technical skills modules, including block transfer, intracorporeal suturing/knot tying (fundamentals of laparoscopic surgery) and ring tower transfer, using the da Vinci robot with the trakSTAR device affixed to the robotic instruments. Recorded objective metrics included task time and path length, which were used to calculate economy of motion. Student t test statistics were performed using STATA®. Results: The novice and experienced groups consisted of 5 subjects each. The experienced group outperformed the novice group in all 3 tasks. Experienced surgeons described the simulator platform as useful for training and agreed with incorporating it into a residency curriculum. Conclusions: Robotic surgery curricula can be validated by an off-the-shelf instrument tracking system. This platform allows surgical educators to objectively assess trainees and may provide credentialing offices with a means of objectively assessing any surgical staff member seeking robotic surgery privileges at an institution. © 2012 American Urological Association Education and Research, Inc.","benchmarking; instrumentation; minimally invasive; robotics; surgical procedures; validation studies","article; clinical practice; comparative study; construct validity; content validity; education program; electromagnetic instrument tracker; human; institutional review; priority journal; quantitative analysis; residency education; robotic surgery; robotics; skill; surgeon; surgical instrument; surgical technique; surgical training; suturing method; task performance; Curriculum; Electromagnetic Phenomena; Humans; Prospective Studies; Robotics; Surgical Procedures, Minimally Invasive; Urologic Surgical Procedures",Article,"Final","",Scopus,2-s2.0-84864954290
"Yoon J., Park H.-S., Damiano D.L.","57218802958;55703108500;7003837780;","A novel walking speed estimation scheme and its application to treadmill control for gait rehabilitation",2012,"Journal of NeuroEngineering and Rehabilitation","9","1", 62,"","",,35,"10.1186/1743-0003-9-62","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865332770&doi=10.1186%2f1743-0003-9-62&partnerID=40&md5=0ce5b4071abe5b62361c5de9f86edd9c","Rehabilitation Medicine Department, Clinical Center, National Institutes of Health, Bethesda, MD, United States; School of Mechanical Engineering and ReCAPT, Gyeongsang National University, Jinju, South Korea","Yoon, J., Rehabilitation Medicine Department, Clinical Center, National Institutes of Health, Bethesda, MD, United States, School of Mechanical Engineering and ReCAPT, Gyeongsang National University, Jinju, South Korea; Park, H.-S., Rehabilitation Medicine Department, Clinical Center, National Institutes of Health, Bethesda, MD, United States; Damiano, D.L., Rehabilitation Medicine Department, Clinical Center, National Institutes of Health, Bethesda, MD, United States","Background: Virtual reality (VR) technology along with treadmill training (TT) can effectively provide goal-oriented practice and promote improved motor learning in patients with neurological disorders. Moreover, the VR + TT scheme may enhance cognitive engagement for more effective gait rehabilitation and greater transfer to over ground walking. For this purpose, we developed an individualized treadmill controller with a novel speed estimation scheme using swing foot velocity, which can enable user-driven treadmill walking (UDW) to more closely simulate over ground walking (OGW) during treadmill training. OGW involves a cyclic acceleration-deceleration profile of pelvic velocity that contrasts with typical treadmill-driven walking (TDW), which constrains a person to walk at a preset constant speed. In this study, we investigated the effects of the proposed speed adaptation controller by analyzing the gait kinematics of UDW and TDW, which were compared to those of OGW at three pre-determined velocities. Methods. Ten healthy subjects were asked to walk in each mode (TDW, UDW, and OGW) at three pre-determined speeds (0.5 m/s, 1.0 m/s, and 1.5 m/s) with real time feedback provided through visual displays. Temporal-spatial gait data and 3D pelvic kinematics were analyzed and comparisons were made between UDW on a treadmill, TDW, and OGW. Results: The observed step length, cadence, and walk ratio defined as the ratio of stride length to cadence were not significantly different between UDW and TDW. Additionally, the average magnitude of pelvic acceleration peak values along the anterior-posterior direction for each step and the associated standard deviations (variability) were not significantly different between the two modalities. The differences between OGW and UDW and TDW were mainly in swing time and cadence, as have been reported previously. Also, step lengths between OGW and TDW were different for 0.5 m/s and 1.5 m/s gait velocities, and walk ratio between OGS and UDW was different for 1.0 m/s gait velocities. Conclusions: Our treadmill control scheme implements similar gait biomechanics of TDW, which has been used for repetitive gait training in a small and constrained space as well as controlled and safe environments. These results reveal that users can walk as stably during UDW as TDW and employ similar strategies to maintain walking speed in both UDW and TDW. Furthermore, since UDW can allow a user to actively participate in the virtual reality (VR) applications with variable walking velocity, it can induce more cognitive activities during the training with VR, which may enhance motor learning effects. © 2012 Yoon et al.; licensee BioMed Central Ltd.","Body-weight supported treadmill training; Gait analysis; Self-selected treadmill speed control; Temporal-spatial gait parameters; Walking velocity estimation","acceleration; adolescent; adult; algorithm; analysis of variance; article; biomechanics; body weight; female; foot; gait; histology; human; learning; male; neurologic gait disorder; pathophysiology; pelvis; physical education; physiology; walking; Acceleration; Adolescent; Adult; Algorithms; Analysis of Variance; Biomechanics; Body Weight; Female; Foot; Gait; Gait Disorders, Neurologic; Humans; Learning; Male; Pelvis; Physical Education and Training; Walking; Young Adult",Article,"Final","",Scopus,2-s2.0-84865332770
"Selvander M., Åsman P.","15027572500;6701369328;","Virtual reality cataract surgery training: Learning curves and concurrent validity",2012,"Acta Ophthalmologica","90","5",,"412","417",,40,"10.1111/j.1755-3768.2010.02028.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864401193&doi=10.1111%2fj.1755-3768.2010.02028.x&partnerID=40&md5=57fbdc53f187a55b5da3aa925b5cab75","Department of Clinical Sciences, Lund University, Malmö: Ophthalmology, Sweden; Centre for Medical Simulation, Skåne University Hospital, Malmö, Sweden","Selvander, M., Department of Clinical Sciences, Lund University, Malmö: Ophthalmology, Sweden, Centre for Medical Simulation, Skåne University Hospital, Malmö, Sweden; Åsman, P., Department of Clinical Sciences, Lund University, Malmö: Ophthalmology, Sweden","Purpose: To investigate initial learning curves on a virtual reality (VR) eye surgery simulator and whether achieved skills are transferable between tasks. Methods: Thirty-five medical students were randomized to complete ten iterations on either the VR Caspulorhexis module (group A) or the Cataract navigation training module (group B) and then two iterations on the other module. Learning curves were compared between groups. The second Capsulorhexis video was saved and evaluated with the performance rating tool Objective Structured Assessment of Cataract Surgical Skill (OSACSS). The students' stereoacuity was examined. Results: Both groups demonstrated significant improvements in performance over the 10 iterations: group A for all parameters analysed including score (p < 0.0001), time (p < 0.0001) and corneal damage (p = 0.0003), group B for time (p < 0.0001), corneal damage (p < 0.0001) but not for score (p = 0.752). Training on one module did not improve performance on the other. Capsulorhexis score correlated significantly with evaluation of the videos using the OSACSS performance rating tool. For stereoacuity < and ≥120 seconds of arc, sum of both modules' second iteration score was 73.5 and 41.0, respectively (p = 0.062). Conclusion: An initial rapid improvement in performance on a simulator with repeated practice was shown. For capsulorhexis, 10 iterations with only simulator feedback are not enough to reach a plateau for overall score. Skills transfer between modules was not found suggesting benefits from training on both modules. Stereoacuity may be of importance in the recruitment and training of new cataract surgeons. Additional studies are needed to investigate this further. Concurrent validity was found for Capsulorhexis module. © 2010 The Authors. Acta Ophthalmologica.","cataract surgery; simulator; skills training; virtual reality","adult; anterior eye segment; article; capsulorhexis; cataract extraction; computer simulation; controlled study; eye surgery; human; medical student; mental performance; Objective Structured Assessment of Cataract Surgical Skill; priority journal; psychomotor performance; rating scale; surgical training; videorecording; virtual reality; viscoelasticity; visual acuity; Adult; Capsulorhexis; Cataract Extraction; Clinical Competence; Computer Simulation; Education, Medical; Educational Measurement; Humans; Learning Curve; Ophthalmology; Transfer (Psychology); User-Computer Interface; Visual Acuity; Young Adult",Article,"Final","",Scopus,2-s2.0-84864401193
"Klein M.I., Warm J.S., Riley M.A., Matthews G., Doarn C., Donovan J.F., Gaitonde K.","35743063600;7003365044;7203009785;7201422023;7003293563;35478229100;6507516465;","Mental workload and stress perceived by novice operators in the laparoscopic and robotic minimally invasive surgical interfaces",2012,"Journal of Endourology","26","8",,"1089","1094",,36,"10.1089/end.2011.0641","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865192210&doi=10.1089%2fend.2011.0641&partnerID=40&md5=f26aeba21a4817cd36f4634b4962be37","Department of Psychology, MS2051, Texas Tech University, Lubbock, TX 79409, United States; Air Force Research Laboratory, Wright Patterson Air Force Base, Dayton, OH, United States; Department of Psychology, University of Cincinnati, Cincinnati, OH, United States; Department of Family and Community Medicine, University of Cincinnati, Cincinnati, OH, United States; Department of Urology, University of Cincinnati, Cincinnati, OH, United States","Klein, M.I., Department of Psychology, MS2051, Texas Tech University, Lubbock, TX 79409, United States; Warm, J.S., Air Force Research Laboratory, Wright Patterson Air Force Base, Dayton, OH, United States; Riley, M.A., Department of Psychology, University of Cincinnati, Cincinnati, OH, United States; Matthews, G., Department of Psychology, University of Cincinnati, Cincinnati, OH, United States; Doarn, C., Department of Family and Community Medicine, University of Cincinnati, Cincinnati, OH, United States; Donovan, J.F., Department of Urology, University of Cincinnati, Cincinnati, OH, United States; Gaitonde, K., Department of Urology, University of Cincinnati, Cincinnati, OH, United States","Background and Purpose: High levels of mental workload and stress are experienced by surgeons in the laparoscopic environment. The da Vinci® surgical robot was developed to provide surgeons a more user-friendly interface while maintaining the patient benefits associated with laparoscopy. This study examined whether the da Vinci robot reduces mental workload and stress in novice medical students. A detailed understanding of trainees' mental workload and mental stress experiences can aid in the development of training programs that are aimed at facilitating the acquisition of laparoscopic and robotic surgery skills. Materials and Methods: Fifteen novice first-year medical students performed a standard peg-transfer task at a laparoscopic simulator and the da Vinci Surgical System. Mental workload and stress were assessed with the Multiple Resources Questionnaire (MRQ) and the Dundee Stress State Questionnaire (DSSQ), respectively. Results: Students' mental workload profiles were identical with the two surgical systems and replicated previous MRQ results reported with the laparoscopic system showing high levels of workload. Students experienced a better stress profile with the robotic system, however, when compared wih the laparoscopic system. Conclusion: Our study shows that novice medical students perceive less stress when working with the robotic surgical interface than with the laparoscopic surgery interface. The MRQ and the DSSQ are valuable tools for identifying mental workload and mental stress in the laparoscopic and robotic surgery environments. This information may be useful for facilitating the acquisition of laparoscopic and robotic surgery skills. © Copyright 2012, Mary Ann Liebert, Inc.",,"adult; article; confidence interval; female; human; laparoscopic surgery; male; medical student; mental stress; minimally invasive surgery; motivation; pretest posttest design; priority journal; questionnaire; robotics; self esteem; simulator; surgical training; task performance; workload; Adult; Confidence Intervals; Female; Humans; Laparoscopy; Male; Questionnaires; Robotics; Stress, Psychological; Students, Medical; Surgical Procedures, Minimally Invasive; Workload",Article,"Final","",Scopus,2-s2.0-84865192210
"Belke T.W.","7003284060;","Contingency discriminability and the generalized matching law describe choice on concurrent ratio schedules of wheel-running reinforcement",2012,"Behavioural Processes","90","3",,"291","301",,1,"10.1016/j.beproc.2012.03.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861989848&doi=10.1016%2fj.beproc.2012.03.001&partnerID=40&md5=deb75e807a5a132cea10a626eecc4956","Department of Psychology, Mount Allison University, Sackville, NB, E4L 1C7, Canada","Belke, T.W., Department of Psychology, Mount Allison University, Sackville, NB, E4L 1C7, Canada","Belke (2010) showed that on concurrent ratio schedules, the difference in ratio requirements required to produce near exclusive preference for the lower ratio alternative was substantively greater when the reinforcer was wheel running than when it was sucrose. The current study replicated this finding and showed that this choice behavior can be described by the matching law and the contingency discriminability model. Eight female Long Evans rats were exposed to concurrent VR schedules of wheel-running reinforcement (30. s) and the schedule value of the initially preferred alternative was systematically increased. Two rats rapidly developed exclusive preference for the lower ratio alternative, but the majority did not - even when ratios differed by 20:1. Analysis showed that estimates of slopes from the matching law and the proportion of reinforcers misattributed from the contingency discriminability model were related to the ratios at which near exclusive preference developed. The fit of these models would be consistent with misattribution of reinforcers or poor discrimination between alternatives due to the long duration of wheel running. © 2012 Elsevier B.V.","Choice; Concurrent ratio schedules; Contingency discriminability; Generalized matching law; Lever press; Rats; Wheel-running reinforcement","discriminant analysis; estimation method; rodent; animal experiment; article; behavior; controlled study; decision making; female; nonhuman; running; statistical parameters; treadmill; Algorithms; Analysis of Variance; Animals; Choice Behavior; Data Interpretation, Statistical; Discrimination Learning; Female; Models, Psychological; Models, Statistical; Motor Activity; Rats; Rats, Long-Evans; Reinforcement (Psychology); Reinforcement Schedule; Running; Rattus",Article,"Final","",Scopus,2-s2.0-84861989848
"Sharma M., Macafee D., Pranesh N., Horgan A.F.","7403268837;26643338900;6505873499;7004192567;","Construct validity of fresh frozen human cadaver as a training model in minimal access surgery",2012,"Journal of the Society of Laparoendoscopic Surgeons","16","3",,"345","352",,21,"10.4293/108680812X13462882735818","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871739003&doi=10.4293%2f108680812X13462882735818&partnerID=40&md5=1d6392ef7c076e78108af4014f785710","Newcastle Surgical Training Centre, Department of General Surgery, Freeman Hospital NHS Trust, Newcastle Upon Tyne, NE7 7DN, United Kingdom; Department of General Surgery, The James Cook University Hospital, Middlesbrough, United Kingdom","Sharma, M., Newcastle Surgical Training Centre, Department of General Surgery, Freeman Hospital NHS Trust, Newcastle Upon Tyne, NE7 7DN, United Kingdom; Macafee, D., Department of General Surgery, The James Cook University Hospital, Middlesbrough, United Kingdom; Pranesh, N., Newcastle Surgical Training Centre, Department of General Surgery, Freeman Hospital NHS Trust, Newcastle Upon Tyne, NE7 7DN, United Kingdom; Horgan, A.F., Newcastle Surgical Training Centre, Department of General Surgery, Freeman Hospital NHS Trust, Newcastle Upon Tyne, NE7 7DN, United Kingdom","Background: The construct validity of fresh human cadaver as a training tool has not been established previously. The aims of this study were to investigate the construct validity of fresh frozen human cadaver as a method of training in minimal access surgery and determine if novices can be rapidly trained using this model to a safe level of performance. Methods: Junior surgical trainees, novices (<3 laparoscopic procedure performed) in laparoscopic surgery, performed 10 repetitions of a set of structured laparoscopic tasks on fresh frozen cadavers. Expert laparoscopists (>100 laparoscopic procedures) performed 3 repetitions of identical tasks. Performances were scored using a validated, objective Global Operative Assessment of Laparoscopic Skills scale. Scores for 3 consecutive repetitions were compared between experts and novices to determine construct validity. Furthermore, to determine if the novices reached a safe level, a trimmed mean of the experts score was used to define a benchmark. Mann-Whitney Utest was used for construct validity analysis and 1-sample t test to compare performances of the novice group with the benchmark safe score. Results: Ten novices and 2 experts were recruited. Four out of 5 tasks (nondominant to dominant hand transfer; simulated appendicectomy; intracorporeal and extracorporeal knot tying) showed construct validity. Novices' scores became comparable to benchmark scores between the eighth and tenth repetition. Conclusion: Minimal access surgical training using fresh frozen human cadavers appears to have construct validity. The laparoscopic skills of novices can be accelerated through to a safe level within 8 to 10 repetitions. © 2012 by JSLS.","Cadaver training; Construct validity; Laparoscopic skills training","article; cadaver; clinical competence; clinical trial; comparative study; computer interface; education; educational model; general surgery; human; medical education; methodology; minimally invasive surgery; teaching; Cadaver; Clinical Competence; Education, Medical; General Surgery; Humans; Models, Educational; Surgical Procedures, Minimally Invasive; Teaching Materials; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84871739003
"De Moraes R.M., Dos Santos MacHado L.","7003717947;55208890500;","Online assessment in medical simulators based on virtual reality using fuzzy gaussian naive bayes",2012,"Journal of Multiple-Valued Logic and Soft Computing","18","5-6",,"479","492",,8,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862564416&partnerID=40&md5=69a78904025c8986fec6fa344635dae8","Department of Statistics, Universidade Federal da Paraíba, Cidade Universitária S/n, 58.051-900 - João Pessoa - PB, Brazil; Department of Informatics, Universidade Federal da Paraíba, Cidade Universitária S/n, 58.051-900 - João Pessoa - PB, Brazil","De Moraes, R.M., Department of Statistics, Universidade Federal da Paraíba, Cidade Universitária S/n, 58.051-900 - João Pessoa - PB, Brazil; Dos Santos MacHado, L., Department of Informatics, Universidade Federal da Paraíba, Cidade Universitária S/n, 58.051-900 - João Pessoa - PB, Brazil","Several approaches have been proposed to perform online or offline assessment in medical training simulators based on virtual reality. The goal is to collect interaction data during a realistic simulation of procedures in order to provide to trainees feedback about their skills. In this paper, we present a new approach to online training assessment based on Fuzzy Gaussian Naive Bayes (FGNB) for modeling and classification of simulation in M pre-defined classes, which is a generalization of Gaussian Bayes Networks. The results obtained showed that FGNB presents significant better assessment when compared to other two methods. © 2012 Old City Publishing, Inc.","Fuzzy gaussian naive bayes; Medical simulators; On-line training assessment; Virtual reality","Bayes networks; Gaussians; Medical training simulator; Naive bayes; Offline; On-line assessment; Online training; Pre-defined class; Realistic simulation; Classifiers; Gaussian distribution; Online systems; Virtual reality; Rating",Article,"Final","",Scopus,2-s2.0-84862564416
"Sadagic A.","6506715040;","Validation of virtual humanoid intelligent agents in virtual reality systems",2012,"Proceedings - IEEE Virtual Reality",,, 6180897,"91","92",,,"10.1109/VR.2012.6180897","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860759778&doi=10.1109%2fVR.2012.6180897&partnerID=40&md5=49319522774f7b2269940eec076a9b00","Naval Postgraduate School - NPS, MOVES Institute, 700 Dyer Rd, Monterey, CA 93943, United States","Sadagic, A., Naval Postgraduate School - NPS, MOVES Institute, 700 Dyer Rd, Monterey, CA 93943, United States","One of the great benefits VR systems offer is their ability to simulate a number of virtual humans when their presence is needed in the context of some learning or training experience. Being that the real humans may not be available to play different roles and support virtual sessions, the ability of a system to generate highly believable representations of autonomous virtual humans - virtual intelligent agents - is vital in achieving specific learning and training objectives. Eliminating the elements of the system that can cause a negative learning and training transfer is a paramount in those systems. We illustrate the results of two user studies focused on validation of non-deterministic domain-specific behaviors generated by our system (example: behaviors typical for a well coordinated group of paramedics or military unit). The results and observations confirmed that when it comes to VR systems with stringent requirements and high expectations for positive learning/training transfer, we still need humans to evaluate and validate synthesized human-like agent behaviors. © 2012 IEEE.","intelligent agents; military applications; simulation and behavior; validation; virtual/digital characters","Agent behavior; Autonomous virtual humans; Domain specific; Learning and training; Military units; simulation and behavior; Specific learning; Stringent requirement; Training experiences; User study; validation; Virtual humanoids; Virtual humans; Virtual reality system; virtual/digital characters; VR systems; Intelligent agents; Military applications; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84860759778
"Jacobs J., Stengel M., Froehlich B.","57198455913;42162165500;18433968300;","A generalized God-object method for plausible finger-based interactions in virtual environments",2012,"IEEE Symposium on 3D User Interfaces 2012, 3DUI 2012 - Proceedings",,, 6184183,"43","51",,20,"10.1109/3DUI.2012.6184183","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860783839&doi=10.1109%2f3DUI.2012.6184183&partnerID=40&md5=1a0387ad7b483d2cf1ca939caf897184","Group Research Virtual Technologies, Volkswagen AG, Germany; Computer Graphics Lab, TU Braunschweig, Germany; Virtual Reality Systems Group, Bauhaus-Universität Weimar, Germany","Jacobs, J., Group Research Virtual Technologies, Volkswagen AG, Germany; Stengel, M., Computer Graphics Lab, TU Braunschweig, Germany; Froehlich, B., Virtual Reality Systems Group, Bauhaus-Universität Weimar, Germany","We generalize the six degree-of-freedom God-object approach to enable its use for multi-finger interactions in virtual environments. The connected finger phalanxes are modeled as multiple constrained God objects. The mutual interdependencies between multiple God objects are resolved using Gauss' principle of least constraint. This generalization of the God-object method allows us to avoid the penetration of multiple fingers and their phalanxes with objects within a physically simulated virtual world. Our observations indicate that the generalized God-object approach leads to plausible collision-free positions and motions of the phalanxes of the user's fingers during complex six degree-of-freedom manipulations, while artifacts such as artificial friction or a stuck hand are avoided. © 2012 IEEE.","G.1.6 [Mathematics of Computing]: Numerical Analysis Optimization; H.5.2 [Information Interfaces and Presentation]: User Interfaces direct manipulation; I.3.6 [Computer Graphics]: Methodology and Techniques Interaction techniques; I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism Virtual reality","Artificial friction; Direct manipulation; I.3.6 [computer graphics]: methodology and techniques; I.3.7 [computer graphics]: three-dimensional graphics and realism; Least constraint; Six degree-of-freedom; Virtual worlds; Numerical analysis; Three dimensional; Virtual reality; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-84860783839
"Orzech N., Palter V.N., Reznick R.K., Aggarwal R., Grantcharov T.P.","6504088962;6507774834;7006153860;8616911800;6603695319;","A comparison of 2 Ex vivo training curricula for advanced laparoscopic skills: A randomized controlled trial",2012,"Annals of Surgery","255","5",,"833","839",,66,"10.1097/SLA.0b013e31824aca09","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859927246&doi=10.1097%2fSLA.0b013e31824aca09&partnerID=40&md5=c2451054db1f6f41595f1595ef58beef","Department of Surgery, University of Toronto, 600 University Avenue, Toronto, ON M5G 1X5, Canada; Department of Surgery, Queen's University, ON, Canada; Department of Surgery and Cancer, Imperial College, London, United Kingdom; Department of Surgery, St Michael's Hospital, University of Toronto, ON, Canada","Orzech, N., Department of Surgery, University of Toronto, 600 University Avenue, Toronto, ON M5G 1X5, Canada; Palter, V.N., Department of Surgery, University of Toronto, 600 University Avenue, Toronto, ON M5G 1X5, Canada; Reznick, R.K., Department of Surgery, Queen's University, ON, Canada; Aggarwal, R., Department of Surgery and Cancer, Imperial College, London, United Kingdom; Grantcharov, T.P., Department of Surgery, St Michael's Hospital, University of Toronto, ON, Canada","Objective: To compare the effectiveness and cost of 2 ex vivo training curricula for laparoscopic suturing. Background: Although simulators have been developed to teach laparoscopic suturing, a barrier to their wide implementation in training programs is a lack of knowledge regarding their relative training benefit and their associated cost. Method: This prospective single-blinded randomized trial allocated 24 surgical residents to train to proficiency using either a virtual reality (VR) simulator or box trainer. All residents then placed intracorporeal laparoscopic stitches during a Nissen fundoplication on a patient. The operating room (OR) cases were video-recorded and technical proficiency was assessed using 2 validated tools. OR performance of both groups was compared to that of conventionally trained residents and to fellowship-trained surgeons. A cost analysis of box training, VR training, and conventional residency training across Canadian surgical programs was performed. Results: After ex vivo training, no significant differences in laparoscopic suturing in the OR were found between the 2 groups with respect to time (P = 0.74)-global rating score (P = 0.65) or checklist score (P = 0.97). It took conventionally trained residents 6 practice attempts in the OR to achieve the technical proficiency of the ex vivo trained groups (P = 0.83). VR training was more efficient than box training (transfer effectiveness ratio of 2.31 vs 1.13). The annual cost of training 5 residents on the FLS trainer box was $11,975.00, on the VR simulator was $77,500.00, and conventional residency training was $17,380.00. Over 5 years, box training was the most cost-effective option for all programs, and VR training was more cost-effective for programs with more 10 residents. Conclusions: Training on either a VR simulator or on a box trainer significantly decreased the learning curve necessary to learn laparoscopic suturing. VR training, however, is the more efficient training modality, whereas box training the more cost-effective option. © 2012 by Lippincott Williams & Wilkins.",,"box trainer; checklist; conference paper; controlled study; cost effectiveness analysis; curriculum; devices; education program; educational model; human; intraoperative period; laparoscopic surgery; operation duration; priority journal; prospective study; randomized controlled trial; residency education; resident; scoring system; simulation; simulator; single blind procedure; stomach fundoplication; surgical training; suturing method; task performance; validity; videorecording; virtual reality; Canada; Clinical Competence; Computer Simulation; Costs and Cost Analysis; Curriculum; Fundoplication; Humans; Internship and Residency; Laparoscopy; Learning Curve; Prospective Studies; Single-Blind Method; Suture Techniques; Task Performance and Analysis; User-Computer Interface",Conference Paper,"Final","",Scopus,2-s2.0-84859927246
"Gray R.J., Kahol K., Islam G., Smith M., Chapital A., Ferrara J.","55710447800;35575889800;36088450600;35584123200;23982100700;7102663691;","High-fidelity, low-cost, automated method to assess laparoscopic skills objectively",2012,"Journal of Surgical Education","69","3",,"335","339",,12,"10.1016/j.jsurg.2011.10.014","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859301536&doi=10.1016%2fj.jsurg.2011.10.014&partnerID=40&md5=b7bd82b79eb55a2eae6baf4bf86c8c02","Department of Surgery, Mayo Clinic Arizona, 13400 E. Shea Blvd., Scottsdale, AZ 85259, United States; Simulation and Education Training Center, Banner Good Samaritan Medical Center, Phoenix, AZ, United States; Human Machine Symbiosis Laboratory, Department of Biomedical Informatics, Arizona State University, Phoenix, AZ, United States","Gray, R.J., Department of Surgery, Mayo Clinic Arizona, 13400 E. Shea Blvd., Scottsdale, AZ 85259, United States; Kahol, K., Simulation and Education Training Center, Banner Good Samaritan Medical Center, Phoenix, AZ, United States, Human Machine Symbiosis Laboratory, Department of Biomedical Informatics, Arizona State University, Phoenix, AZ, United States; Islam, G., Human Machine Symbiosis Laboratory, Department of Biomedical Informatics, Arizona State University, Phoenix, AZ, United States; Smith, M., Simulation and Education Training Center, Banner Good Samaritan Medical Center, Phoenix, AZ, United States; Chapital, A., Department of Surgery, Mayo Clinic Arizona, 13400 E. Shea Blvd., Scottsdale, AZ 85259, United States; Ferrara, J., Human Machine Symbiosis Laboratory, Department of Biomedical Informatics, Arizona State University, Phoenix, AZ, United States","Background: We sought to define the extent to which a motion analysis-based assessment system constructed with simple equipment could measure technical skill objectively and quantitatively. Methods: An ""off-the-shelf"" digital video system was used to capture the hand and instrument movement of surgical trainees (beginner level = PGY-1, intermediate level = PGY-3, and advanced level = PGY-5/fellows) while they performed a peg transfer exercise. The video data were passed through a custom computer vision algorithm that analyzed incoming pixels to measure movement smoothness objectively. Results: The beginner-level group had the poorest performance, whereas those in the advanced group generated the highest scores. Intermediate-level trainees scored significantly (p < 0.04) better than beginner trainees. Advanced-level trainees scored significantly better than intermediate-level trainees and beginner-level trainees (p < 0.04 and p < 0.03, respectively). Conclusions: A computer vision-based analysis of surgical movements provides an objective basis for technical expertise-level analysis with construct validity. The technology to capture the data is simple, low cost, and readily available, and it obviates the need for expert human assessment in this setting. © 2012 Association of Program Directors in Surgery.","Lucas-Kanade optical flow; technical assessment; technical skills; video-based analysis instrument","article; automation; data analysis; hand movement; human; human experiment; image analysis; laparoscopic surgery; motion analysis system; motor performance; normal human; priority journal; skill; task performance; video based analysis instrument; videorecording; Adult; Arizona; Automation; Clinical Competence; Computer Simulation; Cost-Benefit Analysis; Curriculum; Education, Medical, Graduate; Educational Measurement; Evaluation Studies as Topic; Female; General Surgery; Humans; Internship and Residency; Laparoscopy; Male; Problem-Based Learning; Psychomotor Performance; Video Recording",Article,"Final","",Scopus,2-s2.0-84859301536
"Zhang L., Grosdemouge C., Arikatla V.S., Ahn W., Sankaranarayanan G., De S., Jones D., Schwaitzberg S., Cao C.G.L.","37076447700;54580819000;26654027600;9334513400;15623319200;7202304567;55387240300;7007036892;25957557800;","The added value of virtual reality technology and force feedback for surgical training simulators",2012,"Work","41","SUPPL.1",,"2288","2292",,17,"10.3233/WOR-2012-0453-2288","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859820585&doi=10.3233%2fWOR-2012-0453-2288&partnerID=40&md5=02f7bd8976824eac796a5655c5f32b8a","Department of Mechanical Engineering, Tufts University, 200 College Avenue, Medford, MA, United States; Center for Modeling, Simulation and Imaging in Medicine, Rensselaer Polytechnic Institute, 110 8th Street, Troy, NY, United States; Department of Surgery, Beth Israel Deaconess Medical Center, TCC 140, 330 Brookline Avenue, Boston, MA, United States; Department of Surgery, Cambridge Health Alliance Hospital, 1493 Cambridge Street, Cambridge, MA, United States","Zhang, L., Department of Mechanical Engineering, Tufts University, 200 College Avenue, Medford, MA, United States; Grosdemouge, C., Department of Mechanical Engineering, Tufts University, 200 College Avenue, Medford, MA, United States; Arikatla, V.S., Center for Modeling, Simulation and Imaging in Medicine, Rensselaer Polytechnic Institute, 110 8th Street, Troy, NY, United States; Ahn, W., Center for Modeling, Simulation and Imaging in Medicine, Rensselaer Polytechnic Institute, 110 8th Street, Troy, NY, United States; Sankaranarayanan, G., Center for Modeling, Simulation and Imaging in Medicine, Rensselaer Polytechnic Institute, 110 8th Street, Troy, NY, United States; De, S., Center for Modeling, Simulation and Imaging in Medicine, Rensselaer Polytechnic Institute, 110 8th Street, Troy, NY, United States; Jones, D., Department of Surgery, Beth Israel Deaconess Medical Center, TCC 140, 330 Brookline Avenue, Boston, MA, United States; Schwaitzberg, S., Department of Surgery, Cambridge Health Alliance Hospital, 1493 Cambridge Street, Cambridge, MA, United States; Cao, C.G.L., Department of Mechanical Engineering, Tufts University, 200 College Avenue, Medford, MA, United States","Laparoscopic surgery requires more specialized training of the surgeons than traditional open surgery. The Virtual Basic Laparoscopic Surgical Trainer (VBLaST) is being developed as a virtual version of the Fundamentals of Laparoscopic Skills (FLS) trainer. This study assessed the current haptic and virtual reality (VR) technology of a virtual peg transfer task of the VBLaST, based on the subjective preference of surgeons and their objective task performance measures. Twenty-one surgical residents, fellows and attendings performed a peg-transfer task in the FLS and the VBLaST. Each subject performed 10 trials on each simulator. Results showed that subjects performed significantly better on the FLS than on the VBLaST. Subjects showed a significant learning effect on both simulators, but with an accelerated improvement on the VBLaST. Even so, 81% of the subjects preferred the FLS over the VBLaST for surgical training which could be attributed to the novelty of the VR technology and existing deficiencies of the haptic interface. Despite the subjective preference for the physical simulator, the performance results indicate an added value of VR and haptics in surgical training, which is expected to be demonstrated in more surgically relevant tasks such as suturing and knot-tying. © 2012 - IOS Press and the authors. All rights reserved.","force feedback; fundamentals of laparoscopic skills (FLS); surgical training; virtual basic laparoscopic surgical trainer (VBLaST); virtual reality (VR)","article; computer interface; computer simulation; education; evaluation study; feedback system; human; laparoscopy; touch; United States; Boston; Computer Simulation; Feedback; Humans; Laparoscopy; Touch; User-Computer Interface",Conference Paper,"Final","",Scopus,2-s2.0-84859820585
"Palter V.N., Graafland M., Schijven M.P., Grantcharov T.P.","6507774834;27267612800;6602492995;6603695319;","Designing a proficiency-based, content validated virtual reality curriculum for laparoscopic colorectal surgery: A Delphi approach",2012,"Surgery","151","3",,"391","397",,40,"10.1016/j.surg.2011.08.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84857053091&doi=10.1016%2fj.surg.2011.08.005&partnerID=40&md5=704c8c715593f0833231a9dd8076800d","University of Toronto, 600 University Ave, Toronto, ON M5G 1X5, Canada; Department of Surgery, Academic Medical Center Amsterdam, Amsterdam, Netherlands; Department of Surgery, St. Michael's Hospital, Toronto, ON, Canada","Palter, V.N., University of Toronto, 600 University Ave, Toronto, ON M5G 1X5, Canada; Graafland, M., Department of Surgery, Academic Medical Center Amsterdam, Amsterdam, Netherlands; Schijven, M.P., Department of Surgery, Academic Medical Center Amsterdam, Amsterdam, Netherlands; Grantcharov, T.P., Department of Surgery, St. Michael's Hospital, Toronto, ON, Canada","Background: Although task training on virtual reality (VR) simulators has been shown to transfer to the operating room, to date no VR curricula have been described for advanced laparoscopic procedures. The purpose of this study was to develop a proficiency-based VR technical skills curriculum for laparoscopic colorectal surgery. Methods: The Delphi method was used to determine expert consensus on which VR tasks (on the LapSim simulator) are relevant to teaching laparoscopic colorectal surgery. To accomplish this task, 19 international experts rated all the LapSim tasks on a Likert scale (1-5) with respect to the degree to which they thought that a particular task should be included in a final technical skills curriculum. Results of the survey were sent back to participants until consensus (Cronbach's α >0.8) was reached. A cross-sectional design was utilized to define the benchmark scores for the identified tasks. Nine expert surgeons completed all identified tasks on the ""easy,"" ""medium,"" and ""hard"" settings of the simulator. Results: In the first round of the survey, Cronbach's α was 0.715; after the second round, consensus was reached at 0.865. Consensus was reached for 7 basic tasks and 1 advanced suturing task. Median expert time and economy of movement scores were defined as benchmarks for all curricular tasks. Conclusion: This study used Delphi consensus methodology to create a curriculum for an advanced laparoscopic procedure that is reflective of current clinical practice on an international level and conforms to current educational standards of proficiency-based training. © 2012 Mosby, Inc. All rights reserved.",,"article; colorectal surgery; curriculum development; health survey; laparoscopic surgery; methodology; priority journal; simulation; surgeon; surgical training; validation study; virtual reality; Colorectal Surgery; Computer-Assisted Instruction; Curriculum; Delphi Technique; Expert Testimony; Humans; Internship and Residency; Laparoscopy; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84857053091
"Lee J.Y., Mucksavage P., Kerbl D.C., Huynh V.B., Etafy M., McDougall E.M.","36970926700;25635675700;36802104600;35196004000;37080383900;7006424384;","Validation study of a virtual reality robotic simulatorrole as an assessment tool?",2012,"Journal of Urology","187","3",,"998","1002",,75,"10.1016/j.juro.2011.10.160","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862817346&doi=10.1016%2fj.juro.2011.10.160&partnerID=40&md5=38f3870b85f685e342435ba1887c7146","Division of Urology, St Michael's Hospital, University of Toronto (JYL), Toronto, ON, Canada; Department of Urology, University of California-Irvine, Orange, CA, United States","Lee, J.Y., Division of Urology, St Michael's Hospital, University of Toronto (JYL), Toronto, ON, Canada, Department of Urology, University of California-Irvine, Orange, CA, United States; Mucksavage, P., Division of Urology, St Michael's Hospital, University of Toronto (JYL), Toronto, ON, Canada, Department of Urology, University of California-Irvine, Orange, CA, United States; Kerbl, D.C., Division of Urology, St Michael's Hospital, University of Toronto (JYL), Toronto, ON, Canada, Department of Urology, University of California-Irvine, Orange, CA, United States; Huynh, V.B., Division of Urology, St Michael's Hospital, University of Toronto (JYL), Toronto, ON, Canada, Department of Urology, University of California-Irvine, Orange, CA, United States; Etafy, M., Division of Urology, St Michael's Hospital, University of Toronto (JYL), Toronto, ON, Canada, Department of Urology, University of California-Irvine, Orange, CA, United States; McDougall, E.M., Division of Urology, St Michael's Hospital, University of Toronto (JYL), Toronto, ON, Canada, Department of Urology, University of California-Irvine, Orange, CA, United States","Purpose: Virtual reality simulators are often used for surgical skill training since they facilitate deliberate practice in a controlled, low stakes environment. However, to be considered for assessment purposes rigorous construct and criterion validity must be demonstrated. We performed face, content, construct and concurrent validity testing of the dV-Trainer™ robotic surgical simulator. Materials and Methods: Urology residents, fellows and attending surgeons were enrolled in this institutional review board approved study. After a brief introduction to the dV-Trainer each subject completed 3 repetitions each of 4 virtual reality tasks on it, including pegboard ring transfer, matchboard object transfer, needle threading of rings, and the ring and rail task. One week later subjects completed 4 similar tasks using the da Vinci® robot. Subjects were assessed on total task time and total errors using the built-in scoring algorithm and manual scoring for the dV-Trainer and the da Vinci robot, respectively. Results: Seven experienced and 13 novice robotic surgeons were included in the study. Experienced surgeons were defined by greater than 50 hours of clinical robotic console time. Of novice robotic surgeons 77% ranked the dV-Trainer as a realistic training platform and 71% of experienced robotic surgeons ranked it as useful for resident training. Experienced robotic surgeons outperformed novices in many dV-Trainer and da Vinci robot exercises, particularly in the number of errors. On pooled data analysis dV-Trainer total task time and total errors correlated with da Vinci robot total task time and total errors (p = 0.026 and 0.011, respectively). Conclusions: This study confirms the face, content, construct and concurrent validity of the dV-Trainer, which may have a potential role as an assessment tool. © 2012 American Urological Association Education and Research, Inc.","clinical competence; education; medical; robotics; surgery; urology","algorithm; article; clinical competence; concurrent validity; construct validity; content validity; face validity; human; human experiment; job experience; performance measurement system; priority journal; resident; robotics; scoring system; simulator; surgeon; task performance; validation study; virtual reality; Clinical Competence; Computer Simulation; Delphi Technique; Educational Measurement; Humans; Inservice Training; Robotics; Urologic Diseases; Urology; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84862817346
"Pollock B., Winer E., Gilbert S., De La Cruz J.","55104919600;7004856151;14041448900;7101860523;","LVC interaction within a mixed-reality training system",2012,"Proceedings of SPIE - The International Society for Optical Engineering","8289",, 82890K,"","",,4,"10.1117/12.912193","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899065085&doi=10.1117%2f12.912193&partnerID=40&md5=e886c669076106a972cfa4f02e52ff43","Iowa State University, Ames, IA, United States; Army RDECOM - STTC, Orlando, FL, United States","Pollock, B., Iowa State University, Ames, IA, United States; Winer, E., Iowa State University, Ames, IA, United States; Gilbert, S., Iowa State University, Ames, IA, United States; De La Cruz, J., Army RDECOM - STTC, Orlando, FL, United States","The United States military is increasingly pursuing advanced live, virtual, and constructive (LVC) training systems for reduced cost, greater training flexibility, and decreased training times. Combining the advantages of realistic training environments and virtual worlds, mixed reality LVC training systems can enable live and virtual trainee interaction as if co-located. However, LVC interaction in these systems often requires constructing immersive environments, developing hardware for live-virtual interaction, tracking in occluded environments, and an architecture that supports real-time transfer of entity information across many systems. This paper discusses a system that overcomes these challenges to empower LVC interaction in a reconfigurable, mixed reality environment. This system was developed and tested in an immersive, reconfigurable, and mixed reality LVC training system for the dismounted warfighter at ISU, known as the Veldt, to overcome LVC interaction challenges and as a test bed for cuttingedge technology to meet future U.S. Army battlefield requirements. Trainees interact physically in the Veldt and virtually through commercial and developed game engines. Evaluation involving military trained personnel found this system to be effective, immersive, and useful for developing the critical decision-making skills necessary for the battlefield. Procedural terrain modeling, model-matching database techniques, and a central communication server process all live and virtual entity data from system components to create a cohesive virtual world across all distributed simulators and game engines in real-time. This system achieves rare LVC interaction within multiple physical and virtual immersive environments for training in real-time across many distributed systems. © 2012 SPIE-IS&T.","Distributed Systems; LVC; Military Simulation; Mixed Reality; Training","Equipment testing; Human computer interaction; Interactive computer graphics; Personnel training; Virtual reality; Communication servers; Cutting edge technology; Distributed systems; LVC; Military simulation; Mixed reality; Mixed-reality environment; Procedural terrain modeling; Distributed database systems",Conference Paper,"Final","",Scopus,2-s2.0-84899065085
"Xia P., Lopes A.M., Restivo M.T., Yao Y.","13404322900;55905624500;7004694449;55722539100;","A new type haptics-based virtual environment system for assembly training of complex products",2012,"International Journal of Advanced Manufacturing Technology","58","1-4",,"379","396",,58,"10.1007/s00170-011-3381-8","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855678280&doi=10.1007%2fs00170-011-3381-8&partnerID=40&md5=2b46f472228a26ac2011d883fee986e4","IDMEC-Polo FEUP, Faculty of Engineering, Porto University, Porto, Portugal; School of Mechanical and Electrical Engineering, Harbin Institute of Technology, Harbin, China","Xia, P., IDMEC-Polo FEUP, Faculty of Engineering, Porto University, Porto, Portugal; Lopes, A.M., IDMEC-Polo FEUP, Faculty of Engineering, Porto University, Porto, Portugal; Restivo, M.T., IDMEC-Polo FEUP, Faculty of Engineering, Porto University, Porto, Portugal; Yao, Y., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, Harbin, China","Virtual reality (VR)-based assembly training has been an interesting topic for the last decades. Generally, there are two shortcomings for nowadays virtual assembly training systems. One is that the operators cannot move around the virtual environment in a natural way as people activity in the real world: they are constrained in a fixed position or can only move in a limited space. The other is that most of the virtual assembly training systems are based on geometry constraint modeling only, which lacks haptics feedback. A new type haptics-based virtual environment system for assembly training of complex products is described in this paper. A new low-cost motion simulator is designed and integrated with the virtual environment to realize free walking by human. An automatic data integration interface is developed to transfer geometry, topology, assembly, and physics information from a computer-aided design system to a VR application, and a hierarchical constraint-based data model is rebuilt to construct the virtual assembly environment. Physics-based modeling and haptics feedback are undertaken to simulate the realistic assembly operations. The application examples and evaluation experiments demonstrate that both motion simulator and haptics have great value for training of assembly processes. © Springer-Verlag London Limited 2011.","Assembly training; Haptics; Motion simulator; Physics-based modeling; Virtual reality","Application examples; Assembly operations; Assembly process; Complex products; Computer-aided design systems; Constraint-based; Data integration; Evaluation experiments; Geometry constraints; Haptics; Limited space; Motion simulator; Physics-based modeling; Training Systems; Virtual assembly; Virtual environments; VR applications; Computer aided design; E-learning; Simulators; Topology; Virtual reality; Assembly",Article,"Final","",Scopus,2-s2.0-84855678280
"Goulding J., Nadim W., Petridis P., Alshawi M.","9639808300;35275652400;36128917500;6603579234;","Construction industry offsite production: A virtual reality interactive training environment prototype",2012,"Advanced Engineering Informatics","26","1",,"103","116",,85,"10.1016/j.aei.2011.09.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-83555162497&doi=10.1016%2fj.aei.2011.09.004&partnerID=40&md5=b2db4a47453b082275bbb6fb701a5aaa","School of Built and Natural Environment, University of Central Lancashire (UCLan), United Kingdom; Department of Architecture, British University in Egypt (BUE), Egypt; Serious Games Institute, Coventry University, United Kingdom; College of Science and Technology, University of Salford, United Kingdom","Goulding, J., School of Built and Natural Environment, University of Central Lancashire (UCLan), United Kingdom; Nadim, W., Department of Architecture, British University in Egypt (BUE), Egypt; Petridis, P., Serious Games Institute, Coventry University, United Kingdom; Alshawi, M., College of Science and Technology, University of Salford, United Kingdom","The 'traditional' construction industry has constantly been challenged to improve its inherent problematic practices. Offsite production (OSP), under the umbrella of modern methods of construction (MMC), has been acknowledged as a means to help improve construction industry performance as well as meet new market demands through the provision of improved, adaptable, and sustainable buildings. However, the deployment of OSP systems, if not managed properly, may adversely affect the end result and be counterproductive. It is therefore imperative that the construction industry stakeholders learn and appreciate the specifics, merits, as well as the risks associated with OSP systems in order to achieve the desired outcomes and consequently improve industry performance. On-the-job-training (OJT) is usually sought to facilitate 'experiential' learning, which is argued to be particularly effective where a great deal of independence is granted to the task performer. However, OJT has been criticised for being expensive, limited, and sometimes devoid of the actual training context. In order to address the problems encountered with OJT, several virtual reality (VR) solutions have been proposed. This paper introduces one such VR solution prototype, in order to provide a risk-free environment for learning without the 'do-or-die' consequences often faced on real construction projects. The proffered solution provides a unique VR environment for practicing new working conditions associated with OSP practices. While the 'scenes' of the VR environment take place on a construction site, the environment predominantly targets professionals, such as project managers, construction managers, architects, designers, suppliers and manufacturers, to allow multidisciplinary learning to occur, and hence overcome 'knowledge silos' or 'knowledge compartmentation'. The VR environment enables unforeseen problems often caused by professionals' decisions, faulty work, and health and safety issues to occur; where the implications of which can be evaluated in respect of time, cost and resources. The VR environment proposed does not aim to resolve problems associated with OSP per se, rather aims to allow 'things to go wrong' and consequently allows users not only to 'experience' the resulting implications but also to reflect on those implications as part of the learning process. This paper discusses and presents the prototype for the first development phase of the VR interactive training environment. While the prototype was tested and validated with domain experts from industry, the research community, and academia from different EU countries, the data used in developing the prototype was constrained to one project in the UK which may limit the generalisability of results. © 2011 Elsevier Ltd. All rights reserved.","Construction industry; Game engines; Offsite production; Simulation; Training; Virtual environment","Compartmentation; Construction manager; Construction projects; Construction sites; Development phase; Domain experts; EU countries; Game Engine; Health and safety; Interactive training; Learning process; Market demand; Modern methods of constructions; Off-site production; On the job trainings; Project managers; Research communities; Simulation; Sustainable building; Virtual environments; Working conditions; Construction industry; E-learning; Health risks; Intelligent buildings; Managers; Personnel training; Virtual reality; Project management",Article,"Final","",Scopus,2-s2.0-83555162497
"Waugh L.M., Rausch B., Engram T., Aziz F.","14629800800;55561434800;55561059400;54893426100;","Inuvik Super School VR documentation: Mid-project status",2012,"Proceedings of the International Conference on Cold Regions Engineering",,,,"221","230",,3,"10.1061/9780784412473.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872560491&doi=10.1061%2f9780784412473.022&partnerID=40&md5=d96ba29bb798a84c49705a9bea30df94","Department of Civil Engineering, University of New Brunswick, Fredericton, Canada; Government of the Northwest Territories, Department of Public Works and Government Services, Yellowknife, Canada","Waugh, L.M., Department of Civil Engineering, University of New Brunswick, Fredericton, Canada; Rausch, B., Government of the Northwest Territories, Department of Public Works and Government Services, Yellowknife, Canada; Engram, T., Government of the Northwest Territories, Department of Public Works and Government Services, Yellowknife, Canada; Aziz, F., Department of Civil Engineering, University of New Brunswick, Fredericton, Canada","Over the last eight years the Construction Engineering and Management team at the University of New Brunswick have developed technologies to document the status of on-site progress. The evolving system, referred to as VR Doc, presents high-resolution, virtual reality panoramas of on-site operations in an interface that allows the user to explore the construction site throughout the project timeline. Since 2006 VR Doc has been used on six major projects, in particular on the Inuvik Super School for the Government of the Northwest Territories Department of Public Works and Services. This paper is a case study of VR Doc use. A variety of challenges have been overcome. These include temperature and lighting challenges during the photography step, processing challenges due to the low light level, and transfer challenges due to the file sizes. Continuing challenges include constraints on local personnel for on-site capture of the images as well as the integration of this new technology into traditional management processes. To date the greatest value from VR Doc has been as a communication medium for individuals within the Government of the Northwest Territories who are not involved in the project on a day-to-day basis but benefit from a fast visual record of the project. This case study is of interest to those who wish to understand cutting edge technologies for documenting construction progress. Possible roles of these technologies are: as a means of remotely monitoring project progress, as a pre-emptive means of resolving claims, as photographic as-builts for future reference, and as a training tool for personnel embarking on a similar project. © 2012 American Society of Civil Engineering.","Arctic; construction project; progress documentation; virtual reality","Human resource management; Personnel training; Sustainable development; Virtual reality; Arctic; Communication medium; Construction engineering; Construction progress; Construction projects; Cutting edge technology; Department of public works; Traditional management; Arctic engineering",Conference Paper,"Final","",Scopus,2-s2.0-84872560491
"Chellali A., Dumas C., Milleville-Pennel I.","26767578800;16645562300;16242282200;","Haptic communication to support biopsy procedures learning in virtual environments",2012,"Presence: Teleoperators and Virtual Environments","21","4",,"470","489",,10,"10.1162/PRES_a_00128","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869452041&doi=10.1162%2fPRES_a_00128&partnerID=40&md5=58a0d3965b8ed89ca8b8b5df5ec79bf7","Robotics Research Group, IRCCyN, Ecole des Mines de Nantes, France; Cambridge Health Alliance, Department of Surgery Research Group, Cambridge, MA 02139, United States; CSIRO, Australia; PsyCoTech Research Group, IRCCyN-CNRS, France","Chellali, A., Robotics Research Group, IRCCyN, Ecole des Mines de Nantes, France, Cambridge Health Alliance, Department of Surgery Research Group, Cambridge, MA 02139, United States; Dumas, C., Robotics Research Group, IRCCyN, Ecole des Mines de Nantes, France, CSIRO, Australia; Milleville-Pennel, I., PsyCoTech Research Group, IRCCyN-CNRS, France","In interventional radiology, physicians require high haptic sensitivity and fine motor skills development because of the limited real-time visual feedback of the surgical site. The transfer of this type of surgical skill to novices is a challenging issue. This paper presents a study on the design of a biopsy procedure learning system. Our methodology, based on a task-centered design approach, aims to bring out new design rules for virtual learning environments. A new collaborative haptic training paradigm is introduced to support human-haptic interaction in a virtual environment. The interaction paradigm supports haptic communication between two distant users to teach a surgical skill. In order to evaluate this paradigm, a user experiment was conducted. Sixty volunteer medical students participated in the study to assess the influence of the teaching method on their performance in a biopsy procedure task. The results show that to transfer the skills, the combination of haptic communication with verbal and visual communications improves the novices' performance compared to conventional teaching methods. Furthermore, the results show that, depending on the teaching method, participants developed different needle insertion profiles. We conclude that our interaction paradigm facilitates expert-novice haptic communication and improves skills transfer; and new skills acquisition depends on the availability of different communication channels between experts and novices. Our findings indicate that the traditional fellowship methods in surgery should evolve to an off-patient collaborative environment that will continue to support visual and verbal communication, but also haptic communication, in order to achieve a better and more complete skills training. © 2012 by the Massachusetts Institute of Technology.",,"Biopsy; Computer aided instruction; Haptic interfaces; Personnel training; Surgery; Teaching; Virtual reality; Visual communication; Collaborative environments; Haptic communications; Haptic interactions; Interaction paradigm; Interventional radiology; Real time visual feedback; Verbal communications; Virtual learning environments; E-learning",Article,"Final","",Scopus,2-s2.0-84869452041
"Rus-Calafell M., Gutiérrez-Maldonado J., Ribas-Sabaté J.","35094538900;9334173600;51562528400;","Improving social behaviour in schizophrenia patients using an integrated virtual reality programme: A case study",2012,"Annual Review of CyberTherapy and Telemedicine","10",,,"283","286",,9,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84872039197&partnerID=40&md5=cf697ffc657b5192a568ddfbf02e95ee","Department of Personality, Assessment & Psychological Treatments, Faculty of Psychology, University of Barcelona, Spain; Department of Psychiatry and Mental Health, Igualada General Hospital, Spain","Rus-Calafell, M., Department of Personality, Assessment & Psychological Treatments, Faculty of Psychology, University of Barcelona, Spain, Department of Psychiatry and Mental Health, Igualada General Hospital, Spain; Gutiérrez-Maldonado, J., Department of Personality, Assessment & Psychological Treatments, Faculty of Psychology, University of Barcelona, Spain; Ribas-Sabaté, J., Department of Psychiatry and Mental Health, Igualada General Hospital, Spain","Social skills training programmes are among the treatments of choice in schizophrenia. Virtual reality (VR) can improve the results obtained with traditional social skills programmes by helping to generalize the acquired responses to patients’ daily lives. We present the results of a case study involving the application of an integrated VR programme for social skills training. A 30- year-old woman with a well-established diagnosis of schizophrenia was enrolled in the study. She completed four baseline sessions, 16 treatment sessions and four follow-up sessions three months after the end of the treatment. Using a multiple baseline across-behaviours design, three target behaviours were analysed: facial emotion recognition, social anxiety and conversation time. Symptoms and social function variables were also assessed. The results showed a positive change in the three target behaviours and improvements in interpersonal communication, assertiveness and negative symptoms. The VR programme proved useful for training the patient’s social behaviour and, consequently, for improving her performance. © 2012 Interactive Media Institute.","Schizophrenia; Social behaviour; Training; Virtual reality","adult; anxiety; Article; assertiveness; case report; case study; conversation; emotion; facial expression; female; follow up; human; interpersonal communication; mental patient; negative syndrome; recognition; schizophrenia; social behavior; social competence; social status; virtual reality; anxiety assessment; clinical outcome; cognitive behavioral therapy; facial recognition; Positive and Negative Syndrome Scale; psychosocial disorder; schizophrenia; social anxiety; Social Anxiety and Distress Scale; social aspects and related phenomena; social competence; Social Functioning Scale; symptom; article; computer interface; daily life activity; psychological rating scale; schizophrenia; social adaptation; Diagnosis; Personnel training; Virtual reality; Facial emotions; Inter-personal communications; Positive changes; schizophrenia; Schizophrenia patients; Social anxieties; Social behaviour; Social skills training; Diseases; Activities of Daily Living; Adult; Facial Expression; Female; Humans; Psychiatric Status Rating Scales; Schizophrenia; Social Adjustment; Social Behavior; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-84872039197
"Hummel J., Wolff R., Dodiya J., Gerndt A., Kuhlen T.","55211775000;8719300800;24478235300;6507002255;6602984500;","Short paper: Towards interacting with force-sensitive thin deformable virtual objects",2012,"JVRC12: Joint Virtual Reality Conference of ICAT - EGVE - EuroVR 2012, Proceedings",,,,"17","20",,2,"10.2312/EGVE/JVRC12/017-020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891873719&doi=10.2312%2fEGVE%2fJVRC12%2f017-020&partnerID=40&md5=ffbae39cbfe143635235431b0d62aa3e","German Aerospace Center (DLR), Germany; Virtual Reality Group, RWTH Aachen University, Germany","Hummel, J., German Aerospace Center (DLR), Germany; Wolff, R., German Aerospace Center (DLR), Germany; Dodiya, J., German Aerospace Center (DLR), Germany; Gerndt, A., German Aerospace Center (DLR), Germany; Kuhlen, T., Virtual Reality Group, RWTH Aachen University, Germany","The selection of the right input devices for 3D interaction methods is important for a successful VR system. While natural direct interaction is often preferred, research has shown that indirect interaction can be beneficial. This paper focuses on an immersive simulation and training environment, in which one sub-task it is to carefully grasp and move a force-sensitive thin deformable foil without damaging it. In order to ensure transfer of training it was necessary to inform the user of the fact of gentle grasping and moving the foil. We explore the potential of three simple and light-weight interaction methods that each map interaction to a virtual hand in a distinct way. We used a standard tracked joystick with an indirect mapping, a standard finger tracking device with direct mapping based on finger position, and a novel enhanced finger tracking device, which additionally allowed pinch force input. The results of our summative user study show that the task performance did not show a significant difference among the three interaction methods. The simple position based mapping using finger tracking was most preferred, although the enhanced finger tracking device with direct force input offered the most natural interaction mapping. Our findings show that both a direct and indirect input method have potential to interact with force-sensitive thin deformable objects, while the direct method is preferred. © The Eurographics Association 2012.",,"Deformation; Mapping; Virtual reality; Deformable object; Direct interactions; Indirect interactions; Interaction methods; Natural interactions; Simulation and training; Tracking devices; Transfer of trainings; Palmprint recognition",Conference Paper,"Final","",Scopus,2-s2.0-84891873719
"Diego J.P.S., Cox M.J., Quinn B.F.A., Newton J.T., Banerjee A., Woolford M.","26425008100;16306444500;36195649300;35606052400;56365541100;7003879939;","Researching haptics in higher education: The complexity of developing haptics virtual learning systems and evaluating its impact on students' learning",2012,"Computers and Education","59","1",,"156","166",,25,"10.1016/j.compedu.2011.11.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865657964&doi=10.1016%2fj.compedu.2011.11.009&partnerID=40&md5=f8534fd20d8bc7fb6a5cbe705de2356b","King's College London Dental Institute, Guy's Campus Tower Wing, Floor 18, London SE1 9RT, United Kingdom","Diego, J.P.S., King's College London Dental Institute, Guy's Campus Tower Wing, Floor 18, London SE1 9RT, United Kingdom; Cox, M.J., King's College London Dental Institute, Guy's Campus Tower Wing, Floor 18, London SE1 9RT, United Kingdom; Quinn, B.F.A., King's College London Dental Institute, Guy's Campus Tower Wing, Floor 18, London SE1 9RT, United Kingdom; Newton, J.T., King's College London Dental Institute, Guy's Campus Tower Wing, Floor 18, London SE1 9RT, United Kingdom; Banerjee, A., King's College London Dental Institute, Guy's Campus Tower Wing, Floor 18, London SE1 9RT, United Kingdom; Woolford, M., King's College London Dental Institute, Guy's Campus Tower Wing, Floor 18, London SE1 9RT, United Kingdom","HapTEL, an interdisciplinary project funded by two UK research councils from 2007 to 2011, involves a large interdisciplinary team (with undergraduate and post-graduate student participants) which has been developing and evaluating a virtual learning system within an HE healthcare education setting, working on three overlapping strands. Strand 1 involves the technical development and evaluation of the hapTEL workstation which simulates clinical conditions for dental training including haptics (sense of touch). Strand 2 involves examining the traditional undergraduate curriculum and how this could benefit from the use of haptics. Strand 3 is concerned with the educational evaluation of the impact of the work carried out within Strands 1 and 2. Two theoretical frameworks (Entwistle, (1987) and Webb and Cox (2004)) have been used to identify as many factors as possible which could affect the impact of Technology Enhanced Learning (TEL) on the quality of the learning achieved. These frameworks have formed a foundation for measuring the impact of TEL on curriculum change, teachers' pedagogical practices, students' learning and on institutional practices. A range of quantitative and qualitative methods were designed, piloted and evaluated in order to measure the impact of TEL on teaching and learning; and to have a rich and robust data set which also addresses the variables in the frameworks. The results from using these frameworks show that institutional and departmental factors should be considered when evaluating the impact of TEL in higher education and that these had a major influence on the design and curriculum integration of the hapTEL systems. We have also shown that by involving the end users from the beginning enabled not only an enhancement of the students' learning experiences but also a modification to the traditional curriculum itself and the successful integration of TEL within a very traditional undergraduate higher education dental curriculum. The conclusions from this paper confirm earlier reviews of researching TEL that technology integration is extremely complex and the related research requires a comprehensive approach of both quantitative and qualitative methods if one is to take account of the range of variables identified by theoretical frameworks. Finally, repeating the range of empirical investigations for a second year enables researchers to validate the effectiveness of the methods used in the initial year and thereby maximise the reliability and generalisability of the research outcomes. © 2011 Elsevier Ltd.","Evaluation methodologies; Interactive learning environments; Interdisciplinary projects; Pedagogical issues; Virtual reality","Computer aided instruction; Curricula; Deep neural networks; Education; Integration; Learning systems; Students; Teaching; Virtual reality; Empirical investigation; Evaluation methodologies; Interactive learning environment; Interdisciplinary project; Pedagogical issues; Quantitative and qualitative methods; Students' learning experiences; Technology enhanced learning; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-84865657964
"Tan S.C., Marlow N., Field J., Altree M., Babidge W., Hewett P., Maddern G.J.","57028693500;26325516100;36991831100;55875279200;6603097996;7006309268;26643080100;","A randomized crossover trial examining low-versus high-fidelity simulation in basic laparoscopic skills training",2012,"Surgical Endoscopy","26","11",,"3207","3214",,21,"10.1007/s00464-012-2326-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871607809&doi=10.1007%2fs00464-012-2326-0&partnerID=40&md5=3fea6d2ea446e7f3e62a84b1ca234469","Department of Surgery, Royal Adelaide Hospital, Adelaide, SA, Australia; Research Audit and Academic Surgery Division, Royal Australasian College of Surgeons, 199 Ward Street, Adelaide, SA 5006, Australia; John Field Consulting Pty. Ltd, Adelaide, SA, Australia; Dpartment of Surgery, University of Adelaide, Queen Elizabeth Hospital, Adelaide, SA, Australia","Tan, S.C., Department of Surgery, Royal Adelaide Hospital, Adelaide, SA, Australia; Marlow, N., Research Audit and Academic Surgery Division, Royal Australasian College of Surgeons, 199 Ward Street, Adelaide, SA 5006, Australia; Field, J., John Field Consulting Pty. Ltd, Adelaide, SA, Australia; Altree, M., Research Audit and Academic Surgery Division, Royal Australasian College of Surgeons, 199 Ward Street, Adelaide, SA 5006, Australia; Babidge, W., Research Audit and Academic Surgery Division, Royal Australasian College of Surgeons, 199 Ward Street, Adelaide, SA 5006, Australia, Dpartment of Surgery, University of Adelaide, Queen Elizabeth Hospital, Adelaide, SA, Australia; Hewett, P., Dpartment of Surgery, University of Adelaide, Queen Elizabeth Hospital, Adelaide, SA, Australia; Maddern, G.J., Research Audit and Academic Surgery Division, Royal Australasian College of Surgeons, 199 Ward Street, Adelaide, SA 5006, Australia, Dpartment of Surgery, University of Adelaide, Queen Elizabeth Hospital, Adelaide, SA, Australia","Background: Previous randomized studies have compared high- versus low-fidelity laparoscopic simulators; however, no proficiency criteria were defined and results have been mixed. The purpose of this research was to determine whether there were any differences in the learning outcomes of participants who had trained to proficiency on low- or high-fidelity laparoscopic surgical simulators. Methods: We conducted a randomized, prospective crossover trial with participants recruited from New South Wales, Western Australia, and South Australia. Participants were randomized to high-fidelity (LapSim, Surgical Science) or low-fidelity (FLS, SAGES) laparoscopic simulators and trained to proficiency in a defined number of tasks. They then crossed over to the other fidelity simulator and were tested. The outcomes of interest were the crossover mean scores, the proportion of tasks passed, and percentage passes for the crossover simulator tasks. Results: Of the 228 participants recruited, 100 were randomized to LapSim and 128 to FLS. Mean crossover score increased from baseline for both simulators, but there was no significant difference between them (11.0 % vs. 11.9 %). FLS-trained participants passed a significantly higher proportion of crossover tasks compared with Lap- Sim-trained participants (0.26 vs. 0.20, p = 0.016). A significantly higher percentage of FLS-trained participants passed intracorporeal knot tying than LapSim-trained participants (35 % vs. 8 %, p < 0.001). Conclusion: Similar increases in participant score from baseline illustrate that training on either simulator type is beneficial. However, FLS-trained participants demonstrated a greater ability to translate their skills to successfully complete LapSim tasks. The ability of FLS-trained participants to transfer their skills to new settings suggests the benefit of this simulator type compared with the LapSim. © Springer Science+Business Media, LLC 2012.","FLS; Laparoscopy; LapSim; Proficiency-based training; Simulation; Surgical education","adult; article; Australia; comparative study; female; human; laparoscopic surgery; male; medical education; medical practice; priority journal; prospective study; scoring system; simulation; study skills; surgical training; task performance",Article,"Final","",Scopus,2-s2.0-84871607809
"Riva G.","56962750600;","Presence, Actions and Emotions: A Theoretical Framework",2011,"Annual Review of CyberTherapy and Telemedicine","9","1",,"2","5",,4,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-83455163904&partnerID=40&md5=6588d9f255509db90b8c73c88eb14703","Applied Technology for Neuro-Psychology Lab, Istituto Auxologico Italiano, Milan, Italy; Psychology Department, Catholic University of Milan, Italy","Riva, G., Applied Technology for Neuro-Psychology Lab, Istituto Auxologico Italiano, Milan, Italy, Psychology Department, Catholic University of Milan, Italy","As commented by Biocca [1], and agreed by most researchers in the area, ""while the design of Virtual Reality (VR) technology has brought the theoretical issue of presence to the fore, few theorists argue that the experience of presence suddenly emerged with the arrival of VR"" (p. 121). So, what is presence? And what is its possible impact in cybertherapy? For instance, does a strong sense of presence cause patients to better engage and modify emotions and cognitive processes they have already developed in a real environment? Will the skills and the competences acquired in the virtual world transfer to a corresponding real experience? This chapter will try to provide some answers to these questions using the following definition of presence: presence is the non-mediated (prereflexive) perception of using the body/a medium to successfully transform intentions in action (enaction).","Assessment; NeuroVR; Open source; Therapy; Virtual Reality","action; article; behavior; cognition; cybertherapy; emotion; personal experience; presence; psychotherapy; skill; telemedicine; theoretical model; virtual reality",Article,"Final","",Scopus,2-s2.0-83455163904
"Yang S., Hwang W.-H., Tsai Y.-C., Liu F.-K., Hsieh L.-F., Chern J.-S.","7408515375;54581055700;54581748500;54581103000;7101988949;36819947700;","Improving balance skills in patients who had stroke through virtual reality treadmill training",2011,"American Journal of Physical Medicine and Rehabilitation","90","12",,"969","978",,69,"10.1097/PHM.0b013e3182389fae","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81855176112&doi=10.1097%2fPHM.0b013e3182389fae&partnerID=40&md5=cdf3f4b9c54f117dd3a1d988db6321ce","Institute of Biomedical Engineering, National Yang-Ming University, Taipei, Taiwan; Rehabilitation Medicine, Cheng-Hsin Rehabilitation Medical Center, Taipei, Taiwan; Department of Rehabilitation, Shin Kong Wu Ho-Su Memorial Hospital, Taipei, Taiwan; Department of Occupational Therapy, Chang Gung University, No. 259, Wen-Hwa 1st Rd, Kwei-Shan Township, Taoyuan County, 333, Taiwan","Yang, S., Institute of Biomedical Engineering, National Yang-Ming University, Taipei, Taiwan; Hwang, W.-H., Institute of Biomedical Engineering, National Yang-Ming University, Taipei, Taiwan; Tsai, Y.-C., Institute of Biomedical Engineering, National Yang-Ming University, Taipei, Taiwan; Liu, F.-K., Rehabilitation Medicine, Cheng-Hsin Rehabilitation Medical Center, Taipei, Taiwan; Hsieh, L.-F., Department of Rehabilitation, Shin Kong Wu Ho-Su Memorial Hospital, Taipei, Taiwan; Chern, J.-S., Department of Occupational Therapy, Chang Gung University, No. 259, Wen-Hwa 1st Rd, Kwei-Shan Township, Taoyuan County, 333, Taiwan","Objective: The aim of this study was to evaluate the effects of virtual reality (VR) treadmill training on the balance skills of patients who have had a stroke. Design: A total of 14 patients with strokes were recruited and randomly assigned to receive VR treadmill or traditional treadmill training. The outcome measures that were included for the study were center of pressure (COP) sway excursion, COP maximum sway in anterior-posterior direction, COP maximum sway in medial-lateral direction, COP sway area, bilateral limb-loading symmetric index, the sway excursion values for the paretic foot (sway excursion/P), paretic limb stance time (stance time/P), number of steps of the paretic limb (number of steps/P), and contact area of the paretic foot (contact A/P) during quiet stance, sit-to-stand transfer, and level walking. Results: There were no significant improvements in COP-related measures and symmetric index during the quiet stance, either in the VR treadmill or traditional treadmill training group (P > 0.05). However, the difference between groups after training in COP maximum sway in medial-lateral direction during the quiet stance was significant (P = 0.038). Traditional treadmill training failed to improve sit-to-stand performance, whereas VR treadmill training improved symmetric index (P = 0.028) and sway excursion (P = 0.046) significantly during sit-to-stand transfer. The changes of symmetric index between groups were markedly different (P = 0.045). Finally, both groups improved significantly in stance time/P, but only VR treadmill training increased contact A/P (P = 0.034) after training during level walking. The difference between groups during level walking was not significant. Conclusions: Neither traditional treadmill nor VR treadmill training had any effect on balance skill during quiet stance, but VR treadmill training improved balance skill in the medial-lateral direction better than traditional training did. VR treadmill training also improved balance skill during sit-to-stand transfers and the involvement of paretic limb in level walking more than the traditional one did. Copyright © 2011 by Lippincott Williams & Wilkins.","Stroke; Treadmill Exercise; Virtual Reality; Weight Shifting","aged; article; body equilibrium; clinical trial; comparative study; computer interface; computer simulation; controlled clinical trial; controlled study; convalescence; exercise test; female; hospitalization; human; male; middle aged; nonparametric test; physiology; randomized controlled trial; reference value; stroke; walking; Aged; Computer Simulation; Exercise Test; Female; Humans; Male; Middle Aged; Postural Balance; Recovery of Function; Reference Values; Severity of Illness Index; Statistics, Nonparametric; Stroke; User-Computer Interface; Walking",Article,"Final","",Scopus,2-s2.0-81855176112
"Johnson S.J., Guediri S.M., Kilkenny C., Clough P.J.","55466679200;54405446400;49961557500;7004534518;","Development and validation of a virtual reality simulator: Human factors input to interventional radiology training",2011,"Human Factors","53","6",,"612","625",,22,"10.1177/0018720811425042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-82055170541&doi=10.1177%2f0018720811425042&partnerID=40&md5=1d4c502e619bcd9da576574652c43ddc","University of Manchester, Manchester Business School, Booth Street East, Manchester MI5 6PB, United Kingdom; University of Hull, United Kingdom","Johnson, S.J., University of Manchester, Manchester Business School, Booth Street East, Manchester MI5 6PB, United Kingdom; Guediri, S.M., University of Manchester, Manchester Business School, Booth Street East, Manchester MI5 6PB, United Kingdom; Kilkenny, C., University of Hull, United Kingdom; Clough, P.J., University of Hull, United Kingdom","Objective: This study developed and validated a virtual reality (VR) simulator for use by interventional radiologists.Background: Research in the area of skill acquisition reports practice as essential to become a task expert. Studies on simulation show skills learned in VR can be successfully transferred to a real-world task. Recently, with improvements in technology, VR simulators have been developed to allow complex medical procedures to be practiced without risking the patient.Method: Three studies are reported. In Study 1, 35 consultant interventional radiologists took part in a cognitive task analysis to empirically establish the key competencies of the Seldinger procedure. In Study 2, 62 participants performed one simulated procedure, and their performance was compared by expertise. In Study 3, the transferability of simulator training to a real-world procedure was assessed with 14 trainees.Results: Study 1 produced 23 key competencies that were implemented as performance measures in the simulator. Study 2 showed the simulator had both face and construct validity, although some issues were identified. Study 3 showed the group that had undergone simulator training received significantly higher mean performance ratings on a subsequent patient procedure.Conclusion: The findings of this study support the centrality of validation in the successful design of simulators and show the utility of simulators as a training device.Application: The studies show the key elements of a validation program for a simulator. In addition to task analysis and face and construct validities, the authors highlight the importance of transfer of training in validation studies. © 2011 Human Factors and Ergonomics Society.","interventional radiology; simulation; training; validation; virtual reality","Cognitive task analysis; Construct validity; Interventional; Interventional radiology; Interventional radiology training; Key elements; Medical procedures; Performance measure; Performance ratings; Real-world task; simulation; Simulator training; Skill acquisition; Task analysis; validation; Validation Program; Validation study; Virtual reality simulator; Human engineering; Job analysis; Personnel training; Radiation; Radiology; Virtual reality; Simulators; adult; article; clinical competence; computer interface; computer simulation; education; human; interventional radiology; reproducibility; task performance; teaching; Adult; Clinical Competence; Computer Simulation; Computer-Assisted Instruction; Humans; Radiology, Interventional; Reproducibility of Results; Task Performance and Analysis; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-82055170541
"Bayona S., Fernandez-Arroyo J.M., Bayona P., Martin I.","24821639800;24597123900;24597645300;7401825463;","A global approach to the design and evaluation of virtual reality medical simulators",2011,"ASME 2011 World Conference on Innovative Virtual Reality, WINVR 2011",,,,"367","376",,1,"10.1115/WINVR2011-5554","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881472736&doi=10.1115%2fWINVR2011-5554&partnerID=40&md5=cc862f05fdbf51ac9168f340af970580","Universidad Rey Juan Carlos, Mostoles, Madrid, Spain; Hospital Severo Ochoa, Leganes, Madrid, Spain; Instituto de Psicologia Integral, Salud y Coaching Avanza, Madrid, Spain","Bayona, S., Universidad Rey Juan Carlos, Mostoles, Madrid, Spain; Fernandez-Arroyo, J.M., Hospital Severo Ochoa, Leganes, Madrid, Spain; Bayona, P., Instituto de Psicologia Integral, Salud y Coaching Avanza, Madrid, Spain; Martin, I., Universidad Rey Juan Carlos, Mostoles, Madrid, Spain","VR Simulators are a powerful alternative to traditional educational techniques in many domains; and in particular, in surgery. Although they offer new possibilities for learning, training and assessment, they still found difficult to be accepted and integrated into hospitals. In this paper, we explain what we consider the key issues to create successful VR simulators, and we present two methodologies: the guidelines for the simulator design and the evaluation of their validity. Research on VR surgical simulators should be interdisciplinary. It involves medicine, educational psychology, computer science, and engineering. Optimal interdisciplinary communication is difficult, and most projects in surgical simulation are strongly influenced by the engineering perspective, with little or no contributions from the others. This unbalance often leads to a premature end of the project or to simulators which are less practical for surgeons. A design methodology should be used as a guide in the process of creating VR simulators. A thorough description of the problem, the simulator's role, and an exhaustive task analysis will lead to the identification of the requirements. For the technical implementation, decisions will be taken related to the hardware interface and the interaction that users will have with the virtual world; which will determine collision detection and response algorithms, and the behaviour of the 3D models. In addition to the technical testing, it is necessary to prove the validity of the simulator and design procedures to measure the user performance. We explain a methodology to evaluate the validity (face, content, and criterion-related validity), reliability and transfer of skills from a VR simulator to the real environment in a structured and rigorous way. Following this methodology, an evaluation experiment involving 19 orthopaedic doctors using a VR arthroscopy simulator was carried out. Results prove face and content validities, and inform about the factors and measures that are considered important for arthroscopic surgery. In order to consolidate the research results, we encourage the establishment of an intersectorial consortium with agents from the academic, healthcare and industrial sectors to ensure the long-term sustainability of research lines, additional funding, and to guarantee that simulators, once validated, can be widely available in hospitals. This paper presents a global approach including relevant guidelines and methodologies for designing and evaluating VR simulators. It can provide a solid structure for other researchers when facing those processes and contribute to the successful integration of VR simulators within the educational curriculum. Copyright © 2011 by ASME.","Assessment; Experimental research; Healthcare education; Innovative education; Interactive technology; Surgical simulation; System design; System evaluation; Virtual reality","Assessment; Experimental research; Health care education; Innovative education; Interactive technology; Surgical simulation; System evaluation; Curricula; Design; Haptic interfaces; Health care; Hospitals; Industrial research; Job analysis; Personnel training; Simulators; Surgery; Sustainable development; Systems analysis; Virtual reality; Surgical equipment",Conference Paper,"Final","",Scopus,2-s2.0-84881472736
"Hoppen M., Rossmann J., Schluse M., Waspe R., Rast M.","35310501100;56251698200;6507542372;35312849100;36161393400;","Combining 3D simulation technology with object-oriented databases: A database oriented approach to virtual reality systems",2011,"Proceedings of the ASME Design Engineering Technical Conference","2","PARTS A AND B",,"1545","1554",,4,"10.1115/DETC2011-48230","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863572265&doi=10.1115%2fDETC2011-48230&partnerID=40&md5=73fc3d9faadd94d079fddbed51781099","Institute for Man-Machine Interaction, RWTH Aachen University, Aachen, 52074, Germany","Hoppen, M., Institute for Man-Machine Interaction, RWTH Aachen University, Aachen, 52074, Germany; Rossmann, J., Institute for Man-Machine Interaction, RWTH Aachen University, Aachen, 52074, Germany; Schluse, M., Institute for Man-Machine Interaction, RWTH Aachen University, Aachen, 52074, Germany; Waspe, R., Institute for Man-Machine Interaction, RWTH Aachen University, Aachen, 52074, Germany; Rast, M., Institute for Man-Machine Interaction, RWTH Aachen University, Aachen, 52074, Germany","Using object-oriented databases as the primary data source in VR applications has a variety of advantages, but requires the development of new techniques concerning data modeling, data handling and data transfer from a Virtual Reality system's point of view. The many advantages are outlined in the first part of this paper. We first introduce versioning and collaboration techniques as our main motivation. These can also be used in the traditional file based approach, but are much more powerful when realized with a database on an object and attribute level. Using an object-oriented approach to data modeling, objects of the real world can be modeled more intuitively by defining appropriate classes with their relevant attributes. Furthermore, databases can function as central communication hubs for consistent multi user interaction. Besides, the use of databases with open interface standards allows to easily cooperate with other applications such as modeling tools and other data generators. The second part of this paper focuses on our approach to seamlessly integrate such databases in Virtual Reality systems. For this we developed an object-oriented internal graph database and linked it to object-oriented external databases for central storage and collaboration. Object classes defined by XML data schemata allow to easily integrate new data models in VR applications at run-time. A fully transparent database layer in the simulation system makes it easy to interchange the external database. We present the basic structure of our simulation graph database, as well as the mechanisms which are used to transparently map data and meta-data from the external database to the simulation database. To show the validity and flexibility of our approach selected applications realized with our simulation system so far e. g. applications based on geoinformation databases such as forest inventory systems and city models, applications in the field of distributed control and simulation of assembly lines or database-driven virtual testbeds applications for automatic map generation in planetary landing missions are introduced. © 2011 by ASME.",,"3D simulations; Assembly line; Attribute levels; Basic structure; City model; Communication hub; Database layer; Distributed control; Forest inventory; Geo-information; Graph database; Map data; Map generation; Modeling tool; Multi-user interaction; Object class; Object oriented; Object oriented approach; Object oriented database; Open Interface; Planetary landing; Primary data source; Runtimes; Simulation graphs; Simulation systems; Versioning; Virtual reality system; Virtual test beds; VR applications; XML data; Data handling; Data transfer; Design; Distributed parameter control systems; Three dimensional computer graphics; Virtual reality; Database systems",Conference Paper,"Final","",Scopus,2-s2.0-84863572265
"Harter D., Lu S., Kotturu P., Pierce D.","7005776620;55017156300;55327796200;36119152900;","An immersive virtual environment for varying risk and immersion for effective training",2011,"ASME 2011 World Conference on Innovative Virtual Reality, WINVR 2011",,,,"301","307",,3,"10.1115/WINVR2011-5522","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84881453775&doi=10.1115%2fWINVR2011-5522&partnerID=40&md5=47f9f5e5b2e0153b80da492362375d9a","Department of Computer Science and Information Systems, Artificial Intelligence and Robotics Laboratory, Texas A and M University, Commerce, TX 75429, United States; Department of Psychology, Cognitive Science Laboratory, Texas A and M University, Commerce, TX, 75429, United States","Harter, D., Department of Computer Science and Information Systems, Artificial Intelligence and Robotics Laboratory, Texas A and M University, Commerce, TX 75429, United States; Lu, S., Department of Psychology, Cognitive Science Laboratory, Texas A and M University, Commerce, TX, 75429, United States; Kotturu, P., Department of Psychology, Cognitive Science Laboratory, Texas A and M University, Commerce, TX, 75429, United States; Pierce, D., Department of Psychology, Cognitive Science Laboratory, Texas A and M University, Commerce, TX, 75429, United States","We present an immersive virtual environment being developed to study questions of risk perception and their impacts on effective training. Immersion is known to effect the quality of training in virtual environments, and the successful transfer of skills to real world situations. However, the level of perceived immersiveness that an environment invokes is an ill defined concept, and effects of different types of immersion are known to have greater and lesser influences on training outcomes. We concentrate on how immersiveness effects perceived risk in virtual environments, and how risk impacts training effectiveness. Simulated risk can invoke an alief of danger in subjects using a virtual environment. Alief is a concept useful in virtual training that describes situations where the person experiencing a simulated scenario knows it is not real, but suspends disbelief (willingly or unwillingly). This suspension of belief (alief can cause the person to experience the same sorts of autonomic reactions as if they were experiencing the situation in real life (for example, think of fear invoked on amusement park rides). Alief of risk or danger has been proposed as one phenomenon that can influence training outcomes, like the experience of immersion, when training in virtual environments. In this paper we present work on developing a low-cost virtual environment for the manipulation of immersion and risk for cognitive studies. In this environment we provide several alternative input modalities, from mouse to Wii remote interactivity, to control a virtual avatar's hand and arm for performing risky every day tasks. Immersion can be manipulated in several ways, as well as the type and risk associated with tasks. Typical tasks include performing kitchen preparation work (using knives or hot items), or wood or metal working tasks (involving manipulation of dangerous tools). This paper describes the development and technologies used to create the virtual environment, and how we vary risk perception and immersion of users for various cognitive tasks. The capabilities and manipulations of immersiveness and risk are presented together with some findings on using Wii motes as input devices in several ways for virtual environments. The paper concludes with some preliminary results of varying perceived risk on cognitive task performance in the developed environment. Copyright © 2011 by ASME.",,"Alternative input; Amusement-park rides; Cognitive task; Development and technology; Immersive virtual environments; Real world situations; Training effectiveness; Virtual training; Risk perception; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84881453775
"Jung T.J., Rast M., Kaigom E.G., Rossmann J.","57197658917;36161393400;55303709800;56251698200;","Fast VR application development based on versatile rigid multi-body dynamics simulation",2011,"Proceedings of the ASME Design Engineering Technical Conference","2","PARTS A AND B",,"1481","1490",,7,"10.1115/DETC2011-47621","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863606280&doi=10.1115%2fDETC2011-47621&partnerID=40&md5=68bdf72fed447a6b0ae8304b2faff380","Institute for Man-Machine Interaction, RWTH Aachen University, Germany","Jung, T.J., Institute for Man-Machine Interaction, RWTH Aachen University, Germany; Rast, M., Institute for Man-Machine Interaction, RWTH Aachen University, Germany; Kaigom, E.G., Institute for Man-Machine Interaction, RWTH Aachen University, Germany; Rossmann, J., Institute for Man-Machine Interaction, RWTH Aachen University, Germany","More and more areas in research and development use Virtual Reality technologies. To quickly realize new applications at low costs, the reuse of existing functionality is of high importance. In the area of mobile robotics, physics based simulation components promise optimal reusability: The physical laws always stay the same and do not depend on the application. Hence, as long as the applications try to emulate reality, physics based simulation software will be reusable. Unfortunately, depending on the kind of application, different simulation models for different physical domains are needed: Particle models for fluids and soil, finite-elements for non-rigid bodies, multi-body systems and so on. However, for those applications developed at Institute for Man-Machine Interaction at the RWTH Aachen University, a multi-body dynamics component has taken a central role in the process of application development. It is fully integrated within a modern 3D-simulation and visualization tool. It is enhanced by generalized tools of contact graph analysis, which support the fast development of robust applications suitable for daily use. The paper discusses the benefit of this multi-body system as a platform for versatile application development, taking the following three applications as examples: The first example is the development of forest machine simulators for usage in education and training of machine operators. The existence of a purely kinematically realized, phenomenological implementation with widely equivalent range of functions allows a direct comparison of the programming efforts. The second example is the development of algorithms for space robot motion planning. The example demonstrates, how easy and effective innovative robotic simulation applications can be realized using a common, dynamics based simulation framework. The third example finally describes the development of a Virtual Testbed for legged lunar exploration robots. The Virtual Testbed example handles in detail the concept of ""top-down-development"" of simulation models. The refinement of the simulation of foot-soil-contact situations using a force exchange interface and the refinement of the actuator dynamics simulation using an energy exchange interface serve as examples. © 2011 by ASME.",,"3D simulations; Actuator dynamics; Application development; Daily use; Education and training; Energy exchanges; Exploration robots; Finite Element; Forest machines; Fully integrated; Graph analysis; Low costs; Machine operators; Man-machine interaction; Mobile robotic; Multi Body Systems; Multi-body dynamic; New applications; Non-rigid; Particle model; Physical domain; Physical laws; Physics-based Simulation; Research and development; Robotic simulation; Robust application; Simulation framework; Space robots; Virtual reality technology; Virtual test beds; Visualization tools; VR applications; Computer software reusability; Design; Dynamics; Geologic models; Personnel training; Reusability; Robotics; Testbeds; Virtual reality; Visualization; Three dimensional computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-84863606280
"Steinicke F., Lécuyer A., Mohler B., Whitton M.C.","8883314100;6601917415;10239373300;6604019357;","Perceptually inspired methods for naturally navigating virtual worlds",2011,"SIGGRAPH Asia 2011 Courses, SA'11",,, 18,"","",,,"10.1145/2077434.2077449","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855696741&doi=10.1145%2f2077434.2077449&partnerID=40&md5=a396a60d6c7905555bcc45f86cdc793c","Immersive Media Group, University of Würzburg, Germany; BUNRAKU Research Team, INRIA, Rennes, France; Perception and Action in Virtual Environments, MPI for Biological Cybernetics, Germany; Department of Computer Science, University of North Carolina, Chapel Hill, United States","Steinicke, F., Immersive Media Group, University of Würzburg, Germany; Lécuyer, A., BUNRAKU Research Team, INRIA, Rennes, France; Mohler, B., Perception and Action in Virtual Environments, MPI for Biological Cybernetics, Germany; Whitton, M.C., Department of Computer Science, University of North Carolina, Chapel Hill, United States","In recent years many advances have enabled users to more and more naturally navigate large-scale graphical worlds. The entertainment industry is increasingly providing visual and body-based cues to their users to increase the naturalness of their navigational experience. However, so far none of the existing solutions fully supports the most natural ways of locomotion through virtual worlds, and thus techniques and technologies have to be considered, which take advantage of insights into human perceptual sensitivity. In this context, by far the most natural way to move through the real world is via a full body experience where we receive sensory stimulation to all of our senses, i.e., when walking, running, biking or driving. With some exciting technological advances, people are now beginning to get this same full body sensory experience when navigating computer generated three-dimensional environments [11]. Enabling such an active and dynamic ability to navigate through large-scale virtual scenes is of great interest for many 3D applications demanding locomotion, such as video games, edutainment, simulation, rehabilitation, military, tourism or architecture. Today it is still mostly impossible to freely navigate through computer generated environments in exactly the same way as in the real world [1] and instead rather unnatural and artificial approaches are usually applied, which provide only visual sensation of self-motion. However, while moving in the real world, sensory information such as vestibular, proprioceptive, as well as visual information create consistent multi-sensory cues that indicate ones own motion, i. e., acceleration, speed and direction of travel [5]. Computer graphics environments were initially restricted to visual displays, combined with interaction devices, e. g. joystick or mouse, for providing (often unnatural) inputs to generate self-motion [2]. Today, more and more interaction devices, e. g., Nintendos Wii, Microsofts Kinect or Sonys EyeToy, enable intuitive and natural interaction. In this context many research groups are investigating natural, multimodal methods of generating self-motion in virtual worlds based on these consumer hardware. An obvious approach is to transfer the users tracked head movements to changes of the camera in the virtual world by means of a one-to-one mapping. Then, one meter movement in the real world is mapped to one meter movement of the virtual camera in the corresponding direction in the virtual environment (VE). This technique has the drawback that the users movements are restricted by a limited range of the tracking sensors, e. g. optical cameras, and usually a rather small workspace in the real world [2]. The size of the virtual world often differs from the size of the tracked space so that a straightforward implementation of omni-directional and unlimited walking is not possible [12, 2]. Thus, creative virtual locomotion methods (i. e. redirected walking, walking in place, chairs as joysticks, visual indications of natural movement) have been used that enable the experience of traveling over large distances in the virtual world while remaining within a relatively small space in the real world [7, 6]. In recent years, two omni-directional treadmills have been built and are used in the research community (University of Louisiana and Max Planck Institute for Biological Cybernetics). These scientists can now explore infinite virtual worlds while choosing to navigate in any direction. Using these treadmills scientists can determine what about the body-based senses are important for different aspects of entertainment, training and learning. In this course we will present an overview about the development of locomotion interfaces for computer generated virtual environments ranging from desktop-based camera manipulations simulating walking, and different walking metaphors for virtual reality (VR)-based environments to state-of-the-art hardware-based solutions that enable omni-directional and unlimited real locomotion through virtual worlds. As the computer graphics industry advances towards increasingly more natural interaction, computer graphics researchers and professionals will benefit from this course by increasing their understanding of human perception and how this knowledge can apply to enabling the most natural interaction technique of all, navigating through the world. © 2011 ACM.",,"3D application; Biological cybernetics; Edutainment; Entertainment industry; Full body; Head movements; Human perception; Interaction devices; Locomotion interfaces; Louisiana; Max Planck Institute; Multi-modal; Natural interactions; Natural movements; Omni-directional; One-to-one mappings; Optical camera; Research communities; Research groups; Self motion; Sensory information; Sensory stimulation; Technological advances; Three-dimensional environment; Video game; Virtual camera; Virtual environments; Virtual locomotion; Virtual scenes; Virtual worlds; Visual display; Visual information; Walking-in-place; Cameras; Computer hardware; Curricula; Display devices; Human computer interaction; Interactive computer graphics; Military applications; Navigation; Research; Sporting goods; Three dimensional; Three dimensional computer graphics; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84855696741
"Chen M., AlRegib G., Juang B.-H.","56957317100;6506443965;7005536765;","An integrated framework for universal motion control",2011,"Proceedings of VRCAI 2011: ACM SIGGRAPH Conference on Virtual-Reality Continuum and its Applications to Industry",,,,"513","518",,3,"10.1145/2087756.2087854","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863044643&doi=10.1145%2f2087756.2087854&partnerID=40&md5=92327f7e7f4a7ad8a7a2d2d903ed012d","School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332, United States","Chen, M., School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332, United States; AlRegib, G., School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332, United States; Juang, B.-H., School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA 30332, United States","The advance of the motion tracking and 3D display technologies impacts the input and output devices of the general human-computer interaction framework nowadays. The motion sensing devices can provide great tracking accuracy at relatively low prices, which make motion-based interactions affordable and popular for general use. Taking into account all the general interactions required on graphic user interfaces, we propose an integrated framework for motion control, which seamlessly supports 2D, 3D and motion gesture interactions. We categorize the general tasks and define four corresponding operating modes: 2D cursor, 3D manipulation, 3D navigation, and motion gesture. Trade-offs are made between generality, performance, and usability. With a careful design of mapping, we believe the generality of the motion control can outweigh the compromise in performance. In the implementation, a hybrid framework of optical and inertial sensing is used to achieve precise 6 DOF motion tracking. We develop two interesting applications to demonstrate the usability of the integrated motion control framework between the first three operating modes. The motion gesture mode is proposed but not covered in this work. © 2011 ACM.","3D interaction; 3D user interface; Motion control; Motion gesture; Universal user interface","3D display technologies; 3D interactions; 3D manipulation; 3D navigation; 3D user interface; Control framework; Gesture interaction; Graphic user interface; Hybrid framework; Inertial sensing; Input and outputs; Integrated frameworks; Interaction framework; Motion gesture; Motion sensing; Motion tracking; Operating modes; Tracking accuracy; Display devices; Human computer interaction; Integration; Interactive computer graphics; Motion control; Sensors; Three dimensional; Virtual reality; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-84863044643
"Ha T., Woo W.","15020792200;35575439600;","ARWand: Phone-based 3D object manipulation in augmented reality environment",2011,"Proceedings - 2011 International Symposium on Ubiquitous Virtual Reality, ISUVR 2011",,, 6068304,"44","47",,13,"10.1109/ISUVR.2011.14","https://www.scopus.com/inward/record.uri?eid=2-s2.0-82055162736&doi=10.1109%2fISUVR.2011.14&partnerID=40&md5=2f03f1e5d872add11cc4b5a1988ebc6e","GIST U-VR Lab., 500-712, South Korea","Ha, T., GIST U-VR Lab., 500-712, South Korea; Woo, W., GIST U-VR Lab., 500-712, South Korea","In this paper, we suggest a mobile phone-based indirect 3D object manipulation method that uses sensor information in an augmented reality environment. Specifically, we propose 1) a method that exploits a 2D touch screen, a 3DOF accelerometer, and compass sensors information to manipulate 3D objects in 3D space, 2) design transfer functions to map the control space of mobile phones to an augmented reality (AR) display space, and 3) confirm the feasibility of the transfer functions by implementation. Our work could be applicable to the design and implementation of a future mobile phone-based 3D user interface for AR application in normal indoor and outdoor environments without any special tracking installations. © 2011 IEEE.","3D object manipulation; Augmented reality; HMD-based wearable computing; mobile phone; sensor based interaction","3-D space; 3D object; 3D user interface; AR application; Control spaces; Outdoor environment; Sensor informations; Touch screen; Wearable computing; Accelerometers; Augmented reality; Mobile phones; Sensors; Telephone sets; Transfer functions; User interfaces; Virtual reality; Wearable computers; Three dimensional",Conference Paper,"Final","",Scopus,2-s2.0-82055162736
"Huff N.C., Hernandez J.A., Fecteau M.E., Zielinski D.J., Brady R., LaBar K.S.","36792855700;36713497500;55572138900;36954462700;7201469485;6701466778;","Revealing context-specific conditioned fear memories with full immersion virtual reality",2011,"Frontiers in Behavioral Neuroscience",,"NOVEMBER",,"","",,32,"10.3389/fnbeh.2011.00075","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855304478&doi=10.3389%2ffnbeh.2011.00075&partnerID=40&md5=91b69f63192a7db75245ecf328c03074","Psychology and Neuroscience Department, Center for Cognitive Neuroscience, Duke University, Durham, NC, United States; Pratt School of Engineering, Duke University, Durham, NC, United States","Huff, N.C., Psychology and Neuroscience Department, Center for Cognitive Neuroscience, Duke University, Durham, NC, United States; Hernandez, J.A., Psychology and Neuroscience Department, Center for Cognitive Neuroscience, Duke University, Durham, NC, United States; Fecteau, M.E., Psychology and Neuroscience Department, Center for Cognitive Neuroscience, Duke University, Durham, NC, United States; Zielinski, D.J., Pratt School of Engineering, Duke University, Durham, NC, United States; Brady, R., Pratt School of Engineering, Duke University, Durham, NC, United States; LaBar, K.S., Psychology and Neuroscience Department, Center for Cognitive Neuroscience, Duke University, Durham, NC, United States","The extinction of conditioned fear is known to be context-specific and is often considered more contextually bound than the fear memory itself (Bouton, 2004). Yet, recent findings in rodents have challenged the notion that contextual fear retention is initially generalized. The context-specificity of a cued fear memory to the learning context has not been addressed in the human literature largely due to limitations in methodology. Here we adapt a novel technology to test the context-specificity of cued fear conditioning using full immersion 3-D virtual reality (VR). During acquisition training, healthy participants navigated through virtual environments containing dynamic snake and spider conditioned stimuli (CSs), one of which was paired with electrical wrist stimulation. During a 24-h delayed retention test, one group returned to the same context as acquisition training whereas another group experienced the CSs in a novel context. Unconditioned stimulus expectancy ratings were assayed on-line during fear acquisition as an index of contingency awareness. Skin conductance responses time-locked to CS onset were the dependent measure of cued fear, and skin conductance levels during the interstimulus interval were an index of context fear. Findings indicate that early in acquisition training, participants express contingency awareness as well as differential contextual fear, whereas differential cued fear emerged later in acquisition. During the retention test, differential cued fear retention was enhanced in the group who returned to the same context as acquisition training relative to the context shift group. The results extend recent rodent work to illustrate differences in cued and context fear acquisition and the contextual specificity of recent fear memories. Findings support the use of full immersion VR as a novel tool in cognitive neuroscience to bridge rodent models of contextual phenomena underlying human clinical disorders. Copyright © 2011 Huff, Hernandez, Fecteau, Zielinski, Brady and LaBar.","Contextual fear; Fear conditioning; Hippocampus; Memory retention; Virtual reality","adult; anxiety; article; association; cognition; controlled study; expectation; fear; female; habituation; human; human experiment; male; memory; memory consolidation; normal human; psychophysiology; reinforcement; skin conductance; snake; spider; stimulus response; task performance; three dimensional imaging; virtual reality",Article,"Final","",Scopus,2-s2.0-84855304478
"Hodgson E., Bachmann E., Waller D.","14053915200;7005745121;7203026309;","Redirected walking to explore virtual environments: Assessing the potential for spatial interference",2011,"ACM Transactions on Applied Perception","8","4", 22,"","",,46,"10.1145/2043603.2043604","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855243871&doi=10.1145%2f2043603.2043604&partnerID=40&md5=849f0a43f0fe124fd20cbdb756064998","Department of Psychology, 90 N. Patterson Ave., Oxford, OH 45056, United States; Department of Computer Science, Benton Hall, Oxford, OH 45056, United States","Hodgson, E., Department of Psychology, 90 N. Patterson Ave., Oxford, OH 45056, United States; Bachmann, E., Department of Computer Science, Benton Hall, Oxford, OH 45056, United States; Waller, D., Department of Psychology, 90 N. Patterson Ave., Oxford, OH 45056, United States","Redirected walking has gained popularity in recent years as a way of enhancing the safety of users immersed in a virtual reality simulation and of extending the amount of space that can be simulated in a virtual environment (VE). Limits imposed by the available physical space and functional tracking area are overcome by inducing immersed users to veer imperceptibly in a way that prevents them from leaving the confines of the tracking space. Redirected walking has been shown to be feasible at levels below noticeable thresholds and to function without increasing the incidence of simulator sickness. The present studies demonstrate that redirected walking can function without negatively impacting memory for spatial locations of landmarks in a VE, despite introducing discrepancies between various spatial senses and distorting the spatial mapping of movement onto the environment. Additionally, the present studies implement what, to our knowledge, is the first generalized redirected walking algorithm that is independent of any task or environment structure, and can adaptively steer users in real time as they engage in spontaneous, unconstrained navigation. The studies also demonstrate that such an algorithm can be implemented successfully in a gymnasium-sized space. © 2011 ACM.","3D interfaces; Human computer interaction; Multimodal sensory integration; Redirected walking; Spatial cognition; Spatial memory; Spatial senses; Virtual reality","3D interface; Multi-modal; Redirected walking; Spatial cognition; Spatial memory; Spatial senses; Algorithms; Human computer interaction; Virtual reality",Article,"Final","",Scopus,2-s2.0-84855243871
"Zhou Z., Deng C., Pang L., Xu C.","55728182800;36907620100;52364674000;56164373400;","An improved mapping algorithm of cube panorama based on PV3D",2011,"ICIC Express Letters, Part B: Applications","2","5",,"1081","1086",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053533901&partnerID=40&md5=5ab33c606b508a5d80f4fdef20c9d328","School of Computer Science and Information Technology, Northeast Normal University, No. 2555, Jingyue Street, Changchun 130117, China; College of Computer Science and Technology, Jilin University, No. 2699, Qianjin Street, Changchun 130012, China; Faculty of Management Science and Information Engineering, Jilin University of Finance and Economics, No. 3699, Jingyue Street, Changchun 130117, China","Zhou, Z., School of Computer Science and Information Technology, Northeast Normal University, No. 2555, Jingyue Street, Changchun 130117, China; Deng, C., College of Computer Science and Technology, Jilin University, No. 2699, Qianjin Street, Changchun 130012, China; Pang, L., Faculty of Management Science and Information Engineering, Jilin University of Finance and Economics, No. 3699, Jingyue Street, Changchun 130117, China; Xu, C., School of Computer Science and Information Technology, Northeast Normal University, No. 2555, Jingyue Street, Changchun 130117, China","PaperVision3D (PV3D) is a famous open source three-dimension (3D) engine, which could implement powerful Flash 3D application. During developing the project of the Digital City, the author finds that there are some disadvantages on real-time performance, interactivity and image loading speed when constructing the virtual environment with PV3D directly because of the limitation of narrow bandwidth and low computer configuration. To solve the above problem, the author presents a partial texture mapping method to implement cube panorama. In the method, the images needed to be constructed virtual scenes are sliced to image blocks firstly, and these blocks are transferred with the asynchronous technology of Ajax which could use the idle time of network to pre-transfer, then the partial texture mapping is implemented to speed up the image loading. The author improves the algorithm and corresponding codes. A series of contrast experiments shows that the new algorithm could reduce computation load, economize the memory and speed up the image loading efficiently. © 2011 ISSN 2185-2766.","Digital city; Panorama; Pv3d; Virtual reality","3D application; Asynchronous technology; Computation loads; Computer configuration; Contrast experiment; Digital cities; Idle time; Image blocks; Interactivity; Loading speed; Mapping algorithms; Narrow bandwidth; Open sources; Panorama; Pv3d; Real time performance; Texture mapping; Three-dimension; Virtual scenes; Algorithms; Conformal mapping; Loading; Textures; Three dimensional; Virtual reality; Computational efficiency",Article,"Final","",Scopus,2-s2.0-80053533901
"Park K.-M., Ku J., Choi S.-H., Jang H.-J., Park J.-Y., Kim S.I., Kim J.-J.","56164623100;7102897693;56124204300;12445382200;55717071800;55995458100;37106947600;","A virtual reality application in role-plays of social skills training for schizophrenia: A randomized, controlled trial",2011,"Psychiatry Research","189","2",,"166","172",,109,"10.1016/j.psychres.2011.04.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052815890&doi=10.1016%2fj.psychres.2011.04.003&partnerID=40&md5=f9601c2b6df6d19b00b80d2ba47c3f31","Dept. of Psychiatry, Yonsei Univ. College of Medicine, Seoul, South Korea; Inst. of Behavioral Science in Medicine, Yonsei Univ. College of Medicine, Seoul, South Korea; Dept. of Biomedical Engineering, Hanyang University, Seoul, South Korea","Park, K.-M., Dept. of Psychiatry, Yonsei Univ. College of Medicine, Seoul, South Korea, Inst. of Behavioral Science in Medicine, Yonsei Univ. College of Medicine, Seoul, South Korea; Ku, J., Dept. of Biomedical Engineering, Hanyang University, Seoul, South Korea; Choi, S.-H., Dept. of Psychiatry, Yonsei Univ. College of Medicine, Seoul, South Korea, Inst. of Behavioral Science in Medicine, Yonsei Univ. College of Medicine, Seoul, South Korea; Jang, H.-J., Inst. of Behavioral Science in Medicine, Yonsei Univ. College of Medicine, Seoul, South Korea; Park, J.-Y., Inst. of Behavioral Science in Medicine, Yonsei Univ. College of Medicine, Seoul, South Korea; Kim, S.I., Dept. of Biomedical Engineering, Hanyang University, Seoul, South Korea; Kim, J.-J., Dept. of Psychiatry, Yonsei Univ. College of Medicine, Seoul, South Korea, Inst. of Behavioral Science in Medicine, Yonsei Univ. College of Medicine, Seoul, South Korea","Although social skills training (SST) is an effective approach for improving social skills for schizophrenia, the motivational deficit attenuates its efficacy. Virtual reality (VR) applications have allowed individuals with mental disabilities to enhance their motivation for rehabilitations. We compared SST using VR role-playing (SST-VR) to SST using traditional role-playing (SST-TR). This randomized, controlled trial included 91 inpatients with schizophrenia who were assigned to either SST-VR (n=46) or SST-TR (n=45). Both groups were administered over 10 semiweekly group sessions. An experienced, blinded rater assessed vocal, nonverbal and conversational skills. We also obtained data on motivation for SST and various social abilities. Throughout the 10 sessions, the SST-VR group (n=33) showed greater interest in SST and generalization of the skills than the SST-TR group (n=31). After SST, the SST-VR group improved more in conversational skills and assertiveness than the SST-TR group, but less in nonverbal skills. The VR application in role-plays of SST for schizophrenia may be particularly beneficial in terms of improving the conversational skills and assertiveness, possibly through its advantages in enhancing motivation for SST and generalization of the skills, and thus it may be a useful supplement to traditional SST. © 2011 Elsevier Ltd.","Role-plays; Schizophrenia; Social skills training; Virtual reality","adult; article; assertiveness; communication skill; controlled study; female; human; intermethod comparison; major clinical study; male; mental performance; nonverbal communication; priority journal; randomized controlled trial; role playing; schizophrenia; scoring system; social adaptation; stimulus generalization; stimulus response; task performance; verbal communication; virtual reality; Adolescent; Adult; Analysis of Variance; Chi-Square Distribution; Double-Blind Method; Female; Generalization (Psychology); Humans; Interpersonal Relations; Male; Middle Aged; Motivation; Play and Playthings; Problem Solving; Psychiatric Status Rating Scales; Schizophrenia; Schizophrenic Psychology; Social Behavior; Treatment Outcome; User-Computer Interface; Young Adult",Article,"Final","",Scopus,2-s2.0-80052815890
"Pan J.J., Chang J., Yang X., Zhang J.J., Qureshi T., Howell R., Hickish T.","55459051800;55514990300;55683846400;55912086700;50061751400;57196842311;7003268270;","Graphic and haptic simulation system for virtual laparoscopic rectum surgery",2011,"International Journal of Medical Robotics and Computer Assisted Surgery","7","3",,"304","317",,32,"10.1002/rcs.399","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051938056&doi=10.1002%2frcs.399&partnerID=40&md5=e1a1c3733c8fd411e4d01bfcfa0aeb13","National Centre for Computer Animation, Media School, Bournemouth University, United Kingdom; Poole Hospital, Poole, United Kingdom; Royal Bournemouth and Christchurch Hospitals, Bournemouth, United Kingdom","Pan, J.J., National Centre for Computer Animation, Media School, Bournemouth University, United Kingdom; Chang, J., National Centre for Computer Animation, Media School, Bournemouth University, United Kingdom; Yang, X., National Centre for Computer Animation, Media School, Bournemouth University, United Kingdom; Zhang, J.J., National Centre for Computer Animation, Media School, Bournemouth University, United Kingdom; Qureshi, T., Poole Hospital, Poole, United Kingdom; Howell, R., Royal Bournemouth and Christchurch Hospitals, Bournemouth, United Kingdom; Hickish, T., Royal Bournemouth and Christchurch Hospitals, Bournemouth, United Kingdom","Background: Medical simulators with vision and haptic feedback techniques offer a cost-effective and efficient alternative to the traditional medical trainings. They have been used to train doctors in many specialties of medicine, allowing tasks to be practised in a safe and repetitive manner. This paper describes a virtual-reality (VR) system which will help to influence surgeons' learning curves in the technically challenging field of laparoscopic surgery of the rectum. Methods: Data from MRI of the rectum and real operation videos are used to construct the virtual models. A haptic force filter based on radial basis functions is designed to offer realistic and smooth force feedback. To handle collision detection efficiently, a hybrid model is presented to compute the deformation of intestines. Finally, a real-time cutting technique based on mesh is employed to represent the incision operation. Results: Despite numerous research efforts, fast and realistic solutions of soft tissues with large deformation, such as intestines, prove extremely challenging. This paper introduces our latest contribution to this endeavour. With this system, the user can haptically operate with the virtual rectum and simultaneously watch the soft tissue deformation. Conclusions: Our system has been tested by colorectal surgeons who believe that the simulated tactile and visual feedbacks are realistic. It could replace the traditional training process and effectively transfer surgical skills to novices. © 2011 John Wiley & Sons, Ltd.","Cutting algorithm; Haptic force filter; Laparoscopic rectum surgery; Virtual reality","article; colorectal surgery; controlled study; human; human tissue; incision; laparoscopy; nuclear magnetic resonance imaging; rectum surgery; soft tissue disease; surgeon; tactile stimulation; training; videorecording; virtual reality; visual feedback; abdominal surgery; algorithm; animal; bleeding; computer interface; computer simulation; computer system; feedback system; intestine; laparoscopy; procedures; rectum; robotics; surgery; touch; Algorithms; Animals; Computer Simulation; Computer Systems; Digestive System Surgical Procedures; Feedback; Hemorrhage; Humans; Intestines; Laparoscopy; Magnetic Resonance Imaging; Rectum; Robotics; Touch; User-Computer Interface; Video Recording",Article,"Final","",Scopus,2-s2.0-80051938056
"De Maesschalck S., Deveugele M., Willems S.","8684272200;6603647310;7006105514;","Language, culture and emotions: Exploring ethnic minority patients' emotional expressions in primary healthcare consultations",2011,"Patient Education and Counseling","84","3",,"406","412",,35,"10.1016/j.pec.2011.04.021","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051786397&doi=10.1016%2fj.pec.2011.04.021&partnerID=40&md5=e771f37669e45a15de8be716b7a842d1","Department of Family Medicine and Primary Health Care, Ghent University, Belgium","De Maesschalck, S., Department of Family Medicine and Primary Health Care, Ghent University, Belgium; Deveugele, M., Department of Family Medicine and Primary Health Care, Ghent University, Belgium; Willems, S., Department of Family Medicine and Primary Health Care, Ghent University, Belgium","Objective: This study explores ethnic minority patients' expression of emotional cues and concerns in primary healthcare, and examines relationships with patient, provider and consultation attributes. Methods: 191 video-recorded consultations were analyzed using the VR-CoDES. Patients were interviewed before the consultation. Generalized Estimating Equations models (GEE) were used to test for associations. Results: Psychosocial versus bio-medically oriented encounters contained significantly more cues (p≤ 0.05). Patients with poor versus good language proficiency expressed significantly less cues (p≤ 0.001). No significant correlations were found with patients' cultural values, patients' or physicians' gender or the presence of an interpreter. Female patients express more concerns (p≤ 0.05), female physicians have a higher number of concerns expressed by patients (p≤ 0.02). Conclusion: This study shows that independent of physician and diagnosis, patients' language proficiency has a more important impact on the number of cues expressed by the patient than cultural difference. Practice implications: Medical schools and Continuing Medical Education should focus on training programs for recognizing and handling linguistic barriers between physicians and patients. Patient education programs should encourage patients who experience language barriers to open up to physicians. In situations where language is a barrier, physicians and patients should be encouraged to use interpreters to enhance the expression of emotions. © 2011 Elsevier Ireland Ltd.","Cues; Cultural diversity; Language barriers; Minority patients; Patients' emotions","adult; article; consultation; controlled study; cultural competence; cultural value; doctor patient relation; emotionality; ethnic group; female; human; interpersonal communication; language ability; major clinical study; male; patient attitude; primary health care; priority journal; sex difference; social psychology; videorecording; Adult; Cues; Cultural Competency; Cultural Diversity; Emotions; Facial Expression; Female; Humans; Language; Logistic Models; Male; Minority Groups; Models, Statistical; Physician-Patient Relations; Primary Health Care; Questionnaires; Referral and Consultation; Statistics as Topic; Videotape Recording",Article,"Final","",Scopus,2-s2.0-80051786397
"Diesen D.L., Erhunmwunsee L., Bennett K.M., Ben-David K., Yurcisin B., Ceppa E.P., Omotosho P.A., Perez A., Pryor A.","21740961900;25228543000;7202750534;20133390800;6508301165;6506824155;16245953400;7402509791;7005275451;","Effectiveness of laparoscopic computer simulator versus usage of box trainer for endoscopic surgery training of novices",2011,"Journal of Surgical Education","68","4",,"282","289",,92,"10.1016/j.jsurg.2011.02.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959708131&doi=10.1016%2fj.jsurg.2011.02.007&partnerID=40&md5=b24197c68ead38426475c4fbeeeb69a3","Department of Surgery, Duke University Medical Center, DUMC Box 3443 Duke South, Durham, NC 27710, United States; University of Florida, Gainesville FL, United States","Diesen, D.L., Department of Surgery, Duke University Medical Center, DUMC Box 3443 Duke South, Durham, NC 27710, United States; Erhunmwunsee, L., Department of Surgery, Duke University Medical Center, DUMC Box 3443 Duke South, Durham, NC 27710, United States; Bennett, K.M., Department of Surgery, Duke University Medical Center, DUMC Box 3443 Duke South, Durham, NC 27710, United States; Ben-David, K., University of Florida, Gainesville FL, United States; Yurcisin, B., Department of Surgery, Duke University Medical Center, DUMC Box 3443 Duke South, Durham, NC 27710, United States; Ceppa, E.P., Department of Surgery, Duke University Medical Center, DUMC Box 3443 Duke South, Durham, NC 27710, United States; Omotosho, P.A., Department of Surgery, Duke University Medical Center, DUMC Box 3443 Duke South, Durham, NC 27710, United States; Perez, A., Department of Surgery, Duke University Medical Center, DUMC Box 3443 Duke South, Durham, NC 27710, United States; Pryor, A., Department of Surgery, Duke University Medical Center, DUMC Box 3443 Duke South, Durham, NC 27710, United States","Objective: Teaching of laparoscopic skills is a challenge in surgical training programs. Because of the highly technical nature and the steep learning curve, students and residents must learn laparoscopic skills before performing them in the operating room. To improve efficiency of learning and patient safety, research in simulation is essential. Two types of simulators currently in use include virtual reality and box trainers. Our study examined which simulator technique was most effective in teaching novice trainees laparoscopic techniques. Design: This is a prospective, randomized, blinded, controlled trial that enrolled fourth-year medical students and surgical interns to participate in a supervised 6-month laparoscopic training program with either computer simulators or box trainers. Subjects were randomized and trained on appropriate laparoscopic camera skills, instrument handling, object positioning, dissection, ligation, suturing, and knot tying. Students within one group were not allowed to practice, learn or train on the opposing trainers. At time points 0, 2, and 6 months all subjects completed a series of laparoscopic exercises in a live porcine model, which were captured on DVD and scored by blinded expert investigators. Results: Scores improved overall from the pretest to subsequent tests after training with no difference between the virtual reality and box simulator groups. In the medical students specifically, there was overall improvement, and improvement in the needle-transfer and knot-tying skills specifically, with no difference between the box simulator and virtual reality groups. For the interns, both groups showed significant overall improvement with no difference between the virtual reality and box simulator groups or on individual skills. Conclusions: We conclude that laparoscopic simulator training improves surgical skills in novice trainees. We found both the box trainers and the virtual reality simulators are equally effective means of teaching laparoscopic skills to novice learners. © 2011 Association of Program Directors in Surgery.","box trainers; laparoscopy; simulators; training; virtual reality","article; computer aided design; controlled study; endoscopic surgery; female; human; laparoscopy; male; medical student; patient safety; priority journal; randomized controlled trial; scoring system; simulator; single blind procedure; skill; task performance; training; virtual reality; Animals; Clinical Competence; Computer Simulation; Confidence Intervals; Curriculum; Disease Models, Animal; Education, Medical; Female; Humans; Internship and Residency; Laparoscopy; Learning Curve; Male; Models, Anatomic; Prospective Studies; Reference Values; Risk Assessment; Single-Blind Method; Students, Medical; Swine; Task Performance and Analysis; Time Factors; Young Adult",Article,"Final","",Scopus,2-s2.0-79959708131
"Harrington M.C.R.","36836717500;","Empirical evidence of priming, transfer, reinforcement, and learning in the real and virtual trillium trails",2011,"IEEE Transactions on Learning Technologies","4","2", 5539765,"175","186",,21,"10.1109/TLT.2010.20","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81855200302&doi=10.1109%2fTLT.2010.20&partnerID=40&md5=2a5c97a19384afb2be7a113cea8d572e","Department of Computer Science, Slippery Rock University, Slippery Rock, PA 16057, United States","Harrington, M.C.R., Department of Computer Science, Slippery Rock University, Slippery Rock, PA 16057, United States","Over the past 20 years, there has been a debate on the effectiveness of virtual reality used for learning with young children, producing many ideas but little empirical proof. This empirical study compared learning activity in situ of a real environment (Real) and a desktop virtual reality (Virtual) environment, built with video game technology, for discovery-based learning. The experiences were in the form of two field trips featuring statistically identical wildflower reserves. While the results support that the Real is superior for learning activity, they also show that the Virtual is useful for priming and reinforcing in-curriculum material, or for situations when the real environment is inaccessible. Offering the Virtual first primes for learning activity in the Real; if used second, it reinforces the Real experience, as supporting evidence shows significant transfer effects. Thus, the Virtual may serve educational goals, if used appropriately, and can come close to the Real. As informal learning environments, such as field trips and video games, are accepted as motivational, an attitudinal survey was conducted postexperiences to capture motivational factors at play, to aid in comparison and contrast, and to provide context to the empirical results on learning activity in situ; however, more work is needed. © 2008 IEEE.","child-computer interface; Child-computer-environment interaction; discovery-based learning; educational simulation; evaluation/ methodology; human factors in software design; human information processing; human-computer interaction; informal learning; intrinsic learning; modeling; salient events; serious games; simulation; software psychology; user interfaces; user-centered design; virtual reality; visualization","child-computer interface; Child-computer-environment interaction; Discovery-based learning; Educational simulations; evaluation/ methodology; human factors in software design; Human information processing; Human-computer; Informal learning; intrinsic learning; salient events; Serious games; simulation; software psychology; User centered designs; Bionics; Curricula; Data processing; Human computer interaction; Human engineering; Interactive computer graphics; Knowledge management; Reinforcement; Software design; User interfaces; Visualization; Virtual reality",Article,"Final","",Scopus,2-s2.0-81855200302
"Rohs M., Oulasvirta A., Suomalainen T.","17346497700;13006124600;35254183100;","Interaction with magic lenses: Real-world validation of a Fitts' law model",2011,"Conference on Human Factors in Computing Systems - Proceedings",,,,"2725","2728",,26,"10.1145/1978942.1979343","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958152378&doi=10.1145%2f1978942.1979343&partnerID=40&md5=5282decce28aef43d212e86e0843862d","Deutsche Telekom Laboratories, TU Berlin, Germany; Ludwig-Maximilians-Universität München, Munich, Germany; Helsinki Institute for Information Technology, HIIT, Aalto University, Finland; Helsinki Institute for Information Technology, HIIT, University of Helsinki, Finland","Rohs, M., Deutsche Telekom Laboratories, TU Berlin, Germany, Ludwig-Maximilians-Universität München, Munich, Germany; Oulasvirta, A., Helsinki Institute for Information Technology, HIIT, Aalto University, Finland, Helsinki Institute for Information Technology, HIIT, University of Helsinki, Finland; Suomalainen, T., Helsinki Institute for Information Technology, HIIT, Aalto University, Finland, Helsinki Institute for Information Technology, HIIT, University of Helsinki, Finland","Rohs and Oulasvirta (2008) proposed a two-component Fitts' law model for target acquisition with magic lenses in mobile augmented reality (AR) with 1) a physical pointing phase, in which the target can be directly observed on the background surface, and 2) a virtual pointing phase, in which the target can only be observed through the device display. The model provides a good fit (R2=0.88) with laboratory data, but it is not known if it generalizes to real-world AR tasks. In the present outdoor study, subjects (N=12) did building-selection tasks in an urban area. The differences in task characteristics to the laboratory study are drastic: targets are three-dimensional and they vary in shape, size, z-distance, and visual context. Nevertheless, the model yielded an R2 of 0.80, and when using effective target width an R2 of 0.88 was achieved. Copyright 2011 ACM.","Augmented reality; Field experiment; Fitts' law; Humanperformance modeling; Magic lens pointing; Target acquisition","Field experiment; Fitts' law; Human-performance; Magiclenses; Target acquisition; Augmented reality; Display devices; Human computer interaction; Human engineering; Virtual reality; Three dimensional",Conference Paper,"Final","",Scopus,2-s2.0-79958152378
"Crochet P., Aggarwal R., Dubb S.S., Ziprin P., Rajaretnam N., Grantcharov T., Ericsson K.A., Darzi A.","57197269981;8616911800;37025811900;16246742300;37561861400;6603695319;7006566002;14633357600;","Deliberate practice on a virtual reality laparoscopic simulator enhances the quality of surgical technical skills",2011,"Annals of Surgery","253","6",,"1216","1222",,102,"10.1097/SLA.0b013e3182197016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957460430&doi=10.1097%2fSLA.0b013e3182197016&partnerID=40&md5=6d336ee6b18363bc63bdef0ca11efc71","Department of Biosurgery and Surgical Technology, Imperial College London, St. Mary's Hospital, Praed Street, London W2 1NY, United Kingdom; Department of Surgery, University of Toronto, St. Michael's Hospital, Toronto, Canada; Department of Psychology, Florida State University, Tallahassee, FL, United States","Crochet, P., Department of Biosurgery and Surgical Technology, Imperial College London, St. Mary's Hospital, Praed Street, London W2 1NY, United Kingdom; Aggarwal, R., Department of Biosurgery and Surgical Technology, Imperial College London, St. Mary's Hospital, Praed Street, London W2 1NY, United Kingdom; Dubb, S.S., Department of Biosurgery and Surgical Technology, Imperial College London, St. Mary's Hospital, Praed Street, London W2 1NY, United Kingdom; Ziprin, P., Department of Biosurgery and Surgical Technology, Imperial College London, St. Mary's Hospital, Praed Street, London W2 1NY, United Kingdom; Rajaretnam, N., Department of Biosurgery and Surgical Technology, Imperial College London, St. Mary's Hospital, Praed Street, London W2 1NY, United Kingdom; Grantcharov, T., Department of Surgery, University of Toronto, St. Michael's Hospital, Toronto, Canada; Ericsson, K.A., Department of Psychology, Florida State University, Tallahassee, FL, United States; Darzi, A., Department of Biosurgery and Surgical Technology, Imperial College London, St. Mary's Hospital, Praed Street, London W2 1NY, United Kingdom","Introduction: Virtual reality (VR) simulation provides unique training opportunities. This study evaluates whether the deliberate practice (DP) can be successfully applied to simulated laparoscopic cholecystectomy (LC) for enhancement of the quality of surgical skills. Methods: Twenty-six inexperienced surgeons underwent a training program for LC on a VR simulator. Trainees were randomly allocated to 1 of 2 specific protocols of 10 sessions comprising a total of 20 LCs. For each session, the control group performed 2 LCs separated by 30 minutes of occupational activities; the DP group were assigned 30 minutes of DP activities in between 2 LCs. Each participant then performed 2 LCs on a cadaveric porcine model. Quantitative parameters were recorded from the simulator and a motion tracking device; qualitative assessment utilized validated rating scales. Results: Twenty-two subjects completed training. Learning curves on the VR simulator were significant for time taken and number of movements in both groups. The DP group was slower from the third LC (1373 vs. 872 seconds, P = 0.022) and utilized more movements from the seventh (942 vs. 701, P = 0.033). Global rating scores improved significantly in both groups over repeated LCs. The DP group revealed higher scores than control from tenth (19.5 vs. 14, P = 0.014) until the twentieth LC (22 vs. 16, P = 0.003). On the porcine model, the DP group also achieved higher global rating scores (25.5 vs. 19.5, P = 0.002). Conclusions: VR training improved dexterity for both groups, and led to transfer of skill onto a porcine LC model. The DP group achieved higher quality, and demonstrated superior transfer onto real tissues. © 2011 Lippincott Williams & Wilkins.",,"adult; article; cadaver; cholecystectomy; controlled study; female; human; laparoscopic surgery; male; normal human; priority journal; professional competence; qualitative analysis; quantitative analysis; rating scale; simulation; simulator; skill; surgical technique; training; virtual reality; Animals; Cholecystectomy, Laparoscopic; Computer Simulation; Education; Female; Humans; Male; Models, Animal; Swine; User-Computer Interface; Young Adult",Article,"Final","",Scopus,2-s2.0-79957460430
"Rezazadeh I.M., Wang X., Firoozabadi M., Hashemi Golpayegani M.R.","15844046500;8945580300;6506647252;15843404600;","Using affective human-machine interface to increase the operation performance in virtual construction crane training system: A novel approach",2011,"Automation in Construction","20","3",,"289","298",,59,"10.1016/j.autcon.2010.10.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952624201&doi=10.1016%2fj.autcon.2010.10.005&partnerID=40&md5=3b3261e268baa37c5a20c027201e52ae","Department of Biomedical Eng., Science and Research Branch, Islamic Azad University, Tehran, Iran; Faculty of Built Environment, University of New South Wales, Australia; Department of Housing and Interior Design, Kyung Hee University, Seoul, South Korea; School of Medical Sciences, Tarbiat Modares University, Tehran, Iran; Department of Biomedical Eng., Amir Kabir University of Technology, Tehran, Iran","Rezazadeh, I.M., Department of Biomedical Eng., Science and Research Branch, Islamic Azad University, Tehran, Iran; Wang, X., Faculty of Built Environment, University of New South Wales, Australia, Department of Housing and Interior Design, Kyung Hee University, Seoul, South Korea; Firoozabadi, M., Department of Biomedical Eng., Science and Research Branch, Islamic Azad University, Tehran, Iran, School of Medical Sciences, Tarbiat Modares University, Tehran, Iran; Hashemi Golpayegani, M.R., Department of Biomedical Eng., Science and Research Branch, Islamic Azad University, Tehran, Iran, Department of Biomedical Eng., Amir Kabir University of Technology, Tehran, Iran","In the construction industry, some progress have been achieved by researchers to design and implement environments for task training using VR technology and its derivatives such as Augmented and Mixed Reality. Although, these developments have been well recognized at the application level, however crucial to the virtual training system is the effective and reliable measurement of training performance of the particular skill and handling the experiment for long-run. It is known that motor skills cannot be measured directly, but only inferred by observing behaviour or performance measures. The typical way of measuring performance is through measuring task completion time and accuracy, but can be supported by indirect measurement of some other factors. In this paper, a virtual crane training system has been developed which can be controlled using control commands extracted from facial gestures and is capable to lift up loads/materials in the virtual construction sites. Then, we integrate affective computing concept into the conventional VR training platform for measuring the cognitive load and level of satisfaction during performance using human's forehead bioelectric-signals. By employing the affective measures and our novel control scheme, the designed interface could be adapted to user's affective status during the performance in real-time. This adaptable user interface approach helps the trainee to cope with the training for long-run performance, leads to gaining more expertise and provides more effective transfer of learning to other operation environments. The detailed methodology of the affective control is presented in the paper. The results and future applications of the proposed method for disabled users, especially from neck down are discussed. © 2010 Elsevier B.V. All rights reserved.","Affective computing; Affective measures; Construction training; Facial bioelectric-signals; Virtual Reality","Adaptable user interfaces; Affective Computing; Affective measures; Application level; Cognitive loads; Construction training; Control command; Facial bioelectric-signals; Facial gestures; Future applications; Human Machine Interface; Indirect measurements; Level of satisfaction; Long-run performance; Measuring performance; Mixed reality; Motor skills; Novel control scheme; Operation performance; Performance measure; Reliable measurement; Task completion time; Training platform; Training Systems; Transfer of learning; Virtual construction; Virtual construction site; Virtual training; VR technology; Construction industry; Cranes; Human computer interaction; Man machine systems; User interfaces; Virtual reality; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-79952624201
"García-Rodríguez O., Ferrer-García M., Pericot-Valverde I., Gutiérrez-Maldonado J., Secades-Villa R., Carballo J.L.","8343311800;13405944200;36091812500;9334173600;6603281378;36711347100;","Identifying specific cues and contexts related to smoking craving for the development of effective virtual environments.",2011,"Cyberpsychology, behavior and social networking","14","3",,"91","97",,22,"10.1089/cyber.2010.0012","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960954470&doi=10.1089%2fcyber.2010.0012&partnerID=40&md5=62b2633cd4ae44b15d496eefd909d7bf","Department of Personality, Assessment and Psychological Treatments, University of Barcelona, Barcelona, Spain.","García-Rodríguez, O., Department of Personality, Assessment and Psychological Treatments, University of Barcelona, Barcelona, Spain.; Ferrer-García, M.; Pericot-Valverde, I.; Gutiérrez-Maldonado, J.; Secades-Villa, R.; Carballo, J.L.","Craving is considered the main variable associated with relapse after smoking cessation. Cue Exposure Therapy (CET) consists of controlled and repeated exposure to drug-related cues with the aim of extinguishing craving responses. Some virtual reality (VR) environments, such as virtual bars or parties, have previously shown their efficacy as tools for eliciting smoking craving. However, in order to adapt this technology to smoking cessation interventions, there is a need for more diverse environments that enhance the probability of generalization of extinction in real life. The main objective of this study was to identify frequent situations that produce smoking craving, as well as detecting specific craving cues in those contexts. Participants were 154 smokers who responded to an ad hoc self-administered inventory for assessing craving level in 12 different situations. Results showed that having a drink in a bar/pub at night, after having lunch/dinner in a restaurant and having a coffee in a cafe or after lunch/dinner at home were reported as the most craving-inducing scenarios. Some differences were found with regard to participants' gender, age, and number of cigarettes smoked per day. Females, younger people, and heavier smokers reported higher levels of craving in most situations. In general, the most widely cited specific cues across the contexts were people smoking, having a coffee, being with friends, and having finished eating. These results are discussed with a view to their consideration in the design of valid and reliable VR environments that could be used in the treatment of nicotine addicts who wish to give up smoking.",,"addiction; adolescent; adult; aged; article; association; computer interface; computer simulation; female; human; male; methodology; middle aged; psychological aspect; smoking; smoking cessation; social environment; Adolescent; Adult; Aged; Behavior, Addictive; Computer Simulation; Cues; Female; Humans; Male; Middle Aged; Smoking; Smoking Cessation; Social Environment; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-79960954470
"White S.A., Prachyabrued M., Chambers T.L., Borst C.W., Reiners D.","55452526400;18936813700;7202454867;9736479200;6507129285;","Low-cost simulated MIG welding for advancement in technical training",2011,"Virtual Reality","15","1",,"69","81",,9,"10.1007/s10055-010-0162-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951950718&doi=10.1007%2fs10055-010-0162-x&partnerID=40&md5=4949d7a5a2faa7342746e263e141d8e2","University of Louisiana at Lafayette, 537 Cajundome Boulevard, Lafayette, LA 70506, United States","White, S.A., University of Louisiana at Lafayette, 537 Cajundome Boulevard, Lafayette, LA 70506, United States; Prachyabrued, M., University of Louisiana at Lafayette, 537 Cajundome Boulevard, Lafayette, LA 70506, United States; Chambers, T.L., University of Louisiana at Lafayette, 537 Cajundome Boulevard, Lafayette, LA 70506, United States; Borst, C.W., University of Louisiana at Lafayette, 537 Cajundome Boulevard, Lafayette, LA 70506, United States; Reiners, D., University of Louisiana at Lafayette, 537 Cajundome Boulevard, Lafayette, LA 70506, United States","The simulated MIG lab (sMIG) is a training simulator for Metal Inert Gas (MIG) welding. It is based on commercial off the shelf (COTS) components and targeted at familiarizing beginning students with the MIG equipment and best practices to follow to become competent and effective MIG welders. To do this, it simulates the welding process as realistically as possible using standard welding hardware components (helmet, gun) for input and by using head-tracking and a 3D-capable low-cost monitor and standard speakers for output. We developed a simulation to generate realistic audio and visuals based on numerical heat transfer methods and verified the accuracy against real welds. sMIG runs in real time producing a realistic, interactive, and immersive welding experience while maintaining a low installation cost. In addition to being realistic, the system provides instant feedback beyond what is possible in a traditional lab. This help students avoid learning (and unlearning) incorrect movement patterns. © 2010 Springer-Verlag London Limited.","Acoustics; Finite difference; Simulation; Virtual reality; Welding","Best-practices; Commercial off-the-shelf components; Finite difference; Hardware components; Immersive; Installation costs; Metal inert gas welding; MIG welding; Movement pattern; Numerical heat transfer; Real time; Simulation; Technical training; Training simulator; Welding process; Electric welding; Heat transfer; Inert gas welding; Inert gases; Numerical methods; Virtual reality",Article,"Final","",Scopus,2-s2.0-79951950718
"Carelli L., Rusconi M.L., Scarabelli C., Stampatori C., Mattioli F., Riva G.","25926814500;6701839855;36984387500;35086977100;7005211742;56962750600;","The transfer from survey (map-like) to route representations into Virtual Reality Mazes: Effect of age and cerebral lesion",2011,"Journal of NeuroEngineering and Rehabilitation","8","1", 6,"","",,20,"10.1186/1743-0003-8-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79251585565&doi=10.1186%2f1743-0003-8-6&partnerID=40&md5=45fa6d5b0eefe2cc0bdea73e0c6e076f","Department of Human Science, University of Bergamo, Bergamo, Italy; Applied Technology for Neuropsychology - Laboratory, Istituto Auxologico Italiano, Milano, Italy; Neuropsychological Rehabilitation, Spedali Civili, Brescia, Italy","Carelli, L., Department of Human Science, University of Bergamo, Bergamo, Italy, Applied Technology for Neuropsychology - Laboratory, Istituto Auxologico Italiano, Milano, Italy; Rusconi, M.L., Department of Human Science, University of Bergamo, Bergamo, Italy; Scarabelli, C., Department of Human Science, University of Bergamo, Bergamo, Italy; Stampatori, C., Neuropsychological Rehabilitation, Spedali Civili, Brescia, Italy; Mattioli, F., Neuropsychological Rehabilitation, Spedali Civili, Brescia, Italy; Riva, G., Applied Technology for Neuropsychology - Laboratory, Istituto Auxologico Italiano, Milano, Italy","Background. To go from one place to another, we routinely generate internal representations of surrounding spaces, which can include egocentric (body-centred) and allocentric (world-centred) coordinates, combined into route and survey representations. Recent studies have shown how both egocentric and allocentric representations exist in parallel and are joined to support behaviour according to the task. Our study investigated the transfer from survey (map-like) to route representations in healthy and brain-damaged subjects. The aim was two-fold: first, to understand how this ability could change with age in a sample of healthy participants, aged from 40 to 71 years old; second, to investigate how it is affected after a brain lesion in a 8 patients' sample, with reference to specific neuropsychological frames. Methods. Participants were first required to perform the paper and pencil version of eight mazes, then to translate the map-like paths into egocentric routes, in order to find the right way into equivalent Virtual Reality (VR) mazes. Patients also underwent a comprehensive neuropsychological evaluation, including a specific investigation of some topographical orientation components. Results. As regards the healthy sample, we found age-related deterioration in VR task performance. While education level and gender were not found to be related to performance, global cognitive level (Mini Mental State Examination), previous experience with computer and fluidity of navigation into the VR appeared to influence VR task results. Considering the clinical sample, there was a difficulty in performing the VR Maze task; executive functions and visuo-spatial abilities deficits appeared to be more relevant for predicting patients' results. Conclusions. Our study suggests the importance of developing tools aimed at investigating the survey to route transfer ability in both healthy elderly and clinical samples, since this skill seems high cognitive demanding and sensitive to cognitive decline. Human-computer interaction issues should be considered in employing new technologies, such as VR environments, with elderly subjects and neurological patients. © 2011 Carelli et al; licensee BioMed Central Ltd.",,"adult; aged; aging; article; brain injury; computer graphics; computer interface; education; female; human; male; maze test; middle aged; neuropsychological test; orientation; physiology; psychological aspect; psychomotor performance; sexual development; stroke; Adult; Aged; Aging; Brain Injuries; Computer Graphics; Education; Female; Humans; Male; Maze Learning; Middle Aged; Neuropsychological Tests; Orientation; Psychomotor Performance; Sex Characteristics; Stroke; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-79251585565
"Seki Y., Sato T.","56363539500;56119766800;","A training system of orientation and mobility for blind people using acoustic virtual reality",2011,"IEEE Transactions on Neural Systems and Rehabilitation Engineering","19","1", 5559478,"95","104",,42,"10.1109/TNSRE.2010.2064791","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951602368&doi=10.1109%2fTNSRE.2010.2064791&partnerID=40&md5=1086d5eeb5a845e28d2d0928422d7eeb","Human Technology Research Institute, National Institute of Advanced Industrial Science and Technology (AIST), Ibaraki 305-8566, Japan; College of Rehabilitation for the Blind, National Rehabilitation Center for Persons with Disabilities, Saitama 359-8555, Japan; Japan Coast Guard, Ibaraki 314-0103, Japan","Seki, Y., Human Technology Research Institute, National Institute of Advanced Industrial Science and Technology (AIST), Ibaraki 305-8566, Japan; Sato, T., College of Rehabilitation for the Blind, National Rehabilitation Center for Persons with Disabilities, Saitama 359-8555, Japan, Japan Coast Guard, Ibaraki 314-0103, Japan","A new auditory orientation training system was developed for blind people using acoustic virtual reality (VR) based on a head-related transfer function (HRTF) simulation. The present training system can reproduce a virtual training environment for orientation and mobility (O&M) instruction, and the trainee can walk through the virtual training environment safely by listening to sounds such as vehicles, stores, ambient noise, etc., three-dimensionally through headphones. The system can reproduce not only sound sources but also sound reflection and insulation, so that the trainee can learn both sound location and obstacle perception skills. The virtual training environment is described in extensible markup language (XML), and the O&M instructor can edit it easily according to the training curriculum. Evaluation experiments were conducted to test the efficiency of some features of the system. Thirty subjects who had not acquired O&M skills attended the experiments. The subjects were separated into three groups: a no-training group, a virtual-training group using the present system, and a real-training group in real environments. The results suggested that virtual-training can reduce veering more than real-training and also can reduce stress as much as real training. The subjective technical and anxiety scores also improved. © 2010 IEEE.","Auditory orientation; blindness; head-related transfer function; obstacle perception; orientation and mobility; sound localization; stress pulse ratio","Auditory orientation; blindness; Head related transfer function; obstacle perception; orientation and mobility; sound localization; stress pulse ratio; Curricula; Eye protection; Handicapped persons; Hypertext systems; Markup languages; Sound insulation; Transfer functions; Virtual reality; E-learning; acoustics; article; auditory stimulation; blindness; computer assisted therapy; computer interface; equipment; equipment design; instrumentation; teaching; Acoustic Stimulation; Acoustics; Blindness; Computer-Assisted Instruction; Equipment Design; Equipment Failure Analysis; Therapy, Computer-Assisted; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-79951602368
"Arora S., Aggarwal R., Moran A., Sirimanna P., Crochet P., Darzi A., Kneebone R., Sevdalis N.","55156116900;8616911800;56946265600;35491510500;57197269981;14633357600;7004625073;35293409500;","Mental practice: Effective stress management training for novice surgeons",2011,"Journal of the American College of Surgeons","212","2",,"225","233",,72,"10.1016/j.jamcollsurg.2010.09.025","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79251622843&doi=10.1016%2fj.jamcollsurg.2010.09.025&partnerID=40&md5=7c04af6e5f15f400d8f6268b09750754","Division of Surgery and Cancer, Imperial College, London, United Kingdom; University College, Dublin, Ireland","Arora, S., Division of Surgery and Cancer, Imperial College, London, United Kingdom; Aggarwal, R., Division of Surgery and Cancer, Imperial College, London, United Kingdom; Moran, A., University College, Dublin, Ireland; Sirimanna, P., Division of Surgery and Cancer, Imperial College, London, United Kingdom; Crochet, P., Division of Surgery and Cancer, Imperial College, London, United Kingdom; Darzi, A., Division of Surgery and Cancer, Imperial College, London, United Kingdom; Kneebone, R., Division of Surgery and Cancer, Imperial College, London, United Kingdom; Sevdalis, N., Division of Surgery and Cancer, Imperial College, London, United Kingdom","Background: Surgeons are often subject to excessive levels of acute stress that can impair their performance. Mental practice (MP) is a strategy used in other high-performance industries to alleviate anxiety. This study investigated if MP reduces stress in novice surgeons. Study Design A prospective, randomized controlled design was used with 20 novice surgeons recruited by random sampling. After baseline testing, participants underwent training on an evidence-based virtual reality (VR) curriculum. They then performed 5 VR laparoscopic cholecystectomies (LC) after being randomized to MP or control groups. The MP group performed 30 minutes of MP using a validated MP training protocol before each LC; control participants conducted an unrelated activity. Stress was assessed subjectively using the validated State-Trait Anxiety-Inventory (STAI) questionnaire and objectively with a continuous heart rate (HR) monitor and salivary cortisol. Mental imagery was assessed using the validated mental imagery questionnaire. Results Eighteen participants completed the study. There were no intergroup differences in baseline stress, imagery, or technical ability. Comparing the MP group with controls, subjective stress (STAI) was lower for the MP group (median 8.40 vs 11.31, p < 0.01). Objective stress was also significantly reduced for the MP group in terms of the average HR (median 72 vs 88 beats/minute, p < 0.0001), maximum HR (median 102 vs 119 beats/minute, p < 0.01), and cortisol (median 2.26 vs 3.85 nmol/L, p < 0.05). Significant negative correlations were obtained between stress and imagery, indicating that improved imagery was associated with lower stress (p < 0.05). Conclusions A short period of MP reduces the subjective, cardiovascular, and neuroendocrine response to stress on a VR simulator. Additional research should determine whether this effect extends beyond novice surgeons and transfers to the operating room. © 2011 American College of Surgeons.",,"adult; article; cholecystectomy; curriculum; heart beat; heart rate; human; laparoscopy; priority journal; questionnaire; randomized controlled trial; randomized controlled trial (topic); State Trait Anxiety Inventory; stress management; surgeon; training; virtual reality; Adult; Anxiety; Biological Markers; Computer Simulation; Female; General Surgery; Heart Rate; Humans; Hydrocortisone; Imagery (Psychotherapy); Male; Operating Rooms; Physicians; Prospective Studies; Questionnaires; Saliva; Stress, Psychological; Task Performance and Analysis; Treatment Outcome",Article,"Final","",Scopus,2-s2.0-79251622843
"Schreuder H.W.R., Oei G., Maas M., Borleffs J.C.C., Schijven M.P.","7004444996;7005217897;7103204541;35902591300;6602492995;","Implementation of simulation in surgical practice: Minimally invasive surgery has taken the lead: The Dutch experience",2011,"Medical Teacher","33","2",,"105","115",,38,"10.3109/0142159X.2011.550967","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551555014&doi=10.3109%2f0142159X.2011.550967&partnerID=40&md5=082cf8ac167a6886a1a7191e429c43ff","Division of Women and Baby, Department of Gynecologic Surgery and Oncology, University Medical Centre Utrecht, P.O. Box 85500, 3508 GA, Utrecht, Netherlands; Máxima Medical Centre, Veldhoven, Netherlands; Academic Medical Centre, Amsterdam, Netherlands; University of Groningen, Netherlands; Department of Surgery, Academic Medical Centre, Amsterdam, Netherlands","Schreuder, H.W.R., Division of Women and Baby, Department of Gynecologic Surgery and Oncology, University Medical Centre Utrecht, P.O. Box 85500, 3508 GA, Utrecht, Netherlands; Oei, G., Máxima Medical Centre, Veldhoven, Netherlands; Maas, M., Academic Medical Centre, Amsterdam, Netherlands; Borleffs, J.C.C., University of Groningen, Netherlands; Schijven, M.P., Department of Surgery, Academic Medical Centre, Amsterdam, Netherlands","Minimal invasive techniques are rapidly becoming standard surgical techniques for many surgical procedures. To develop the skills necessary to apply these techniques, box trainers and/or inanimate models may be used, but these trainers lack the possibility of inherent objective classification of results. In the past decade, virtual reality (VR) trainers were introduced for training minimal invasive techniques. Minimally invasive surgery (MIS) is, by nature, very suitable for this type of training. The specific psychomotor skills and eye-hand coordination needed for MIS can be mastered largely using VR simulation techniques. It is also possible to transfer skills learned on a simulator to real operations, resulting in error reduction and shortening of procedural operating time. The authors aim to enlighten the process of gaining acceptance in the Netherlands for novel training techniques. The Dutch Societies of Surgery, Obstetrics and Gynecology, and Urology each developed individual training curricula for MIS using simulation techniques, to be implemented in daily practice. The ultimate goal is to improve patient safety. The authors outline the opinions of actors involved, such as different simulators, surgical trainees, surgeons, surgical societies, hospital boards, government, and the public. The actual implementation of nationwide training curricula for MIS is, however, a challenging step. © 2011 Informa UK Ltd All rights reserved.",,"article; clinical competence; computer interface; computer simulation; education; human; minimally invasive surgery; Netherlands; patient care; psychomotor performance; Clinical Competence; Computer Simulation; Humans; Netherlands; Patient Care Team; Psychomotor Performance; Surgical Procedures, Minimally Invasive; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-79551555014
"Fraser K., Wright B., Girard L., Tworek J., Paget M., Welikovich L., McLaughlin K.","35878628300;7402346826;21740967400;24464690500;35389642300;36926661800;7102438727;","Simulation training improves diagnostic performance on a real patient with similar clinical findings",2011,"Chest","139","2",,"376","381",,33,"10.1378/chest.10-1107","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551603995&doi=10.1378%2fchest.10-1107&partnerID=40&md5=8ab8623dc8be872cf1184d13b688cc96","Department of Medicine, University of Calgary, Calgary, AB, Canada; Department of Family Medicine, University of Calgary, Calgary, AB, Canada; Office of Undergraduate Medical Education, University of Calgary, Health Sciences Centre, 3330 Hospital Dr NW, Calgary, AB T2N 4N1, Canada","Fraser, K., Department of Medicine, University of Calgary, Calgary, AB, Canada; Wright, B., Department of Family Medicine, University of Calgary, Calgary, AB, Canada, Office of Undergraduate Medical Education, University of Calgary, Health Sciences Centre, 3330 Hospital Dr NW, Calgary, AB T2N 4N1, Canada; Girard, L., Department of Medicine, University of Calgary, Calgary, AB, Canada; Tworek, J., Office of Undergraduate Medical Education, University of Calgary, Health Sciences Centre, 3330 Hospital Dr NW, Calgary, AB T2N 4N1, Canada; Paget, M., Office of Undergraduate Medical Education, University of Calgary, Health Sciences Centre, 3330 Hospital Dr NW, Calgary, AB T2N 4N1, Canada; Welikovich, L., Department of Medicine, University of Calgary, Calgary, AB, Canada; McLaughlin, K., Department of Medicine, University of Calgary, Calgary, AB, Canada, Office of Undergraduate Medical Education, University of Calgary, Health Sciences Centre, 3330 Hospital Dr NW, Calgary, AB T2N 4N1, Canada","Background: Training on a cardiopulmonary simulator improves subsequent diagnostic performance on the same simulator. But data are lacking on transfer of learning. The objective of this study was to determine whether training on a cardiorespiratory simulator improves diagnostic performance on a real patient. Methods: We randomly allocated fi rst-year medical students at the University of Calgary to simulator training in one of three clinical scenarios of acute-onset chest pain: pulmonary embolism with right ventricular strain but no murmur, symptomatic aortic stenosis, or myocardial ischemia causing mitral regurgitation. Simulation sessions ran for 20 min, after which participants had a standardized debriefi ng session and reviewed the physical findings. Immediately following the training sessions, students assessed the auscultatory fi ndings of a real patient with mitral regurgitation. Our outcome measures were accuracy of identifying abnormal auscultatory fi ndings and diagnosing the underlying cardiac abnormality (mitral regurgitation). Results: Eighty-six students participated in the study. Students trained on mitral regurgitation were more likely to identify and diagnose these findings on a real patient with mitral regurgitation than those who had trained on aortic stenosis or a scenario with no cardiac murmur. The accuracy(SD) of identifying clinical features of mitral regurgitation for these three groups was 74.0 (36.4) vs 56.2 (34.3) vs 36.8 (33.1), respectively (P 5.0005), and for diagnosing mitral regurgitation, the accuracy was 68.0 (45.4) vs 51.6 (50.0) vs 29.9 (40.7), respectively (P 5.01). Conclusions: Simulator training on mitral regurgitation increases the likelihood of diagnosing this abnormality on a real patient. © 2011 American College of Chest Physicians.",,"accuracy; aorta stenosis; article; auscultation; Canada; clinical feature; diagnostic procedure; heart muscle ischemia; human; lung embolism; medical education; medical student; mitral valve regurgitation; outcome assessment; priority journal; simulation; thorax pain",Article,"Final","",Scopus,2-s2.0-79551603995
"Deutsch J.E.","7201985389;","Using virtual reality to improve walking post-stroke: Translation to individuals with diabetes",2011,"Journal of Diabetes Science and Technology","5","2",,"309","314",,11,"10.1177/193229681100500216","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80053193651&doi=10.1177%2f193229681100500216&partnerID=40&md5=3d4cbed9fd801c234bf41c42920ccbfb","Department of Rehabilitation and Movement Sciences, School of Health Related Professions, University of Medicine and Dentistry, New Jersey, Newark, NJ, United States","Deutsch, J.E., Department of Rehabilitation and Movement Sciences, School of Health Related Professions, University of Medicine and Dentistry, New Jersey, Newark, NJ, United States","Use of virtual reality (VR) technology to improve walking for people post-stroke has been studied for its clinical application since 2004. The hardware and software used to create these systems has varied but has predominantly been constituted by projected environments with users walking on treadmills. Transfer of training from the virtual environment to real-world walking has modest but positive research support. Translation of the research findings to clinical practice has been hampered by commercial availability and costs of the VR systems. Suggestions for how the work for individuals post-stroke might be applied and adapted for individuals with diabetes and other impaired ambulatory conditions include involvement of the target user groups (both practitioners and clients) early in the design and integration of activity and education into the systems. © Diabetes Technology Society.","Fitness; Interactive video gaming; Mobility; Motor control; Stroke; Virtual reality","cerebrovascular accident; clinical practice; conference paper; diabetes mellitus; education; financial management; human; lifestyle modification; mobilization; physical activity; treadmill; virtual reality; walking; biomechanics; computer interface; computer simulation; diabetes mellitus; exercise; health promotion; kinesiotherapy; methodology; review; stroke; treatment outcome; walking; Biomechanics; Computer Simulation; Diabetes Mellitus; Exercise; Exercise Therapy; Health Promotion; Humans; Stroke; Treatment Outcome; User-Computer Interface; Walking",Conference Paper,"Final","",Scopus,2-s2.0-80053193651
"Bordnick P.S., Carter B.L., Traylor A.C.","6602137534;7203070626;8914734300;","What virtual reality research in addictions can tell us about the future of obesity assessment and treatment",2011,"Journal of Diabetes Science and Technology","5","2",,"265","271",,37,"10.1177/193229681100500210","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84858704402&doi=10.1177%2f193229681100500210&partnerID=40&md5=0595f5878135caa7a3066d115c855a03","Graduate College of Social Work, University of Houston, Houston, TX, United States; School of Social Work, University of Alabama, Tuscaloosa, AL, United States","Bordnick, P.S., Graduate College of Social Work, University of Houston, Houston, TX, United States; Carter, B.L., Graduate College of Social Work, University of Houston, Houston, TX, United States; Traylor, A.C., School of Social Work, University of Alabama, Tuscaloosa, AL, United States","Virtual reality (VR), a system of human-computer interaction that allows researchers and clinicians to immerse people in virtual worlds, is gaining considerable traction as a research, education, and treatment tool. Virtual reality has been used successfully to treat anxiety disorders such as fear of flying and post-traumatic stress disorder, as an aid in stroke rehabilitation, and as a behavior modification aid in the treatment of attention deficit disorder. Virtual reality has also been employed in research on addictive disorders. Given the strong evidence that drug-dependent people are highly prone to use and relapse in the presence of environmental stimuli associated with drug use, VR is an ideal platform from which to study this relationship. Research using VR has shown that drug-dependent people react with strong craving to specific cues (e.g., cigarette packs, liquor bottles) as well as environments or settings (e.g., bar, party) associated with drug use. Virtual reality has also been used to enhance learning and generalization of relapse prevention skills in smokers by reinforcing these skills in lifelike environments. Obesity researchers and treatment professionals, building on the lessons learned from VR research in substance abuse, have the opportunity to adapt these methods for investigating their own research and treatment questions. Virtual reality is ideally suited to investigate the link between food cues and environmental settings with eating behaviors and self-report of hunger. In addition, VR can be used as a treatment tool for enhancing behavior modification goals to support healthy eating habits by reinforcing these goals in life-like situations. © Diabetes Technology Society.","Addictions; Food cues; Obesity; Technology; Virtual reality","addiction; anxiety disorder; association; attention deficit disorder; behavior modification; behavior therapy; cerebrovascular accident; clinical assessment; conference paper; drug use; eating habit; fear; feeding behavior; human computer interaction; learning; liquid; medical research; obesity; patient education; posttraumatic stress disorder; rehabilitation care; reinforcement; scientist; self report; smoking; substance abuse; virtual reality; addiction; cognitive therapy; computer interface; computer simulation; equipment design; health behavior; human; methodology; obesity; recreation; review; stroke; Behavior Therapy; Cognitive Therapy; Computer Simulation; Equipment Design; Health Behavior; Humans; Obesity; Stroke; Substance-Related Disorders; User-Computer Interface; Video Games",Conference Paper,"Final","",Scopus,2-s2.0-84858704402
"Wang X., Dunston P.S., Proctor R., Hou L., So J.C.Y.","8945580300;6602079727;7101687932;55729885900;55311366400;","Reflections on using a game engine to develop a virtual training system for construction excavator operators",2011,"Proceedings of the 28th International Symposium on Automation and Robotics in Construction, ISARC 2011",,,,"631","636",,12,"10.22260/isarc2011/0118","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863748258&doi=10.22260%2fisarc2011%2f0118&partnerID=40&md5=8ea09f468b1561a3984210e7f3e78704","Faculty of the Built Environment, University of New South Wales, Australia; Purdue University, United States","Wang, X., Faculty of the Built Environment, University of New South Wales, Australia; Dunston, P.S., Purdue University, United States; Proctor, R., Purdue University, United States; Hou, L., Faculty of the Built Environment, University of New South Wales, Australia; So, J.C.Y., Purdue University, United States","Virtual Reality (VR) technology can facilitate training in construction equipment operations, as the cost for virtual training is lower and the practical hazard is eliminated. This paper presents a virtual training system (VTS) for construction excavator operators based on a game engine tool. The focus of this paper is not to present a simulator that replaces those existing tools on the market, but to describe the development of a prototype for testing skill acquisition and transfer. The study reflects the experience of using a game engine to develop a VTS for an earthmoving excavator in a construction site. The development was initiated after exploring critical aspects of training. This paper also elaborates the principles of constructing a virtual excavator simulator based on the Unity3D game development engine.","Simulator; Skill acquisition and transfer; Virtual training system","Construction equipment; Excavation; Excavators; Personnel training; Robotics; Simulators; Software design; Virtual reality; Construction equipment operations; Construction sites; Earthmoving; Game development; Game Engine; Skill acquisition and transfers; Virtual training; Virtual training systems; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-84863748258
"Moyano-Cuevas J.L., Sánchez-Margallo F.M., Sánchez-Peralta L.F., Pagador J.B., Enciso S., Sánchez-González P., Gómez-Aguilera E.J., Usón-Gargallo J.","35811111400;6507750669;35811197200;7801485529;37101357400;24512442400;7201729604;6603379138;","Validation of SINERGIA as training tool: A randomized study to test the transfer of acquired basic psychomotor skills to LapMentor",2011,"International Journal of Computer Assisted Radiology and Surgery","6","6",,"839","846",,5,"10.1007/s11548-011-0561-9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027954549&doi=10.1007%2fs11548-011-0561-9&partnerID=40&md5=ec0184e7bf9f76df97e55ce29b496299","Bioengineering and Health Technology Unit, Jesús Usón Minimally Invasive Surgery Centre, Cáceres, Spain; Laparoscopy Unit, Jesús Usón Minimally Invasive Surgery Centre, Cáceres, Spain; Bioengineering and Telemedicine Centre, Univesidad Politécnica de Madrid, Madrid, Spain","Moyano-Cuevas, J.L., Bioengineering and Health Technology Unit, Jesús Usón Minimally Invasive Surgery Centre, Cáceres, Spain; Sánchez-Margallo, F.M., Laparoscopy Unit, Jesús Usón Minimally Invasive Surgery Centre, Cáceres, Spain; Sánchez-Peralta, L.F., Bioengineering and Health Technology Unit, Jesús Usón Minimally Invasive Surgery Centre, Cáceres, Spain; Pagador, J.B., Bioengineering and Health Technology Unit, Jesús Usón Minimally Invasive Surgery Centre, Cáceres, Spain; Enciso, S., Laparoscopy Unit, Jesús Usón Minimally Invasive Surgery Centre, Cáceres, Spain; Sánchez-González, P., Bioengineering and Telemedicine Centre, Univesidad Politécnica de Madrid, Madrid, Spain; Gómez-Aguilera, E.J., Bioengineering and Telemedicine Centre, Univesidad Politécnica de Madrid, Madrid, Spain; Usón-Gargallo, J., Laparoscopy Unit, Jesús Usón Minimally Invasive Surgery Centre, Cáceres, Spain","Purpose: Laparoscopic surgery is commonly used in many surgical procedures but requires a learning process to develop the necessary skills. Virtual reality simulators play an essential role within the training curricula. This paper aims to determine whether training in SINERGIA VR simulator allows novice surgeons to improve their basic psychomotor laparoscopic skills. Methods: Forty-two people participated in this study, including 28 unexperience medical students and 14 expert surgeons who developed previously more than 100 laparoscopic procedures. Medical students made a pre-training test in LapMentor II; then, they trained in SINERGIA and they finally accomplished a post-training test in LapMentor II. Experts just made one trial in LapMentor II. A statistical analysis was carried out and results of pre- and post-training tests of novices were compared with Wilcoxon signed-rank test. Pre- and post-training tests of novices were also compared with results of experts with Mann-Whitney U test. Results: Most metrics provided by LapMentor II and included in this study show significant differences when comparing pre- and post-training tests of novices. Analysis of pre-training test of novices and experts results show significant differences in all analyzed metrics for all studied tasks. On the other hand, LapMentor was not able to distinguish between experts and novices after training in SINERGIA for any metric in the camera manipulation task and for some metrics of the other tasks. Conclusions: Training in SINERGIA VR simulator allows improvement of basic psychomotor laparoscpic skills and transferring them to another virtual simulator. Therefore, it could be used in laparoscopic surgery training programs. © 2011 CARS.","Laparoscopy; Simulator; Training; Validation; Virtual reality","adult; article; camera; controlled study; female; human; laparoscopic surgery; male; medical student; priority journal; psychomotor performance; simulator; surgeon; surgical training; validation study; virtual reality",Article,"Final","",Scopus,2-s2.0-85027954549
"Hall V., Conboy-Hill S., Taylor D.","7007164275;6507306360;55851945195;","Using virtual reality to provide health care information to people with intellectual disabilities: Acceptability, usability, and potential utility",2011,"Journal of Medical Internet Research","13","4", e91,"","",,34,"10.2196/jmir.1917","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81855173629&doi=10.2196%2fjmir.1917&partnerID=40&md5=8dd3d695f6429265d3b2e36017a61a81","Centre for Health Research, University of Brighton, 265 Mayfield House, Falmer Brighton, BN1 9PH, United Kingdom; Research and Development, Sussex Partnership NHS Foundation Trust, Hove, United Kingdom; Division of Surgery, Imperial College, London, United Kingdom","Hall, V., Centre for Health Research, University of Brighton, 265 Mayfield House, Falmer Brighton, BN1 9PH, United Kingdom; Conboy-Hill, S., Research and Development, Sussex Partnership NHS Foundation Trust, Hove, United Kingdom; Taylor, D., Division of Surgery, Imperial College, London, United Kingdom","Background: People with intellectual disabilities have poor access to health care, which may be further compromised by a lack of accessible health information. To be effective, health information must be easily understood and remembered. People with intellectual disabilities learn better from multimodal information sources, and virtual reality offers a 3-dimensional (3D) computer-generated environment that can be used for providing information and learning. To date, research into virtual reality experiences for people with intellectual disabilities has been limited to skill-based training and leisure opportunities within the young to mid age ranges. Objective: This study assessed the acceptability, usability, and potential utility of a virtual reality experience as a means of providing health care-related information to people with intellectual disabilities. We designed a prototype multimodal experience based on a hospital scenario and situated on an island in the Second Life 3D virtual world. We wanted to know how people of different ages and with varying levels of cognitive function would participate in the customized virtual environment, what they understood from being there, and what they remembered a week later. Methods: The study drew on qualitative data. We used a participatory research approach that involved working alongside people with intellectual disabilities and their supporters in a community setting. Cognitive function was assessed, using the Matrix Analogies Test and the British Picture Vocabulary Scale, to describe the sample. Participants, supported by facilitators, were video recorded accessing and engaging with the virtual environment. We assessed recall 1 week later, using a specialized interview technique. Data were downloaded into NVivo 8 and analyzed using the framework analysis technique. Results: Study participants were 20 people aged between 20 and 80 years with mild to severe intellectual disabilities. All participants were able to access the environment and voluntarily stayed there for between 23 and 57 minutes. With facilitator support, all participants moved the avatar themselves. Participants engaged with the scenario as if they were actually there, indicating cognitive presence. Some referred back to previous medical experiences, indicating the potential for experiential knowledge to become the foundation of new learning and retention of knowledge. When interviewed, all participants remembered some aspects of the environment. Conclusions: A sample of adults with intellectual disabilities of all ages, and with varying levels of cognitive function, accessed and enjoyed a virtual-world environment that drew on a health care-related scenario, and remembered aspects of it a week later. The small sample size limits generalizability of findings, but the potential shown for experiential learning to aid retention of knowledge on which consent is based appears promising. Successfully delivering health care-related information in a non-National Health Service setting indicates potential for delivery in institutional, community, or home settings, thereby widening access to the information. © Valerie Hall, Suzanne Conboy-Hill, Dave Taylor.","Capacity to consent; Health information; Intellectual disabilities; Learning disabilities; Participatory research; Presence; Virtual reality","achievement; adult; aged; article; computer interface; computer simulation; female; health care delivery; human; intellectual impairment; Internet; knowledge; learning; male; middle aged; patient attitude; psychological aspect; United Kingdom; validation study; Achievement; Adult; Aged; Aged, 80 and over; Computer Simulation; Delivery of Health Care; Female; Great Britain; Humans; Intellectual Disability; Internet; Knowledge; Learning; Male; Middle Aged; Patient Acceptance of Health Care; User-Computer Interface; Young Adult",Article,"Final","",Scopus,2-s2.0-81855173629
"Zheng B., Tien G., Atkins S.M., Swindells C., Tanin H., Meneghetti A., Qayumi K.A., Neely O., Panton M.","35294347300;35772913000;7102310616;57203349817;37119599100;6701853632;6602302777;46062316500;46062521800;","Surgeon's vigilance in the operating room",2011,"American Journal of Surgery","201","5",,"673","677",,45,"10.1016/j.amjsurg.2011.01.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955698114&doi=10.1016%2fj.amjsurg.2011.01.016&partnerID=40&md5=bfeba409047cee5edb45898d2478dc48","Department of Surgery, University of British Columbia, 3602-910 W 10th Avenue, Vancouver, BC V5Z 4E3, Canada; Computing Science, Simon Fraser University, Burnaby, BC, Canada; University of Victoria, Locarna Systems, Inc., Victoria, BC, Canada","Zheng, B., Department of Surgery, University of British Columbia, 3602-910 W 10th Avenue, Vancouver, BC V5Z 4E3, Canada; Tien, G., Computing Science, Simon Fraser University, Burnaby, BC, Canada; Atkins, S.M., Computing Science, Simon Fraser University, Burnaby, BC, Canada; Swindells, C., University of Victoria, Locarna Systems, Inc., Victoria, BC, Canada; Tanin, H., Department of Surgery, University of British Columbia, 3602-910 W 10th Avenue, Vancouver, BC V5Z 4E3, Canada; Meneghetti, A., Department of Surgery, University of British Columbia, 3602-910 W 10th Avenue, Vancouver, BC V5Z 4E3, Canada; Qayumi, K.A., Department of Surgery, University of British Columbia, 3602-910 W 10th Avenue, Vancouver, BC V5Z 4E3, Canada; Neely, O., Department of Surgery, University of British Columbia, 3602-910 W 10th Avenue, Vancouver, BC V5Z 4E3, Canada; Panton, M., Department of Surgery, University of British Columbia, 3602-910 W 10th Avenue, Vancouver, BC V5Z 4E3, Canada","Objective: Surgeons' vigilance regarding patient condition was assessed using eye-tracking techniques during a simulated laparoscopic procedure. Methods: Surgeons were required to perform a partial cholecystectomy in a virtual reality trainer (SurgicalSim; METI Inc, Sarasota, FL) while wearing a lightweight head-mounted eye-tracker (Locarna systems Inc, Victoria, British Columbia, Canada). Half of the patients were preprogrammed to present a mildly unstable cardiac condition during the procedure. Surgical performance (evaluated by task time, instrument trajectory, and errors), mental workload (by the National Aeronautics and Space Administration Task Load Index), and eye movement were recorded and compared between 13 experienced and 10 novice surgeons. Results: Experienced surgeons took longer to complete the task and also made more errors. The overall workload reported by surgeons was similar, but expert surgeons reported a higher level of frustration and a lower level of physical demands. Surgeon workload was greater when operating on the unstable patient than on the stable patient. Novices performed faster but focused more of their attention on the surgical task. In contrast, experts glanced more frequently at the anesthetic monitor. Conclusions: This study shows the usefulness of using eye-tracking technology to measure a surgeon's vigilance during an operation. Eye-tracking observations can lead to inferences about a surgeon's behavior for patient safety. The unsatisfactory performance of expert surgeons on the VR simulator suggests that the fidelity of the virtual simulator needs to improve to enable surgeons to transfer their clinical skills. This, in turn, suggests using caution when having clinical experts as instructors to teach skills with virtual simulators. © 2011 Elsevier Inc. All rights reserved.","Eye-tracking; Intraoperating room performance; Patient safety; Simulation; Vigilance","adult; alertness; article; cholecystectomy; controlled study; eye tracking; frustration; heart disease; human; laparoscopy; medical expert; operating room; priority journal; simulation; surgeon; surgical error; workload",Article,"Final","",Scopus,2-s2.0-79955698114
"Scott D.J., Pugh C.M., Ritter E.M., Jacobs L.M., Pellegrini C.A., Sachdeva A.K.","35550052600;8833944500;35518395300;7202388309;7101984946;7003532148;","New directions in simulation-based surgical education and training: Validation and transfer of surgical skills, use of nonsurgeons as faculty, use of simulation to screen and select surgery residents, and long-term follow-up of learners",2011,"Surgery","149","6",,"735","744",,35,"10.1016/j.surg.2010.11.010","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957677550&doi=10.1016%2fj.surg.2010.11.010&partnerID=40&md5=466308577c87a57ef05ff1882d822926","University of Texas Southwestern Medical Center, Dallas, TX, United States; Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Uniformed Services University, Bethesda, MD, United States; University of Connecticut School of Medicine, Hartford, CT, United States; University of Washington, Seattle, WA, United States; American College of Surgeons, 633 N. Saint Clair Street, Chicago, IL 60611, United States","Scott, D.J., University of Texas Southwestern Medical Center, Dallas, TX, United States; Pugh, C.M., Northwestern University Feinberg School of Medicine, Chicago, IL, United States; Ritter, E.M., Uniformed Services University, Bethesda, MD, United States; Jacobs, L.M., University of Connecticut School of Medicine, Hartford, CT, United States; Pellegrini, C.A., University of Washington, Seattle, WA, United States; Sachdeva, A.K., American College of Surgeons, 633 N. Saint Clair Street, Chicago, IL 60611, United States","The Consortium of American College of Surgeons-Accredited Education Institutes was created to explore new opportunities in simulation-based surgical education and training beyond the scope of individual accredited institutes. During the Third Annual Meeting of the Consortium of American College of Surgeons-Accredited Education Institutes Consortium, 4 work groups addressed the validation and transfer of surgical skills, the use of nonsurgeons as faculty, the use of simulation to screen and select surgery residents, and long-term follow-up of learners. The key elements from the deliberations and conclusions are summarized in this manuscript. © 2011 Mosby, Inc. All rights reserved.",,"breast cancer; breast examination; cancer screening; catheter; cholecystectomy; clinical competence; clinical practice; curriculum; digestive tract endoscopy; drain; faculty practice; follow up; geriatrics; health care personnel; health care quality; hemodialysis; high risk pregnancy; human; long term care; medical student; nurse; operating room personnel; outcome assessment; paramedical student; patient care; patient education; patient safety; physician; priority journal; psychologist; puerperium; residency education; respiration control; respiratory therapist; review; simulation; skill; surgical training; suturing method; task performance; treatment outcome; validation study",Article,"Final","",Scopus,2-s2.0-79957677550
"Wilson M.R., Vine S.J., Bright E., Masters R.S.W., Defriend D., McGrath J.S.","55574207642;36811509000;15069550000;7102880488;6603918469;12774961300;","Gaze training enhances laparoscopic technical skill acquisition and multi-tasking performance: A randomized, controlled study",2011,"Surgical Endoscopy","25","12",,"3731","3739",,89,"10.1007/s00464-011-1802-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81955163031&doi=10.1007%2fs00464-011-1802-2&partnerID=40&md5=e5d013154c32dc95c7c346de966aea97","College of Life and Environmental Sciences, University of Exeter, St Luke's Campus, Exeter EX1 2LU, United Kingdom; Exeter Surgical Health Services Research Unit, Royal Devon and Exeter NHS Foundation Trust, Exeter, United Kingdom; Institute of Human Performance, University of Hong Kong, Hong Kong, Hong Kong; Centre for Innovation and Training in Elective Care, Torbay Hospital, Devon, United Kingdom","Wilson, M.R., College of Life and Environmental Sciences, University of Exeter, St Luke's Campus, Exeter EX1 2LU, United Kingdom; Vine, S.J., College of Life and Environmental Sciences, University of Exeter, St Luke's Campus, Exeter EX1 2LU, United Kingdom; Bright, E., Exeter Surgical Health Services Research Unit, Royal Devon and Exeter NHS Foundation Trust, Exeter, United Kingdom; Masters, R.S.W., Institute of Human Performance, University of Hong Kong, Hong Kong, Hong Kong; Defriend, D., Centre for Innovation and Training in Elective Care, Torbay Hospital, Devon, United Kingdom; McGrath, J.S., Exeter Surgical Health Services Research Unit, Royal Devon and Exeter NHS Foundation Trust, Exeter, United Kingdom","Background: The operating room environment is replete with stressors and distractions that increase the attention demands of what are already complex psychomotor procedures. Contemporary research in other fields (e.g., sport) has revealed that gaze training interventions may support the development of robust movement skills. This current study was designed to examine the utility of gaze training for technical laparoscopic skills and to test performance under multitasking conditions. Methods: Thirty medical trainees with no laparoscopic experience were divided randomly into one of three treatment groups: gaze trained (GAZE), movement trained (MOVE), and discovery learning/control (DISCOVERY). Participants were fitted with a Mobile Eye gaze registration system, which measures eye-line of gaze at 25 Hz. Training consisted of ten repetitions of the ""eye-hand coordination"" task from the LAP Mentor VR laparoscopic surgical simulator while receiving instruction and video feedback (specific to each treatment condition). After training, all participants completed a control test (designed to assess learning) and a multitasking transfer test, in which they completed the procedure while performing a concurrent tone counting task. Results: Not only did the GAZE group learn more quickly than the MOVE and DISCOVERY groups (faster completion times in the control test), but the performance difference was even more pronounced when multitasking. Differences in gaze control (target locking fixations), rather than tool movement measures (tool path length), underpinned this performance advantage for GAZE training. Conclusions: These results suggest that although the GAZE intervention focused on training gaze behavior only, there were indirect benefits for movement behaviors and performance efficiency. Additionally, focusing on a single external target when learning, rather than on complex movement patterns, may have freed-up attentional resources that could be applied to concurrent cognitive tasks. © 2011 The Author(s).","Distractions; Eye-hand coordination; Gaze strategy; Implicit motor learning; Psychomotor control; Stress","adult; article; clinical effectiveness; controlled study; eye fixation; eye hand coordination; eye tracking; female; gaze; human; intermethod comparison; laparoscopic surgery; learning style; male; physical mobility; priority journal; professional competence; professional development; simulator; skill retention; surgical training; task performance",Article,"Final","",Scopus,2-s2.0-81955163031
"Gutiérrez T., Rodríguez J., Vélaz Y., Casado S., Suescun A., Sánchez. E.J.","18036923100;57194191682;36662969400;7005494293;24282105300;57196876065;","IMA-VR: A multimodal virtual training system for skills transfer in Industrial Maintenance and Assembly tasks",2010,"Proceedings - IEEE International Workshop on Robot and Human Interactive Communication",,, 5598643,"428","433",,30,"10.1109/ROMAN.2010.5598643","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649887580&doi=10.1109%2fROMAN.2010.5598643&partnerID=40&md5=e056988459082e88e90c396a90a89540","Department of Applied Mechanics, CEIT, TECNUN, Spain; LABEIN-TECNALIA, Spain","Gutiérrez, T., LABEIN-TECNALIA, Spain; Rodríguez, J., Department of Applied Mechanics, CEIT, TECNUN, Spain; Vélaz, Y., Department of Applied Mechanics, CEIT, TECNUN, Spain; Casado, S., LABEIN-TECNALIA, Spain; Suescun, A., Department of Applied Mechanics, CEIT, TECNUN, Spain; Sánchez., E.J., Department of Applied Mechanics, CEIT, TECNUN, Spain","Industrial Maintenance and Assembly is a very complex task involving both cognitive skills (procedural skills) and motor skills (fine motor control and bi-manual coordination skills). This paper presents a controlled multimodal training system, for transferring the motor and cognitive skills involved in these tasks. The new platform provides different multimodal aids and learning strategies that help and guide the users during their training process. One of the main features of this system is its flexibility to adapt itself to the task demands and to the users' preferences and needs supporting different configurations. To address bi-manual operations the platform offers different alternatives, one of them is a set-up composed of a haptic device to track the motion of the operator's dominant hand and simulate the physical interaction within the virtual environment, together with a marker-less motion capture system to track the motion of the other hand in real time. © 2010 IEEE.",,"Assembly tasks; Bi manuals; Co-ordination skills; Cognitive skill; Complex task; Fine motor control; Haptic devices; Industrial maintenance; Learning strategy; Motion capture system; Motor skills; Multi-modal; Physical interactions; Real time; Task demand; Training process; Training Systems; Virtual environments; Virtual training; Maintenance; Virtual reality; Coordination reactions",Conference Paper,"Final","",Scopus,2-s2.0-78649887580
"Hulin T., Schmirgel V., Yechiam E., Zimmermann U.E., Preusche C., Pöhler G.","23008567500;57199627082;55892873800;7201909731;6602947104;57220760440;","Evaluating exemplary training accelerators for programming-by-demonstration",2010,"Proceedings - IEEE International Workshop on Robot and Human Interactive Communication",,, 5598611,"440","445",,8,"10.1109/ROMAN.2010.5598611","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649872096&doi=10.1109%2fROMAN.2010.5598611&partnerID=40&md5=855a0146c91be5af1131171d337aab81","KUKA Roboter GmbH, Germany; Faculty of Industrial Engineering and Management, Technion, Israel; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Otto-von-Guericke University, Magdeburg, Germany","Hulin, T., Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Schmirgel, V., KUKA Roboter GmbH, Germany; Yechiam, E., Faculty of Industrial Engineering and Management, Technion, Israel; Zimmermann, U.E., KUKA Roboter GmbH, Germany; Preusche, C., Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Pöhler, G., Otto-von-Guericke University, Magdeburg, Germany","Robot Programming by Demonstration requires comprehending the usage of a robotic system. This article is about accelerating the training of these skills, using the example of a DLR/KUKA light-weight robot. An augmented reality and a virtual reality setup are presented that aim to demonstrate and evaluate skills transfer of two different sub-tasks of this system: Avoiding robot singularities and setting correct compliance parameters. For this purpose training accelerators are introduced for visualising robot singularities, exploring robot singularities and feeling compliance parameters. An evaluation procedure for all three accelerators is suggested and has been performed on the first two. As interesting evaluation result a contrast to the Cognitive Theory of Multimedia Learning hypothesis could be observed: Additional visual information on the robot singularities impairs the participants' performance. © 2010 IEEE.",,"Cognitive theory of multimedia learning; Evaluation results; Light weight; Robot programming by demonstration; Robotic systems; Subtasks; Visual information; Augmented reality; Human computer interaction; Programmable robots; Virtual reality; Visual communication; Robot programming",Conference Paper,"Final","",Scopus,2-s2.0-78649872096
"Luber B., Haigermoser A., Grabner G.","28267974000;6506268515;9741585000;","Track geometry evaluation method based on vehicle response prediction",2010,"Vehicle System Dynamics","48","SUPPL. 1",,"157","173",,19,"10.1080/00423111003692914","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649724231&doi=10.1080%2f00423111003692914&partnerID=40&md5=cdada07f66ceb3f2ae03f7fcb1a35292","Kompetenzzentrum - das Virtuelle Fahrzeug Forschungsgesellschaft MbH (ViF), A-8010 Graz, Austria; Siemens AG Österreich, A-8020 Graz, Austria","Luber, B., Kompetenzzentrum - das Virtuelle Fahrzeug Forschungsgesellschaft MbH (ViF), A-8010 Graz, Austria; Haigermoser, A., Siemens AG Österreich, A-8020 Graz, Austria; Grabner, G., Siemens AG Österreich, A-8020 Graz, Austria","Testing of the running characteristics of railway vehicles requires well-defined boundary conditions like track geometry quality. Test sections with the same track geometry quality must lead to the same dynamic vehicle response (VR) forces. The state-of-the-art methods do not fulfil this important requirement for a track quality definition. Our proposed method for track geometry assessment considers the vehicle/track interaction. 'Representative' transfer functions are used for the prediction of the vehicle reaction. Therefore, the results show a significant enhancement of the correlation between the track assessment quantities and the VR forces. © 2010 Taylor & Francis.","dynamic simulation; track geometry assessment; vehicle response analysis; vehicle/track interaction","Dynamic simulation; Railway vehicles; Running characteristic; State-of-the-art methods; Test sections; Track geometry; Track geometry quality; Track quality; Vehicle response; vehicle response analysis; vehicle/track interaction; Computer simulation; Railroad tracks; Vehicles; Computational geometry",Conference Paper,"Final","",Scopus,2-s2.0-78649724231
"Nathanael D., Vosniakos G.-C., Mosialos S.","6506068895;6701789136;14058702100;","Cognitive task analysis for virtual reality training: The case of CNC tool offsetting",2010,"ECCE 2010 - European Conference on Cognitive Ergonomics 2010: The 28th Annual Conference of the European Association of Cognitive Ergonomics",,,,"241","244",,4,"10.1145/1962300.1962350","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955139098&doi=10.1145%2f1962300.1962350&partnerID=40&md5=698ba6798f79f45070616892c42a1b9f","National Technical University of Athens, School of Mechanical Engineering, GR- 15780, Zografou, Greece","Nathanael, D., National Technical University of Athens, School of Mechanical Engineering, GR- 15780, Zografou, Greece; Vosniakos, G.-C., National Technical University of Athens, School of Mechanical Engineering, GR- 15780, Zografou, Greece; Mosialos, S., National Technical University of Athens, School of Mechanical Engineering, GR- 15780, Zografou, Greece","Motivation - To examine if cognitive task analysis of expert machinists can be effective in developing a virtual reality based training system for CNC tool offsetting. Research approach - A cognitive task analysis of expert machinists was conducted which informed the development of a VR training system for CNC tool offsetting. Subsequently the effectiveness of the analysis was evaluated by conducting an experiment with 31 mechanical engineering students. Findings/Design - The virtual reality system demonstrated positive training transfer for the task of tool offsetting. The above indicates that the cognitive task analysis performed was effective in identifying a number of key skills of the tool offsetting task. Research limitations/Implications - The study does not prove the superiority of cognitive task analysis over other approaches for specifying virtual reality training systems, since it does not compare the cognitively tuned system with another one. Originality/Value - The present work provides evidence that skill transfer can be achieved even with low physical fidelity provided that the cognitive organization of a task is adequately mapped in the virtual reality system. Take away message - Further and beyond fidelity issues, cognitive task analysis can provide important input in specifying effective VR training systems.","CNC machining; Sensory - Motor skills; Simulation; Training; Virtual reality","Cnc machining; Cognitive organization; Cognitive task analysis; Mechanical engineering students; Research approach; Sensory - Motor skills; Simulation; Skill transfer; Training; Training Systems; Virtual reality system; Virtual reality training; Cognitive systems; Ergonomics; Job analysis; Machining; Virtual reality; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-79955139098
"Scerbo M.W., Turner T.R., Newlin-Canzone E., Meglan D., Waddington R., King D., Champion H.","7004570474;57196941049;37056115100;6602725067;36026141900;37085357100;7102210750;","A preliminary evaluation of a burr hole drilling simulator for craniotomy",2010,"Proceedings of the Human Factors and Ergonomics Society","3",,,"2361","2365",,2,"10.1518/107118110X12829370266969","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953075136&doi=10.1518%2f107118110X12829370266969&partnerID=40&md5=6748b3bddce5f143ebb0aba2e92ad506","Department of Psychology, Old Dominion University, United States; SimQuest, LLC, United States","Scerbo, M.W., Department of Psychology, Old Dominion University, United States; Turner, T.R., Department of Psychology, Old Dominion University, United States; Newlin-Canzone, E., Department of Psychology, Old Dominion University, United States; Meglan, D., SimQuest, LLC, United States; Waddington, R., SimQuest, LLC, United States; King, D., SimQuest, LLC, United States; Champion, H., SimQuest, LLC, United States","A training transfer paradigm was used to evaluate a virtual reality (VR) simulator for performing the burr hole drilling portion of a craniotomy procedure. Participants used a VR simulator that had a physical drill handle interfaced with a haptic force/torque feedback system. They practiced until they met a priori performance criteria and then repeated the procedure with a genuine drill and foam model of a skull. The results showed some positive transfer related to hand steadiness, but not for drilling time. The drilling model incorporated in the simulator may require more effort to maintain the drill position and more revolutions of the drill bit to penetrate the model skull. Thus, practice on the VR simulator enabled the participants to maintain better drill position on the physical model. From a clinical perspective, the findings underscore the advantages of practicing a critical surgical procedure on a simulator prior to performing on a genuine patient. Copyright 2010 by Human Factors and Ergonomics Society, Inc. All rights reserved.",,"Drilling time; Feedback systems; Hole drilling; Performance criterion; Physical model; Surgical procedures; Drills; Simulators; Virtual reality; Ergonomics",Conference Paper,"Final","",Scopus,2-s2.0-79953075136
"Cha M., Choi B.","56224749400;8154681000;","Visualizing and experiencing harmful gases in the VR environment",2010,"ACM SIGGRAPH ASIA 2010 Posters, SA'10",,, 57,"","",,,"10.1145/1900354.1900418","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951900079&doi=10.1145%2f1900354.1900418&partnerID=40&md5=2308ea43d96251f205b7b7589c339cb3","Korea Institute of Machinery and Materials (KIMM), South Korea","Cha, M., Korea Institute of Machinery and Materials (KIMM), South Korea; Choi, B., Korea Institute of Machinery and Materials (KIMM), South Korea","We present an approach to visualizing and experiencing the harmful gases caused by fire in the virtual reality environment. It is known that a large portion of the casualties that result from fires in an enclosed space are due to poisoning by noxious gases rather than serious burns. The virtual-reality based visualization of those harmful gases will help people to enhance first emergency response and increase human safety. Because it is not currently possible to simulate the propagation of harmful gases in real time, we numerically simulate the behavior of fire-driven gases using an appropriate CFD solver off-line, then visualize the resulting voxel data through direct volume rendering, enabling an intuitive experience of gases in a virtual 3D space. Also, to visualize this type of naturally invisible gas data, we designed a transfer function based on the safety or danger range of gases, which can be customized by fire engineers or training supervisors.",,"3-D space; CFD solver; Direct volume rendering; Emergency response; Enclosed spaces; Fire engineers; Harmful gas; Human safety; Noxious gas; Real time; Virtual-reality environment; Voxel data; Fires; Interactive computer graphics; Personnel training; Virtual reality; Visualization; Volume rendering; Gases",Conference Paper,"Final","",Scopus,2-s2.0-79951900079
"Anderson E.F., McLoughlin L., Liarokapis F., Peters C., Petridis P., de Freitas S.","34976300400;26656832500;7801416785;26425154400;36128917500;57203045925;","Developing serious games for cultural heritage: A state-of-the-art Review",2010,"Virtual Reality","14","4",,"255","275",,173,"10.1007/s10055-010-0177-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649514858&doi=10.1007%2fs10055-010-0177-3&partnerID=40&md5=74e34a16c358fff2a58b9ec302a3ab56","Interactive Worlds Applied Research Group (iWARG), Coventry University, Coventry, United Kingdom; The National Centre for Computer Animation (NCCA), Bournemouth University, Bournemouth, United Kingdom; Serious Games Institute (SGI), Coventry University, Coventry, United Kingdom","Anderson, E.F., Interactive Worlds Applied Research Group (iWARG), Coventry University, Coventry, United Kingdom; McLoughlin, L., The National Centre for Computer Animation (NCCA), Bournemouth University, Bournemouth, United Kingdom; Liarokapis, F., Interactive Worlds Applied Research Group (iWARG), Coventry University, Coventry, United Kingdom; Peters, C., Interactive Worlds Applied Research Group (iWARG), Coventry University, Coventry, United Kingdom; Petridis, P., Serious Games Institute (SGI), Coventry University, Coventry, United Kingdom; de Freitas, S., Serious Games Institute (SGI), Coventry University, Coventry, United Kingdom","Although the widespread use of gaming for leisure purposes has been well documented, the use of games to support cultural heritage purposes, such as historical teaching and learning, or for enhancing museum visits, has been less well considered. The state-of-the-art in serious game technology is identical to that of the state-of-the-art in entertainment games technology. As a result, the field of serious heritage games concerns itself with recent advances in computer games, real-time computer graphics, virtual and augmented reality and artificial intelligence. On the other hand, the main strengths of serious gaming applications may be generalised as being in the areas of communication, visual expression of information, collaboration mechanisms, interactivity and entertainment. In this report, we will focus on the state-of-the-art with respect to the theories, methods and technologies used in serious heritage games. We provide an overview of existing literature of relevance to the domain, discuss the strengths and weaknesses of the described methods and point out unsolved problems and challenges. In addition, several case studies illustrating the application of methods and technologies used in cultural heritage are presented. © 2010 Springer-Verlag London Limited.","Computer games technology; Cultural heritage; Serious games","Collaboration mechanisms; Computer game; Computer games technology; Cultural heritage; Cultural heritages; Interactivity; Real time computer graphics; Serious games; Serious gaming; State-of-the-art reviews; Teaching and learning; Unsolved problems; Virtual and augmented reality; Artificial intelligence; Augmented reality; Computer software; Human computer interaction; Virtual reality; Technology",Article,"Final","",Scopus,2-s2.0-78649514858
"Haase T., Winter M., Fredrich H., Hednen A.","35955982300;57197032208;26325224200;55504101500;","Interactive training application for working under electrical voltage",2010,"WMSCI 2010 - The 14th World Multi-Conference on Systemics, Cybernetics and Informatics, Proceedings","1",,,"227","229",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870229032&partnerID=40&md5=a529fc2e3ee2af533660e256c7985a83","Fraunhofer Institute for Factory and Automation, Sandtorstrasse 22, 39106 Magdeburg, Germany; RWE Rheinland Westfalen Netz AG, Rauschermühlenstr., 56637 Plaidt, Germany","Haase, T., Fraunhofer Institute for Factory and Automation, Sandtorstrasse 22, 39106 Magdeburg, Germany; Winter, M., Fraunhofer Institute for Factory and Automation, Sandtorstrasse 22, 39106 Magdeburg, Germany; Fredrich, H., Fraunhofer Institute for Factory and Automation, Sandtorstrasse 22, 39106 Magdeburg, Germany; Hednen, A., RWE Rheinland Westfalen Netz AG, Rauschermühlenstr., 56637 Plaidt, Germany","The paper presents an interactive training application for qualifying technicians for working under electrical voltage. Due to some restrictions of the on-site training the presented application shows possibilities of knowledge transfer in a descriptive and motivating manner by using 2-D as well as 3-D visualization techniques. An overview of deployed hardware settings and use cases is given. For application development the ADDIE Instruction Design Model is applied. Its implementation in the phases analysis, design, development and evaluation is presented.","3-D; ADDIE; Instructional design; Training; Virtual reality","3-D; 3D Visualization; ADDIE; Application development; Hardware settings; Instruction design; Instructional designs; Interactive training; Knowledge transfer; On-site training; Cybernetics; Information science; Knowledge management; Personnel training; Virtual reality; Three dimensional computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-84870229032
"Chuang C.-H., Lai P.-C., Ko L.-W., Kuo B.-C., Lin C.-T.","26653452200;42661704900;8308152000;7102294126;8942403600;","Driver's cognitive state classification toward brain computer interface via using a generalized and supervised technology",2010,"Proceedings of the International Joint Conference on Neural Networks",,, 5596835,"","",,15,"10.1109/IJCNN.2010.5596835","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959391520&doi=10.1109%2fIJCNN.2010.5596835&partnerID=40&md5=3497027439290f5b0868c44ee1df9235","Institute of Electrical Control Engineering, Brain Research Center, National Chiao-Tung University, 1001 Ta Hsueh Rd., Hsinchu 300, Taiwan; Department of Biological Science and Technology, Brain Research Center, National Chiao Tung University, 1001 Ta Hsueh Rd., Hsinchu 300, Taiwan; Graduate Institute of Educational Measurement and Statistics, National Taichung University, 140 MinShen Rd., Taichung 403, Taiwan","Chuang, C.-H., Institute of Electrical Control Engineering, Brain Research Center, National Chiao-Tung University, 1001 Ta Hsueh Rd., Hsinchu 300, Taiwan; Lai, P.-C., Graduate Institute of Educational Measurement and Statistics, National Taichung University, 140 MinShen Rd., Taichung 403, Taiwan; Ko, L.-W., Department of Biological Science and Technology, Brain Research Center, National Chiao Tung University, 1001 Ta Hsueh Rd., Hsinchu 300, Taiwan; Kuo, B.-C., Graduate Institute of Educational Measurement and Statistics, National Taichung University, 140 MinShen Rd., Taichung 403, Taiwan; Lin, C.-T., Institute of Electrical Control Engineering, Brain Research Center, National Chiao-Tung University, 1001 Ta Hsueh Rd., Hsinchu 300, Taiwan","Growing numbers of traffic accidents had become a serious social safety problem in recent years. The main factor of the high fatalities was the obvious decline of the driver's cognitive state in their perception, recognition and vehicle control abilities while being sleepy. The key to avoid the terrible consequents is to build a detecting system for ongoing assessment of driver's cognitive state. A quickly growing research, brain-computer interface (BCI), offers a solution offering great assistance to those who require alternative communicatory and control mechanisms. In this study, we propose an alertness/drowsiness classification system based on investigating electroencephalographic (EEG) brain dynamics in lane-keeping driving experiments in a virtual reality (VR) driving environment with a motion platform. The core of the classification system is composed of dimension reduction technique and classifier learning algorithm. In order to find the suitable method for better describing the data structure, we explore the performances using different feature extraction and feature selection methods with different classifiers. Experiment results show that the accuracy is over 80% in most combinations and even near 90% under Principal Component Analysis (PCA) and Nonparametric Weighted Feature Extraction (NWFE) going with Gaussian Maximum Likelihood classifier (ML) and k-Nearest-Neighbor classifier (kNN), respectively. In addition, this developed classification system can also solve the individual brain dynamic differences caused from different subjects and overcome the subject dependent limitation. The optimized solution with better accuracy performance out of all combinations can be considered to implement in the kernel brain-computer interface. © 2010 IEEE.",,"Brain dynamics; Classification system; Classifier learning; Cognitive state; Control mechanism; Detecting systems; Dimension reduction techniques; Driving environment; Feature selection methods; Gaussian maximum likelihood; K-nearest neighbors; Motion platforms; Nonparametric weighted feature extractions; Optimized solutions; Safety problems; Vehicle Control; Automobile drivers; Brain; Control system synthesis; Data structures; Experiments; Feature extraction; Interfaces (computer); Learning algorithms; Maximum likelihood estimation; Neural networks; Principal component analysis; Virtual reality; Brain computer interface",Conference Paper,"Final","",Scopus,2-s2.0-79959391520
"Keefe D.F., Sotiropoulos F., Interrante V., Runesha H.B., Coffey D., Staker M., Lin C., Sun Y., Borazjani I., Le T., Rowe N., Erdman A.","7101683249;7003581647;6701782618;6603177432;35730766900;36613804300;36613465500;55737845700;23003805400;36613342100;36613677000;7007082404;","A process for design, verification, validation, and manufacture of medical devices using immersive VR environments",2010,"Journal of Medical Devices, Transactions of the ASME","4","4", 045002,"","",,12,"10.1115/1.4002561","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78049521962&doi=10.1115%2f1.4002561&partnerID=40&md5=a5eef285041d016c39db37dea6c81f73","Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN 55455, United States; Saint Anthony Falls Laboratory, University of Minnesota, Minneapolis, MN 55414, United States; Minnesota Supercomputing Institute, University of Minnesota, Minneapolis, MN 55455, United States; Medical Devices Center and Department of Mechanical Engineering, University of Minnesota, Minneapolis, MN 55455, United States","Keefe, D.F., Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN 55455, United States; Sotiropoulos, F., Saint Anthony Falls Laboratory, University of Minnesota, Minneapolis, MN 55414, United States; Interrante, V., Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN 55455, United States; Runesha, H.B., Minnesota Supercomputing Institute, University of Minnesota, Minneapolis, MN 55455, United States; Coffey, D., Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN 55455, United States; Staker, M., Medical Devices Center and Department of Mechanical Engineering, University of Minnesota, Minneapolis, MN 55455, United States; Lin, C., Medical Devices Center and Department of Mechanical Engineering, University of Minnesota, Minneapolis, MN 55455, United States; Sun, Y., Medical Devices Center and Department of Mechanical Engineering, University of Minnesota, Minneapolis, MN 55455, United States; Borazjani, I., Saint Anthony Falls Laboratory, University of Minnesota, Minneapolis, MN 55414, United States; Le, T., Saint Anthony Falls Laboratory, University of Minnesota, Minneapolis, MN 55414, United States; Rowe, N., Minnesota Supercomputing Institute, University of Minnesota, Minneapolis, MN 55455, United States; Erdman, A., Medical Devices Center and Department of Mechanical Engineering, University of Minnesota, Minneapolis, MN 55455, United States","This paper presents a framework and detailed vision for using immersive virtual reality (VR) environments to improve the design, verification, validation, and manufacture of medical devices. Major advances in medical device design and manufacture currently require extensive and expensive product cycles that include animal and clinical trials. The current design process limits opportunities to thoroughly understand and refine current designs and to explore new high-risk, high-payoff designs. For the past 4 years, our interdisciplinary research group has been working toward developing strategies to dramatically increase the role of simulation in medical device engineering, including linking simulations with visualization and interactive design. Although this vision aligns nicely with the stated goals of the FDA and the increasingly important role that simulation plays in engineering, manufacturing, and science today, the interdisciplinary expertise needed to realize a simulation-based visual design environment for real-world medical device design problems makes implementing (and even generating a system-level design for) such a system extremely challenging. In this paper, we present our vision for a new process of simulation-based medical device engineering and the impact it can have within the field. We also present our experiences developing the initial components of a framework to realize this vision and applying them to improve the design of replacement mechanical heart valves. Relative to commercial software packages and other systems used in engineering research, the vision and framework described are unique in the combined emphasis on 3D user interfaces, ensemble visualization, and incorporating state-of-the-art custom computational fluid dynamics codes. We believe that this holistic conception of simulation-based engineering, including abilities to not just simulate with unprecedented accuracy but also to visualize and interact with simulation results, is critical to making simulation-based engineering practical as a tool for major innovation in medical devices. Beyond the medical device arena, the framework and strategies described may well generalize to simulation-based engineering processes in other domains that also involve simulating, visualizing, and interacting with data that describe spatially complex time-varying phenomena. © 2010 American Society of Mechanical Engineers.","Fluid dynamics; Heart valve; Human-computer interaction; Mechanical engineering; Medical devices; Simulation; Simulation-based engineering; Visualization","3D user interface; Clinical trial; Commercial software; Computational Fluid Dynamics codes; Design process; Developing strategy; Engineering process; Expensive products; Heart valve; Immersive virtual reality; Immersive VR; Interactive design; Interdisciplinary research; Mechanical heart valves; Medical device design; Medical Devices; New high; New process; Real-world; Simulation; Simulation result; Simulation-based; System level design; Time varying; Visual design; Biomedical engineering; Computational fluid dynamics; Design; Economic analysis; Fluid dynamics; Fluids; Human computer interaction; Innovation; Knowledge management; Manufacture; Mechanical engineering; Medical problems; User interfaces; Valves (mechanical); Virtual reality; Visualization; Industrial applications; article; biomedical engineering; clinical research; computational fluid dynamics; computer aided design; computer assisted tomography; computer program; drug delivery system; food and drug administration; heart valve prosthesis; heart valve regurgitation; heart valve replacement; human; human computer interaction; immersion; medical instrumentation; nonhuman; nuclear magnetic resonance imaging; process design; risk assessment; simulation; validation process; virtual reality",Article,"Final","",Scopus,2-s2.0-78049521962
"Da Cruz J.A.S., Sandy N.S., Passerotti C.C., Nguyen H., Antunes A.A., Dos Reis S.T., Dall'Oglio M.F., Duarte R.J., Srougi M.","36342181400;35786587900;14007212500;7403322087;7102537522;26432175700;6603771736;7005370698;7006308114;","Does training laparoscopic skills in a virtual reality simulator improve surgical performance?",2010,"Journal of Endourology","24","11",,"1845","1849",,22,"10.1089/end.2010.0328","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78149377782&doi=10.1089%2fend.2010.0328&partnerID=40&md5=19d76cab5c84511797e15995022496e5","Urology Department, Faculdade de Medicina da Universidade de São Paulo (FMUSP), São Paulo, Brazil; Urology Department, Children's Hospital Boston, Boston, MA, United States","Da Cruz, J.A.S., Urology Department, Faculdade de Medicina da Universidade de São Paulo (FMUSP), São Paulo, Brazil; Sandy, N.S., Urology Department, Faculdade de Medicina da Universidade de São Paulo (FMUSP), São Paulo, Brazil; Passerotti, C.C., Urology Department, Faculdade de Medicina da Universidade de São Paulo (FMUSP), São Paulo, Brazil, Urology Department, Children's Hospital Boston, Boston, MA, United States; Nguyen, H., Urology Department, Children's Hospital Boston, Boston, MA, United States; Antunes, A.A., Urology Department, Faculdade de Medicina da Universidade de São Paulo (FMUSP), São Paulo, Brazil; Dos Reis, S.T., Urology Department, Faculdade de Medicina da Universidade de São Paulo (FMUSP), São Paulo, Brazil; Dall'Oglio, M.F., Urology Department, Faculdade de Medicina da Universidade de São Paulo (FMUSP), São Paulo, Brazil; Duarte, R.J., Urology Department, Faculdade de Medicina da Universidade de São Paulo (FMUSP), São Paulo, Brazil; Srougi, M., Urology Department, Faculdade de Medicina da Universidade de São Paulo (FMUSP), São Paulo, Brazil","Background and Purpose: Several different methods of teaching laparoscopic skills have been advocated, with virtual reality surgical simulation (VRSS) being the most popular. Its effectiveness in improving surgical performance is not a consensus yet, however. The purpose of this study was to determine whether practicing surgical skills in a virtual reality simulator results in improved surgical performance. Materials and Methods: Fifteen medical students recruited for the study were divided into three groups. Group I (control) did not receive any VRSS training. For 10 weeks, group II trained basic laparoscopic skills (camera handling, cutting skill, peg transfer skill, and clipping skill) in a VRSS laparoscopic skills simulator. Group III practiced the same skills and, in addition, performed a simulated cholecystectomy. All students then performed a cholecystectomy in a swine model. Their performance was reviewed by two experienced surgeons. The following parameters were evaluated: Gallbladder pedicle dissection time, clipping time, time for cutting the pedicle, gallbladder removal time, total procedure time, and blood loss. Results: With practice, there was improvement in most of the evaluated parameters by each of the individuals. There were no statistical differences in any of evaluated parameters between those who did and did not undergo VRSS training, however. Conclusion: VRSS training is assumed to be an effective tool for learning and practicing laparoscopic skills. In this study, we could not demonstrate that VRSS training resulted in improved surgical performance. It may be useful, however, in familiarizing surgeons with laparoscopic surgery. More effective methods of teaching laparoscopic skills should be evaluated to help in improving surgical performance. Copyright 2010, Mary Ann Liebert, Inc.",,"article; bleeding; camera; cholecystectomy; clinical practice; clip; gallbladder; laparoscopic surgery; medical student; nonhuman; priority journal; swine; training; virtual reality; Animals; Blood Loss, Surgical; Clinical Competence; Computer Simulation; Gallbladder; Humans; Intraoperative Care; Laparoscopy; Students, Medical; Sus scrofa; Time Factors; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-78149377782
"Dack C., Reed P., Mchugh L.","24467238500;7202010595;22985561200;","Multiple determinants of transfer of evaluative function after conditioning with free-operant schedules of reinforcement",2010,"Learning and Behavior","38","4",,"348","366",,5,"10.3758/LB.38.4.348","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79751500105&doi=10.3758%2fLB.38.4.348&partnerID=40&md5=295db2311bc91c63e0bee519ad3de88f","Department of Psychology, Swansea University, Singleton Park, Swansea SA2 8PP, United Kingdom","Dack, C., Department of Psychology, Swansea University, Singleton Park, Swansea SA2 8PP, United Kingdom; Reed, P., Department of Psychology, Swansea University, Singleton Park, Swansea SA2 8PP, United Kingdom; Mchugh, L., Department of Psychology, Swansea University, Singleton Park, Swansea SA2 8PP, United Kingdom","The aim of the four present experiments was to explore how different schedules of reinforcement influence schedule-induced behavior, their impact on evaluative ratings given to conditioned stimuli associated with each schedule through evaluative conditioning, and the transfer of these evaluations through derived stimulus networks. Experiment 1 compared two contrasting response reinforcement rules (variable ratio [VR], variable interval [VI]). Experiment 2 varied the response to reinforcement rule between two schedules but equated the outcome to response rate (differential reinforcement of high rate [DRH] vs. VR). Experiment 3 compared molar and molecular aspects of contingencies of reinforcement (tandem VIVR vs. tandem VRVI). Finally, Experiment 4 employed schedules that induced low rates of responding to determine whether, under these circumstances, responses were more sensitive to the molecular aspects of a schedule (differential reinforcement of low rate [DRL] vs. VI). The findings suggest that the transfer of evaluative functions is determined mainly by differences in response rate between the schedules and the molar aspects of the schedules. However, when neither schedule was based on a strong response reinforcement rule, the transfer of evaluative judgments came under the control of the molecular aspects of the schedule. © 2070 The Psychonomic Society, Inc.",,"adolescent; adult; article; color vision; female; human; instrumental conditioning; learning; male; motivation; pattern recognition; psychomotor performance; reaction time; reinforcement; semantics; Adolescent; Adult; Association Learning; Color Perception; Conditioning, Operant; Female; Humans; Male; Motivation; Pattern Recognition, Visual; Psychomotor Performance; Reaction Time; Reinforcement Schedule; Semantics; Transfer (Psychology); Young Adult",Article,"Final","",Scopus,2-s2.0-79751500105
"Muresan III C., Lee T.H., Seagull J., Park A.E.","36008980200;56711438700;6701610185;7201557376;","Transfer of training in the development of intracorporeal suturing skill in medical student novices: A prospective randomized trial",2010,"American Journal of Surgery","200","4",,"537","541",,33,"10.1016/j.amjsurg.2009.12.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77957374057&doi=10.1016%2fj.amjsurg.2009.12.018&partnerID=40&md5=56679ee7ac5d9b1435f5f41cbcd329c1","Department of Surgery, University of Maryland, 22 S. Greene St., Baltimore, MD 21201-1595, United States; Department of Surgery, Creighton University Medical Center, Omaha, NE, United States","Muresan III, C., Department of Surgery, University of Maryland, 22 S. Greene St., Baltimore, MD 21201-1595, United States; Lee, T.H., Department of Surgery, University of Maryland, 22 S. Greene St., Baltimore, MD 21201-1595, United States, Department of Surgery, Creighton University Medical Center, Omaha, NE, United States; Seagull, J., Department of Surgery, University of Maryland, 22 S. Greene St., Baltimore, MD 21201-1595, United States; Park, A.E., Department of Surgery, University of Maryland, 22 S. Greene St., Baltimore, MD 21201-1595, United States","Background: To help optimize the use of limited resources in trainee education, we developed a prospective randomized trial to determine the most effective means of teaching laparoscopic suturing to novices. Methods: Forty-one medical students received rudimentary instruction in intracorporeal suturing, then were pretested on a pig enterotomy model. They then were posttested after completion of 1 of 4 training arms: laparoscopic suturing, laparoscopic drills, open suturing, and virtual reality (VR) drills. Tests were scored for speed, accuracy, knot quality, and mental workload (National Aeronautics and Space Administration [NASA] Task Load Index). Results: Paired t tests were used. Task time was improved in all groups except the VR group. Knot quality improved only in the open or laparoscopic suturing groups. Mental workload improved only for those practicing on a physical laparoscopic trainer. Conclusions: For novice trainees, the efficacy of VR training is questionable. In contrast, the other training methods had benefits in terms of time, quality, and perceived workload. © 2010 Elsevier Inc. All rights reserved.","Laparoscopic suturing; Skills transfer; Surgical training","article; laparoscopic surgery; medical education; medical student; priority journal; suturing method; task performance; virtual reality; animal; audiovisual equipment; comparative study; controlled study; education; human; laparoscopy; medical education; procedures; prospective study; psychology; randomized controlled trial; reproducibility; suturing method; swine; Animals; Education, Medical; Humans; Laparoscopy; Models, Anatomic; Prospective Studies; Reproducibility of Results; Students, Medical; Suture Techniques; Swine; Task Performance and Analysis; Animals; Education, Medical; Humans; Laparoscopy; Models, Anatomic; Prospective Studies; Reproducibility of Results; Students, Medical; Suture Techniques; Swine; Task Performance and Analysis",Article,"Final","",Scopus,2-s2.0-77957374057
"Cameirão M.S., Badia S.B.I., Oller E.D., Verschure P.F.M.J.","21740694600;6506360007;25927398500;7006315557;","Neurorehabilitation using the virtual reality based Rehabilitation Gaming System: Methodology, design, psychometrics, usability and validation",2010,"Journal of NeuroEngineering and Rehabilitation","7","1", 48,"","",,200,"10.1186/1743-0003-7-48","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77956799027&doi=10.1186%2f1743-0003-7-48&partnerID=40&md5=79115b93e16570166a80d961567a0d6e","Department of Technology, Laboratory of Synthetic Perceptive Emotive and Cognitive Systems (SPECS), Universitat Pompeu Fabra, Roc Boronat 138, 08018 Barcelona, Spain; Servei de Medicina Física i Rehabilitaciá, Hospital de l'Esperança, Barcelona, Spain; Instituciá Catalana de Recerca i Estudis Avançats (ICREA), Barcelona, Spain","Cameirão, M.S., Department of Technology, Laboratory of Synthetic Perceptive Emotive and Cognitive Systems (SPECS), Universitat Pompeu Fabra, Roc Boronat 138, 08018 Barcelona, Spain; Badia, S.B.I., Department of Technology, Laboratory of Synthetic Perceptive Emotive and Cognitive Systems (SPECS), Universitat Pompeu Fabra, Roc Boronat 138, 08018 Barcelona, Spain; Oller, E.D., Servei de Medicina Física i Rehabilitaciá, Hospital de l'Esperança, Barcelona, Spain; Verschure, P.F.M.J., Department of Technology, Laboratory of Synthetic Perceptive Emotive and Cognitive Systems (SPECS), Universitat Pompeu Fabra, Roc Boronat 138, 08018 Barcelona, Spain, Instituciá Catalana de Recerca i Estudis Avançats (ICREA), Barcelona, Spain","Background: Stroke is a frequent cause of adult disability that can lead to enduring impairments. However, given the life-long plasticity of the brain one could assume that recovery could be facilitated by the harnessing of mechanisms underlying neuronal reorganization. Currently it is not clear how this reorganization can be mobilized. Novel technology based neurorehabilitation techniques hold promise to address this issue. Here we describe a Virtual Reality (VR) based system, the Rehabilitation Gaming System (RGS) that is based on a number of hypotheses on the neuronal mechanisms underlying recovery, the structure of training and the role of individualization. We investigate the psychometrics of the RGS in stroke patients and healthy controls. Methods: We describe the key components of the RGS and the psychometrics of one rehabilitation scenario called Spheroids. We performed trials with 21 acute/subacute stroke patients and 20 healthy controls to study the effect of the training parameters on task performance. This allowed us to develop a Personalized Training Module (PTM) for online adjustment of task difficulty. In addition, we studied task transfer between physical and virtual environments. Finally, we assessed the usability and acceptance of the RGS as a rehabilitation tool. Results: We show that the PTM implemented in RGS allows us to effectively adjust the difficulty and the parameters of the task to the user by capturing specific features of the movements of the arms. The results reported here also show a consistent transfer of movement kinematics between physical and virtual tasks. Moreover, our usability assessment shows that the RGS is highly accepted by stroke patients as a rehabilitation tool. Conclusions: We introduce a novel VR based paradigm for neurorehabilitation, RGS, which combines specific rehabilitative principles with a psychometric evaluation to provide a personalized and automated training. Our results show that the RGS effectively adjusts to the individual features of the user, allowing for an unsupervised deployment of individualized rehabilitation protocols. © 2010 Cameiro et al; licensee BioMed Central Ltd.",,"adult; aged; algorithm; article; calibration; computer graphics; computer interface; computer program; female; hemiplegia; human; male; methodology; middle aged; neurologic disease; physiology; physiotherapy; psychometry; psychomotor performance; recreation; reproducibility; statistical analysis; stroke; Adult; Aged; Algorithms; Calibration; Computer Graphics; Data Interpretation, Statistical; Female; Hemiplegia; Humans; Male; Middle Aged; Nervous System Diseases; Physical Therapy Modalities; Psychometrics; Psychomotor Performance; Reproducibility of Results; Software Design; Stroke; User-Computer Interface; Video Games",Article,"Final","",Scopus,2-s2.0-77956799027
"Kartiko I., Kavakli M., Cheng K.","35185198900;6602420178;7402998367;","Learning science in a virtual reality application: The impacts of animated-virtual actors' visual complexity",2010,"Computers and Education","55","2",,"881","891",,34,"10.1016/j.compedu.2010.03.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953144820&doi=10.1016%2fj.compedu.2010.03.019&partnerID=40&md5=46d81efc9d661e55d46b5e439629d6b2","Department of Computing, Macquarie University, North Ryde, Sydney, NSW 2109, Australia; Department of Brain, Behaviour and Evolution, Macquarie University, North Ryde, Sydney, NSW 2109, Australia","Kartiko, I., Department of Computing, Macquarie University, North Ryde, Sydney, NSW 2109, Australia; Kavakli, M., Department of Computing, Macquarie University, North Ryde, Sydney, NSW 2109, Australia; Cheng, K., Department of Brain, Behaviour and Evolution, Macquarie University, North Ryde, Sydney, NSW 2109, Australia","As the technology in computer graphics advances, Animated-Virtual Actors (AVAs) in Virtual Reality (VR) applications become increasingly rich and complex. Cognitive Theory of Multimedia Learning (CTML) suggests that complex visual materials could hinder novice learners from attending to the lesson properly. On the other hand, previous studies have shown that visual complexity correlates with presence and may increase the perceived affective quality of the virtual world, towards an optimal experience or flow. Increasing these in VR applications may promote enjoyment and higher cognitive engagement for better learning outcomes. While visually complex materials could be motivating and pleasing to attend to, would they affect learning adversely? We developed a series of VR presentations to teach second-year psychology students about the navigational behaviour of Cataglyphis ants with flat, cartoon, or lifelike AVAs. To assess learning outcomes, we used Program Ratings, which measured perception of learning and perceived difficulty, and retention and transfer tests. The results from 200 students did not reveal any significant differences in presence, perceived affective quality, or learning outcomes as a function of the AVA's visual complexity. While the results showed positive correlations between presence, perceived affective quality and perception of learning, none of these correlates with perceived difficulty, retention, or transfer scores. Nevertheless, our simulation produced significant improvements on retention and transfer scores in all conditions. We discuss possible explanations and future research directions. © 2010 Elsevier Ltd. All rights reserved.","Applications of animated-virtual actors; Evaluation of CAL systems; Human-computer interface; Multimedia/hypermedia systems; Virtual reality","Evaluation of CAL systems; Human computer interfaces; Multimedia/hypermedia systems; Virtual actors; Computer supported cooperative work; Virtual reality",Article,"Final","",Scopus,2-s2.0-77953144820
"Edelman D.A., Mattos M.A., Bouwman D.L.","7102054542;7005139167;7003461011;","FLS skill retention (Learning) in first year surgery residents",2010,"Journal of Surgical Research","163","1",,"24","28",,48,"10.1016/j.jss.2010.03.057","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955920230&doi=10.1016%2fj.jss.2010.03.057&partnerID=40&md5=68c3e6dbe99a2df34297a9fbf1b00919","Department of Surgery, Surgical Simulation Skills Laboratory, Harper Professional Building, 3990 John R, Detroit, MI 48201, United States","Edelman, D.A., Department of Surgery, Surgical Simulation Skills Laboratory, Harper Professional Building, 3990 John R, Detroit, MI 48201, United States; Mattos, M.A., Department of Surgery, Surgical Simulation Skills Laboratory, Harper Professional Building, 3990 John R, Detroit, MI 48201, United States; Bouwman, D.L., Department of Surgery, Surgical Simulation Skills Laboratory, Harper Professional Building, 3990 John R, Detroit, MI 48201, United States","Background: Fundamentals of Laparoscopic Surgery (FLS) certification is reliable and valid; the American Board of Surgery requires FLS certification. Dynamics of skill retention after FLS training effect training schedules for residents. We hypothesized that the initial elevation of performance levels after FLS training would deteriorate predictably with time. Methods: FLS performance data on 16 new surgical residents (R01s) was examined retrospectively. These R01s trained at 16 weekly sessions. Training included 4 FLS tasks, VR simulator tasks, and open surgical skills. FLS skills were practiced weekly with feedback but no instruction. Performance was tested PRE, POST, and DELAY. Outcome metrics were task completion times (TCTs). Results: POST TCTs were below PRE TCTs in all R01s for all FLS tasks (P < 0.05). No difference was seen between the DELAY TCT and POST TCT for peg transfer (P = 0.726) and pattern cut (P = 0.114). The DELAY TCTs were longer than POST TCTs for extra- and intra corporeal knot-tying (P < 0.0001 and P = 0.029). Relative retention was 103% for peg transfer, 85% for pattern cut, 47% for extracorporeal knot tying, and 59% for intracorporeal knot tying. However, many individual's displayed DELAY TCT equal to or lower than POST TCT implying full retention. Conclusions: This study extends the data on FLS skill retention to an actual ""production"" training curriculum. This FLS training provided effective learning in R01s. Although performance levels fell across these tasks on average and for the majority of individual R01s, significant skill retention remained at 7-8 months. Early training will enable R01s to maintain or elevate skill levels with additional training sessions. © 2010 Elsevier Inc. All rights reserved.","FLS; laparoscopic simulators; retention; skill training","article; curriculum; evaluation; human; laparoscopic surgery; learning; outcome assessment; performance; prediction; priority journal; resident; skill retention; surgical training; Humans; Internship and Residency; Laparoscopy; Retention (Psychology); Retrospective Studies; Task Performance and Analysis",Article,"Final","",Scopus,2-s2.0-77955920230
"Lange B., Flynn S., Proffitt R., Chang C.-Y., Rizzo A.","25927240000;7007046039;36701809600;37033519500;57213231655;","Development of an interactive game-based rehabilitation tool for dynamic balance training",2010,"Topics in Stroke Rehabilitation","17","5",,"345","352",,126,"10.1310/tsr1705-345","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79251629065&doi=10.1310%2ftsr1705-345&partnerID=40&md5=4be5fd05a7fb552f47dade4ee343dc73","Medical Virtual Reality Group, Institute for Creative Technologies, University of Southern California, Playa Vista, CA, United States; Blue Marble Game Company, Altadena, CA, United States","Lange, B., Medical Virtual Reality Group, Institute for Creative Technologies, University of Southern California, Playa Vista, CA, United States; Flynn, S., Medical Virtual Reality Group, Institute for Creative Technologies, University of Southern California, Playa Vista, CA, United States, Blue Marble Game Company, Altadena, CA, United States; Proffitt, R., Medical Virtual Reality Group, Institute for Creative Technologies, University of Southern California, Playa Vista, CA, United States; Chang, C.-Y., Medical Virtual Reality Group, Institute for Creative Technologies, University of Southern California, Playa Vista, CA, United States; Rizzo, A., Medical Virtual Reality Group, Institute for Creative Technologies, University of Southern California, Playa Vista, CA, United States","Conventional physical therapy techniques have been shown to improve balance, mobility, and gait following neurological injury. Treatment involves training patients to transfer weight onto the impaired limb to improve weight shift while standing and walking. Visual biofeedback and force plate systems are often used for treatment of balance and mobility disorders. Researchers have also been exploring the use of video game consoles such as the Nintendo Wii Fit as rehabilitation tools. Case studies have demonstrated that the use of video games may have promise for balance rehabilitation. However, initial usability studies and anecdotal evidence suggest that the current commercial games are not compatible with controlled, specific exercise required to meet therapy goals. Based on focus group data and observations with patients, a game has been developed to specifically target weight shift training using an open source game engine and the Nintendo Wii Fit Balance Board. The prototype underwent initial usability testing with a sample of clinicians and with persons with neurological injury. Overall, feedback was positive, and areas for improvement were identified. This preliminary research provides support for the development of a game that caters specifically to the key requirements of balance rehabilitation. © 2010 Thomas Land Publishers, Inc.","balance training; game-based rehabilitation; video game; Wii Fit Balance Board","adult; article; balance disorder; body equilibrium; clinical article; clinical effectiveness; computer assisted therapy; dynamic balance training; human; interactive game based rehabilitation tool; male; neurologic disease; patient participation; physiotherapy; positive feedback; recreation; rehabilitation; rehabilitation research; stroke; stroke patient; weight bearing; Biofeedback, Psychology; Computer Simulation; Exercise Therapy; Feedback, Physiological; Humans; Movement; Nervous System Diseases; Nonlinear Dynamics; Photic Stimulation; Postural Balance; Questionnaires; User-Computer Interface; Video Games; Watchful Waiting",Article,"Final","",Scopus,2-s2.0-79251629065
"Rhienmora P., Haddawy P., Khanal P., Suebnukarn S., Dailey M.N.","23767398500;6701739890;56588844200;8893011200;56187964300;","A virtual reality simulator for teaching and evaluating dental procedures",2010,"Methods of Information in Medicine","49","4",,"396","405",,17,"10.3414/ME9310","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955542777&doi=10.3414%2fME9310&partnerID=40&md5=fec405a9fb887a999148ea8c8b81bcad","Computer Science and Information Management, School of Engineering and Technology, Asian Institute of Technology, Klongluang Pathumthani 12120, Thailand; Faculty of Dentistry, Thammasat University, Pathumthani, Thailand","Rhienmora, P., Computer Science and Information Management, School of Engineering and Technology, Asian Institute of Technology, Klongluang Pathumthani 12120, Thailand; Haddawy, P., Computer Science and Information Management, School of Engineering and Technology, Asian Institute of Technology, Klongluang Pathumthani 12120, Thailand; Khanal, P., Faculty of Dentistry, Thammasat University, Pathumthani, Thailand; Suebnukarn, S., Faculty of Dentistry, Thammasat University, Pathumthani, Thailand; Dailey, M.N., Computer Science and Information Management, School of Engineering and Technology, Asian Institute of Technology, Klongluang Pathumthani 12120, Thailand","Objectives: We present a dental training system with a haptic interface that allows dental students or experts to practice dental procedures in a virtual environment. The simulator is able to monitor and classify the performance of an operator into novice or expert categories. The intelligent training module allows a student to simultaneously and pro - actively follow the correct dental procedures demonstrated by an intelligent tutor. Methods: The virtual reality (VR) simulator simulates the tooth preparation procedure both graphically and haptically, using a video display and haptic device. We evaluated the performance of users using hidden Markov models (HMMs) incorporating various data collected by the simulator. We implemented an intelligent training module which is able to record and replay the procedure that was performed by an expert and allows students to follow the correct steps and apply force pro - actively by themselves while reproducing the procedure. Results: We find that the level of graphics and haptics fidelity is acceptable as evaluated by dentists. The accuracy of the objective performance assessment using HMMs is encouraging with 100 percent accuracy. Conclusions: The simulator can simulate realistic tooth surface exploration and cutting. The accuracy of automatic performance assessment system using HMMs is also acceptable on relatively small data sets. The intelligent training allows skill transfer in a proactive manner which is an advantage over the passive method in a traditional training. We will soon conduct experiments with more participants and implement a variety of training strategies. © Schattauer 2010.","Dental performance assessment; Dental skills training; Haptic interface; Hidden Markov model; Intelligent training system; Virtual reality","article; artificial intelligence; attitude to health; clinical competence; computer interface; computer simulation; dental education; dental student; dentistry; human; methodology; probability; standard; task performance; teaching; Thailand; Artificial Intelligence; Clinical Competence; Computer Simulation; Dentistry; Education, Dental; Health Knowledge, Attitudes, Practice; Humans; Markov Chains; Students, Dental; Task Performance and Analysis; Teaching; Thailand; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-77955542777
"Gruzelier J., Inoue A., Smart R., Steed A., Steffert T.","7004536505;36611844400;36612395100;18435050200;24725819800;","Acting performance and flow state enhanced with sensory-motor rhythm neurofeedback comparing ecologically valid immersive VR and training screen scenarios",2010,"Neuroscience Letters","480","2",,"112","116",,62,"10.1016/j.neulet.2010.06.019","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954533066&doi=10.1016%2fj.neulet.2010.06.019&partnerID=40&md5=9797bd8bb41075d4eaf4b5025731db59","Department of Psychology, Goldsmiths, University of London, Lewisham Way, London SE14 6NW, United Kingdom; Department of Drama, Goldsmiths, University of London, United Kingdom; Department of Computer Science, University College London, United Kingdom","Gruzelier, J., Department of Psychology, Goldsmiths, University of London, Lewisham Way, London SE14 6NW, United Kingdom; Inoue, A., Department of Psychology, Goldsmiths, University of London, Lewisham Way, London SE14 6NW, United Kingdom; Smart, R., Department of Drama, Goldsmiths, University of London, United Kingdom; Steed, A., Department of Computer Science, University College London, United Kingdom; Steffert, T., Department of Psychology, Goldsmiths, University of London, Lewisham Way, London SE14 6NW, United Kingdom","Actors were trained in sensory-motor rhythm (SMR) neurofeedback interfaced with a computer rendition of a theatre auditorium. Enhancement of SMR led to changes in the lighting while inhibition of theta and high beta led to a reduction in intrusive audience noise. Participants were randomised to a virtual reality (VR) representation in a ReaCTor, with surrounding image projection seen through glasses, or to a 2D computer screen, which is the conventional neurofeedback medium. In addition there was a no-training comparison group. Acting performance was evaluated by three experts from both filmed, studio monologues and Hamlet excerpts on the stage of Shakespeare's Globe Theatre. Neurofeedback learning reached an asymptote earlier as did identification of the required mental state following training in the ReaCTor training compared with the computer screen, though groups reached the same asymptote. These advantages were paralleled by higher ratings of acting performance overall, well-rounded performance, and especially the creativity subscale including imaginative expression, conviction and characterisation. On the Flow State scales both neurofeedback groups scored higher than the no-training controls on self-ratings of sense of control, confidence and feeling at-one. This is the first demonstration of enhancement of artistic performance with eyes-open neurofeedback training, previously demonstrated only with eyes-closed slow-wave training. Efficacy is attributed to psychological engagement through the ecologically relevant learning context of the acting-space, putatively allowing transfer to the real world otherwise achieved with slow-wave training through imaginative visualisation. The immersive VR technology was more successful than a 2D rendition. © 2010 Elsevier Ireland Ltd.","Acting performance; Flow state; Neurofeedback; Virtual reality","adult; alpha rhythm; article; beta rhythm; controlled study; creativity; electroencephalogram; evaluation; feedback system; female; human; human experiment; image display; imagination; intermethod comparison; learning; male; normal human; performance; performing artist; performing arts; priority journal; rating scale; sensorimotor integration; sensory motor rhythm neurofeedback; theta rhythm; training; virtual reality; art; comparative study; electroencephalography; learning; neuropsychological test; periodicity; psychophysiology; randomized controlled trial; Art; Biofeedback, Psychology; Electroencephalography; Female; Humans; Male; Neuropsychological Tests; Periodicity; Practice (Psychology); Art; Biofeedback, Psychology; Electroencephalography; Female; Humans; Male; Neuropsychological Tests; Periodicity; Practice (Psychology)",Article,"Final","",Scopus,2-s2.0-77954533066
"Schout B.M.A., Ananias H.J.K., Bemelmans B.L.H., D'Ancona F.C.H., Muijtjens A.M.M., Dolmans V.E.M.G., Scherpbier A.J.J.A., Hendrikx A.J.M.","23493570600;25951236900;7003815613;6701700995;7003959944;23492124200;35403072600;7004341048;","Transfer of cysto-urethroscopy skills from a virtual-reality simulator to the operating room: A randomized controlled trial",2010,"BJU International","106","2",,"226","231",,34,"10.1111/j.1464-410X.2009.09049.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953866778&doi=10.1111%2fj.1464-410X.2009.09049.x&partnerID=40&md5=37dd102f95ddff3b8cc1c8a7ca148f27","Catharina Hospital Eindhoven, Urology Department, PO Box 1350, Eindhoven, ZA 5602, Netherlands; VU Medical Centre Amsterdam, Amsterdam, Netherlands; University Medical Centre Groningen, Netherlands; Radboud University, Nijmegen Medical Centre, Nijmegen, Netherlands; Maastricht University, Maastricht, Netherlands","Schout, B.M.A., Catharina Hospital Eindhoven, Urology Department, PO Box 1350, Eindhoven, ZA 5602, Netherlands, VU Medical Centre Amsterdam, Amsterdam, Netherlands; Ananias, H.J.K., University Medical Centre Groningen, Netherlands; Bemelmans, B.L.H., VU Medical Centre Amsterdam, Amsterdam, Netherlands; D'Ancona, F.C.H., Radboud University, Nijmegen Medical Centre, Nijmegen, Netherlands; Muijtjens, A.M.M., VU Medical Centre Amsterdam, Amsterdam, Netherlands; Dolmans, V.E.M.G., Catharina Hospital Eindhoven, Urology Department, PO Box 1350, Eindhoven, ZA 5602, Netherlands; Scherpbier, A.J.J.A., Maastricht University, Maastricht, Netherlands; Hendrikx, A.J.M., Catharina Hospital Eindhoven, Urology Department, PO Box 1350, Eindhoven, ZA 5602, Netherlands, Maastricht University, Maastricht, Netherlands","OBJECTIVE To assess whether real-time cysto-urethroscopy (CUS) performance improves by simulator-based training (criterion or predictive validity), addressing the research question 'Does practical skills training on the URO Mentor (UM, Simbionix USA Corp., Cleveland, OH, USA) virtual-reality simulator improve the performance of flexible CUS in patients'. SUBJECTS AND METHODS Participants (71 interns from Catharina Hospital Eindhoven, CHE, and 29 from University Medical Centre Groningen, UMCG) were randomized to carry out CUS in a patient after training on the UM (UM-trained, 50) or without training on UM (control, 50). The assessment of real-time performance consisted of scoring on a Global Rating Scale (GRS) by supervisors unaware of training status. Data were analysed using stepwise multiple linear regression. The effect size (ES) indication for correlations was used to interpret the magnitude of a standard regression coefficient (β); an ES of 0.10, 0.30 and 0.50 were considered small, moderate and large, respectively. The study was approved by the Medical Review Ethics Committees of the participating hospitals. RESULTS Overall, the group that received training performed significantly better than the controls (P ≤ 0.003, β range 0.30-0.47). There was no effect of training for participants with a specific preference for a surgical speciality in two of five GRS scores. Participants from CHE obtained higher GRS 3 scores than those from UMCG. Significantly more UMCG trainees indicated having had stress than those from CHE (P < 0.001). CONCLUSIONS The results showed that interns who had trained on UM outperformed controls for a CUS procedure in a patient. Training for CUS on the UM is to be recommended for learning to respect tissue, procedural knowledge, flow of procedure and forward planning. Use of the UM to train interns with a specific interest in a surgical speciality in handling instruments, and time and motion, seems to be of limited value. © 2009 the Authors.","cysto-urethroscopy; randomized controlled trial; simulation; training; transfer; validation","article; controlled study; correlation analysis; cystoscopy; female; human; male; medical personnel; multiple linear regression analysis; normal human; operating room; priority journal; randomization; scoring system; simulation; skill; surgical training; training; urethroscopy; virtual reality; Adult; Clinical Competence; Computer Simulation; Computer-Assisted Instruction; Cystoscopy; Education, Medical, Continuing; Educational Measurement; Female; Humans; Male; Medical Staff, Hospital; Single-Blind Method; Urologic Surgical Procedures; Young Adult",Article,"Final","",Scopus,2-s2.0-77953866778
"Ha T., Woo W.","15020792200;35575439600;","An empirical evaluation of virtual hand techniques for 3D object manipulation in a tangible augmented reality environment",2010,"3DUI 2010 - IEEE Symposium on 3D User Interfaces 2010, Proceedings",,, 5444713,"91","98",,25,"10.1109/3DUI.2010.5444713","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953077148&doi=10.1109%2f3DUI.2010.5444713&partnerID=40&md5=bad2d4402b928dfdb6ba9ae1862ffaaa","GIST U-VR Lab., 500-712, South Korea","Ha, T., GIST U-VR Lab., 500-712, South Korea; Woo, W., GIST U-VR Lab., 500-712, South Korea","In this paper, we present a Fitts' law-based formal evaluation process and the corresponding results for 3D object manipulation techniques based on a virtual hand metaphor in a tangible augmented reality (TAR) environment. Specifically, we extend the design parameters of the 1D scale Fitts' law to 3D scale and then refine an evaluation model in order to bring generality and ease of adaptation to various TAR applications. Next, we implement and compare standard TAR manipulation techniques using a cup, a paddle, a cube, and a proposed extended paddle prop. Most manipulation techniques were well-modeled in terms of linear regression according to Fitts' law, with a correlation coefficient value of over 0.9. Notably, the throughput by ISO 9241-9 of the extended paddle technique peaked at around 1.39 to 2 times higher than in the other techniques, due to the instant 3D positioning of the 3D objects. In the discussion, we subsequently examine the characteristics of the TAR manipulation techniques in terms of stability, speed, comfort, and understanding. As a result, our evaluation process, results, and analysis can be useful in guiding the design and implementation of future TAR interfaces. ©2010 IEEE.","3D object manipulation; Augmented reality; Empirical evaluation; Fitts' law; H.5.1 [Information Interfaces and Presentation]: Multimedia information systems - Artificial, augmented, and virtual realities; H.5.2 [Information Interfaces and Presentation]: User interfaces - Input interaction styles; Tangible user interface; Virtual hand technique","3D object; 3D object manipulation; Empirical evaluations; Fitts' law; H.5.1 [information interfaces and presentation]: multimedia information systems - Artificial , augmented , and virtual realities; Interaction styles; Tangible user interfaces; Virtual hand; Augmented reality; Environmental regulations; Information systems; Tar; Three dimensional; Three dimensional computer graphics; Virtual reality; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-77953077148
"Wallet G., Sauzéon H., Rodrigues J., Larrue F., N'Kaoua B.","26425357400;7801452039;26425235600;36139685200;6603602499;","Virtual/real transfer of spatial learning: Impact of activity according to the retention delay",2010,"Annual Review of CyberTherapy and Telemedicine","8","1",,"115","118",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952895771&partnerID=40&md5=df3edf1dbc29de17edda2d427e4d54cd","Laboratoire Cognition et Facteurs Humains, Bordeaux, 33000, France","Wallet, G., Laboratoire Cognition et Facteurs Humains, Bordeaux, 33000, France; Sauzéon, H., Laboratoire Cognition et Facteurs Humains, Bordeaux, 33000, France; Rodrigues, J., Laboratoire Cognition et Facteurs Humains, Bordeaux, 33000, France; Larrue, F., Laboratoire Cognition et Facteurs Humains, Bordeaux, 33000, France; N'Kaoua, B., Laboratoire Cognition et Facteurs Humains, Bordeaux, 33000, France","Within the framework of cognitive rehabilitation using virtual reality (VR), one of the major challenges is to study beforehand the effectiveness of the virtual-real transfer of learning and to define cognitive aids. The aim of this experiment was to verify if, after learning spatial knowledge (i.e., a route) in VR, performances can be transferred to reality, then maintained in real time, and improved with the aid of an active navigation (i.e., using a joystick). Ninety student volunteers from the University of Bordeaux 2 (45 men and 45 women) participated in the experiment. The virtual environment (VE) used for learning was a replica of an area of Bordeaux. The factors tested were retention delay (Immediate vs. 48 hours) and type of navigation (Passive virtual vs. Active virtual vs. Real), using three recall tasks: wayfinding, freehand sketch and photograph classification. Our results showed that the virtual-real transfer was not degraded by a retention delay of 48 hours and that active navigation allowed performances to be optimized.","Exploration mode; Knowledge transfer; Retention delay, recall tasks; Spatial cognition; Virtual reality","adult; article; cognition; controlled study; female; human; human experiment; knowledge; learning; male; scoring system; task performance; virtual reality",Article,"Final","",Scopus,2-s2.0-77952895771
"Lau R.W.H., Lee K.","7103010017;55574241657;","On error bound estimation for motion prediction",2010,"Proceedings - IEEE Virtual Reality",,, 5444795,"171","178",,1,"10.1109/VR.2010.5444795","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952731460&doi=10.1109%2fVR.2010.5444795&partnerID=40&md5=1619fe694223ac458ef087235fb5516b","Department of Computer Science, City University of Hong Kong, Hong Kong, Hong Kong","Lau, R.W.H., Department of Computer Science, City University of Hong Kong, Hong Kong, Hong Kong; Lee, K., Department of Computer Science, City University of Hong Kong, Hong Kong, Hong Kong","A collaborative virtual environment (CVE) allows remote users to access and modify shared data through networks, such as the Internet. However, when the users are connected via the Internet, the network latency problem may become significant and affect the performance of user interactions. Existing works to address the network latency problem mainly focus on developing motion prediction methods that appear statistically accurate for certain applications. However, it is often not known how reliable they are in a CVE. In this work, we study the sources of error introduced by a motion predictor and propose to address the errors by estimating the error bounds of each prediction made by the motion predictor. Without loss of generality, we discuss how we may estimate the upper and lower error bounds based on a particular motion predictor. Finally, we evaluate the effectiveness of our method extensively through a number of experiments and show the effectiveness of using the estimated error bound in an area-based visibility culling algorithm for DVE navigation. ©2010 IEEE.","Collaborative virtual environments; Motion prediction; Network latency; Prediction error","Area-based; Collaborative virtual environment; Error bound; Estimated error; Motion prediction; Network latencies; Prediction errors; Remote users; Shared data; User interaction; Visibility culling; Display devices; Distributed computer systems; Internet; Packet networks; Virtual reality; Forecasting",Conference Paper,"Final","",Scopus,2-s2.0-77952731460
"Fong K.N.K., Chow K.Y.Y., Chan B.C.H., Lam K.C.K., Lee J.C.K., Li T.H.Y., Yan E.W.H., Wong A.T.Y.","14119428500;36100962600;36101103800;56332495000;36101284200;36101162400;36101952000;36101832300;","Usability of a virtual reality environment simulating an automated teller machine for assessing and training persons with acquired brain injury",2010,"Journal of NeuroEngineering and Rehabilitation","7","1", 19,"","",,23,"10.1186/1743-0003-7-19","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951541583&doi=10.1186%2f1743-0003-7-19&partnerID=40&md5=862df39812c55fd9b464bd23cb8dd916","Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong, Hong Kong; Occupational Therapy Department, Kowloon Hospital, Hong Kong, Hong Kong","Fong, K.N.K., Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong, Hong Kong; Chow, K.Y.Y., Occupational Therapy Department, Kowloon Hospital, Hong Kong, Hong Kong; Chan, B.C.H., Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong, Hong Kong; Lam, K.C.K., Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong, Hong Kong; Lee, J.C.K., Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong, Hong Kong; Li, T.H.Y., Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong, Hong Kong; Yan, E.W.H., Occupational Therapy Department, Kowloon Hospital, Hong Kong, Hong Kong; Wong, A.T.Y., Occupational Therapy Department, Kowloon Hospital, Hong Kong, Hong Kong","Objective. This study aimed to examine the usability of a newly designed virtual reality (VR) environment simulating the operation of an automated teller machine (ATM) for assessment and training. Design. Part I involved evaluation of the sensitivity and specificity of a non-immersive VR program simulating an ATM (VR-ATM). Part II consisted of a clinical trial providing baseline and post-intervention outcome assessments. Setting. A rehabilitation hospital and university-based teaching facilities were used as the setting. Participants. A total of 24 persons in the community with acquired brain injury (ABI) - 14 in Part I and 10 in Part II - made up the participants in the study. Interventions. In Part I, participants were randomized to receive instruction in either an ""early"" or a ""late"" VR-ATM program and were assessed using both the VR program and a real ATM. In Part II, participants were assigned in matched pairs to either VR training or computer-assisted instruction (CAI) teaching programs for six 1-hour sessions over a three-week period. Outcome Measures. Two behavioral checklists based on activity analysis of cash withdrawals and money transfers using a real ATM were used to measure average reaction time, percentage of incorrect responses, level of cues required, and time spent as generated by the VR system; also used was the Neurobehavioral Cognitive Status Examination. Results. The sensitivity of the VR-ATM was 100% for cash withdrawals and 83.3% for money transfers, and the specificity was 83% and 75%, respectively. For cash withdrawals, the average reaction time of the VR group was significantly shorter than that of the CAI group (p = 0.021). We found no significant differences in average reaction time or accuracy between groups for money transfers, although we did note positive improvement for the VR-ATM group. Conclusion. We found the VR-ATM to be usable as a valid assessment and training tool for relearning the use of ATMs prior to real-life practice in persons with ABI. © 2010 Fong et al; licensee BioMed Central Ltd.",,"adult; article; brain injury; clinical trial; computer assisted therapy; computer interface; controlled clinical trial; controlled study; daily life activity; female; human; instrumentation; male; methodology; middle aged; randomized controlled trial; reaction time; sensitivity and specificity; Activities of Daily Living; Adult; Brain Injuries; Female; Humans; Male; Middle Aged; Reaction Time; Sensitivity and Specificity; Therapy, Computer-Assisted; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-77951541583
"Bullinger H.-J., Bauer W., Wenzel G., Blach R.","7004916256;35483043700;23399167200;15057595400;","Towards user centred design (UCD) in architecture based on immersive virtual environments",2010,"Computers in Industry","61","4",,"372","379",,55,"10.1016/j.compind.2009.12.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953232146&doi=10.1016%2fj.compind.2009.12.003&partnerID=40&md5=9cd7462cf1f0f9ebfdeb8bed14e24920","Fraunhofer Headquarter, Hansastraße 27c, 80686 Munich, Germany; Fraunhofer Institute for Industrial Engineering IAO, Nobelstr. 12, 70569 Stuttgart, Germany","Bullinger, H.-J., Fraunhofer Headquarter, Hansastraße 27c, 80686 Munich, Germany; Bauer, W., Fraunhofer Institute for Industrial Engineering IAO, Nobelstr. 12, 70569 Stuttgart, Germany; Wenzel, G., Fraunhofer Institute for Industrial Engineering IAO, Nobelstr. 12, 70569 Stuttgart, Germany; Blach, R., Fraunhofer Institute for Industrial Engineering IAO, Nobelstr. 12, 70569 Stuttgart, Germany","This paper describes a generic concept of how to combine the experience of user centred design (UCD) in the field of Human Computer Interaction (HCI) with the traditional approach of participatory design (PD) in an architectural design process. Even if some basic requirements of this generic method are not available yet, this paper will also describe an approach, which enables planners even now to involve end users by using virtual environments (VE) as immersive and spatial prototype. It will be described and illustrated by the way of example using the building project Centre of Virtual Engineering of the Fraunhofer Institute for Industrial Engineering (IAO) in Stuttgart. It demonstrates that the transfer of the UCD approach to architectural planning combined with the provision of an adequate prototype can make a significant contribution towards an increase in quality and performance in building and construction projects. © 2010 Elsevier B.V. All rights reserved.","Architectural design; User centred design; Virtual environments","Building projects; End users; Fraunhofer; Generic method; Immersive; Immersive virtual environments; In-buildings; Participatory design; User centred design; Virtual engineering; Virtual environments; Architectural design; Construction industry; Structural design; Virtual reality; Human computer interaction",Article,"Final","",Scopus,2-s2.0-77953232146
"Fiorentino M., Uva A.E., Dellisanti Fabiano M., Monno G.","56350129000;6505665039;25959581000;6603171537;","Improving bi-manual 3D input in CAD modelling by part rotation optimisation",2010,"CAD Computer Aided Design","42","5",,"462","470",,13,"10.1016/j.cad.2008.12.002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950187544&doi=10.1016%2fj.cad.2008.12.002&partnerID=40&md5=e61c41c9c14f64dc1a291aa2324fafb6","DIMEG, Politecnico di Bari, Viale Japigia 182, 70126 Bari, Italy","Fiorentino, M., DIMEG, Politecnico di Bari, Viale Japigia 182, 70126 Bari, Italy; Uva, A.E., DIMEG, Politecnico di Bari, Viale Japigia 182, 70126 Bari, Italy; Dellisanti Fabiano, M., DIMEG, Politecnico di Bari, Viale Japigia 182, 70126 Bari, Italy; Monno, G., DIMEG, Politecnico di Bari, Viale Japigia 182, 70126 Bari, Italy","Part modelling in a CAD environment requires a bi-manual 3D input interface to fully exploit its potentialities. In this research we provide extensive user tests on bi-manual modelling using different devices to control 3D model's rotation. Our results suggest that a simple trackball device is effective when the user task is mostly limited to rotation control (i.e. when modelling parts in a CAD environment). In our tests, performances are even better than those achieved with a specifically designed device. Since the task of rotating a CAD part often shows the need of flipping the controlled object, we introduce a non linear transfer function which combines the precision of a zero order control mode with the ability to recognise fast movements. This new modality shows a significant improvement in the user's performances and candidates itself for integration in next generation CAD interfaces. © 2008 Elsevier Ltd. All rights reserved.","3D input; Bimanual interaction; Human computer interface; Part modelling; VR CAD","3D models; Bi-manual interaction; CAD interfaces; Controlled objects; Fast movement; Human computer interfaces; Input interface; New modality; Non-linear; Optimisations; Rotation control; Trackballs; User tests; Zero order; Human computer interaction; Interfaces (computer); Rotation; Three dimensional",Article,"Final","",Scopus,2-s2.0-77950187544
"Buzink S.N., Goossens R.H.M., Schoon E.J., De Ridder H., Jakimowicz J.J.","14064457800;7006683516;6603349081;35387764300;35391591600;","Do basic psychomotor skills transfer between different image-based procedures?",2010,"World Journal of Surgery","34","5",,"933","940",,10,"10.1007/s00268-010-0432-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954740541&doi=10.1007%2fs00268-010-0432-5&partnerID=40&md5=98f40f1641953ffa9fce67dda3bbd002","Faculty of Industrial Design Engineering, Delft University of Technology, Landbergstraat 15, 2628 CE Delft, Netherlands; Department of Surgery, Catharina Hospital Eindhoven, Michelangelolaan 2, 5623 EJ Eindhoven, Netherlands; Department of Gastroenterology, Catharina Hospital Eindhoven, Michelangelolaan 2, 5623 EJ Eindhoven, Netherlands","Buzink, S.N., Faculty of Industrial Design Engineering, Delft University of Technology, Landbergstraat 15, 2628 CE Delft, Netherlands, Department of Surgery, Catharina Hospital Eindhoven, Michelangelolaan 2, 5623 EJ Eindhoven, Netherlands; Goossens, R.H.M., Faculty of Industrial Design Engineering, Delft University of Technology, Landbergstraat 15, 2628 CE Delft, Netherlands, Department of Surgery, Catharina Hospital Eindhoven, Michelangelolaan 2, 5623 EJ Eindhoven, Netherlands; Schoon, E.J., Department of Gastroenterology, Catharina Hospital Eindhoven, Michelangelolaan 2, 5623 EJ Eindhoven, Netherlands; De Ridder, H., Faculty of Industrial Design Engineering, Delft University of Technology, Landbergstraat 15, 2628 CE Delft, Netherlands; Jakimowicz, J.J., Faculty of Industrial Design Engineering, Delft University of Technology, Landbergstraat 15, 2628 CE Delft, Netherlands","Background Surgical techniques that draw from multiple types of image-based procedures (IBP) are increasing, such as Natural Orifice Transluminal Endoscopic Surgery, fusing laparoscopy and flexible endoscopy. However, little is known about the relation between psychomotor skills for performing different types of IBP. For example, do basic psychomotor colonoscopy and laparoscopy skills interact? Methods Following a cross-over study design, 29 naïve endoscopists were trained on the Simbionix GI Mentor and the SimSurgery SEP simulators. Group C (n = 15) commenced with a laparoscopy session, followed by four colonoscopy sessions and a second laparoscopy session. Group L (n = 14) started with a colonoscopy session, followed by four laparoscopy sessions and a second colonoscopy session. Results No significant differences were found between the performances of group L and group C in their first training sessions on either technique. With additional colonoscopy training, group C outperformed group L in the second laparoscopy training session on the camera navigation task. Conclusions Overall, training in the basic colonoscopy tasks does not affect performance of basic laparoscopy tasks (and vice versa). However, to limited extent, training of basic psychomotor skills for colonoscopy do appear to contribute to the performance of angled laparoscope navigation tasks. Thus, training and assessment of IBP typespecific skills should focus on each type of tasks independently. Future research should further investigate the influence of psychometric abilities on the performance of IBP and the transfer of skills for physicians who are experienced in one IBP type and would like to become proficient in another type of IBP. © The Author(s) 2010.",,"article; clinical trial; colonoscopy; crossover procedure; education; endoscopy; human; laparoscopy; minimally invasive surgery; motor performance; psychomotor performance; Colonoscopy; Cross-Over Studies; Education; Educational Measurement; Endoscopy; Humans; Laparoscopy; Motor Skills; Psychomotor Performance; Surgical Procedures, Minimally Invasive",Article,"Final","",Scopus,2-s2.0-77954740541
"Jian C., Xiumin F.","35756105000;13104865800;","Dynamic model of an astronaut equipped with a manned maneuvering unit in virtual reality",2010,"Journal of Aerospace Engineering","23","2",,"139","145",,2,"10.1061/(ASCE)AS.1943-5525.0000018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949727166&doi=10.1061%2f%28ASCE%29AS.1943-5525.0000018&partnerID=40&md5=efc7081be83a93ec5de763a073208636","Institute of Computer Integrated Manufacturing, Shanghai Jiaotong Univ., Shanghai 200030, China","Jian, C., Institute of Computer Integrated Manufacturing, Shanghai Jiaotong Univ., Shanghai 200030, China; Xiumin, F., Institute of Computer Integrated Manufacturing, Shanghai Jiaotong Univ., Shanghai 200030, China","A virtual reality simulation system for a manned maneuvering unit (MMU) and a training system for an astronaut space walk is introduced. The system can simulate an astronaut's outer space walk by means of manipulating the MMU, and it also can be used as a training environment by taking advantage of virtual reality properties of imagination, interaction, and immersion. As in microgravity space, an astronaut's moving limbs cause changes in the MMU posture; these changes result in great offsets to correct direction and have a great effect on the MMU's manipulation performance. A multibody astronaut model is developed by using relative coordinates according to the motion characteristics of an astronaut equipped with MMU. Motion information on the user's limbs are captured by means of a motion capture subsystem and are mapped to an astronaut in virtual environment to simulate the astronaut's limb motions while the astronaut is navigating in outer space. It is an open-chain system for an astronaut multibody model. As an astronaut can control his limbs, the whole system dynamics is a hybrid forward and inverse dynamic problem. Recursive dynamic formulations of a previous method are introduced to solve the forward dynamic problem. For the inverse dynamic part, because the system can get motion characteristics of parts of the relative coordinates, unknown generalized driving forces are applied on these known relative coordinates. All the unknown generalized driving forces and unknown relative coordinates can be combined in a set of hybrid dynamic formulations based on a forward dynamic formulation. The motion characteristics of an astronaut multibody model can be obtained by solving the hybrid formulations. Finally, some simulation results for astronaut forward-flying mode with moving limbs are presented; these results show that the movement of an astronaut's limbs has great effects on astronaut navigation and MMU manipulation performance. The multibody astronaut model has the capability of simulating real space walk with an MMU equipped astronaut. © 2010 ASCE.","Aerospace engineering; Dynamic models; Hybrid dynamic formulation; Hybrid methods; Manned maneuvering unit; Multibody; Simulation; Virtual reality","Hybrid dynamics; Hybrid method; Manned maneuvering units; Multibody; Multibody simulations; Simulation; Aerospace engineering; Chains; Hybrid sensors; Models; Virtual reality; Dynamic models",Article,"Final","",Scopus,2-s2.0-77949727166
"Sankaranarayanan G., Lin H., Arikatla V.S., Mulcare M., Zhang L., Derevianko A., Lim R., Fobert D., Cao C., Schwaitzberg S.D., Jones D.B., De S.","15623319200;36027219300;26654027600;55406555500;37076447700;36893032600;35749955200;35749907800;25957557800;7007036892;55387240300;7202304567;","Preliminary face and construct validation study of a virtual basic laparoscopic skill trainer",2010,"Journal of Laparoendoscopic and Advanced Surgical Techniques","20","2",,"153","157",,24,"10.1089/lap.2009.0030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949641337&doi=10.1089%2flap.2009.0030&partnerID=40&md5=5c1b1da6b01ec04be981accc93bca65d","Department of Mechanical, Aerospace and Nuclear Engineering, Rensselaer Polytechnic Institute, JEC 2046, 110 8th Street, Troy, NY 12180, United States; Department of Surgery, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; Department of Mechanical Engineering, Tufts University, Medford, MA, United States; Carl J. Shapiro Simulation and Skills Center, Beth Israel Deaconess Medical Center, Boston, MA, United States; Cambridge Health Alliance, Cambridge, MA, United States","Sankaranarayanan, G., Department of Mechanical, Aerospace and Nuclear Engineering, Rensselaer Polytechnic Institute, JEC 2046, 110 8th Street, Troy, NY 12180, United States; Lin, H., Department of Surgery, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; Arikatla, V.S., Department of Mechanical, Aerospace and Nuclear Engineering, Rensselaer Polytechnic Institute, JEC 2046, 110 8th Street, Troy, NY 12180, United States; Mulcare, M., Department of Mechanical Engineering, Tufts University, Medford, MA, United States; Zhang, L., Department of Mechanical Engineering, Tufts University, Medford, MA, United States; Derevianko, A., Carl J. Shapiro Simulation and Skills Center, Beth Israel Deaconess Medical Center, Boston, MA, United States; Lim, R., Department of Surgery, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; Fobert, D., Carl J. Shapiro Simulation and Skills Center, Beth Israel Deaconess Medical Center, Boston, MA, United States; Cao, C., Department of Mechanical Engineering, Tufts University, Medford, MA, United States; Schwaitzberg, S.D., Cambridge Health Alliance, Cambridge, MA, United States; Jones, D.B., Department of Surgery, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; De, S., Department of Mechanical, Aerospace and Nuclear Engineering, Rensselaer Polytechnic Institute, JEC 2046, 110 8th Street, Troy, NY 12180, United States","Background: The Virtual Basic Laparoscopic Skill Trainer (VBLaST™) is a developing virtual-reality-based surgical skill training system that incorporates several of the tasks of the Fundamentals of Laparoscopic Surgery (FLS) training system. This study aimed to evaluate the face and construct validity of the VBLaST™ system. Materials and Methods: Thirty-nine subjects were voluntarily recruited at the Beth Israel Deaconess Medical Center (Boston, MA) and classified into two groups: experts (PGY 5, fellow and practicing surgeons) and novice (PGY 1-4). They were then asked to perform three FLS tasks, consisting of peg transfer, pattern cutting, and endoloop, on both the VBLaST and FLS systems. The VBLaST performance scores were automatically computed, while the FLS scores were rated by a trained evaluator. Face validity was assessed using a 5-point Likert scale, varying from not realistic/useful (1) to very realistic/useful (5). Results: Face-validity scores showed that the VBLaST system was significantly realistic in portraying the three FLS tasks (3.95±0.909), as well as the reality in trocar placement and tool movements (3.67±0.874). Construct-validity results show that VBLaST was able to differentiate between the expert and novice group (P=0.015). However, of the two tasks used for evaluating VBLaST, only the peg-transfer task showed a significant difference between the expert and novice groups (P=0.003). Spearman correlation coefficient analysis between the two scores showed significant correlation for the peg-transfer task (Spearman coefficient 0.364; P=0.023). Conclusions: VBLaST demonstrated significant face and construct validity. A further set of studies, involving improvement to the current VBLaST system, is needed to thoroughly demonstrate face and construct validity for all the tasks. Copyright 2010, Mary Ann Liebert, Inc.",,"article; construct validity; face validity; laparoscopic surgery; medical education; medical expert; medical practice; priority journal; scoring system; surgical technique; task performance; virtual reality; Adult; Clinical Competence; Competency-Based Education; Education, Medical, Continuing; Education, Medical, Graduate; Educational Measurement; Endoscopy; Female; Humans; Laparoscopy; Male; Statistics, Nonparametric; Task Performance and Analysis; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-77949641337
"Kruglikova I., Grantcharov T.P., Drewes A.M., Funch-Jensen P.","35210468300;6603695319;35477645700;7005950921;","The impact of constructive feedback on training in gastrointestinal endoscopy using high-fidelity virtual-reality simulation: A randomised controlled trial",2010,"Gut","59","2",,"181","185",,73,"10.1136/gut.2009.191825","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77149164124&doi=10.1136%2fgut.2009.191825&partnerID=40&md5=889e7c5b919c410e98df820015b08fd4","Department of Surgical Gastroenterology L, Aarhus University Hospital, Noerrebrogade 44, DK-8000 Aarhus C, Denmark; Department of Surgery, University of Toronto, St. Michael's Hospital, Toronto, ON, Canada; Department of Gastroenterology M, Aalborg University Hospital, Aalborg, Denmark","Kruglikova, I., Department of Surgical Gastroenterology L, Aarhus University Hospital, Noerrebrogade 44, DK-8000 Aarhus C, Denmark; Grantcharov, T.P., Department of Surgery, University of Toronto, St. Michael's Hospital, Toronto, ON, Canada; Drewes, A.M., Department of Gastroenterology M, Aalborg University Hospital, Aalborg, Denmark; Funch-Jensen, P., Department of Surgical Gastroenterology L, Aarhus University Hospital, Noerrebrogade 44, DK-8000 Aarhus C, Denmark","Background: Recently, virtual reality computer simulators have been used to enhance traditional endoscopy teaching. Previous studies have demonstrated construct validity of these systems and transfer of virtual skills to the operating room. However, to date no simulator-training curricula have been designed and there is very little evidence on the impact of external feedback on acquisition of endoscopic skills. The aim of the present study was to assess the impact of external feedback on the learning curves on a VR colonoscopy simulator using inexperienced trainees. Materials and methods: 22 trainees, without colonoscopy experience were randomised to a group which received structured feedback provided by an experienced supervisor and a controlled group. All participants performed 15 repetitions of task 3 from the Introduction colonoscopy module of the Accu Touch Endoscopy simulator. Retention/transfer tests on simulator were performed 4-6 weeks after the last repetition. The proficiency levels were based on the performance of eight experienced colonoscopists. Results: All subjects were able to complete the procedure on the simulator. There were no perforations in the feedback group versus seven in the non-feedback group. Subjects in the feedback group reached expert proficiency levels in percentage of mucosa visualised and time to reach the caecum significantly faster compared with the control group. None of the groups demonstrated significant degradation of performance in simulator retention/transfer tests. Conclusion: Concurrent feedback given by supervisor concur an advantage in acquisition of basic colonoscopy skills and achieving of proficiency level as compared to independent training.",,"adult; article; cecum; clinical article; clinical trial; colonoscopy; controlled clinical trial; controlled study; degradation; feedback system; female; gastrointestinal endoscopy; human; learning; male; mucosa; perforation; priority journal; randomized controlled trial; simulation; simulator; skill; student; task performance; training; virtual reality; Adult; Clinical Competence; Colonoscopy; Computer Simulation; Education, Medical, Graduate; Educational Measurement; Endoscopy; Feedback, Psychological; Female; Gastroenterology; Humans; Male; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-77149164124
"Young G.","18439037900;","Virtually real emotions and the paradox of fiction: Implications for the use of virtual environments in psychological research",2010,"Philosophical Psychology","23","1",,"1","21",,11,"10.1080/09515080903532274","https://www.scopus.com/inward/record.uri?eid=2-s2.0-76149134346&doi=10.1080%2f09515080903532274&partnerID=40&md5=09bfd8f79bfbc78c7e764366f46f11f0","Nottingham Trent University-Psychology, Chaucer Building, Goldsmith Street, Nottingham, Nottinghamshire NG1 5LT, United Kingdom","Young, G., Nottingham Trent University-Psychology, Chaucer Building, Goldsmith Street, Nottingham, Nottinghamshire NG1 5LT, United Kingdom","Many of the psychological studies carried out within virtual environments are motivated by the idea that virtual research findings are generalizable to the non-virtual world. This idea is vulnerable to the paradox of fiction, which questions whether it is possible to express genuine emotion toward a character (or event) known to be fictitious. As many of these virtual studies are designed to elicit, broadly speaking, emotional responses through interactions with fictional characters (avatars) or objects/places, the issue raised by the paradox seems particularly apt. This paper assesses the extent to which the paradox of fiction constitutes a legitimate challenge to psychological research within virtual environments, and argues that any alleged conflict is in fact a product of an overly simplistic view of emotions which a more complete understanding resolves. Moreover, through a more detailed analysis of why the paradox cannot be sustained, one finds justification for the claim that emotions elicited through interactions with virtual (fictitious) objects/events are valid. However, their generalizability to the non-virtual world must still be treated with caution. © 2010 Taylor & Francis.","Affect program; Paradox of fiction; Quasi-emotions; Virtual psychology; Virtual reality",,Article,"Final","",Scopus,2-s2.0-76149134346
"Buzink S.N., Goossens R.H.M., Ridder H.D., Jakimowicz J.J.","14064457800;7006683516;35387764300;35391591600;","Training of basic laparoscopy skills on SimSurgery SEP",2010,"Minimally Invasive Therapy and Allied Technologies","19","1",,"35","41",,21,"10.3109/13645700903384468","https://www.scopus.com/inward/record.uri?eid=2-s2.0-76749123901&doi=10.3109%2f13645700903384468&partnerID=40&md5=4c021063286f3fbe55dc89303473597d","Delft University of Technology, Faculty of Industrial Design Engineering, Landbergstraat 15, 2628 CE, Delft, Netherlands; Department of Surgery, Catharina Hospital Eindhoven, Eindhoven, Netherlands","Buzink, S.N., Delft University of Technology, Faculty of Industrial Design Engineering, Landbergstraat 15, 2628 CE, Delft, Netherlands, Department of Surgery, Catharina Hospital Eindhoven, Eindhoven, Netherlands; Goossens, R.H.M., Delft University of Technology, Faculty of Industrial Design Engineering, Landbergstraat 15, 2628 CE, Delft, Netherlands; Ridder, H.D., Delft University of Technology, Faculty of Industrial Design Engineering, Landbergstraat 15, 2628 CE, Delft, Netherlands; Jakimowicz, J.J., Delft University of Technology, Faculty of Industrial Design Engineering, Landbergstraat 15, 2628 CE, Delft, Netherlands, Department of Surgery, Catharina Hospital Eindhoven, Eindhoven, Netherlands","The aim of this study was to assess the performance curve for novices training in bimanual tissue manipulation and angled laparoscope navigation, and compare those performances with the performances of experienced laparoscopic surgeons. The Camera Navigation task with a 30° angled laparoscope and the Place Arrow task of the new SimSurgery SEP virtual reality simulator were used. Fourteen medical trainees (no laparoscopy experience) performed four training sessions within one week, including 15 repetitions of each task in total. The experienced participants (>50 procedures & familiar with angled laparoscope) performed each task twice. The performance on both tasks by the novices improved significantly over the training sessions. The experienced participants performed both tasks significantly better than the novices in repetition 3. After repetition 15, the performances of the novices on both tasks were of the same level as the performances of the experienced participants. By training on SimSurgery SEP, medical trainees can extensively improve their skills in navigation with 30° angled laparoscope and bimanual tissue manipulation. Further research should focus on the transfer of skills acquired on the simulator to the clinical setting. Knowledge on proficiency thresholds and training end-points for pre-clinical criterion-based training of different laparoscopic tasks also needs to be extended.","Bimanual tissue manipulation; Laparoscope navigation; Laparoscopy; Simulator training; Skills assessment","article; clinical competence; job experience; job performance; laparoscopic surgery; medical education; medical practice; priority journal; surgical approach; surgical technique; task performance; virtual reality; Clinical Competence; Computer Simulation; Educational Measurement; Humans; Laparoscopes; Laparoscopy; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-76749123901
"Wiederhold B.K., Wiederhold M.D.","7003634518;7005352040;","Virtual reality treatment of posttraumatic stress disorder due to motor vehicle accident",2010,"Cyberpsychology, Behavior, and Social Networking","13","1",,"21","27",,23,"10.1089/cyber.2009.0394","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949693671&doi=10.1089%2fcyber.2009.0394&partnerID=40&md5=e608792b09956b6862d2a9ac74c3cd60","Virtual Reality Medical Institute, 28/7 Rue de la Loi, 1040 Brussels, Belgium; Virtual Reality Medical Center, San Diego, CA, United States","Wiederhold, B.K., Virtual Reality Medical Institute, 28/7 Rue de la Loi, 1040 Brussels, Belgium; Wiederhold, M.D., Virtual Reality Medical Center, San Diego, CA, United States","Posttraumatic stress disorder (PTSD) is a complex, multifaceted disorder encompassing behavioral, emotional, cognitive, and physiological factors. Although PTSD was only codified in 1980, there has been an increasing interest in this area of research. Unfortunately, relatively little attention has been given to the psychological treatment of motor vehicle accident survivors, which is remarkable because vehicular collisions are deemed the number one cause of PTSD. As the emotional consequences of vehicular collisions prevail, so does the need for more effective treatments. Randomized controlled clinical trials have identified exposure-based therapies as being the most efficacious for extinguishing fears. One type of exposure-based treatment, called virtual reality exposure therapy (VRET), provides a safe, controlled, and effective therapeutic alternative that is not dependent on real-life props, situations, or even a person's imagination capabilities. This modality, while relatively new, has been implemented successfully in the treatment of a variety of anxiety disorders and may offer a particularly beneficial and intermediary step for the treatment of collision-related PTSD. In particular, VRET combined with physiological monitoring and feedback provides a unique opportunity for individuals to objectively recognize both anxiety and relaxation; learn how to manage their anxiety during difficult, albeit simulated, driving conditions; and then transfer these skills onto real-life roadways. © Copyright 2010, Mary Ann Liebert, Inc. 2010.",,"computer interface; computer simulation; human; life event; methodology; posttraumatic stress disorder; psychological aspect; psychotherapy; review; traffic accident; treatment outcome; Accidents, Traffic; Computer Simulation; Humans; Life Change Events; Psychotherapy; Stress Disorders, Post-Traumatic; Treatment Outcome; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-77949693671
"Maschuw K., Hassan I., Bartsch D.K.","23019369500;7103346703;7101724849;","Surgical training using simulator: Virtual reality [Chirurgisches Training am Simulator: ""Virtual reality""]",2010,"Chirurg","81","1",,"19","24",,16,"10.1007/s00104-009-1757-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-74349087249&doi=10.1007%2fs00104-009-1757-1&partnerID=40&md5=f3910d7f395598b5258cde0200ef72fa","Klinik für Visceral-, Thorax- und Gefäßchirurgie, Universitätsklinikum Gießen und Marburg, Standort Marburg, Philipps-Universität, Baldingerstraße, 35033 Marburg, Germany; Al Ain Hospital, Al Ain, United Arab Emirates","Maschuw, K., Klinik für Visceral-, Thorax- und Gefäßchirurgie, Universitätsklinikum Gießen und Marburg, Standort Marburg, Philipps-Universität, Baldingerstraße, 35033 Marburg, Germany; Hassan, I., Al Ain Hospital, Al Ain, United Arab Emirates; Bartsch, D.K., Klinik für Visceral-, Thorax- und Gefäßchirurgie, Universitätsklinikum Gießen und Marburg, Standort Marburg, Philipps-Universität, Baldingerstraße, 35033 Marburg, Germany","Learning of laparoscopic operative skills is often complex and time consuming resulting in a learning curve especially for novices in surgery. Virtual reality (VR) simulation was developed as an alternative to conventional training, such as active assistance and conventional laparoscopic training with artificially perfused organs (Pop-Trainer). VR simulation enables a wide range of repeatable laparoscopic techniques in variable virtual scenarios. For abdominal surgery four different simulation systems (MIST-VR®, LapSim®, Simsurgery®, Lap-Mentor®) are currently available and the modules allow simulation of abstract exercises to more advanced laparoscopic procedures, such as laparoscopic sigmoid resection. The effect of VR training on laparoscopic performance and its impact on non-technical skills was evaluated using the simulator LapSim® after a constructive validity study. Novices benefited most from VR training and performance in the operating room improved significantly after VR training. Good spatial perception and positive stress coping strategies also enhanced laparoscopic performance. VR simulation provides a tool to shift the laparoscopic learning curve outside the operating room and thus contributes to patient safety. It would be worthwhile to include VR training in the surgical curriculum. For economic reasons regional training centers seem to be an effective way to realize a broad implementation of VR simulation in surgical training. Application and development of VR simulators should be professionally promoted just as flight simulators in aviation. © Springer Medizin Verlag 2009.","Minimally invasive surgery; Simulation training; Stress coping strategie; Surgical training; Virtual reality","article; audiovisual equipment; clinical competence; computer interface; computer simulation; curriculum; education; general surgery; Germany; human; instrumentation; laparoscopy; learning; methodology; minimally invasive surgery; teaching; Clinical Competence; Computer Simulation; Computer-Assisted Instruction; Curriculum; General Surgery; Germany; Humans; Laparoscopy; Models, Anatomic; Surgical Procedures, Minimally Invasive; Transfer (Psychology); User-Computer Interface",Article,"Final","",Scopus,2-s2.0-74349087249
"Wallet G., Sauzéon H., Rodrigues J., Larrue F., N'kaoua B.","26425357400;7801452039;26425235600;36139685200;6603602499;","Virtual/real transfer of spatial learning: Impact of activity according to the retention delay",2010,"Studies in Health Technology and Informatics","154",,,"145","149",,10,"10.3233/978-1-60750-561-7-145","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954609123&doi=10.3233%2f978-1-60750-561-7-145&partnerID=40&md5=aeafac012e6e3e11d68001d55853b7bb","Laboratoire Cognition et Facteurs Humains (EA-487), Université Victor Segalen Bordeaux II, France","Wallet, G., Laboratoire Cognition et Facteurs Humains (EA-487), Université Victor Segalen Bordeaux II, France; Sauzéon, H., Laboratoire Cognition et Facteurs Humains (EA-487), Université Victor Segalen Bordeaux II, France; Rodrigues, J., Laboratoire Cognition et Facteurs Humains (EA-487), Université Victor Segalen Bordeaux II, France; Larrue, F., Laboratoire Cognition et Facteurs Humains (EA-487), Université Victor Segalen Bordeaux II, France; N'kaoua, B., Laboratoire Cognition et Facteurs Humains (EA-487), Université Victor Segalen Bordeaux II, France","Within the framework of cognitive rehabilitation using virtual reality (VR), one of the major challenges is to study beforehand the effectiveness of the virtual-real transfer of learning and to define cognitive aids. The aim of this experiment was to verify if, after learning spatial knowledge (i.e., a route) in VR, performances can be transferred to reality, then maintained in real time, and improved with the aid of an active navigation (i.e., using a joystick). Ninety student volunteers from the University of Bordeaux 2 (45 men and 45 women) participated in the experiment. The virtual environment (VE) used for learning was a replica of an area of Bordeaux. The factors tested were retention delay (Immediate vs. 48 hours) and type of navigation (Passive virtual vs. Active virtual vs. Real), using three recall tasks: wayfinding, freehand sketch and photograph classification. Our results showed that the virtual-real transfer was not degraded by a retention delay of 48 hours and that active navigation allowed performances to be optimized. © 2010 The Interactive Media Institute and IOS Press. All rights reserved.","exploration mode; knowledge transfer; recall tasks; retention delay; spatial cognition; Virtual reality","Knowledge management; Navigation; Virtual reality; Cognitive rehabilitation; Knowledge transfer; recall tasks; Retention delays; Spatial cognition; Spatial knowledge; Student volunteers; Transfer of learning; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-77954609123
"Dorlette Paul M., Rupasinghe T., Cho B.R., Gramopadhye A., Vembar D., Duchowski A., Washburn C.","47961816000;36714335600;7401747631;7005569103;14822811300;6701824388;23096821100;","Virtual borescope in training aircraft maintenance technicians: Transfer effect study",2010,"IIE Annual Conference and Expo 2010 Proceedings",,,,"","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901009071&partnerID=40&md5=7b57e7f5fbc48280c4e80ff2a5ca552d","Department of Industrial Engineering, Clemson University, Clemson, SC 29634, United States; Department of Computer Science, Clemson University, Clemson, SC 29634, United States; Greenville Technical College, Greenville, SC 29607, United States","Dorlette Paul, M., Department of Industrial Engineering, Clemson University, Clemson, SC 29634, United States; Rupasinghe, T., Department of Industrial Engineering, Clemson University, Clemson, SC 29634, United States; Cho, B.R., Department of Industrial Engineering, Clemson University, Clemson, SC 29634, United States; Gramopadhye, A., Department of Industrial Engineering, Clemson University, Clemson, SC 29634, United States; Vembar, D., Department of Computer Science, Clemson University, Clemson, SC 29634, United States; Duchowski, A., Department of Computer Science, Clemson University, Clemson, SC 29634, United States; Washburn, C., Greenville Technical College, Greenville, SC 29607, United States","This study assesses the value of virtual reality (VR) based training in borescope aided reviews of aircraft engines. A group of Greenville Technical College students, with academic knowledge of borescope inspection procedures, was split quasi-randomly into two groups based on subjects' Graduate Point Average. Each underwent training with respectively the borescope, and the simulator. Speed, accuracy and perceptions of ease of use and usefulness were collected and analyzed. Results indicate that there were no significant differences in performance between the two groups of students, thus VR may be an acceptable method of hands-on training.","Human factors; Training; Virtual reality","Aircraft engines; Human engineering; Optical instruments; Personnel training; Students; Virtual reality; Aircraft maintenance technicians; Borescope inspection; Ease-of-use; Hands-on-trainings; Technical college; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-84901009071
"Smit F., van Liere R., Beck S., Froehlich B.","18435203500;57195257466;18433681600;18433968300;","A shared-scene-graph image-warping architecture for VR: Low latency versus image quality",2010,"Computers and Graphics (Pergamon)","34","1",,"3","16",,5,"10.1016/j.cag.2009.10.006","https://www.scopus.com/inward/record.uri?eid=2-s2.0-75149145853&doi=10.1016%2fj.cag.2009.10.006&partnerID=40&md5=5f88c5a0467d50504dd7fd4c9fffe7d5","CWI, Amsterdam, Netherlands; Bauhaus-Universität Weimar, Germany","Smit, F., CWI, Amsterdam, Netherlands; van Liere, R., CWI, Amsterdam, Netherlands; Beck, S., Bauhaus-Universität Weimar, Germany; Froehlich, B., Bauhaus-Universität Weimar, Germany","Designing low end-to-end latency system architectures for virtual reality is still an open and challenging problem. We describe the design, implementation and evaluation of a client-server depth-image warping architecture that updates and displays the scene graph at the refresh rate of the display. Our approach works for scenes consisting of dynamic and interactive objects. The end-to-end latency is minimized as well as smooth object motion generated. However, this comes at the expense of image quality inherent to warping techniques. To improve image quality, we present a novel way of detecting and resolving occlusion errors due to warping. Furthermore, we investigate the use of asynchronous data transfers to increase the architecture's performance in a multi-GPU setting. Besides polygonal rendering, we also apply image-warping techniques to iso-surface rendering. Finally, we evaluate the architecture and its design trade-offs by comparing latency and image quality to a conventional rendering system. Our experience with the system confirms that the approach facilitates common interaction tasks such as navigation and object manipulation. © 2009 Elsevier Ltd. All rights reserved.","Image-based rendering; Latency; Virtual reality","Air navigation; Architecture; Computer architecture; Data transfer; Economic and social effects; Image enhancement; Image quality; Quality control; Virtual reality; Asynchronous data transfers; End to end latencies; Image based rendering; Interactive objects; Latency; Object manipulation; System architectures; Warping techniques; Rendering (computer graphics)",Article,"Final","",Scopus,2-s2.0-75149145853
"Liang J.S.","7404541082;","An approach for generating a tasks schedule model in web-based virtual manufacturing system of screw threads",2010,"International Journal of Advanced Manufacturing Technology","46","5-8",,"737","755",,8,"10.1007/s00170-009-2148-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-74249122700&doi=10.1007%2fs00170-009-2148-y&partnerID=40&md5=856658ebec5cf3b9b64b5550796d0a89","Department of Vehicle Engineering, Yung-Ta Institute of Technology and Commerce, 316 Chunshan Road, Linlo, Ping Tung 909, Taiwan","Liang, J.S., Department of Vehicle Engineering, Yung-Ta Institute of Technology and Commerce, 316 Chunshan Road, Linlo, Ping Tung 909, Taiwan","In this paper, several web-based interfaces for user interaction and a task-oriented decision approach are proposed to build a tasks schedule model and then display the manufacturing process in a virtual environment, which is created by a geometric virtual-reality-based visualization technology for screw threads generation. The proposed tasks schedule model consists of four types of objects: virtual component, state manager, transfer operator, and flow controller. The virtual component has a geometric model with kinematics and their attributes. To control the geometric model, a component controller which models the logical aspects of a component is used. The component controller should be able to implement component-level orders by operating the geometric model. For the fidelity of the tasks schedule model, a transfer operator has a set of component-level command imitating the physical mechanism of a transfer. As a result, more accurate simulation results can be expected. The flow controller makes decisions on friable transfers based on decision parameters, which are maintained by the state manager. To have better structure and easier implementation, a virtual manufacturing platform can be modeled in a hierarchical and modular manner as an integrated system consisting of a product design suite, a web interface module, and a visualization module. Meanwhile, it provides a solution of learning of manufacturing sequences, cost effective, platform independent, and sharing visualized information over the internet for virtual manufacturing. Finally, the tasks schedule model has been implemented with an example in screw threads generation. © 2009 Springer-Verlag London Limited.","Screw threads generation; Tasks schedule model; Virtual manufacturing environment","Cost effective; Decision parameters; Flow controllers; Geometric models; Integrated systems; Manufacturing process; Physical mechanism; Platform independent; Simulation result; Transfer operator; User interaction; Virtual components; Virtual environments; Virtual manufacturing; Virtual manufacturing environment; Visualization modules; Visualization technologies; Web interface; Web-based interface; Agile manufacturing systems; Controllers; Flow control; Geometry; Integrated optics; Management; Managers; Product design; Virtual reality; Visualization; Screw threads",Article,"Final","",Scopus,2-s2.0-74249122700
"Miller R.M., Tsui Y.H.W., Dearden T., Wolthuis S.L., Stanley T.","55493267000;56069395000;56070255700;55348956900;19640442700;","Learning and human computer interactions: Does wii bowling transfer to real bowling?",2010,"IMSCI 2010 - 4th International Multi-Conference on Society, Cybernetics and Informatics, Proceedings","1",,,"164","167",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896290739&partnerID=40&md5=4420d81fe4c780b25640f194d670fb0e","Brigham Young University-Hawaii, 55-220 Kulanui, St. Laie, HI 96762, United States","Miller, R.M., Brigham Young University-Hawaii, 55-220 Kulanui, St. Laie, HI 96762, United States; Tsui, Y.H.W., Brigham Young University-Hawaii, 55-220 Kulanui, St. Laie, HI 96762, United States; Dearden, T., Brigham Young University-Hawaii, 55-220 Kulanui, St. Laie, HI 96762, United States; Wolthuis, S.L., Brigham Young University-Hawaii, 55-220 Kulanui, St. Laie, HI 96762, United States; Stanley, T., Brigham Young University-Hawaii, 55-220 Kulanui, St. Laie, HI 96762, United States","The Wii video game console has many games that include physical movements related to the actual activity being simulated. What this paper proposes to do is measure in controlled experiments the transfer of experience from simulated bowling to actual bowling on a real lane. Certainly simulation has been used by many organizations, for example flight simulators in the military, to lower total training costs. And clearly some experience is transferable, but how much? This is an experiment to quantify experience gain in a simulation environment as applied later to an actual task. Analysis will include a characterization of the simulation tool from the perspective of the Information Technology discipline of Human Computer Interaction.","Bowling; Gaming console; Presence; Wii","Cybernetics; Experiments; Flight simulators; Information science; Information technology; Bowling; Controlled experiment; Gaming consoles; Physical movements; Presence; Simulation environment; Video game consoles; Wii; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-84896290739
"Danilicheva P., Klimenko S., Baturin Y., Serebrov A.","35226263400;7101864397;6603102121;35273061100;","Education in virtual worlds: Virtual storytelling",2009,"2009 International Conference on CyberWorlds, CW '09",,, 5279531,"333","338",,20,"10.1109/CW.2009.57","https://www.scopus.com/inward/record.uri?eid=2-s2.0-72349095655&doi=10.1109%2fCW.2009.57&partnerID=40&md5=1e32755c357e46d22ed238f6737359b5","Institute of Computing for Physics and Technology, Protvino, Moscow region, Russian Federation","Danilicheva, P., Institute of Computing for Physics and Technology, Protvino, Moscow region, Russian Federation; Klimenko, S., Institute of Computing for Physics and Technology, Protvino, Moscow region, Russian Federation; Baturin, Y., Institute of Computing for Physics and Technology, Protvino, Moscow region, Russian Federation; Serebrov, A., Institute of Computing for Physics and Technology, Protvino, Moscow region, Russian Federation","This paper is dedicated to the idea of studying in virtual worlds and discusses how virtual storytelling technology (VST) can provide an educational process. We try to answer the question - is it possible to substitute a real learning environment with a fully immersive 3D virtual space? And if so, what role should a virtual teacher play and what skills should he have? We describe several advantages that virtual environment (VE) has as compared to an ordinary classroom. It enables children to explore a phenomenon involved and gives them a strong incentive to study. Further, in VE we can transfer a lesson to inaccessible places and carry out demonstrations and experiments that are unrealizable on Earth. We consider the relationship between VST and game-like environments. We present some particular educational applications developed at our institute on the basis of Avango VR-system. Finally, we discuss the future of educational virtual environments and virtual storytelling. © 2009 IEEE.","Education in virtual worlds; Interactive narrative; Lessons from space; Virtual storytelling","3D virtual spaces; Educational Applications; Educational process; Educational virtual environments; Immersive; Interactive narrative; Learning environments; Virtual environments; Virtual storytelling; Virtual worlds; Teaching; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-72349095655
"Adelola I.A., Cox S.L., Rahman A.","35184914700;57207415134;36925388200;","Virtual environments for powered wheelchair learner drivers: Case studies",2009,"Technology and Disability","21","3",,"97","106",,17,"10.3233/TAD-2009-0276","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70549085866&doi=10.3233%2fTAD-2009-0276&partnerID=40&md5=ca01cc421d63d7b1a09cf670abc6818d","Department of Electronic and Computer Engineering, University of Limerick, Limerick, Ireland; Department of Manufacturing and Operations Engineering, University of Limerick, Limerick, Ireland","Adelola, I.A., Department of Electronic and Computer Engineering, University of Limerick, Limerick, Ireland; Cox, S.L., Department of Manufacturing and Operations Engineering, University of Limerick, Limerick, Ireland; Rahman, A., Department of Electronic and Computer Engineering, University of Limerick, Limerick, Ireland","Early intervention through the use of a powered wheelchair can meliorate the developmental experience of children with mobility impairment. It is therefore important to design an effective training and assessment strategy to facilitate the potentials of each child in readiness to drive the device. The use of virtual reality (VR) technology for wheelchair training purposes is therefore considered. The skills acquired during training in a virtual reality system should be observable in the functional activities of the learner. It is necessary to evaluate the degree and the permanence of the skills learnt from the virtual environment to other activities outside the training environment. The mode of evaluation applied during conventional wheelchair training could provide the basis upon which permanence of skills is determined after training in virtual reality. Thus, an induction factor is proposed as a measure of the transfer of powered wheelchair control skills from virtual reality to the functional activities of daily living by the learner. The outcomes show that virtual reality technology could offer an appropriate means of providing powered wheelchair training that can be tailored to the needs of the learner. © 2009 IOS Press. All rights reserved.","Induction factor; Powered wheelchair; Skills transfer; Training; Virtual reality","adolescent; article; assistive technology; case report; cerebral palsy; child; computer interface; daily life activity; early intervention; educational technology; female; human; human computer interaction; learning; learning disorder; male; motor dysfunction; outcome assessment; patient education; powered wheelchair; preschool child; skill retention; task performance; virtual reality",Article,"Final","",Scopus,2-s2.0-70549085866
"Repetto C., Gorini A., Algeri D., Vigna C., Gaggioli A., Riva G.","16025546600;23099679200;35217496800;24923793200;6603138127;56962750600;","The use of biofeedback in clinical virtual reality: The intrepid project",2009,"Annual Review of CyberTherapy and Telemedicine","7","1",,"128","132",,13,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-71749105754&partnerID=40&md5=b318ea666a80b42740fc1775180d6cff","Applied Technology for Neuropsychology Laboratory, Istituto Auxologico Italiano, Via Pelizza da Volpedo 41, Milano, Italy; Psychology Department, Catholic University of Milan, Italy; Research Institute Brain and Behaviour, Maastricht University, Netherlands","Repetto, C., Applied Technology for Neuropsychology Laboratory, Istituto Auxologico Italiano, Via Pelizza da Volpedo 41, Milano, Italy; Gorini, A., Applied Technology for Neuropsychology Laboratory, Istituto Auxologico Italiano, Via Pelizza da Volpedo 41, Milano, Italy, Research Institute Brain and Behaviour, Maastricht University, Netherlands; Algeri, D., Applied Technology for Neuropsychology Laboratory, Istituto Auxologico Italiano, Via Pelizza da Volpedo 41, Milano, Italy; Vigna, C., Applied Technology for Neuropsychology Laboratory, Istituto Auxologico Italiano, Via Pelizza da Volpedo 41, Milano, Italy; Gaggioli, A., Applied Technology for Neuropsychology Laboratory, Istituto Auxologico Italiano, Via Pelizza da Volpedo 41, Milano, Italy, Psychology Department, Catholic University of Milan, Italy; Riva, G., Applied Technology for Neuropsychology Laboratory, Istituto Auxologico Italiano, Via Pelizza da Volpedo 41, Milano, Italy, Psychology Department, Catholic University of Milan, Italy","In our protocol for the treatment of Generalized Anxiety Disorders we use Virtual reality (VR) to facilitate emotional regulation and the relaxation process. Using a biofeedback biomonitoring system (GSR, HR, Thermal) the patient is made aware of his or her reactions through the modification of some features of the VR environment in real time. Using mental exercises the patient learns to control these physiological parameters and using the feedback provided by the virtual environment is able to gauge his or her success. To test this concept, we planned a randomized controlled trial (NCT00602212), including three groups of 15 patients each (for a total of 45 patients): (1) the VR group, (2) the non-VR group, and (3) the waiting list (WL) group.","Biofeedback; Generalized anxiety disorders; Intrepid project; Virtual reality","article; biological monitoring; clinical article; clinical trial; controlled clinical trial; controlled study; electrodermal response; emotionality; exercise; feedback system; generalized anxiety disorder; human; leisure; randomized controlled trial; virtual reality; computer interface; computer simulation; emotion; environment; psychophysiology; Biofeedback; Physiological models; Biomonitoring; Generalized anxiety disorders; Intrepid project; Mental exercise; Physiological parameters; Randomized controlled trial; Real time; Waiting lists; Virtual reality; Biofeedback, Psychology; Computer Simulation; Emotions; Environment; Humans; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-71749105754
"Edlinger G., Krausz G., Groenegress C., Holzner C., Guger C., Slater M.","6602846965;6506292679;6508144123;33367618100;55903211100;7202932472;","Brain-Computer Interfaces for Virtual Environment Control",2009,"IFMBE Proceedings","23",,,"366","369",,6,"10.1007/978-3-540-92841-6_90","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891920897&doi=10.1007%2f978-3-540-92841-6_90&partnerID=40&md5=2f578b37243eef92b6802b5b40314d56","Guger Technologies OEG, Herbersteinstrasse 60, 8020 Graz, Austria; Centre de Realitat Virtual (CRV), Universitat Politècnica de Catalunya, Barcelona, Spain","Edlinger, G., Guger Technologies OEG, Herbersteinstrasse 60, 8020 Graz, Austria; Krausz, G., Guger Technologies OEG, Herbersteinstrasse 60, 8020 Graz, Austria; Groenegress, C., Centre de Realitat Virtual (CRV), Universitat Politècnica de Catalunya, Barcelona, Spain; Holzner, C., Guger Technologies OEG, Herbersteinstrasse 60, 8020 Graz, Austria; Guger, C., Guger Technologies OEG, Herbersteinstrasse 60, 8020 Graz, Austria; Slater, M., Centre de Realitat Virtual (CRV), Universitat Politècnica de Catalunya, Barcelona, Spain","A brain-computer interface (BCI) is a new communication channel between the human brain and a digital computer. Furthermore a BCI enables communication without using any muscle activity for a subject. The ambitious goal of a BCI is finally the restoration of movements, communication and environmental control for handicapped people. However, in more recent research also BCI control in combination with Virtual Environments (VE) gains more and more interest. Within this study we present experiments combining BCI systems and control VE for navigation and control purposes just by thoughts. A comparison of the applicability and reliability of different BCI types based on event related potentials (P300 approach) will be presented. BCI experiments for navigation in VR were conducted so far with (i) synchronous BCI and (ii) asynchronous BCI systems. A synchronous BCI analyzes the EEG patterns in a predefined time window and has 2-3 degrees of freedom. A asynchronous BCI analyzes the EEG signal continuously and if a specific event is detected then a control signal is generated. This study is focused on a BCI system that can be realized for Virtual Reality (VR) control with a high degree of freedom and high information transfer rate. Therefore a P300 based human computer interface has been developed in a VR implementation of a smart home for controlling. the environment (television, music, telephone calls) and navigation control in the house. Results show that the new P300 based BCI system allows a very reliable control of the VR system. Of special importance is the possibility to select very rapidly the specific command out of many different choices. This eliminates the usage of decision trees as previously done with BCI systems.","Brain-Computer Interface; evoked potential; P300; Virtual Environment","Environmental control; Event related potentials; High Degree of Freedom; Human computer interfaces; Information transfer rate; Navigation and control; P300; Virtual environment control; Automation; Bioelectric potentials; Biomedical engineering; Communication; Decision trees; Degrees of freedom (mechanics); Digital computers; Electroencephalography; Environmental management; Experiments; Human computer interaction; Intelligent buildings; Interfaces (computer); Navigation; Virtual reality; Brain computer interface",Conference Paper,"Final","",Scopus,2-s2.0-84891920897
"Koenig S.T., Crucian G.P., Dalrymple-Alford J.C., Dünser A.","35217731600;6603877788;57216532845;8649328200;","Virtual reality rehabilitation of spatial abilities after brain damage",2009,"Annual Review of CyberTherapy and Telemedicine","7","1",,"105","107",,5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-71749106575&partnerID=40&md5=09e13196fd95d2f45502acdcbb5faaec","University of Canterbury, Department of Psychology, Christchurch, New Zealand; HIT Lab NZ, University of Canterbury, Christchurch, New Zealand","Koenig, S.T., University of Canterbury, Department of Psychology, Christchurch, New Zealand; Crucian, G.P., University of Canterbury, Department of Psychology, Christchurch, New Zealand; Dalrymple-Alford, J.C., University of Canterbury, Department of Psychology, Christchurch, New Zealand; Dünser, A., HIT Lab NZ, University of Canterbury, Christchurch, New Zealand","Current rehabilitation of navigation and spatial orientation ability after brain damage is generally focused on training within the rehabilitation hospital or the patient's home as part of common physio- and occupational therapy sessions. To further promote generalization of gained abilities and to quantify functional improvements, this project aims at developing a Virtual Reality (VR) application that can be used for training and assessment of spatial orientation and navigation skills in brain-damaged patients. The training is administered after the standard hospital rehabilitation training is completed. Additionally, the program will be used as an assessment tool to quantify the participants' wayfinding performance. The data will be compared with real-world navigation performance in tasks of similar complexity to evaluate real-world transfer of the VR training. Currently, the application is under development and basic functionality and data acquisition are being implemented.","Navigation; Neuropsychological rehabilitation; Virtual reality","article; biomedical technology assessment; brain damage; computer interface; controlled study; human; occupational therapy; rehabilitation medicine; spatial orientation; training; virtual reality; brain; brain injury; computer interface; computer simulation; Brain; Data acquisition; Hospitals; Navigation; Patient treatment; Virtual reality; Assessment tool; Functional improvements; Navigation performance; Neuropsychological; Rehabilitation hospitals; Rehabilitation training; Spatial abilities; Spatial orientations; Patient rehabilitation; Brain; Brain Injuries; Computer Simulation; Humans; Spatial Navigation; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-71749106575
"Hoang T.N., Porter S.R., Thomas B.H.","14819594500;35180376500;55467685600;","Augmenting Image Plane AR 3D Interactions for Wearable Computers",2009,"Conferences in Research and Practice in Information Technology Series","93",,,"9","16",,3,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873305889&partnerID=40&md5=b5f50b20260cd223906abc6ff078b773","Wearable Computer Lab, School of Computer and Information Science, University of South Australia, Australia","Hoang, T.N., Wearable Computer Lab, School of Computer and Information Science, University of South Australia, Australia; Porter, S.R., Wearable Computer Lab, School of Computer and Information Science, University of South Australia, Australia; Thomas, B.H., Wearable Computer Lab, School of Computer and Information Science, University of South Australia, Australia","This paper presents a set of large object manipulation techniques implemented in a wearable augmented reality computer system that are optimised for the outdoor setting. These techniques supplement the current image plane approach, to provide a comprehensive solution to 3D object manipulation in an augmented reality outdoor environment. The three extended manipulation techniques, Revolve, Xscale, and Ground plane translation, are focused on using what we determined to be the best coordinate system for object rotation, scaling and translation. This paper goes on to present the generalised plane technique for the constrained translation of graphical objects on arbitrary planes to enable more complex translation operations. The paper presents the techniques from both the user interface and software development perspectives. © 2009, Australian Computer Society, Inc.","3D object manipulation; And virtual environments; Outdoor augmented reality; User interfaces","3D interactions; 3D object; Co-ordinate system; Current image; Graphical objects; Ground planes; Image plane; Manipulation techniques; Object manipulation; Outdoor augmented reality; Outdoor environment; Rotation , scaling and translations; Augmented reality; Three dimensional; Three dimensional computer graphics; Virtual reality; Wearable computers; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-84873305889
"Pallavicini F., Algeri D., Repetto C., Gorini A., Riva G.","6701879031;35217496800;16025546600;23099679200;56962750600;","Biofeedback, virtual reality and mobile phones in the treatment of generalized anxiety disorder (gad): A phase-2 controlled clinical trial",2009,"Journal of Cyber Therapy and Rehabilitation","2","4",,"315","327",,41,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-78649906371&partnerID=40&md5=86c62e8ce52b2289f70df76bc150ae22","Istituto Auxologico Italiano IRCCS, Applied Technology for Neuro-Psychology Laboratory, Milan, Italy; University of Milano-Bicocca, Italy; Department of Psychology, Catholic University of Milan, Italy; Research Institute Brain and Behaviour, Maastricht University, Netherlands","Pallavicini, F., Istituto Auxologico Italiano IRCCS, Applied Technology for Neuro-Psychology Laboratory, Milan, Italy, University of Milano-Bicocca, Italy; Algeri, D., Istituto Auxologico Italiano IRCCS, Applied Technology for Neuro-Psychology Laboratory, Milan, Italy; Repetto, C., Istituto Auxologico Italiano IRCCS, Applied Technology for Neuro-Psychology Laboratory, Milan, Italy, Department of Psychology, Catholic University of Milan, Italy; Gorini, A., Istituto Auxologico Italiano IRCCS, Applied Technology for Neuro-Psychology Laboratory, Milan, Italy, Research Institute Brain and Behaviour, Maastricht University, Netherlands; Riva, G., Istituto Auxologico Italiano IRCCS, Applied Technology for Neuro-Psychology Laboratory, Milan, Italy, Department of Psychology, Catholic University of Milan, Italy","Generalized Anxiety Disorder (GAD) is a psychiatric disease characterized by long-lasting anxiety that is not focused on a specific object or situation. Within the treatment of GAD, physical (relaxation and controlled breathing), behavioral (visualization and controlled exposure) and cognitive control strategies (challenging negative thoughts) represent a key part of the treatment, even if they difficult to learn. To overcome this limitation, the EU-funded INTREPID research project (IST-2002-507464) proposes improvement of exiting treatment for GAD through the use of a biofeedback-enhanced virtual reality (VR) system, used both for relaxation and controlled exposure. Furthermore, this experience is strengthened by the use of a mobile phone that allows patients to perform the virtual experience even in an outpatient setting. This approach was tested in a Phase II randomized controlled trial (NCT00602212), including three groups of four patients each, resulting in a total of 12 patients. The first group consisted of the VR and Mobile group (VRMB) including biofeedback, the second of the VR and Mobile group (VRM) without biofeedback, and the third the waiting list (WL) group. This study provides initial evidence for better efficacy of treatment for the VRMB group. Subjects belonging to this group reported a higher decrease in some of the anxiety psychometric questionnaires after the treatment than both VRM and WL groups, even if the VRM group, too, reported some significant improvements at the end of therapy. Moreover, qualitative reports concerning outpatient use of mobile phones suggests that it can solve a classical problem of VR therapies-the impossibility of using a VR system in the real life context of the patient. © Virtual Reality Medical Institute.","Biofeedback; Generalized anxiety disorder (GAD); Portable devices; Relaxation; Virtual reality (VR)","adult; article; Beck Anxiety Inventory; clinical article; clinical protocol; computer system; controlled study; feedback system; generalized anxiety disorder; Generalized Anxiety Disorder 7; Hamilton Anxiety Scale; human; mobile phone; patient satisfaction; Penn State Worry Questionnaire; psychometry; questionnaire; randomized controlled trial; State Trait Anxiety Inventory; training; treatment outcome; virtual reality; visual analog scale",Article,"Final","",Scopus,2-s2.0-78649906371
"Cárdenas G., Botella C., Quero S., Moreyra L., De La Rosa A., Muñoz S.","14420705400;7004121622;7801639581;35242959500;55534703500;36921831300;","A cross-cultural validation of VR treatment system for flying phobia in the Mexican population",2009,"Annual Review of CyberTherapy and Telemedicine","7","1",,"141","144",,2,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952984017&partnerID=40&md5=9e93536e56eb1f6dcbd0e916b7ee0dbd","National Autonomous University of Mexico, Mexico; Jaume i University, Spain","Cárdenas, G., National Autonomous University of Mexico, Mexico; Botella, C., Jaume i University, Spain; Quero, S., Jaume i University, Spain; Moreyra, L., National Autonomous University of Mexico, Mexico; De La Rosa, A., National Autonomous University of Mexico, Mexico; Muñoz, S., National Autonomous University of Mexico, Mexico","Anxiety as a symptom or disorder is affected by multiple variables such as antecedent events, interpretation of the events, psychological vulnerability, and individual differences in the reaction towards an event. Nowadays, virtual-reality therapy is used as therapeutic tool for patients suffering from some kind of anxiety disorder. In Mexico, the National Survey on Psychiatric Epidemiology [1] informed that anxiety disorders are the most common disorders followed by affective disorders, which are more prevalent in women than in men. Among the different anxiety disorders, the category of specific phobias (7.1%) was the most common. Based on this demand, a collaborative effort between research groups from the University Jaume I in Spain and the National Autonomous University of Mexico (UNAM), initiated a project which purpose was the technological transfer of systems based on virtual reality for the treatment of Fear of Flying to be implemented and evaluated in the Mexican population. The treatment protocol developed by Botella et al., [2] has been applied to five volunteer participants. In this paper we present data of adapted treatment protocols in Mexican population that support the efficacy of VR of treatment of fear of flying, achieved by the Spanish research group.","Cognitive-behavioral treatment; Fear of flying; Phobias; Virtual reality","adult; anxiety disorder; article; clinical article; cultural factor; female; human; Mexico; mood disorder; phobia; prevalence; psychological aspect; technology; treatment indication; validation process; virtual reality; anxiety disorder; cultural factor; fear; phobia; psychology; virtual reality exposure therapy; Anxiety Disorders; Cross-Cultural Comparison; Fear; Humans; Phobic Disorders; Virtual Reality Exposure Therapy",Article,"Final","",Scopus,2-s2.0-77952984017
"Qu Z., Jiang T.","23390440900;56767494400;","Research on the realization of substation virtual equipment based on 3D engine",2009,"IFCSTA 2009 Proceedings - 2009 International Forum on Computer Science-Technology and Applications","2",, 5384578,"299","302",,,"10.1109/IFCSTA.2009.195","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949828259&doi=10.1109%2fIFCSTA.2009.195&partnerID=40&md5=cfb757f5c5287418598249058e783e36","School of Information Engineering, Northeast Dianli University, Jilin City, Jilin Province, China","Qu, Z., School of Information Engineering, Northeast Dianli University, Jilin City, Jilin Province, China; Jiang, T., School of Information Engineering, Northeast Dianli University, Jilin City, Jilin Province, China","According to training requirements that a substation virtual training scene needs substation virtual equipment with high actual sense and high interaction. This paper proposes a thought which is used to achieve substation virtual equipment by 3D engine, and then generalizes a method which contains geometrical characteristic, interactive characteristic and behavioral characteristic towards Virtual equipment achieved by 3D engine. This method uses modeling tool to construct the geometrical appearance of substation virtual equipment, takes the 3D engine VR technique as core to realize interactive characteristic and behavioral characteristic of the virtual equipment. Combining with substation the application characteristics of substation virtual equipment, the paper proposes an interactive algorithm suiting to virtual equipment to improve the interaction of virtual equipment. © 2009 IEEE.","Object-oriented; Substation; The 3D engine; Virtual equipment; Virtual reality","3D engine; Behavioral characteristics; Geometrical characteristics; Interactive algorithms; Modeling tool; Object oriented; Substation; The 3D engine; Training requirement; Virtual training; Computer science; Engines; Equipment; Virtual reality; Three dimensional",Conference Paper,"Final","",Scopus,2-s2.0-77949828259
"Berberich M., Amburn P., Moorhead R., Dyer J., Brill M.","36025051600;57213961315;7006526147;7202228406;23491677200;","Geospatial visualization using hardware accelerated real-time volume rendering",2009,"MTS/IEEE Biloxi - Marine Technology for Our Future: Global and Local Challenges, OCEANS 2009",,, 5422170,"","",,5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77951564335&partnerID=40&md5=1654cd008b732ef4b5f41b06d8b3dc8c","Geosystems Research Institute, Mississippi State University, Mississippi State, MS 39762, United States; Geosciences Department, Mississippi State University, Mississippi State, MS 39762, United States; Computer Science and Microsystems Technology Department, University of Applied Sciences Kaiserslautern, Zweibruecken, 66482, Germany","Berberich, M., Computer Science and Microsystems Technology Department, University of Applied Sciences Kaiserslautern, Zweibruecken, 66482, Germany; Amburn, P., Geosystems Research Institute, Mississippi State University, Mississippi State, MS 39762, United States; Moorhead, R., Geosystems Research Institute, Mississippi State University, Mississippi State, MS 39762, United States; Dyer, J., Geosciences Department, Mississippi State University, Mississippi State, MS 39762, United States; Brill, M., Computer Science and Microsystems Technology Department, University of Applied Sciences Kaiserslautern, Zweibruecken, 66482, Germany","We present a visualization framework using direct volume rendering techniques that achieves real-time performance and high image quality. The visualization program runs on a desktop as well as in an immersive environment. The application is named HurricaneVis, and it uses OpenGL, GLSL and VTK. For immersive visualization VRJuggler is added. To achieve real-time rendering rates for 4D scalar data we use the programmability of the GPU and in particular store the transfer functions as well as the 3D volume of scalar data on the GPU in texture memory. The initial use was visualization of scalar data from numerical weather model simulations of tropical cyclones, namely Hurricanes Isabelle and Lili. We are expanding that to include visualization of other types of data sets. We conducted a user study to compare the implemented volume rendering technique with state-of-the-art isosurface rendering. The subjects were students in the Dynamic Meteorology II and Physical Meteorology classes in the Department of Geosciences at Mississippi State University. The results establish that both volume rendering and isosurface visualizations are effective in examining data from computer simulations of hurricanes. Because of the higher image quality and the higher frame rates, direct volume rendering using ray-casting or view-aligned texture slicing was preferred. ©2009 MTS.",,"Data sets; Direct volume rendering; Frame rate; Geosciences; Geospatial visualization; Hardware-accelerated; High image quality; Immersive environment; Immersive visualization; Isabelle; Iso surface; Mississippi State University; Numerical weather model; Programmability; Raycasting; Real time performance; Real-time rendering; Scalar data; Texture memory; Texture slicing; Tropical cyclone; User study; Visualization framework; Computer graphics equipment; Computer simulation; Data transfer rates; Hurricanes; Image quality; Marine engineering; Oceanography; Textures; Visualization; Volume rendering; Data visualization",Conference Paper,"Final","",Scopus,2-s2.0-77951564335
"Ku C.-W., Tsai K.-L., Li P.-Y.","35785980900;35786435800;55495057500;","Medical Images Illustrator - A flexible image processing system",2009,"APSIPA ASC 2009 - Asia-Pacific Signal and Information Processing Association 2009 Annual Summit and Conference",,,,"887","894",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950580767&partnerID=40&md5=54e10882b4548065ca63f4919631247a","National Center for High-Performance Computing, Hsinchu, Taiwan","Ku, C.-W., National Center for High-Performance Computing, Hsinchu, Taiwan; Tsai, K.-L., National Center for High-Performance Computing, Hsinchu, Taiwan; Li, P.-Y., National Center for High-Performance Computing, Hsinchu, Taiwan","In this paper, we propose a medical image processing and visualization system, Medical Image Illustrator (MIIL), which is able to help doctors for symptom diagnosis, detection and surgical planning. MIIL can process and visualize the Digital Imaging and Communications in Medicine (DICOM) data directly. We have implemented some processing concepts, such as ""dynamic processing flow"", ""dynamic flowing branch"" and ""multiple masks / images operation"", which make MIIL a very flexible workbench for image processing. The system can also be easy extendable for different situations. Dynamic processing flow enables MIIL to apply a variety of 2D and 3D image processing algorithms on images or masks to filter out some features. This can results in better images for analysis and segmentation. Dynamic flowing branch allows the user to create different process-flow on images or masks. Each flowing branch can apply different operations independently. Users can also perform operations on multiple flows, or combine the results from different processing-flow. In the visualization stage, the 3D volume datasets are generated from different masks of 3D images. MIIL supports interactive direct volume rendering on multiple datasets, users can visualize these data with the ability to adjust the transfer function of each dataset individually. Therefore, MIIL could allow users to visualize and interact with multiple volumes that each volume represents different tissue or organ. Besides, MIIL also supports stereoscopic display, which is suitable for Virtual Reality (VR) application to enhance the visual effect. With above features, MIIL can provide very useful and decent visual effect to display medical or other 3D images. We will give two examples which use MIIL to process data. In the first case, we use MIIL to process the CT data of human chest. We were able to find possible tumor tissues in the data and provide visual analytics to these tissues. In the second case, we use MIIL to process the T1 MRI and Diffusion Spectrum MRI (DSI) together, doctors are able to visualize the relationship between tumor, tracts and brain structure. Based on the above two successful cases, we believe that MIIL is helpful for diagnosis and surgical planning for a trained medical staff.",,"3-D image; 3D image processing; Brain structure; CT data; Data sets; Different process; Diffusion spectra; Digital imaging and communications in medicines; Direct volume rendering; Human chest; Image processing system; Medical Image Processing; Medical images; Multiple flows; Process data; Processing flow; Stereoscopic display; Successful case; Surgical planning; Tumor tissues; Visual analytics; Visual effects; Visualization system; Volume data sets; Computer supported cooperative work; Computerized tomography; Data processing; Histology; Image processing; Imaging systems; Tumors; Virtual reality; Visual communication; Visualization; Volume rendering; Three dimensional",Conference Paper,"Final","",Scopus,2-s2.0-77950580767
"Watanuki K.","7005697643;","VR Mediated Skill Transfer",2009,"2008 Proceedings of the ASME International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, DETC 2008","3","PART B",,"1201","1206",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349231311&partnerID=40&md5=1801e164dca2357f0119daf0dedbb256","Department ot Mechanical engineering, Graduate School of Science and Engineering, Saitama University, 255 Shimo-okubo, Sakura-ku, Saitama-shi, Saitama 338-8570, Japan","Watanuki, K., Department ot Mechanical engineering, Graduate School of Science and Engineering, Saitama University, 255 Shimo-okubo, Sakura-ku, Saitama-shi, Saitama 338-8570, Japan","This paper proposes a new virtual reality mediated skill transfer and human resource development system for manufacturing technology and skill, which are composed of the explicit and tacit knowledge transfer systems using synchronized multimedia and the knowledge internalization system using portable virtual environment. In our proposed system, the education content is displayed in the immersive virtual environment, whereby a trainee may experience work in the virtual site operation. Provided that the trainee has gained explicit and tacit knowledge of casting through the multimedia-based knowledge transfer system, the immersive virtual environment catalyzes the internalization of knowledge and also enables the trainee to gain tacit knowledge before undergoing on-the-job training at a real-time operation site. Copyright © 2008 by ASME.",,"Explicit and tacit knowledge; Human resource development; Immersive virtual environments; Knowledge transfer; Manufacturing technologies; On-the-job training; Real-time operation; Site operations; Skill transfer; Tacit knowledge; Virtual environments; Knowledge management; Personnel training; Virtual reality; Multimedia systems",Conference Paper,"Final","",Scopus,2-s2.0-70349231311
"Elion O., Bahat Y., Siev-Ner I., Sela I., Karni A., Weiss P.L.","6505628303;25926895000;6602071770;36950653300;57207543301;55435137100;","No transfer of gains after a single training session within a virtual environment to fundamental tests of stability",2009,"2009 Virtual Rehabilitation International Conference, VR 2009",,, 05174220,"136","139",,1,"10.1109/ICVR.2009.5174220","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70449112527&doi=10.1109%2fICVR.2009.5174220&partnerID=40&md5=145568b1f4d6470b97879df1bd2a60ee","CAREN VR Lab., C Sheba Medical Centre, Tel Hashomer, Israel; Dept. of Neurobiology and Ethology, Dept. of Learning Disabilities, University of Haifa, Haifa, Israel; Dept. of Occupational Therapy, University of Haifa, Haifa, Israel","Elion, O., CAREN VR Lab., C Sheba Medical Centre, Tel Hashomer, Israel; Bahat, Y., CAREN VR Lab., C Sheba Medical Centre, Tel Hashomer, Israel; Siev-Ner, I., CAREN VR Lab., C Sheba Medical Centre, Tel Hashomer, Israel; Sela, I., Dept. of Neurobiology and Ethology, Dept. of Learning Disabilities, University of Haifa, Haifa, Israel; Karni, A., Dept. of Neurobiology and Ethology, Dept. of Learning Disabilities, University of Haifa, Haifa, Israel; Weiss, P.L., Dept. of Occupational Therapy, University of Haifa, Haifa, Israel","How specific are postural and balance control skills? An important issue for the establishment of effective training and retraining (rehabilitation) programs is whether skills gained while training in laboratory settings can be transferred to performance gains in somewhat different conditions (including every-day life). While there is much evidence showing that for volitional motor tasks the gains in performance (procedural, implicit, knowledge) accrued in practice may not always be transferable to novel task conditions, it is not clear whether the (implicit) knowledge gained in learning postural adjustments can be transferred to measures of balance (reaction to external perturbations) that have not been trained. The objective of the current study was to elucidate what aspects of a postural skill learned within a virtual environment (VE) by healthy adults may be transferable to the performance of standard tests of postural adjustments. Sixteen healthy young adults, aged 20-40 years (mean ± SD = 29.8 ± 2.8 years), were pseudo-randomly assigned to either a training group (Group A) or a no-training, control group (Group B). Group A performed a single training session in a VE in which maintenance of stability on a platform, while travelling along a road scenario and reaching for visual targets (secondary task) were required. Each participant underwent 8 consecutive runs of the task (2:48 m per run). A balance assessment with a given set of perturbations was performed before and after training as well as at 24 hours and 4 weeks post-training. Group B underwent the same assessments but without VE training. The results showed that the Center of Pressure (CoP) displacement tended to decrease over successive balance assessments in both groups, however, this decrease was not statistically significant. Moreover, there was no clear advantage for Group A. Thus, the postural adjustment gains were not transferred to the balance assessment tests. Nonvolitional balance control gains are, in this respect, similar to gains attained in a volitional manual task learning. ©2009 IEEE.","Postural adjustments; Procedural knowledge; Specificity; Transfer","Balance control; Before and after; Center of pressure; Control groups; External perturbations; Motor tasks; Novel task; Performance Gain; Postural adjustments; Procedural knowledge; Specificity; Standard tests; Task learning; Training sessions; Transfer; Virtual environments; Visual targets; Motion control; Virtual reality; Patient rehabilitation",Conference Paper,"Final","",Scopus,2-s2.0-70449112527
"Schlickum M.K., Hedman L., Enochsson L., Kjellin A., Felländer-Tsai L.","29167509300;7007166091;6602469928;6603625212;6603715643;","Systematic video game training in surgical novices improves performance in virtual reality endoscopic surgical simulators: A prospective randomized study",2009,"World Journal of Surgery","33","11",,"2360","2367",,133,"10.1007/s00268-009-0151-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350035549&doi=10.1007%2fs00268-009-0151-y&partnerID=40&md5=3a32673cf243bae5a70702ae1e7786e2","Department of Clinical Science Intervention and Technology (CLINTEC), Karolinska Institutet, Stockholm 141 86, Sweden; Center for Advanced Medical Simulation, Karolinska University Hospital, Stockholm 141 86, Sweden; Department of Psychology, Umeå University, Umeå 901 87, Sweden","Schlickum, M.K., Department of Clinical Science Intervention and Technology (CLINTEC), Karolinska Institutet, Stockholm 141 86, Sweden, Center for Advanced Medical Simulation, Karolinska University Hospital, Stockholm 141 86, Sweden; Hedman, L., Center for Advanced Medical Simulation, Karolinska University Hospital, Stockholm 141 86, Sweden, Department of Psychology, Umeå University, Umeå 901 87, Sweden; Enochsson, L., Department of Clinical Science Intervention and Technology (CLINTEC), Karolinska Institutet, Stockholm 141 86, Sweden, Center for Advanced Medical Simulation, Karolinska University Hospital, Stockholm 141 86, Sweden; Kjellin, A., Department of Clinical Science Intervention and Technology (CLINTEC), Karolinska Institutet, Stockholm 141 86, Sweden, Center for Advanced Medical Simulation, Karolinska University Hospital, Stockholm 141 86, Sweden; Felländer-Tsai, L., Department of Clinical Science Intervention and Technology (CLINTEC), Karolinska Institutet, Stockholm 141 86, Sweden, Center for Advanced Medical Simulation, Karolinska University Hospital, Stockholm 141 86, Sweden","Background: Previous studies have shown a correlation between previous video game experience and performance in minimally invasive surgical simulators. The hypothesis is that systematic video game training with high visual-spatial demands and visual similarity to endoscopy would show a transfer effect on performance in virtual reality endoscopic surgical simulation. Methods: A prospective randomized study was performed. Thirty surgical novices were matched and randomized to five weeks of systematic video game training in either a first-person shooter game (Half Life) with high visual-spatial demands and visual similarities to endoscopy or a video game with mainly cognitive demands (Chessmaster). A matched control group (n = 10) performed no video game training during five weeks. Performance in two virtual reality endoscopic surgical simulators (MIST-VR and GI Mentor II) was measured pre- and post-training. Before simulator training we also controlled for students' visual-spatial ability, visual working memory, age, and previous video game experience. Results: The group training with Half Life showed significant improvement in two GI Mentor II variables and the MIST-VR task MD level medium. The group training with Chessmaster only showed an improvement in the MIST-VR task. No effect was observed in the control group. As recently shown in other studies, current and previous video game experience was important for simulator performance. Conclusions: Systematic video game training improved surgical performance in advanced virtual reality endoscopic simulators. The transfer effect increased when increasing visual similarity. The performance in intense, visual-spatially challenging video games might be a predictive factor for the outcome in surgical simulation. © 2009 Société Internationale de Chirurgie.",,"adult; article; clinical trial; controlled clinical trial; controlled study; depth perception; endoscopic surgery; female; human; human experiment; male; minimally invasive surgery; normal human; psychomotor activity; randomized controlled trial; simulator; staff training; surgical training; systematic video game training; task performance; virtual reality; Adult; Computer Simulation; Educational Measurement; Endoscopy; Female; General Surgery; Humans; Male; Prospective Studies; Psychomotor Performance; Students, Medical; Video Games",Article,"Final","",Scopus,2-s2.0-70350035549
"Kaphingst K.A., Persky S., McCall C., Lachance C., Loewenstein J., Beall A.C., Blascovich J.","6602375694;23006054100;18037830200;36798249400;24341813000;7103222399;7003855290;","Testing the effects of educational strategies on comprehension of a genomic concept using virtual reality technology",2009,"Patient Education and Counseling","77","2",,"224","230",,9,"10.1016/j.pec.2009.03.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350084951&doi=10.1016%2fj.pec.2009.03.029&partnerID=40&md5=d2b745ff61e10f600dbb102b967e492e","Social and Behavioral Research Branch, National Human Genome Research Institute, Bethesda, United States; Department of Psychology, University of California-Santa Barbara, Santa Barbara, United States","Kaphingst, K.A., Social and Behavioral Research Branch, National Human Genome Research Institute, Bethesda, United States; Persky, S., Social and Behavioral Research Branch, National Human Genome Research Institute, Bethesda, United States; McCall, C., Department of Psychology, University of California-Santa Barbara, Santa Barbara, United States; Lachance, C., Social and Behavioral Research Branch, National Human Genome Research Institute, Bethesda, United States; Loewenstein, J., Social and Behavioral Research Branch, National Human Genome Research Institute, Bethesda, United States; Beall, A.C., Department of Psychology, University of California-Santa Barbara, Santa Barbara, United States; Blascovich, J., Department of Psychology, University of California-Santa Barbara, Santa Barbara, United States","Objective: Applying genetic susceptibility information to improve health will likely require educating patients about abstract concepts, for which there is little existing research. This experimental study examined the effect of learning mode on comprehension of a genomic concept. Methods: 156 individuals aged 18-40 without specialized knowledge were randomly assigned to either a virtual reality active learning or didactic learning condition. The outcome was comprehension (recall, transfer, mental models). Results: Change in recall was greater for didactic learning than for active learning (p < 0.001). Mean transfer and change in mental models were also higher for didactic learning (p < 0.0001 and p < 0.05, respectively). Believability was higher for didactic learning (p < 0.05), while ratings for motivation (p < 0.05), interest (p < 0.0001), and enjoyment (p < 0.0001) were higher for active learning, but these variables did not mediate the association between learning mode and comprehension. Conclusion: These results show that learning mode affects comprehension, but additional research is needed regarding how and in what contexts different approaches are best for educating patients about abstract concepts. Practice implications: Didactic, interpersonal health education approaches may be more effective than interactive games in educating patients about abstract, unfamiliar concepts. These findings indicate the importance of traditional health education approaches in emerging areas like genomics.","Genetic communication; Genetics; Learning approaches; Patient education","adult; article; attitude to health; comprehension; controlled study; education program; female; genetic susceptibility; happiness; health education; human; knowledge; learning; male; medical research; motivation; normal human; patient education; priority journal; recall; virtual reality; Adolescent; Adult; Analysis of Variance; Comprehension; Computer-Assisted Instruction; Female; Humans; Linear Models; Male; Mental Recall; Models, Educational; Patient Education as Topic; Risk Factors; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-70350084951
"Panait L., Akkary E., Bell R.L., Roberts K.E., Dudrick S.J., Duffy A.J.","6603648726;24334261800;7404520114;8604798500;57011758000;12243581200;","The Role of Haptic Feedback in Laparoscopic Simulation Training",2009,"Journal of Surgical Research","156","2",,"312","316",,139,"10.1016/j.jss.2009.04.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70249107719&doi=10.1016%2fj.jss.2009.04.018&partnerID=40&md5=8e07670a8d0bfaf001876256cdfbd1a2","Saint Mary's Hospital, Waterbury, CT, United States; Yale School of Medicine, New Haven, CT, United States","Panait, L., Saint Mary's Hospital, Waterbury, CT, United States; Akkary, E., Yale School of Medicine, New Haven, CT, United States; Bell, R.L., Yale School of Medicine, New Haven, CT, United States; Roberts, K.E., Yale School of Medicine, New Haven, CT, United States; Dudrick, S.J., Saint Mary's Hospital, Waterbury, CT, United States, Yale School of Medicine, New Haven, CT, United States; Duffy, A.J., Yale School of Medicine, New Haven, CT, United States","Introduction: Laparoscopic virtual reality simulators are becoming a ubiquitous tool in resident training and assessment. These devices provide the operator with various levels of realism, including haptic (or force) feedback. However, this feature adds significantly to the cost of the devices, and limited data exist assessing the value of haptics in skill acquisition and development. Utilizing the Laparoscopy VR (Immersion Medical, Gaithersburg, MD), we hypothesized that the incorporation of force feedback in the simulated operative environment would allow superior trainee performance compared with performance of the same basic skills tasks in a non-haptic model. Methods: Ten medical students with minimal laparoscopic experience and similar baseline skill levels as proven by performance of two fundamentals of laparoscopic surgery (FLS) tasks (peg transfer and cutting drills) voluntarily participated in the study. Each performed two tasks, analogous to the FLS drills, on the Laparoscopy VR at 3 levels of difficulty, based on the established settings of the manufacturer. After achieving familiarity with the device and tasks, the students completed the drills both with and without force feedback. Data on completion time, instrument path length, right and left hand errors, and grasping tension were analyzed. The scores in the haptic-enhanced simulation environment were compared with the scores in the non-haptic model and analyzed utilizing Student's t-test. Results: The peg transfer drill showed no difference in performance between the haptic and non-haptic simulations for all metrics at all three levels of difficulty. For the more complex cutting exercise, the time to complete the tasks was significantly shorter when force feedback was provided, at all levels of difficulty (158 ± 56 versus 187 ± 51 s, 176 ± 49 versus 222 ± 68 s, and 275 ± 76 versus 422 ± 220 s, at levels 1, 2, and 3, respectively, P < 0.05). Data on instrument path length, grasping tension, and errors showed a trend toward a benefit from haptics at all difficulty levels, but this difference did not achieve statistical significance. Conclusions: In the more advanced tasks, haptics allowed superior precision, resulting in faster completion of tasks and a trend toward fewer technical errors. In the more basic tasks, haptic-enhanced simulation did not demonstrate an appreciable performance improvement among our trainees. These data suggest that the additional expense of haptic-enhanced laparoscopic simulators may be justified for advanced skill development in surgical trainees as simulator technology continues to improve. © 2009 Elsevier Inc. All rights reserved.","force feedback; haptic; surgical simulation; virtual reality","article; laparoscopic surgery; laparoscopy; medical student; priority journal; simulation; surgical instrument; surgical training; virtual reality; Clinical Competence; Computer Simulation; Computer-Assisted Instruction; Education, Medical; Educational Measurement; Feedback; Humans; Internship and Residency; Laparoscopy; Students, Medical; Surgical Procedures, Operative; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-70249107719
"Domuracki K.J., Moule C.J., Owen H., Kostandoff G., Plummer J.L.","25958045400;36975299800;7102959280;25958124800;7203004612;","Learning on a simulator does transfer to clinical practice",2009,"Resuscitation","80","3",,"346","349",,51,"10.1016/j.resuscitation.2008.10.036","https://www.scopus.com/inward/record.uri?eid=2-s2.0-59649092905&doi=10.1016%2fj.resuscitation.2008.10.036&partnerID=40&md5=2a3b7d4ff02d6119f360d331eec8eae8","Department of Anaesthesia and Pain Medicine, Flinders University, Bedford Park, SA, Australia; SA and NT Rotational Training Scheme in Anaesthesia, Australia; Clinical Skills and Simulation Unit, Department of Medical Education, Department of Anaesthesia and Pain Medicine, Bedford Park, SA, Australia; Department of Anesthesia, McMaster University, Hamilton, Ont., Canada; Department of Anaesthesia and Intensive Care, Flinders University, Bedford Park, SA, Australia","Domuracki, K.J., Department of Anaesthesia and Pain Medicine, Flinders University, Bedford Park, SA, Australia; Moule, C.J., SA and NT Rotational Training Scheme in Anaesthesia, Australia; Owen, H., Clinical Skills and Simulation Unit, Department of Medical Education, Department of Anaesthesia and Pain Medicine, Bedford Park, SA, Australia; Kostandoff, G., Department of Anesthesia, McMaster University, Hamilton, Ont., Canada; Plummer, J.L., Department of Anaesthesia and Intensive Care, Flinders University, Bedford Park, SA, Australia","Aim of the study: Cricoid pressure is recommended during positive pressure ventilation CPR and during anaesthesia when there is a risk of regurgitation. Studies suggest that cricoid pressure is frequently applied incorrectly placing patients at risk of regurgitation. Simulation training has been shown to improve the performance of cricoid pressure on a simulator, but whether simulation training improves the clinical performance of cricoid pressure was unknown. The aim of our study was to determine if simulator training improved the clinical performance of cricoid pressure. Methods: 101 medical students and nursing staff were recruited and randomised to receive cricoid pressure simulator training with or without force feedback. Subjects then applied cricoid pressure to an anaesthetised patient while standing on a force plate. The main outcome measure was the number of subjects who applied a mean force of 20-30 N during their trial. Results: Significantly more subjects (20/53, 38%) in the feedback group applied force in the appropriate range (20-30 N) compared to the control group (9/48, 19%) (p = 0.035, chi square test). The feedback group applied significantly higher forces than did the control group (p = 0.029, Mann-Whitney U test). Conclusion: Simulation training with force feedback significantly improved the performance of cricoid pressure in the clinical setting. Simulation training should be used more frequently to train and maintain resuscitation skills. © 2008 Elsevier Ireland Ltd. All rights reserved.","Airway management; Anaesthesia; Aspiration; Cricoid pressure; Medical education; Simulation","adult; aged; airway pressure; article; clinical practice; control group; controlled study; cricoid; feedback system; human; human experiment; medical education; medical student; nursing staff; outcome assessment; priority journal; resuscitation; simulation; simulator; Adolescent; Adult; Aged; Anesthesia, General; Biomechanics; Cardiopulmonary Resuscitation; Cricoid Cartilage; Education, Medical, Graduate; Education, Nursing, Graduate; Gastroesophageal Reflux; Heart Arrest; Humans; Intraoperative Care; Manikins; Middle Aged; Pressure; Young Adult",Article,"Final","",Scopus,2-s2.0-59649092905
"Riecke B.E., Väljamäe A., Schulte-Pelkum J.","6603396361;15133296000;56242751100;","Moving sounds enhance the visually-induced self-motion illusion (circular vection) in virtual reality",2009,"ACM Transactions on Applied Perception","6","2", 7,"","",,67,"10.1145/1498700.1498701","https://www.scopus.com/inward/record.uri?eid=2-s2.0-63049105058&doi=10.1145%2f1498700.1498701&partnerID=40&md5=a4056d5c05d555f20bf63bb1d716512f","Max Planck Institute for Biological Cybernetics, Germany; Chalmers University of Technology, Sweden; Simon Fraser University, 250-13450 102nd Ave., Surrey, BC V3T 0A3, Canada; CRAGmsa, Division of Applied Acoustics, Chalmers University of Technology, Sven Hultins gata 8a, 41296, Gothenburg, Sweden","Riecke, B.E., Max Planck Institute for Biological Cybernetics, Germany, Simon Fraser University, 250-13450 102nd Ave., Surrey, BC V3T 0A3, Canada; Väljamäe, A., Chalmers University of Technology, Sweden, CRAGmsa, Division of Applied Acoustics, Chalmers University of Technology, Sven Hultins gata 8a, 41296, Gothenburg, Sweden; Schulte-Pelkum, J., Max Planck Institute for Biological Cybernetics, Germany","While rotating visual and auditory stimuli have long been known to elicit self-motion illusions (""circular vection""), audiovisual interactions have hardly been investigated. Here, two experiments investigated whether visually induced circular vection can be enhanced by concurrently rotating auditory cues that match visual landmarks (e.g., a fountain sound). Participants sat behind a curved projection screen displaying rotating panoramic renderings of a market place. Apart from a no-sound condition, headphone-based auditory stimuli consisted of mono sound, ambient sound, or low-/high-spatial resolution auralizations using generic head-related transfer functions (HRTFs). While merely adding nonrotating (mono or ambient) sound showed no effects, moving sound stimuli facilitated both vection and presence in the virtual environment. This spatialization benefit was maximal for a medium (20° × 15°) FOV, reduced for a larger (54° × 45°) FOV and unexpectedly absent for the smallest (10° × 7.5°) FOV. Increasing auralization spatial fidelity (from low, comparable to five-channel home theatre systems, to high, 5° resolution) provided no further benefit, suggesting a ceiling effect. In conclusion, both self-motion perception and presence can benefit from adding moving auditory stimuli. This has important implications both for multimodal cue integration theories and the applied challenge of building affordable yet effective motion simulators. © 2009 ACM.","Audiovisual interactions; Presence; Psychophysics; Self-motion simulation; Spatial sound; Vection; Virtual reality","Audiovisual interactions; Presence; Psychophysics; Self-motion simulation; Spatial sound; Vection; Physics; Projection screens; Psychophysiology; Rotation; Virtual reality",Article,"Final","",Scopus,2-s2.0-63049105058
"Yip B.C.B., Man D.W.K.","35871899800;7006360144;","Virtual reality (VR)-based community living skills training for people with acquired brain injury: A pilot study",2009,"Brain Injury","23","13-14",,"1017","1026",,34,"10.3109/02699050903379412","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70450212237&doi=10.3109%2f02699050903379412&partnerID=40&md5=6546779cff5bb4298b4d7f6ca0e726cd","Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong, Hong Kong","Yip, B.C.B., Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong, Hong Kong; Man, D.W.K., Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong, Hong Kong","Primary objective: The purpose of the present study was to test the usability and effectiveness of a newly-developed virtual reality (VR)-based community living skills training program for people with acquired brain injury (ABI). Method: A small-sample, pre- and post-quasi experimental design was adopted to initially study the efficacy of the VR-based training program. Its usability was also investigated through interviewing subjects. Outcomes were documented in terms of subjects' skills acquisition, self-efficacy in applying the learnt skills and the transfer ratio of the learnt skills to the real environment. Global cognitive ability and the functional independence level were also assessed. Results: Four subjects with ABI (one traumatic brain injury and three stroke subjects) were successfully recruited and received 10 sessions of VR-based community living skills training. All four subjects showed improvement in skills acquisition and memory performance, while three out of four also showed improvement in self-efficacy and demonstrated transfer of skills to the real environment. Usability was initially supported. Conclusions: Preliminary results suggested positive changes in ABI subjects. The proposed virtual reality (VR) community living skills training software will be further investigated in a randomized controlled trial. © 2009 Informa UK Ltd All rights reserved.","Brain injury; Cognition; Community-living; Rehabilitation; Virtual reality","article; brain injury; case report; cognition; comprehension; decision making; female; human; learning environment; male; mental concentration; orientation; outcome assessment; pilot study; scoring system; self concept; skill; training; virtual reality; virtual reality based community living skills training; working memory",Article,"Final","",Scopus,2-s2.0-70450212237
"Mirelman A., Bonato P., Deutsch J.E.","35332484600;7006225560;7201985389;","Effects of training with a robot-virtual reality system compared with a robot alone on the gait of individuals after stroke",2009,"Stroke","40","1",,"169","174",,219,"10.1161/STROKEAHA.108.516328","https://www.scopus.com/inward/record.uri?eid=2-s2.0-60549105219&doi=10.1161%2fSTROKEAHA.108.516328&partnerID=40&md5=f1ccd9b5cf53303383cbb893e49474a1","RiVERS Lab., Department of Rehabilitation and Movement Science, University of Medicine and Dentistry of New Jersey, NJ, United States; Department of Physical Medicine and Rehabilitation, Harvard Medical School, Spaulding Rehabilitation Hospital, Boston, MA, United States; Harvard-MIT Division of Health Sciences and Technology, Boston, MA, United States; Gait and Neurodynamics Lab., Tel Aviv Medical Center, 6 Weizmann st, Tel Aviv, 64239, Israel","Mirelman, A., RiVERS Lab., Department of Rehabilitation and Movement Science, University of Medicine and Dentistry of New Jersey, NJ, United States, Department of Physical Medicine and Rehabilitation, Harvard Medical School, Spaulding Rehabilitation Hospital, Boston, MA, United States, Gait and Neurodynamics Lab., Tel Aviv Medical Center, 6 Weizmann st, Tel Aviv, 64239, Israel; Bonato, P., Department of Physical Medicine and Rehabilitation, Harvard Medical School, Spaulding Rehabilitation Hospital, Boston, MA, United States, Harvard-MIT Division of Health Sciences and Technology, Boston, MA, United States; Deutsch, J.E., RiVERS Lab., Department of Rehabilitation and Movement Science, University of Medicine and Dentistry of New Jersey, NJ, United States","BACKGROUND AND PURPOSE: Training of the lower extremity (LE) using a robot coupled with virtual environments has shown to transfer to improved overground locomotion. The purpose of this study was to determine whether the transfer of training of LE movements to locomotion was greater using a virtual environment coupled with a robot or with the robot alone. METHODS: A single, blind, randomized clinical trial was conducted. Eighteen individuals poststroke participated in a 4-week training protocol. One group trained with the robot virtual reality (VR) system and the other group trained with the robot alone. Outcome measures were temporal features of gait measured in a laboratory setting and the community. RESULTS: Greater changes in velocity and distance walked were demonstrated for the group trained with the robotic device coupled with the VR than training with the robot alone. Similarly, significantly greater improvements in the distance walked and number of steps taken in the community were measured for the group that trained with robot coupled with the VR. These differences were maintained at 3 months' follow-up. CONCLUSIONS: The study is the first to demonstrate that LE training of individuals with chronic hemiparesis using a robotic device coupled with VR improved walking ability in the laboratory and the community better than robot training alone. Copyright © 2009 American Heart Association. All rights reserved.","Community ambulation; Gait; Robotics; Stroke; Virtual reality","adult; aged; article; clinical article; clinical trial; controlled clinical trial; controlled study; female; gait; hemiparesis; human; locomotion; male; physiotherapy; priority journal; randomized controlled trial; robotics; single blind procedure; stroke; virtual reality; walking speed; comparative study; computer interface; exercise tolerance; fitness; instrumentation; kinesiotherapy; leg; methodology; middle aged; muscle strength; neurologic disease; paresis; pathophysiology; physiology; physiotherapy; robotics; skeletal muscle; stroke; teaching; treatment outcome; Adult; Aged; Exercise Movement Techniques; Exercise Tolerance; Female; Gait Disorders, Neurologic; Humans; Leg; Locomotion; Male; Middle Aged; Muscle Strength; Muscle, Skeletal; Paresis; Physical Fitness; Physical Therapy Modalities; Robotics; Stroke; Teaching; Treatment Outcome; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-60549105219
"Brzegowy P., Urbanik A., Popiela T.J.","6508068545;7005720469;35187697700;","Application of DynaCT in interventional neuroradiology",2009,"Polish Journal of Radiology","74","4",,"39","42",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-74749106317&partnerID=40&md5=194ac195ed9e126b26247f9f47e85348","Radiology Department, CM, Jagiellonian University, Kopernika 19 Str, 31-501 Cracow, Poland","Brzegowy, P., Radiology Department, CM, Jagiellonian University, Kopernika 19 Str, 31-501 Cracow, Poland; Urbanik, A., Radiology Department, CM, Jagiellonian University, Kopernika 19 Str, 31-501 Cracow, Poland; Popiela, T.J., Radiology Department, CM, Jagiellonian University, Kopernika 19 Str, 31-501 Cracow, Poland","Background: DynaCT (Angiographic GT) is a new imaging technique that with the use of the angiographic apparatus allows the researchers to obtain images of the human body comparable to standard CTs. Owing to this, only one procedure gives us the possibility to evaluate the vascular system together with the surrounding soft tissues Material/Methods: DynaCT, similarly to the 3D DSA method, involves the use of a G-arm rotating around the patient during the acquisition process. Like in CT, the acquired data may be processed into secondary reconstructions: multiplanar (MPR), maximum-intensity projections (MIP) and volume rendering (VR). Results: Neuroradiologically obtained images allow for an assessment of such brain structures as: ventricular system, subarachnoid cisternae and, to a lesser degree, brain tissue. In case of examinations with intra-arterial contrast administration we get precise images of the vascular system together with cranial bone structures and soft tissues, comparable (from the qualitative point of view) to those obtained during the angioCTs using multi-slice scanners. In case of angioplasty, DynaCT with contrast administration provides us with information on the exact location of a stent inside a vessel. Similarly, in patients with aneurysms embolised with stents, this technique enables the visualization of the stent position in relation to the neck of the aneurysm. Owing to DynaCT, it is possible to quickly evaluate the complications which may appear during endovascular procedures, especially the intracranial bleeding. Conclusions: DynaCT provides us with information that facilitates the process of qualification for the surgical or intravascular treatment. It also allows for a fast evaluation of possible complications which may appear during endovascular procedures, without wasting time for patient's transfer to the CT room. © Pol J Radiol, 2009.","DynaCT; Interventional neuroradiology","article; artificial embolism; brain artery aneurysm; brain ventricle; computed tomographic angiography; contrast enhancement; digital subtraction angiography; human; image reconstruction; interventional radiology; neuroradiology; skull; stent; subarachnoid space",Article,"Final","",Scopus,2-s2.0-74749106317
"Shi S., Zhang G., Shao X.","24167398000;56909086100;55266954900;","A VR-based simulation system for glass pressing",2008,"Computer Applications in Engineering Education","16","4",,"315","320",,3,"10.1002/cae.20216","https://www.scopus.com/inward/record.uri?eid=2-s2.0-57949104145&doi=10.1002%2fcae.20216&partnerID=40&md5=67aad9e00ef8fd66d9633d36de656920","State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wunan, Hubei 430074, China","Shi, S., State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wunan, Hubei 430074, China; Zhang, G., State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wunan, Hubei 430074, China; Shao, X., State Key Laboratory of Digital Manufacturing Equipment and Technology, School of Mechanical Science and Engineering, Huazhong University of Science and Technology, Wunan, Hubei 430074, China","The integration with virtual reality is a new boost to CAD and CAE. This paper presents a research effort aimed at creating a desktop-based, low-cost and independent VR-based simulation system for glass pressing, which integrates the forming process simulation and mold motion simulation. The skeletal animation technique is employed for motion simulation of the mold. The stereoscopic view of the virtual system is achieved by CrystalEyes shutter glasses, with C++ language and OpenGL support library selected as the development tool. With the stereoscopic display of the mold design, pressing motion and numerical CAE results, the system enables engineers to gain a cohesive view of mold structure, assembly issues, and possible forming faults. It can also support training of students and engineers to acquire the theoretical know-how, practical skills, and the problem troubleshooting techniques of glass pressing. © 2008 Wiley Periodicals Inc.","Glass pressing; Numerical simulation; Skeletal animation; Virtual reality","Animation; Computer simulation; Digital libraries; Glass; Mathematical models; Molds; Personnel training; Structural panels; Technology transfer; Virtual reality; C++ languages; Development tools; Forming processes; Glass pressing; Mold designs; Mold structures; Motion simulations; Numerical simulation; Practical skills; Research efforts; Shutter glasses; Simulation systems; Skeletal animation; Stereoscopic displays; Stereoscopic views; Support libraries; Troubleshooting techniques; Virtual systems; Pressing (forming)",Article,"Final","",Scopus,2-s2.0-57949104145
"Winterbottom C., Blake E.","10045558800;7006460560;","Constructivism, virtual reality and tools to support design",2008,"Proceedings of the Conference on Designing Interactive Systems: Processes, Practices, Methods, and Techniques, DIS",,,,"230","239",,6,"10.1145/1394445.1394470","https://www.scopus.com/inward/record.uri?eid=2-s2.0-57549105879&doi=10.1145%2f1394445.1394470&partnerID=40&md5=c767905b5fc4c5bdd0abe0b36aa586eb","Collaborative Visual Computing Lab., Department of Computer Science, University of Cape Town","Winterbottom, C., Collaborative Visual Computing Lab., Department of Computer Science, University of Cape Town; Blake, E., Collaborative Visual Computing Lab., Department of Computer Science, University of Cape Town","This paper describes a process for creating a design tool, which is based in constructivism. The process is described for the creation of a tool to help novices in designing virtual environment interactions, however it can be generalized to other design domains. The process consists of four steps: first constructivist values of atomic simplicity, multiplicity, exploration, control and reflection are distilled. Next, expert practices are researched and reframed in terms of the constructivist values. Thirdly, novice processes are examined and understood in constructivist terms. Lastly, prototypes are created and shown to target users. These steps are iterated until the designed tool is satisfactory. Copyright 2008 ACM.","Design,; Human Factor","Design domains; Design tools; Human Factor; Support designs; Virtual environments; Human engineering; Virtual reality; Design",Conference Paper,"Final","",Scopus,2-s2.0-57549105879
"Watanuki K.","7005697643;","VR mediated skill transfer",2008,"Proceedings of the ASME Design Engineering Technical Conference","3","PARTS A AND B",,"1201","1206",,,"10.1115/DETC2008-50153","https://www.scopus.com/inward/record.uri?eid=2-s2.0-81155151261&doi=10.1115%2fDETC2008-50153&partnerID=40&md5=389843d2abb564099c06685d883feeeb","Department of Mechanical Engineering, Graduate School of Science and Engineering, Saitama University, 255 Shimo-okubo, Sakura-ku, Saitama-shi, Saitama 338-8570, Japan","Watanuki, K., Department of Mechanical Engineering, Graduate School of Science and Engineering, Saitama University, 255 Shimo-okubo, Sakura-ku, Saitama-shi, Saitama 338-8570, Japan","This paper proposes a new virtual reality mediated skill transfer and human resource development system for manufacturing technology and skill, which are composed of the explicit and tacit knowledge transfer systems using synchronized multimedia and the knowledge internalization system using portable virtual environment. In our proposed system, the education content is displayed in the immersive virtual environment, whereby a trainee may experience work in the virtual site operation. Provided that the trainee has gained explicit and tacit knowledge of casting through the multimedia-based knowledge transfer system, the immersive virtual environment catalyzes the internalization of knowledge and also enables the trainee to gain tacit knowledge before undergoing on-the-job training at a real-time operation site. Copyright © 2008 by ASME.",,"Explicit and tacit knowledge; Human resource development; Immersive virtual environments; Knowledge transfer; Manufacturing technologies; On-the-job training; Real-time operation; Site operations; Skill transfer; Tacit knowledge; Design; Knowledge management; Manufacture; Multimedia systems; Personnel training; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-81155151261
"Stone R.T., Bisantz A., Llinas J., Paquet V.","57194665670;6603831596;7004600442;7004183484;","Improving tele-robotic landmine detection through augmented reality devices",2008,"Proceedings of the Human Factors and Ergonomics Society","1",,,"206","210",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350616147&partnerID=40&md5=f8a1db73471675a4e1939e10b3b284c2","University at Buffalo, State University of New York, Amherst, NY, United States; Iowa State University, Ames, IA, United States","Stone, R.T., University at Buffalo, State University of New York, Amherst, NY, United States, Iowa State University, Ames, IA, United States; Bisantz, A., University at Buffalo, State University of New York, Amherst, NY, United States; Llinas, J., University at Buffalo, State University of New York, Amherst, NY, United States; Paquet, V., University at Buffalo, State University of New York, Amherst, NY, United States","Tele-robotic landmine/UXO (unexploded ordinance) detection and disposal is a real world example of a complex human robot interaction task. This study demonstrates that the use of augmented reality interfaces, designed based on a theoretically driven framework, can significantly improve performance, and that these same devices can be used as effective training technologies. Participants in this study were assigned to one of four experimental conditions (two uni-sensory and one multisensory augmented reality interface, and a control group). All participants were trained in tele-robotic landmine detection and the groups performed these tasks first with augmentation (session one) and then without (session two/transfer task). The results show that participants in the augmented groups significantly outperformed the control group in terms of the numbers of landmines correctly identified (in both sessions). The multisensory condition was found to result in both significantly increased landmine detection and significantly decreased task time (in both sessions).",,"Control groups; Experimental conditions; Human robot interactions; Land mine; Land mine detection; Multisensory; Unexploded ordinances; Augmented reality; Bombs (ordnance); Ergonomics; Human computer interaction; Metal detectors; Robotics; Robots; Virtual reality; Explosives",Conference Paper,"Final","",Scopus,2-s2.0-70350616147
"Seehaus T.","55355863200;","Model-based system interaction specification meets virtual reality prototyping methods within a holistic consistent HMI development process",2008,"FISITA World Automotive Congress 2008, Congress Proceedings - Mobility Concepts, Man Machine Interface, Process Challenges, Virtual Reality","1",,,"353","359",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84866141382&partnerID=40&md5=44023217d0fae2d18b89f0a45657d51c","Porsche AG, Germany","Seehaus, T., Porsche AG, Germany","Porsche has geared its process chain in the HMI areas of prototyping, specification and testing - with the aim of reducing the development time, confirming decisions at an early project stage and guaranteeing a high quality level. When creating HMI prototypes and HMI-specifications a paradigm change takes place. The currently used mere office documentation is more and more replaced by machine-readable model-based system specifications. The resulting models can be used to simulate both, graphical user interfaces and suppliers' target specifications. This presentation shows the HMI prototyping chain including everything from user-interface simulation through mock-up and driving-simulator integration up to 3D stereo HMI virtual-reality environments. 3D HMI VR allows engineers to virtually integrate all aspects of design, behaviour, hardware exterior, and ergonomics which make up a top-quality man-machine interface provided that they arc correctly combined. By using 3D visualization tools, which arc integrated directly into the car exterior and interior design, complete top-quality 3D models can be made available at a very early project stage already. There are various interfaces which make it possible to directly transfer arbitrary image generators - such as a HMI computer simulation, into the 3D visualization environment where they can be evaluated and also controlled. Interaction is guaranteed by a feedback channel which provides objects within the three-dimensional representation in order to trigger control operations. In combination with stereo projection and head-tracking, highly realistic presentations as well as interactive operations arc possible. The focus is on realizing a consistent development chain based on the synergctic combination of model-based HMI specification and HMI prototyping, and on utilizing those models in 3D visualization and HMI testing such as the Porsche Communication Management System PCM, for example.","Automated Testing; HMI Development Process; Model-based System Interaction Specification; Prototyping; Virtual Reality","3D models; 3D Visualization; Automated testing; Communication management; Control operations; Development time; Feedback channel; High quality; HMI development; Image generators; Interactive operations; Interior designs; Man-machine interface; Model-based systems; Porsche; Process chain; Project stages; Stereo projection; Target specifications; Virtual-reality environment; Architectural design; Ergonomics; Graphical user interfaces; Software prototyping; Specifications; Three dimensional computer graphics; Virtual reality; Visualization; Three dimensional",Conference Paper,"Final","",Scopus,2-s2.0-84866141382
"Lin H., Hou C., Zhen X.","23011908600;7202210214;25724750800;","Bypassing spinal cord injury: Surgical reconstruction of afferent and efferent pathways to the urinary bladder after conus medullaris injury in a rat model",2008,"Journal of Reconstructive Microsurgery","24","8",,"575","581",,10,"10.1055/s-0028-1090599","https://www.scopus.com/inward/record.uri?eid=2-s2.0-57149120970&doi=10.1055%2fs-0028-1090599&partnerID=40&md5=bdf704d0c7eeea76dc2869416d7e9df4","Department of Orthopedic Surgery, Changzheng Hospital, Second Military Medical University, Shanghai, China; Department of Orthopedic Surgery, Changzheng Hospital, Second Military Medical University, Fengyang Road 415, Shanghai 200003, China","Lin, H., Department of Orthopedic Surgery, Changzheng Hospital, Second Military Medical University, Shanghai, China; Hou, C., Department of Orthopedic Surgery, Changzheng Hospital, Second Military Medical University, Shanghai, China, Department of Orthopedic Surgery, Changzheng Hospital, Second Military Medical University, Fengyang Road 415, Shanghai 200003, China; Zhen, X., Department of Orthopedic Surgery, Changzheng Hospital, Second Military Medical University, Shanghai, China","Afferent and efferent nerve function in the atonic bladder caused by conus medullaris injury in a rat model was established by intradural microanastomosis of the left L5 ventral root (VR) to right S2 VR to restore pure motor-to-motor reinnervation coupled with extradural postganglionic spinal nerve transfer of L5 dorsal root (DR) to S2 DR for pure sensory-to-sensory reinnervation. Early function of the reflex arc was evaluated by electrophysiological study, as well as by intravesicular pressure measurement and histological examination. The results demonstrated that single focal stimulation of the left S2 DR elicited evoked potentials at the left vesicular plexus before and after horizontal spinal cord damage between the L6 and S4 level. Bladder contraction was successfully initiated by trains of stimuli targeting the left L5-S2 DR anastomosis. Achievable bladder pressures and amplitude of bladder smooth muscle complex action potentials were unchanged before and after induced paraplegia and comparable to those of the control. Prominent axonal sprouting was seen in the distal part of nerve graft. Both afferent and efferent nerve pathways in the atonic bladder can be reconstructed by suprasacral motor-to-motor and sensory-to-sensory nerve transfer after spinal cord injury in rats. This reconstructive strategy has significant potential in clinical application. Copyright © 2008 by Thieme Medical Publishers, Inc.","Bladder; Micturition; Reflex pathway; Spinal cord injury (SCI)","action potential; animal experiment; animal model; animal tissue; article; bladder; bladder contraction; controlled study; conus medullaris; dorsal root; efferent nerve; electrophysiology; evoked response; histopathology; male; microsurgery; muscle action potential; nerve graft; nonhuman; priority journal; rat; reflex arc; sensory nerve; smooth muscle; spinal cord injury; ventral root; Afferent Pathways; Anastomosis, Surgical; Animals; Disease Models, Animal; Efferent Pathways; Electrophysiology; Evoked Potentials; Male; Nerve Transfer; Paraplegia; Pressure; Rats; Rats, Sprague-Dawley; Reconstructive Surgical Procedures; Reflex; Spinal Cord Injuries; Spinal Nerve Roots; Spinal Nerves; Urinary Bladder; Urination",Article,"Final","",Scopus,2-s2.0-57149120970
"Saladin S.P., Hansmann S.E.","25422927100;25421666200;","Psychosocial variables related to the adoption of video relay services among deaf or hard-of-hearing employees at the Texas school for the deaf",2008,"Assistive Technology","20","1",,"36","47",,8,"10.1080/10400435.2008.10131930","https://www.scopus.com/inward/record.uri?eid=2-s2.0-54049107300&doi=10.1080%2f10400435.2008.10131930&partnerID=40&md5=f1a315d6483b9421412fab614a8e25ce","University of Texas Pan American, Department of Rehabilitation, Health Sciences Human Services West 1.126, 1201 West University Drive, Edinburg, TX 78541, United States","Saladin, S.P., University of Texas Pan American, Department of Rehabilitation, Health Sciences Human Services West 1.126, 1201 West University Drive, Edinburg, TX 78541, United States; Hansmann, S.E., University of Texas Pan American, Department of Rehabilitation, Health Sciences Human Services West 1.126, 1201 West University Drive, Edinburg, TX 78541, United States","Assistive technology (AT) can help individuals with disabilities address a range of barriers and increase community and work participation, yet many devices are abandoned soon after acquisition. Video Relay Service (VRS) is a new communication technology available to people who are deaf or hard of hearing, but little is known about VRS adoption and use by intended consumers. Previous research suggests that psychosocial factors may have significant impact on adoption and use of AT thus a nonexperimental research design was used to investigate the impact of psychosocial and demographic variables on adoption of VRS by deaf or hard-of-hearing adults. Participating employees of the Texas School for the Deaf completed a demographic based on Rogers's characteristics of adopters of innovations, along with the Psychosocial Impact of Assistive Device Scale (PIADS), a 26-item self-report of psychosocial factors related to independence, well-being, and quality of life. Multiple Discriminant Analysis indicated that variables of Competence, Adaptability, and Self-Esteem were predictive of VRS adoption. Of demographic variables, only Training was highly correlated to Competence and Adaptability. Possible limitations include novelty effect and transferability. Recommendations for future research are included. © 2008 RESNA.","Adoption of innovation; Communication technology; Deaf or hard of hearing; Psychosocial impact of assistive device scale (PIADS); Rogers's theory; Video relay service","Adoption of innovations; Communication technology; Deaf or hard of hearing; Psychosocial impact of assistive device scale (PIADS); Rogers's theory; Video relay service; Discriminant analysis; Innovation; Personnel; Population statistics; Research; Technology transfer; Audition; adult; aged; article; communication aid; consumer; female; hearing disorder; human; information processing; male; mass communication; middle aged; patient; patient attitude; psychologic test; psychological aspect; psychometry; qualitative research; questionnaire; United States; workplace; Adult; Aged; Aged, 80 and over; Communication Aids for Disabled; Consumer Satisfaction; Data Collection; Diffusion of Innovation; Female; Hearing Disorders; Hearing Impaired Persons; Humans; Male; Middle Aged; Patient Acceptance of Health Care; Psychological Tests; Psychometrics; Qualitative Research; Questionnaires; Texas; United States; Workplace",Article,"Final","",Scopus,2-s2.0-54049107300
"Popescu J.A., Vilag V.A., Petcu R., Vataman I., Silivestru V.","34979199900;24492387500;24492122100;36957207200;23976609400;","Numerical simulation to determine ejection device geometry for turbo-shaft driven water pump",2008,"Proceedings of the ASME Turbo Expo","7",,,"255","262",,1,"10.1115/GT2008-50968","https://www.scopus.com/inward/record.uri?eid=2-s2.0-69949154728&doi=10.1115%2fGT2008-50968&partnerID=40&md5=e2cf9c7142aa4daff7d354c4aa548429","Department of Gas Turbines, Cogeneration, Turbo-engines Test Facilities, Spain; National Research and Development Institute for Gas Turbines COMOTI, Bucharest, ROU, Romania; Politehnica University of Bucharest, Romania","Popescu, J.A., Department of Gas Turbines, Cogeneration, Turbo-engines Test Facilities, Spain, National Research and Development Institute for Gas Turbines COMOTI, Bucharest, ROU, Romania; Vilag, V.A., Department of Gas Turbines, Cogeneration, Turbo-engines Test Facilities, Spain, National Research and Development Institute for Gas Turbines COMOTI, Bucharest, ROU, Romania; Petcu, R., Department of Gas Turbines, Cogeneration, Turbo-engines Test Facilities, Spain, National Research and Development Institute for Gas Turbines COMOTI, Bucharest, ROU, Romania; Vataman, I., Department of Gas Turbines, Cogeneration, Turbo-engines Test Facilities, Spain, National Research and Development Institute for Gas Turbines COMOTI, Bucharest, ROU, Romania; Silivestru, V., National Research and Development Institute for Gas Turbines COMOTI, Bucharest, ROU, Romania, Politehnica University of Bucharest, Romania","Turbo-engines with known performances reaching the end of their useful flying life can become useful assets in the execution of industrial projects. One such project reported in this paper is to install a high capacity complex device which will clear out the water in cases of floods.The partnership created in order to accomplish the task includes specialists in energetic, turbo-machinery, amelioration, hydraulic and action logistics fields and is aiming to acquire knowledge, results and experience and to transfer the information to economic and social environment. The TV2-117A turbo-shaft is the main component of the power group representing the energy source of the installation. It is connected to a reducer gear-box and a high capacity water pump. Considering the purpose of the installation to be realised, a device destined to handle natural calamities effects, the solution must fulfil several very important conditions: mobility, power and reliability. Being known the fact that moving elements have lower reliability conducts to the idea of an oil cooling system without mechanical or electrical driven fans. This is possible through using the ejection effect in a system based on the exhausted hot gases from the turbo-engine. The ejection device is a tubular structure using three concentric tubes on the outlet. The central one absorbs the hot gases and drives the cool air from the surrounding environment through the other two to accomplish both the oil and turbo-engine box cooling. The numerical analysis, using a CFD code, is still in progress and the paper presents intermediate results. The CFD conditions were imposed by the turbo-engine experimental data obtained in previous tests and the known working conditions established for the device to be created. The preliminary results helped to eliminate many flow problems caused by geometric dimensions and to establish the necessary adjustments in order to obtain the expected mass flow and speed values for the cooling devices. The adjustments on the geometry consisted in modifying the lengths, the bending and the diameters of the tubes. The final and most suitable geometry is still to be determined using the CFD code. Copyright © 2008 by ASME.",,"CFD codes; Complex devices; Concentric tube; Cool air; Cooling devices; Device geometries; Energy source; Experimental data; Flow problems; Geometric dimensions; High capacity; Hot gas; Industrial projects; Intermediate results; Main component; Mass flow; Numerical simulation; Oil cooling system; Power group; Social environment; Surrounding environment; System-based; Tubular structures; Water pump; Working conditions; Bending (forming); Computational geometry; Computer simulation; Cooling; Hydraulic machinery; Lithium batteries; Mining; Pumps; Tubular steel structures; Computational fluid dynamics",Conference Paper,"Final","",Scopus,2-s2.0-69949154728
"Arendarski B., Termath W., Mecking P.","24830119700;24831100200;24831023900;","Maintenance of complex machines in electric power systems using Virtual Reality techniques",2008,"Conference Record of IEEE International Symposium on Electrical Insulation",,, 4570378,"483","487",,22,"10.1109/ELINSL.2008.4570378","https://www.scopus.com/inward/record.uri?eid=2-s2.0-52049095031&doi=10.1109%2fELINSL.2008.4570378&partnerID=40&md5=27c62232ba194103fe3537463e347da1","Fraunhofer Institute for Factory Operation and Automation (IFF), Sandtorstrasse 22, 39106 Magdeburg, Germany; RWE Rhein-Rulir-Netzservice GmbH, Reeser Landstrasse 41, 46483 Wesel, Germany","Arendarski, B., Fraunhofer Institute for Factory Operation and Automation (IFF), Sandtorstrasse 22, 39106 Magdeburg, Germany; Termath, W., Fraunhofer Institute for Factory Operation and Automation (IFF), Sandtorstrasse 22, 39106 Magdeburg, Germany; Mecking, P., RWE Rhein-Rulir-Netzservice GmbH, Reeser Landstrasse 41, 46483 Wesel, Germany","This paper illustrates how Virtual Reality (VR) techniques can be used in electric power systems visualization and how this can increase effectiveness of vocational training in field of power industry. The content of this article is based on a project oriented to specialized staff members, dealing with maintenance, repairs and diagnostics of complex machines such transformers and generators. Introducing a scheme that integrates VR technologies to electrical machines and equipment provides an efficient tool for implementing operator training methods. Three-dimensional (3D) visualization brings a new ways of knowledge transfer and education regarding complex equipment. ©2008 IEEE.",,"Chlorine compounds; Electric generators; Electric industry; Electric power measurement; Electric power systems; Electric power transmission networks; Information management; Knowledge management; Maintainability; Maintenance; Paper coating; Power transmission; Technical presentations; Three dimensional; Virtual reality; Visualization; Complex equipment; Complex machining; Electrical insulation; Electrical machines; In-field; International symposium; Knowledge transfer; Operator training; Power industries; Staff members; Three-dimensional visualization; Virtual reality (VR); Vocational training; Personnel training",Conference Paper,"Final","",Scopus,2-s2.0-52049095031
"Quarles J., Lampotang S., Fischler I., Fishwick P., Lok B.","55868360300;35587861100;35588972600;56252883400;57203616548;","A mixed reality approach for merging abstract and concrete knowledge",2008,"Proceedings - IEEE Virtual Reality",,, 4480746,"27","34",,24,"10.1109/VR.2008.4480746","https://www.scopus.com/inward/record.uri?eid=2-s2.0-50349097941&doi=10.1109%2fVR.2008.4480746&partnerID=40&md5=e541bedde2a5a643d1d30ad169d0dd8d","Dept. of CISE, University of Florida; Dept. of Anesthesiology, University of Florida; Dept. of Psychology, University of Florida","Quarles, J., Dept. of CISE, University of Florida; Lampotang, S., Dept. of Anesthesiology, University of Florida; Fischler, I., Dept. of Psychology, University of Florida; Fishwick, P., Dept. of CISE, University of Florida; Lok, B., Dept. of CISE, University of Florida","Mixed reality's (MR) ability to merge real and virtual spaces is applied to merging different knowledge types, such as abstract and concrete knowledge. To evaluate whether the merging of knowledge types can benefit learning, MR was applied to an interesting problem in anesthesia machine education. The Virtual Anesthesia Machine (VAM) is an interactive, abstract 2D transparent reality [14] simulation of the internal components and invisible gas flows of an anesthesia machine. It is widely used in anesthesia education. However when presented with an anesthesia machine, some students have difficulty transferring abstract VAM knowledge to the concrete real device. This paper presents the Augmented Anesthesia Machine (AAM). The AAM applies a magic-lens approach to combine the VAM simulation and a real anesthesia machine. The AAM allows students to interact with the real anesthesia machine while visualizing how these interactions affect the internal components and invisible gas flows in the real world context. To evaluate the AAM's learning benefits, a user study was conducted. Twenty participants were divided into either the VAM (abstract only) or AAM (concrete+abstract) conditions. The results of the study show that MR can help users bridge their abstract and concrete knowledge, thereby improving their knowledge transfer into real world domains. © 2008 IEEE.","Anesthesiology; Mixed reality; Modeling and simulation; Psychology; User studies","Gas flowing; Interesting problem; Knowledge transfer; Knowledge types; Mixed reality; Modeling and simulation; Psychology; Real-world; Real-world domains; User studies; Virtual spaces; Abstracting; Aerodynamics; Anesthesiology; Concrete construction; Education; Flow of gases; Gas dynamics; Information management; Knowledge management; Merging; Students; Virtual reality; Machine components",Conference Paper,"Final","",Scopus,2-s2.0-50349097941
"Lendvay T.S., Casale P., Sweet R., Peters C.","14319319500;7006635445;35560028800;7402558645;","Initial validation of a virtual-reality robotic simulator",2008,"Journal of Robotic Surgery","2","3",,"145","149",,44,"10.1007/s11701-008-0099-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-51549091569&doi=10.1007%2fs11701-008-0099-1&partnerID=40&md5=090b9b4b0a58280c7880153a4f4d68c9","Children's Hospital, Regional Medical Center, 4800 Sand Point Way NE, Seattle, WA 98015, United States; American Urological Association, Office of Education, Baltimore, MD, United States; Children's Hospital of Philadelphia, Wood Center, 34th Street and Civic Center Blvd, Philadelphia, PA 19104, United States; Department of Urologic Surgery, University of Minnesota, Mayo Mail Code 394, 420 Delaware Street S.E., Minneapolis, MN 55455, United States; Department of Urology, University of Virginia Health System, PO Box 800422, Charlottesville, VA 22908, United States","Lendvay, T.S., Children's Hospital, Regional Medical Center, 4800 Sand Point Way NE, Seattle, WA 98015, United States, American Urological Association, Office of Education, Baltimore, MD, United States; Casale, P., American Urological Association, Office of Education, Baltimore, MD, United States, Children's Hospital of Philadelphia, Wood Center, 34th Street and Civic Center Blvd, Philadelphia, PA 19104, United States; Sweet, R., Department of Urologic Surgery, University of Minnesota, Mayo Mail Code 394, 420 Delaware Street S.E., Minneapolis, MN 55455, United States; Peters, C., American Urological Association, Office of Education, Baltimore, MD, United States, Department of Urology, University of Virginia Health System, PO Box 800422, Charlottesville, VA 22908, United States","Robotic surgery is an accepted adjunct to minimally invasive surgery, but training is restricted to console time. Virtual-reality (VR) simulation has been shown to be effective for laparoscopic training and so we seek to validate a novel VR robotic simulator. The American Urological Association (AUA) Office of Education approved this study. Subjects enrolled in a robotics training course at the 2007 AUA annual meeting underwent skills training in a da Vinci dry-lab module and a virtual-reality robotics module which included a three-dimensional (3D) VR robotic simulator. Demographic and acceptability data were obtained, and performance metrics from the simulator were compared between experienced and nonexperienced roboticists for a ring transfer task. Fifteen subjects-four with previous robotic surgery experience and 11 without-participated. Nine subjects were still in urology training and nearly half of the group had reported playing video games. Overall performance of the da Vinci system and the simulator were deemed acceptable by a Likert scale (0-6) rating of 5.23 versus 4.69, respectively. Experienced subjects outperformed nonexperienced subjects on the simulator on three metrics: total task time (96 s versus 159 s, P < 0.02), economy of motion (1,301 mm versus 2,095 mm, P < 0.04), and time the telemanipulators spent outside of the center of the platform's workspace (4 s versus 35 s, P < 0.02). This is the first demonstration of face and construct validity of a virtual-reality robotic simulator. Further studies assessing predictive validity are ultimately required to support incorporation of VR robotic simulation into training curricula. © 2008 Springer-Verlag London Ltd.","Da Vinci; Robotic surgery; Simulation education; Virtual reality",,Article,"Final","",Scopus,2-s2.0-51549091569
"Van Schaik P., Martyr A., Blackman T., Robinson J.","6603734216;22941748200;7004627937;57198434020;","Involving persons with dementia in the evaluation of outdoor environments",2008,"Cyberpsychology and Behavior","11","4",,"415","424",,16,"10.1089/cpb.2007.0105","https://www.scopus.com/inward/record.uri?eid=2-s2.0-50149111634&doi=10.1089%2fcpb.2007.0105&partnerID=40&md5=3b6592e796eb9765852a2f9e0bb64966","School of Social Sciences and Law, University of Teesside, Middlesbrough, United Kingdom; Department of Psychology, University of Wales, Bangor, United Kingdom; School of Applied Social Sciences, University of Durham, Durham, United Kingdom; School of Computing, University of Teesside, Middlesbrough, United Kingdom; Psychology Section, School of Social Sciences and Law, University of Teesside, Borough Road, Middlesbrough, TS1 3BA, United Kingdom","Van Schaik, P., School of Social Sciences and Law, University of Teesside, Middlesbrough, United Kingdom, Psychology Section, School of Social Sciences and Law, University of Teesside, Borough Road, Middlesbrough, TS1 3BA, United Kingdom; Martyr, A., Department of Psychology, University of Wales, Bangor, United Kingdom; Blackman, T., School of Applied Social Sciences, University of Durham, Durham, United Kingdom; Robinson, J., School of Computing, University of Teesside, Middlesbrough, United Kingdom","Using virtual reality (VR), we examined the barriers to and facilitators of functioning outdoors in persons with dementia (PwD) and investigated the generalizability of findings in VR to the real world. An existing town center was modeled in VR. PwD took part in both real-world and VR walks. Based on the results, the model was redesigned and then tested again. Performance on the walks improved, and potentially beneficial adaptations to outdoor environments were identified, but limitations of VR as a representation of the real world were also identified. We conclude that VR models, together with a rigorous behavioral testing method, can be a useful tool for the evaluation of outdoor environments and for identifying improvements for PwD. © 2008 Mary Ann Liebert, Inc.",,"aged; article; clinical article; clinical evaluation; cognition; dementia; environment; female; human; male; outdoor environment; performance measurement system; task performance; virtual reality; walking; Activities of Daily Living; Aged; Aged, 80 and over; Computer Simulation; Dementia; Environment Design; Female; Humans; Male; Recreation; Severity of Illness Index; Space Perception; Therapy, Computer-Assisted; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-50149111634
"Dias P., Campos G., Santos V., Casaleiro R., Seco R., Santos B.S.","22333370800;8603962700;35616433200;24477040900;24477807400;7006476948;","3D reconstruction and Auralisation of the ""painted dolmen"" of antelas",2008,"Proceedings of SPIE - The International Society for Optical Engineering","6805",, 68050Y,"","",,2,"10.1117/12.766607","https://www.scopus.com/inward/record.uri?eid=2-s2.0-47949110073&doi=10.1117%2f12.766607&partnerID=40&md5=8cf6b741616e6b2cc561071a4c67c4e0","DETI - Dep. de Electrónica, Telecomunicações e Informática, Univ. of Aveiro, Portugal; IEETA - Instituto de Engenharia Electrónica e Telemática de Aveiro, Portugal; Departamento de Engenharia Mecânica, Univ. of Aveiro, Aveiro, Portugal","Dias, P., DETI - Dep. de Electrónica, Telecomunicações e Informática, Univ. of Aveiro, Portugal, IEETA - Instituto de Engenharia Electrónica e Telemática de Aveiro, Portugal; Campos, G., DETI - Dep. de Electrónica, Telecomunicações e Informática, Univ. of Aveiro, Portugal, IEETA - Instituto de Engenharia Electrónica e Telemática de Aveiro, Portugal; Santos, V., Departamento de Engenharia Mecânica, Univ. of Aveiro, Aveiro, Portugal; Casaleiro, R., DETI - Dep. de Electrónica, Telecomunicações e Informática, Univ. of Aveiro, Portugal; Seco, R., DETI - Dep. de Electrónica, Telecomunicações e Informática, Univ. of Aveiro, Portugal; Santos, B.S., DETI - Dep. de Electrónica, Telecomunicações e Informática, Univ. of Aveiro, Portugal, IEETA - Instituto de Engenharia Electrónica e Telemática de Aveiro, Portugal","This paper presents preliminary results on the development of a 3D audiovisual model of the Anta Pintada (painted dolmen) of Antelas, a Neolithic chamber tomb located in Oliveira de Frades and listed as Portuguese national monument. The final aim of the project is to create a highly accurate Virtual Reality (VR) model of this unique archaeological site, capable of providing not only visual but also acoustic immersion based on its actual geometry and physical properties. The project started in May 2006 with in situ data acquisition. The 3D geometry of the chamber was captured using a Laser Range Finder. In order to combine the different scans into a complete 3D visual model, reconstruction software based on the Iterative Closest Point (ICP) algorithm was developed using the Visualization Toolkit (VTK). This software computes the boundaries of the room on a 3D uniform grid and populates its interior with ""free-space nodes"", through an iterative algorithm operating like a torchlight illuminating a dark room. The envelope of the resulting set of ""free-space nodes"" is used to generate a 3D iso-surface approximating the interior shape of the chamber. Each polygon of this surface is then assigned the acoustic absorption coefficient of the corresponding boundary material. A 3D audiovisual model operating in real-time was developed for a VR Environment comprising head-mounted display (HMD) I-glasses SVGAPro, an orientation sensor (tracker) InterTrax 2 with 3 Degrees Of Freedom (3DOF) and stereo headphones. The auralisation software is based on a geometric model. This constitutes a first approach, since geometric acoustics have well-known limitations in rooms with irregular surfaces. The immediate advantage lies in their inherent computational efficiency, which allows real-time operation. The program computes the early reflections forming the initial part of the chamber's impulse response (IR), which carry the most significant cues for source localisation. These early reflections are processed through Head Related Transfer Functions (HRTF) updated in real-time according to the orientation of the user's head, so that sound waves appear to come from the correct location in space, in agreement with the visual scene. The late-reverberation tail of the IR is generated by an algorithm designed to match the reverberation time of the chamber, calculated from the actual acoustic absorption coefficients of its surfaces. The sound output to the headphones is obtained by convolving the IR with anechoic recordings of the virtual audio source. © 2008 SPIE-IS&T.","3D acquisition; Augmented reality; Auralisation; Laser range finder; Virtual reality","Absorption; Acoustic wave absorption; Acoustics; Architectural acoustics; Audio acoustics; Computational efficiency; Display devices; Energy absorption; Functions; Headphones; Helmet mounted displays; Image reconstruction; Imaging systems; Impulse response; Lasers; Loudspeakers; Medical imaging; Mergers and acquisitions; Range finders; Range finding; Reflection; Restoration; Reverberation; Surfaces; Three dimensional computer graphics; Virtual reality; 3D acquisition; 3D geometries; 3D reconstructions; 3d visual models; Acoustic absorption coefficients; Archaeological sites; Audio sources; Audio visuals; Augmented reality; Auralisation; Dark rooms; Geometric acoustics; Geometric models; Head Related Transfer Functions; In-situ; Irregular surfaces; Iterative algorithms; Iterative Closest points; Laser range finder; Orientation sensors; Reconstruction softwares; Reverberation times; Software computes; Sound waves; Source localisation; Stereo headphones; Uniform grids; Visual scenes; Visualization toolkits; Three dimensional",Conference Paper,"Final","",Scopus,2-s2.0-47949110073
"Verdaasdonk E.G.G., Dankelman J., Lange J.F., Stassen L.P.S.","9245716500;7003296968;8636415000;57202564496;","Transfer validity of laparoscopic knot-tying training on a VR simulator to a realistic environment: A randomized controlled trial",2008,"Surgical Endoscopy and Other Interventional Techniques","22","7",,"1636","1642",,63,"10.1007/s00464-007-9672-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-50249157670&doi=10.1007%2fs00464-007-9672-3&partnerID=40&md5=664e4e02065e1c1066f4a0c8865a5732","Department of Biomechanical Engineering, Faculty of Mechanical, Marine and Materials Engineering, Delft University of Technology, Delft, Netherlands; Department of Surgery, Reinier de Graaf Group, Delft, Netherlands; Department of Surgery, Erasmus Medical Center Rotterdam, Rotterdam, Netherlands; Delft University of Technology, Department of BioMechanical Engineering, Faculty of Mechanical, Marine and Materials Engineering, Mekelweg 2, CD Delft 2628, Netherlands","Verdaasdonk, E.G.G., Department of Biomechanical Engineering, Faculty of Mechanical, Marine and Materials Engineering, Delft University of Technology, Delft, Netherlands, Department of Surgery, Reinier de Graaf Group, Delft, Netherlands, Delft University of Technology, Department of BioMechanical Engineering, Faculty of Mechanical, Marine and Materials Engineering, Mekelweg 2, CD Delft 2628, Netherlands; Dankelman, J., Department of Biomechanical Engineering, Faculty of Mechanical, Marine and Materials Engineering, Delft University of Technology, Delft, Netherlands; Lange, J.F., Department of Surgery, Erasmus Medical Center Rotterdam, Rotterdam, Netherlands; Stassen, L.P.S., Department of Biomechanical Engineering, Faculty of Mechanical, Marine and Materials Engineering, Delft University of Technology, Delft, Netherlands, Department of Surgery, Reinier de Graaf Group, Delft, Netherlands","Background: Laparoscopic suturing is one of the most difficult tasks in endoscopic surgery, requiring extensive training. The aim of this study was to determine the transfer validity of knot-tying training on a virtual-reality (VR) simulator to a realistic laparoscopic environment. Methods: Twenty surgical trainees underwent basic eye-hand coordination training on a VR simulator (SIMENDO, DelltaTech, Delft, the Netherlands) until predefined performance criteria were met. Then, they were randomized into two groups. Group A (the experimental group) received additional training with the knot-tying module on the simulator, during which they had to tie a double laparoscopic knot ten times. Group B (controls) did not receive additional manual training. Within a week the participants tied a double knot in the abdominal cavity of an anaesthetized porcine model. Their performance was captured on digital video and coded. Objective analysis parameters were: time taken to tie the knot and number of predefined errors made. Subjective assessments were also made by two laparoscopic surgeons using a global rating list with a five-point Likert scale. Results: Trainees in group A (n = 9) were significantly faster than the controls (n = 10), with a median of 262 versus 374 seconds (p = 0.034). Group A made a significantly lower number of errors than the controls (median of 24 versus 36 errors, p = 0.030). Subjective assessments by the laparoscopic experts did not show any significant differences in economy of movement and erroneous behavior between the two groups. Conclusion: Surgical trainees who received knot-tying training on the VR simulator were faster and made fewer errors than the controls. The VR module is a useful tool to train laparoscopic knot-tying. Opportunities arose to improve simulator-based instruction that might enhance future training. © 2007 Springer Science+Business Media, LLC.","Education; Laparoscopy; Suturing; VR simulation","analytical error; anesthesia; article; economic aspect; environmental factor; human; human experiment; laparoscopy; medical education; medical student; normal human; peritoneal cavity; priority journal; rating scale; simulation; statistical significance; surgeon; videorecording; virtual reality; Animals; Competency-Based Education; Computer Simulation; Computer-Assisted Instruction; Female; Humans; Laparoscopy; Male; Models, Animal; Netherlands; Suture Techniques; Swine; Task Performance and Analysis; User-Computer Interface; Video Recording",Article,"Final","",Scopus,2-s2.0-50249157670
"Lietsch S., Zabel H., Berssenbruegge J.","15136225100;15137714700;24340966700;","Computational steering of interactive and distributed Virtual Reality applications",2008,"2007 Proceedings of the ASME International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, DETC2007","2 PART B",,,"1023","1032",,2,"10.1115/DETC2007-34550","https://www.scopus.com/inward/record.uri?eid=2-s2.0-44849094437&doi=10.1115%2fDETC2007-34550&partnerID=40&md5=7035f6d83c381144f0fccf1277dd3d06","Paderborn Center for Parallel Computing, University of Paderborn, Paderborn, NRW 33102, Germany; C-Lab, University of Paderborn, Paderborn, NRW 33102, Germany; Heinz Nixdorf Institute, University of Paderborn, Paderborn, NRW 33102, Germany","Lietsch, S., Paderborn Center for Parallel Computing, University of Paderborn, Paderborn, NRW 33102, Germany; Zabel, H., C-Lab, University of Paderborn, Paderborn, NRW 33102, Germany; Berssenbruegge, J., Heinz Nixdorf Institute, University of Paderborn, Paderborn, NRW 33102, Germany","In this paper we present a system that transfers the well-known computational steering paradigm to interactive and distributed Virtual Reality applications. Those are often used in areas like rapid prototyping and all kinds of vehicle simulation. The distribution has many different purposes and affects various subsystems of a VR application. Most of the currently existing systems are very specialized and have a proprietary design for data-exchange and coupling of the components. We propose a more flexible approach by designing a computational steering framework that is well-adapted to the needs of highly interactive and distributed VR systems. Thereby we achieve higher reusability and scalability for the steering component itself as well as the possibility to exchange and compare subsystems. As a proof-of-concept we adapted an existing driving simulator to the proposed computational steering framework and discuss the advantages and difficulties in the second part of the paper. Copyright © 2007 by ASME.",,"Computational steering; Data exchange (DX); Distributed virtual reality; Driving simulators; Existing systems; International designs; Proof-of-concept (POC); prototyping; Technical conferences; vehicle simulation; VR systems; Architectural design; Automobile parts and equipment; Automobile simulators; Automobile steering equipment; Computational methods; Computer networks; Computers; Concurrent engineering; Engineering; Job analysis; Paper; Product development; Rapid prototyping; Steering; Virtual reality; Technology",Conference Paper,"Final","",Scopus,2-s2.0-44849094437
"Rosen K.R.","35546116600;","The history of medical simulation",2008,"Journal of Critical Care","23","2",,"157","166",,242,"10.1016/j.jcrc.2007.12.004","https://www.scopus.com/inward/record.uri?eid=2-s2.0-44449132188&doi=10.1016%2fj.jcrc.2007.12.004&partnerID=40&md5=f756ae03e80d631a594d0476ad1d2d05","Department of Anesthesiology, Case Western Reserve University School of Medicine, Cleveland, OH 44106, United States","Rosen, K.R., Department of Anesthesiology, Case Western Reserve University School of Medicine, Cleveland, OH 44106, United States","The historical roots of simulation might be described with the broadest definition of medical simulation: ""an imitation of some real thing, state of affairs, or process"" for the practice of skills, problem solving, and judgment. From the first ""blue box"" flight simulator to the military's impetus in the transfer of modeling and simulation technology to medicine, worldwide acceptance of simulation training is growing. Large collaborative simulation centers support the expectation of increases in multidisciplinary, interprofessional, and multimodal simulation training. Virtual worlds, both immersive and Web-based, are at the frontier of innovation in medical education. © 2008 Elsevier Inc. All rights reserved.","Flight simulation; Link trainer; Manikin; Mannequin; Medical simulation; Patient simulation; Programmed patient; Standardized patient; Virtual reality; Web-based simulation","article; aviation; computer program; education program; human; medical education; problem solving; professional competence; simulation; training; virtual reality; Education, Medical; History, 20th Century; History, 21st Century; Manikins; Patient Simulation; United States",Article,"Final","",Scopus,2-s2.0-44449132188
"Dayan A.B., Ziv A., Berkenstadt H., Munz Y.","24331367600;7005936898;7004048805;6602197387;","A simple, low-cost platform for basic laparoscopic skills training",2008,"Surgical Innovation","15","2",,"136","142",,19,"10.1177/1553350608318142","https://www.scopus.com/inward/record.uri?eid=2-s2.0-44349098666&doi=10.1177%2f1553350608318142&partnerID=40&md5=93fe9a225f73d059b43fe248284c0950","Israel Centre for Medical Simulation, Sheba Medical Centre, Tel Hashomer, Israel; Department of General Surgery and Transplantation, Sheba Medical Centre, Tel Hashomer, Israel; 24th Yarden St., Ramat Hasharon 47204, Israel","Dayan, A.B., Department of General Surgery and Transplantation, Sheba Medical Centre, Tel Hashomer, Israel; Ziv, A., Israel Centre for Medical Simulation, Sheba Medical Centre, Tel Hashomer, Israel; Berkenstadt, H., Israel Centre for Medical Simulation, Sheba Medical Centre, Tel Hashomer, Israel; Munz, Y., Israel Centre for Medical Simulation, Sheba Medical Centre, Tel Hashomer, Israel, Department of General Surgery and Transplantation, Sheba Medical Centre, Tel Hashomer, Israel, 24th Yarden St., Ramat Hasharon 47204, Israel","Laparoscopic basic skills' training relies mainly on costly video trainers. The aim of this study was to evaluate a simple, low-cost devise for laparoscopic training. In all, 32 participants with varying levels of skill were recruited. A Simulab LapTrainer (Simulab, Seattle, Washington), using a simple plastic box, a webcam, and a Universal Serial Bus 2 card, was used together with standard operating tools. Participants performed 3 tasks (rope passing, peg transfer, and intracorporeal knot tying), which were video recorded and blindly assessed by 2 experts using error scores, checklists, and time. Statistical analysis included nonparametric tests and Cronbach α for inter-rater reliability. A P < .05 was deemed significant. Highly significant differences were noted between groups in all tasks and for all parameters (P = .001). Inter-rater reliability was 0.88. Simulator ratings were good: 63%, excellent: 28%, and only 9% rated it as average. The Simulab LapTrainer provides a valid alternative for skills training. Its simplicity, portability, and relatively low cost make it an attractive surgical training tool. © 2008 Sage Publications.","Box trainer; Innovative; Laparoscopic skills; Low cost; Training","article; checklist; controlled study; cost; Cronbach alpha coefficient; human; interrater reliability; laparoscopic surgery; nonparametric test; scoring system; simulator; skill; statistical analysis; surgical training; task performance; videorecording; Analysis of Variance; Clinical Competence; Humans; Laparoscopy; Questionnaires; Reproducibility of Results; Surgery; Task Performance and Analysis; Video Recording",Article,"Final","",Scopus,2-s2.0-44349098666
"Gorini A., Riva G.","23099679200;56962750600;","The potential of Virtual Reality as anxiety management tool: A randomized controlled study in a sample of patients affected by generalized anxiety disorder",2008,"Trials","9",, 25,"","",,37,"10.1186/1745-6215-9-25","https://www.scopus.com/inward/record.uri?eid=2-s2.0-44949179316&doi=10.1186%2f1745-6215-9-25&partnerID=40&md5=d673921d5aef32b6b686d09ca134b432","Applied Technology for Neuro-Psychology Lab, Istituto Auxologico Italiano, Milan, Italy; Research Institute Brain and Behaviour, Maastricht University, Maastricht, Netherlands; Psychology Department, Catholic University of Milan, Milan, Italy","Gorini, A., Applied Technology for Neuro-Psychology Lab, Istituto Auxologico Italiano, Milan, Italy, Research Institute Brain and Behaviour, Maastricht University, Maastricht, Netherlands; Riva, G., Applied Technology for Neuro-Psychology Lab, Istituto Auxologico Italiano, Milan, Italy, Psychology Department, Catholic University of Milan, Milan, Italy","Background: Generalized anxiety disorder (GAD) is a psychiatric disorder characterized by a constant and unspecific anxiety that interferes with daily-life activities. Its high prevalence in general population and the severe limitations it causes, point out the necessity to find new efficient strategies to treat it. Together with the cognitive-behavioural treatments, relaxation represents a useful approach for the treatment of GAD, but it has the limitation that it is hard to be learned. To overcome this limitation we propose the use of virtual reality (VR) to facilitate the relaxation process by visually presenting key relaxing images to the subjects. The visual presentation of a virtual calm scenario can facilitate patients' practice and mastery of relaxation, making the experience more vivid and real than the one that most subjects can create using their own imagination and memory, and triggering a broad empowerment process within the experience induced by a high sense of presence. According to these premises, the aim of the present study is to investigate the advantages of using a VR-based relaxation protocol in reducing anxiety in patients affected by GAD. Methods/Design: The trialis based on a randomized controlled study, including three groups of 25 patients each (for a total of 75 patients): (1) the VR group, (2) the non-VR group and (3) the waiting list (WL) group. Patients in the VR group will be taught to relax using a VR relaxing environment and audio-visual mobile narratives; patients in the non-VR group will be taught to relax using the same relaxing narratives proposed to the VR group, but without the VR support, and patients in the WL group will not receive any kind of relaxation training. Psychometric and psychophysiological outcomes will serve as quantitative dependent variables, while subjective reports of participants will be used as qualitative dependent variables. Conclusion: We argue that the use of VR for relaxation represents a promising approach in the treatment of GAD since it enhances the quality of the relaxing experience through the elicitation of the sense of presence. This controlled trial will be able to evaluate the effects of the use of VR in relaxation while preserving the benefits of randomization to reduce bias. © 2008 Gorini and Riva; licensee BioMed Central Ltd.",,"article; audiovisual equipment; clinical trial; controlled clinical trial; controlled study; dependent variable; generalized anxiety disorder; human; major clinical study; narrative; patient education; psychometry; psychophysiology; quantitative analysis; randomized controlled trial; relaxation training; stress management; virtual reality",Article,"Final","",Scopus,2-s2.0-44949179316
"Klein M.I., Warm J.S., Riley M.A., Matthews G., Gaitonde K., Donovan J.F.","35743063600;7003365044;7203009785;7201422023;6507516465;35478229100;","Perceptual distortions produce multidimensional stress profiles in novice users of an endoscopic surgery simulator",2008,"Human Factors","50","2",,"291","300",,20,"10.1518/001872008X288312","https://www.scopus.com/inward/record.uri?eid=2-s2.0-44349120541&doi=10.1518%2f001872008X288312&partnerID=40&md5=e47711817b92dfb8a444c950a3772de2","Department of Psychology, Waldorf College, Forest City, IA, United States; Department of Psychology, University of Cincinnati, Cincinnati, OH, United States; Department of Urology, University of Cincinnati, College of Medicine, Cincinnati, OH, United States; Urology Residency Program, University of Cincinnati, College of Medicine, Cincinnati, OH, United States; Department of Psychology, University of Cincinnati, Cincinnati, OH 45221-0376, United States","Klein, M.I., Department of Psychology, Waldorf College, Forest City, IA, United States; Warm, J.S., Department of Psychology, University of Cincinnati, Cincinnati, OH, United States, Department of Psychology, University of Cincinnati, Cincinnati, OH 45221-0376, United States; Riley, M.A., Department of Psychology, University of Cincinnati, Cincinnati, OH, United States; Matthews, G., Department of Psychology, University of Cincinnati, Cincinnati, OH, United States; Gaitonde, K., Department of Urology, University of Cincinnati, College of Medicine, Cincinnati, OH, United States; Donovan, J.F., Urology Residency Program, University of Cincinnati, College of Medicine, Cincinnati, OH, United States","Objectives: We determine the impact of perceptual-motor distortions on multidimensional stress dynamics in novice users of an endoscopic/laparoscopic surgery simulator during performance of a peg-transfer task. Background: Surgeons find the endoscopic/laparoscopic surgery procedure to be more mentally stressful than open surgery. This investigation was designed to identify specific stress dimensions associated with these procedures and to determine the contributions to that stress made by loss of depth information resulting from image-guided views of the surgical field and by disruption of eye-hand mapping. Because stress reactions might depend upon familiarity with these procedures, the study focused upon novice participants. Method: An endoscopic box-simulator featured in surgical training was used in conjunction with the Dundee Stress State Questionnaire, a well-validated multidimensional stress state instrument. A control group (no perceptual distortions) viewed the simulated ""surgical field"" directly. Two other groups viewed the surgical field through TV images in which spatial rotation of the images was absent or in which the images were rotated 90° from the actual line of sight. Results: Performance efficiency in the simulator varied inversely with the degree of perceptual-motor distortion. Reactions reflecting increased task coping were observed in all groups. These were accompanied in the image groups by negative reactions involving decreases in hedonic tone and control and confidence and an increase in tense arousal. Conclusions: Perceptual-motor distortions are sources of complex task-induced stress profiles in novices using an endoscopic surgery simulator. Application: Procedures to reduce stress in endoscopic/laparoscopic surgery trainees may benefit from knowledge regarding specific stress dimensions involved. Copyright © 2008, Human Factors and Ergonomics Society.",,"Information retrieval; Simulators; Surgery; Multidimensional stress profiles; Perceptual distortions; Endoscopy; adult; article; Dundee Stress State Questionnaire; endoscopic surgery; female; human; human experiment; job stress; male; normal human; perception disorder; questionnaire; simulator; surgical training; task performance; television; Adolescent; Adult; Analysis of Variance; Attention; Computer Simulation; Endoscopy; Female; Humans; Male; Motivation; Perceptual Distortion; Questionnaires; Stress, Psychological; Students, Medical; Surgery; Task Performance and Analysis; Television; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-44349120541
"Howells N.R., Gill H.S., Carr A.J., Price A.J., Rees J.L.","36845622900;7102377084;57213262958;7202636742;55597569300;","Transferring simulated arthroscopic skills to the operating theatre: A randomised blinded study",2008,"Journal of Bone and Joint Surgery - Series B","90","4",,"494","499",,169,"10.1302/0301-620X.90B4.20414","https://www.scopus.com/inward/record.uri?eid=2-s2.0-42149136819&doi=10.1302%2f0301-620X.90B4.20414&partnerID=40&md5=c870005b761484f38bf497e0299c2ba0","Nuffield Orthopaedic Centre, Oxford, United Kingdom; Department of Orthopaedic Surgery, University of Oxford, Nuffield Orthopaedic Centre, Oxford OX3 7LD, United Kingdom; Nuffield Department of Orthopaedic Surgery, University of Oxford, Nuffield Orthopaedic Centre, Oxford OX3 7LD, United Kingdom","Howells, N.R., Nuffield Orthopaedic Centre, Oxford, United Kingdom, Nuffield Department of Orthopaedic Surgery, University of Oxford, Nuffield Orthopaedic Centre, Oxford OX3 7LD, United Kingdom; Gill, H.S., Nuffield Orthopaedic Centre, Oxford, United Kingdom, Nuffield Department of Orthopaedic Surgery, University of Oxford, Nuffield Orthopaedic Centre, Oxford OX3 7LD, United Kingdom; Carr, A.J., Nuffield Orthopaedic Centre, Oxford, United Kingdom, Department of Orthopaedic Surgery, University of Oxford, Nuffield Orthopaedic Centre, Oxford OX3 7LD, United Kingdom; Price, A.J., Nuffield Orthopaedic Centre, Oxford, United Kingdom, Nuffield Department of Orthopaedic Surgery, University of Oxford, Nuffield Orthopaedic Centre, Oxford OX3 7LD, United Kingdom; Rees, J.L., Nuffield Orthopaedic Centre, Oxford, United Kingdom, Nuffield Department of Orthopaedic Surgery, University of Oxford, Nuffield Orthopaedic Centre, Oxford OX3 7LD, United Kingdom","The aim of this study was to investigate the effect of laboratory-based simulator training on the ability of surgical trainees to perform diagnostic arthroscopy of the knee. A total of 20 junior orthopaedic trainees were randomised to receive either a fixed protocol of arthroscopic simulator training on a bench-top knee simulator or no additional training. Motion analysis was used to assess performance objectively. Each trainee then received traditional instruction and demonstrations of diagnostic arthroscopy of the knee in theatre before performing the procedure under the supervision of a blinded consultant trainer. Their performance was assessed using a procedure-based assessment from the Orthopaedic Competence Assessment Project and a five-point global rating assessment scale. In theatre the simulator-trained group performed significantly better than the untrained group using the Orthopaedic Competence Assessment Project score (p = 0.0007) and assessment by the global rating scale (p = 0.0011), demonstrating the transfer of psychomotor skills from simulator training to arthroscopy in the operating theatre. This has implications for the planning of future training curricula. ©2008 British Editorial Society of Bone and Joint Surgery.",,"article; competence; diagnostic procedure; human; knee; knee arthroscopy; motion analysis system; operating room; orthopedics; priority journal; psychomotor performance; rating scale; simulation; surgical training; task performance; Arthroscopy; Clinical Competence; Computer Simulation; Education, Medical, Graduate; Feasibility Studies; Humans; Knee Joint; Models, Educational; Orthopedics; Single-Blind Method",Article,"Final","",Scopus,2-s2.0-42149136819
"Bossard C., Kermarrec G., Buche C., Tisseau J.","14041141200;6507390430;8349259000;6603486416;","Transfer of learning in virtual environments: A new challenge?",2008,"Virtual Reality","12","3",,"151","161",,38,"10.1007/s10055-008-0093-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-51549098199&doi=10.1007%2fs10055-008-0093-y&partnerID=40&md5=15bf4f1b075d8df2e6176ea6eac87bbf","LISyC UEB UBO-ENIB-ENSIETA, European Center for Virtual Reality, 25 rue Claude Chappe, 38, Plouzané 29280, France","Bossard, C., LISyC UEB UBO-ENIB-ENSIETA, European Center for Virtual Reality, 25 rue Claude Chappe, 38, Plouzané 29280, France; Kermarrec, G., LISyC UEB UBO-ENIB-ENSIETA, European Center for Virtual Reality, 25 rue Claude Chappe, 38, Plouzané 29280, France; Buche, C., LISyC UEB UBO-ENIB-ENSIETA, European Center for Virtual Reality, 25 rue Claude Chappe, 38, Plouzané 29280, France; Tisseau, J., LISyC UEB UBO-ENIB-ENSIETA, European Center for Virtual Reality, 25 rue Claude Chappe, 38, Plouzané 29280, France","The aim of all education is to apply what we learn in different contexts and to recognise and extend this learning to new situations. Virtual learning environments can be used to build skills. Recent research in cognitive psychology and education has shown that acquisitions are linked to the initial context. This provides a challenge for virtual reality in education or training. A brief overview of transfer issues highlights five main ideas: (1) the type of transfer enables the virtual environment (VE) to be classified according to what is learned; (2) the transfer process can create conditions within the VE to facilitate transfer of learning; (3) specific features of VR must match and comply with transfer of learning; (4) transfer can be used to assess a VE's effectiveness; and (5) future research on transfer of learning must examine the singular context of learning. This paper discusses how new perspectives in cognitive psychology influence and promote transfer of learning through the use of VEs. © Springer-Verlag London Limited 2008.","Learning models; Training; Transfer of learning; Virtual environment","Virtual reality; Learning models; Training; Transfer of learning; Virtual environment; Education",Article,"Final","",Scopus,2-s2.0-51549098199
"Herrera G., Alcantud F., Jordan R., Blanquer A., Labajo G., De Pablo C.","56368923300;22233261800;7401610771;6602954525;22334051500;21734145500;","Development of symbolic play through the use of virtual reality tools in children with autistic spectrum disorders: Two case studies",2008,"Autism","12","2",,"143","157",,78,"10.1177/1362361307086657","https://www.scopus.com/inward/record.uri?eid=2-s2.0-40449115651&doi=10.1177%2f1362361307086657&partnerID=40&md5=85a460477b2129a93cb8832ea6008302","Universitat de Valencia Estudi General, Spain; University of Birmingham, Birmingham, United Kingdom; Centro Comunica de Diagnóstico e Intervención, Spain; Autismo Burgos, Spain","Herrera, G., Universitat de Valencia Estudi General, Spain; Alcantud, F., Universitat de Valencia Estudi General, Spain; Jordan, R., University of Birmingham, Birmingham, United Kingdom; Blanquer, A., Centro Comunica de Diagnóstico e Intervención, Spain; Labajo, G., Autismo Burgos, Spain; De Pablo, C., Autismo Burgos, Spain","Difficulties in understanding symbolism have been documented as characteristic of autistic spectrum disorders (ASDs). In general, virtual reality (VR) environments offer a set of potential advantages for educational intervention in ASD. In particular, VR offers the advantage, for teaching pretend play and for understanding imagination, of it being possible to show these imaginary transformations explicitly. This article reports two case studies of children with autism (aged 8:6 and 15:7, both male), examining the effectiveness of using a VR tool specifically designed to work on teaching understanding of pretend play. The results, confirmed by independent observers, showed a significant advance in pretend play abilities after the intervention period in both participants, and a high degree of generalization of the acquired teaching in one of them. © 2008 Sage Publication.","Autism; Imagination; Pretend play; Virtual reality","adolescent; article; autism; case report; child psychiatry; clinical effectiveness; human; intervention study; learning environment; learning style; male; play; priority journal; school child; symbolism; teaching; virtual reality; Adolescent; Autistic Disorder; Child; Humans; Imagination; Learning Disorders; Male; Play and Playthings; Symbolism; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-40449115651
"Reed P., Morgan T.A.","7202010595;8357657400;","Effect on subsequent fixed-interval schedule performance of prior exposure to ratio and interval schedules of reinforcement",2008,"Learning and Behavior","36","2",,"82","91",,3,"10.3758/LB.36.2.82","https://www.scopus.com/inward/record.uri?eid=2-s2.0-46649107779&doi=10.3758%2fLB.36.2.82&partnerID=40&md5=894b34f07d85a4d8ec4fb07ad4a2200e","Swansea University, Swansea, United Kingdom; University of Iowa, Iowa City, IA, United States; Department of Psychology, Swansea University, Singleton Park, Swansea SA2 8PP, United Kingdom","Reed, P., Swansea University, Swansea, United Kingdom, Department of Psychology, Swansea University, Singleton Park, Swansea SA2 8PP, United Kingdom; Morgan, T.A., University of Iowa, Iowa City, IA, United States","In three experiments, we examined the effect on the patterns of responding noted on fixed interval (FI) schedules of prior exposure to a range of interval and ratio schedules. Rats leverpressed for food reinforcement on random ratio (RR), random interval (RI), or variable interval (VI) schedules prior to transfer to FI schedules. In Experiment 1, prior exposure to an RR schedule retarded the development of typical FI patterns of responding. Exposure to a yoked RI schedule produced even greater retardation of typical FI performance. This effect was replicated in Experiment 2, using a within-subjects design. Rats responded on a multiple RR-RI schedule prior to a multiple FI-FI schedule. Typical FI performance emerged more slowly in the component previously associated with the RI than with that associated with the RR. In Experiment 3, exposure to an RR schedule retarded the development of FI performance to a greater extent than did exposure to a VR schedule. The latter schedule was programmed to allow the possibility that inhibitory control would develop after reinforcement. These results confirm that ratio schedules independently result in the disruption of FI responding. This effect was not long lasting and cannot be used plausibly to explain species differences in responding to FI schedules. However, it does suggest that temporal control - as manifested by the transfer of inhibitory control from one schedule to another - could facilitate movement between interval schedules. Copyright 2008 Psychonomic Society, Inc.",,"animal experiment; article; behavior; controlled study; fixed interval schedule; male; nonhuman; random interval; random ratio; rat; reinforcement; task performance; analysis of variance; animal; inhibition (psychology); learning; physiology; psychomotor performance; rat strain; reaction time; Analysis of Variance; Animals; Association Learning; Inhibition (Psychology); Male; Psychomotor Performance; Rats; Rats, Inbred Strains; Reaction Time; Reinforcement Schedule; Transfer (Psychology)",Article,"Final","",Scopus,2-s2.0-46649107779
"Frisoli A., Ruffaldi E., Bagnoli L., Filippeschi A., Avizzano C.A., Vanni F., Bergamasco M.","6603070041;15023001900;57045738000;26666003000;6603815755;37115043600;7003907071;","Preliminary design of rowing simulator for in-door skill training",2008,"Proceedings of the 2008 Ambi-Sys Workshop on Haptic User Interfaces in Ambient Media Systems, HAS 2008",,, 1413916,"","",,7,"10.4108/icst.ambisys2008.2911","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85002986680&doi=10.4108%2ficst.ambisys2008.2911&partnerID=40&md5=3a129f709b7a8b96e69ffc6940db0270","PERCRO, Scuola Superiore Sant'Anna, Pisa, Italy","Frisoli, A., PERCRO, Scuola Superiore Sant'Anna, Pisa, Italy; Ruffaldi, E., PERCRO, Scuola Superiore Sant'Anna, Pisa, Italy; Bagnoli, L., PERCRO, Scuola Superiore Sant'Anna, Pisa, Italy; Filippeschi, A., PERCRO, Scuola Superiore Sant'Anna, Pisa, Italy; Avizzano, C.A., PERCRO, Scuola Superiore Sant'Anna, Pisa, Italy; Vanni, F., PERCRO, Scuola Superiore Sant'Anna, Pisa, Italy; Bergamasco, M., PERCRO, Scuola Superiore Sant'Anna, Pisa, Italy","In this paper we report on the preliminary design of a rowing simulator to be integrated in a VR sport training system for rowing. The proposed simulator aims at bringing in an in-door location the specific features and situations of outdoor rowing, by means of an enhanced Virtual Environment (VE) that combines visual, haptic, acoustic flows to proprio- and exteroception of user status. This paper describes the experimental activities carried out on in-door rowing to characterize the main features of the stroke gesture, the design and analytical study of a fluidodynamic dissipator for force rendering and an overview of graphic simulation and of the overall system architecture. © 2008, Association for Computing Machinery, Inc. All rights reserved.","Haptics; Rowing simulator; Skill transfer","Haptic interfaces; Simulators; Virtual reality; Analytical studies; Experimental activities; Graphic simulation; Haptics; Preliminary design; Skill transfer; System architectures; Training Systems; Sports",Conference Paper,"Final","",Scopus,2-s2.0-85002986680
"Jiang P., Liu Y., Zhao L.","7201470064;55649532100;55493558600;","Distributed VR-driven collaborative support for modelling 3D silicon micro components",2008,"International Journal of Internet Manufacturing and Services","1","4",,"345","365",,1,"10.1504/IJIMS.2008.022991","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864407259&doi=10.1504%2fIJIMS.2008.022991&partnerID=40&md5=f439e3b6e6caa26706c35a779d5d8846","National Key Laboratory for Manufacturing Systems Engineering, School of Mechanical Engineering, Xi'an Jiaotong University, Xia'an 710049, China; CAD/CAM Institute, School of Mechanical Engineering, Xi'an Jiaotong University, Xian 710049, China","Jiang, P., National Key Laboratory for Manufacturing Systems Engineering, School of Mechanical Engineering, Xi'an Jiaotong University, Xia'an 710049, China; Liu, Y., CAD/CAM Institute, School of Mechanical Engineering, Xi'an Jiaotong University, Xian 710049, China; Zhao, L., CAD/CAM Institute, School of Mechanical Engineering, Xi'an Jiaotong University, Xian 710049, China","To making MEMS structure design in an intuitive way and to reducing design iteration, a 3D feature-based collaborative structure modelling work flow of 3D silicon micro components is proposed according to 'function to 3D shape to fabrication' design methodology. Around this collaborative structure modelling workflow, design privileges are specified to designers through design multi-views, CSG/ B-rep solid model constructs the basis of feature modelling, distributed VR devices driving model is put forward to enhance man-machine interaction and P2P communication infrastructure is used to accelerate 3D model transfer through internet. Using a micro RF switch as an example, corresponding collaborative design flow and design multi-views is scheduled and execute on the collaborative micro-components modelling prototype. Copyright © 2008, Inderscience Publishers.","3D modelling; Collaborative design; Distributed virtual reality; P2P; Peer to peer; Silicon fabricated micro-components","3D modeling; Distributed computer systems; Iterative methods; Microoptics; Silicon; Virtual reality; 3D modelling; Collaborative design; Distributed virtual reality; Micro-components; Peer to peer; Structural design",Article,"Final","",Scopus,2-s2.0-84864407259
"De Moraes R.M., Dos Santos Machado L.","7003717947;55208890500;","Online training assessment in virtual reality simulators based on Gaussian Naive Bayes",2008,"World Scientific Proceedings Series on Computer Engineering and Information Science 1; Computational Intelligence in Decision and Control - Proceedings of the 8th International FLINS Conference",,,,"1147","1152",,4,"10.1142/9789812799470_0188","https://www.scopus.com/inward/record.uri?eid=2-s2.0-58049166505&doi=10.1142%2f9789812799470_0188&partnerID=40&md5=05e32aa17d39dd57209acb06216f28c2","Department of Statistics, Federal University of Paraíba, Cidade Universitária s/n, João Pessoa-PB. 58.059-900, Brazil; Department of Informatics, Federal University of Paraíba, Cidade Universitária s/n, João Pessoa-PB. 58.059-900, Brazil","De Moraes, R.M., Department of Statistics, Federal University of Paraíba, Cidade Universitária s/n, João Pessoa-PB. 58.059-900, Brazil; Dos Santos Machado, L., Department of Informatics, Federal University of Paraíba, Cidade Universitária s/n, João Pessoa-PB. 58.059-900, Brazil","Training systems based on virtual reality are used in several areas. In these systems the user is immersed into a virtual world to have realistic training through realistic interactions. In such training is important to know the quality of user's training. An online assessment system allows the user to improve his/her learning because it can identify, immediately after the training, where he/she committed mistakes. In this paper, we present a new approach to online training assessment based on Gaussian Naive Bayes, a generalization of Naive Bayes Networks, for modeling and classification of simulation in M pre-defined classes.",,"Artificial intelligence; Bayesian networks; Classifiers; Online systems; Virtual reality; Naive bayes; New approaches; On-line assessment; On-line training assessments; Pre-defined class; Training Systems; Virtual reality simulator; Virtual worlds; E-learning",Conference Paper,"Final","",Scopus,2-s2.0-58049166505
"Mirelman A., Patritti B.L., Bonato P., Deutsch J.E.","35332484600;10840065100;7006225560;7201985389;","Effects of robot-virtual reality compared with robot alone training on gait kinetics of individuals post stroke",2007,"2007 Virtual Rehabilitation, IWVR",,, 4362132,"65","69",,4,"10.1109/ICVR.2007.4362132","https://www.scopus.com/inward/record.uri?eid=2-s2.0-50849122343&doi=10.1109%2fICVR.2007.4362132&partnerID=40&md5=c4a6848165f872bcd03bee106d31a25c","IEEE; Department of Developmental and Rehabilitative Sciences, University of Medicine and Dentistry of New Jersey, Newark, NJ 07101, United States; Department of Physical Medicine and Rehabilitation, Harvard Medical School, Spaulding Rehabilitation Hospital, Boston, MA 02114, United States; Department of Physical Medicine and Rehabilitation, Harvard Medical School, Spaulding Rehabilitation Hospital, Boston MA 02114, United States; Harvard-MIT Division of Health Sciences and Technology, Cambridge, MA 02139, United States; Department of Developmental and Rehabilitative Sciences, University of Medicine and Dentistry of New Jersey, Newark NJ 07101, United States","Mirelman, A., Department of Developmental and Rehabilitative Sciences, University of Medicine and Dentistry of New Jersey, Newark, NJ 07101, United States, Department of Physical Medicine and Rehabilitation, Harvard Medical School, Spaulding Rehabilitation Hospital, Boston, MA 02114, United States; Patritti, B.L., Department of Physical Medicine and Rehabilitation, Harvard Medical School, Spaulding Rehabilitation Hospital, Boston, MA 02114, United States; Bonato, P., IEEE, Department of Physical Medicine and Rehabilitation, Harvard Medical School, Spaulding Rehabilitation Hospital, Boston MA 02114, United States, Harvard-MIT Division of Health Sciences and Technology, Cambridge, MA 02139, United States; Deutsch, J.E., Department of Developmental and Rehabilitative Sciences, University of Medicine and Dentistry of New Jersey, Newark NJ 07101, United States","Virtual reality systems have been used to deliver goal directed repetitive training to promote rehabilitation of individuals post-stroke. Lower extremity training of individuals post-stroke who used a robot coupled with virtual environments was shown to transfer to improved over-ground locomotion. To elucidate an underlying mechanism that enabled this functional change we compared the kinetic outcomes of training with the robot-virtual reality (VR) system to the robot alone. Eighteen individuals post-stroke participated in a four-week training protocol. One group trained with the robot-VR system and the other group with the robot alone. Training parameters were comparable for the two groups; however, the improvements in moments and powers generated in the ankle and hip of subjects in the robot-VR group were significantly greater than those in the robot alone group. These findings demonstrate that lower extremity training using virtual environments coupled with a robot produced greater gait related strength gains than training with robot alone. © 2007 IEEE.",,"Lower extremity; Virtual environments; Virtual rehabilitation; Computer networks; Patient rehabilitation; Virtual reality; Robots",Conference Paper,"Final","",Scopus,2-s2.0-50849122343
"Göttel T.","23984476800;","ProBoNO: Transferring knowledge of virtual environments to real world situations",2007,"Proceedings of the 6th international Conference on Interaction Design And Children, IDC 2007",,,,"81","88",,8,"10.1145/1297277.1297294","https://www.scopus.com/inward/record.uri?eid=2-s2.0-41149144746&doi=10.1145%2f1297277.1297294&partnerID=40&md5=6b156c828a4ab27183339e3f00ebe250","Applied and Social Informatics, University of Hamburg, Vogt-Kodie;lln-Str. 30, 22527 Hamburg, Germany","Göttel, T., Applied and Social Informatics, University of Hamburg, Vogt-Kodie;lln-Str. 30, 22527 Hamburg, Germany","This paper presents a software environment for children at the age of four to six years. It is designed to teach navigational knowledge in a virtual environment. A prototype of a prop based input device is proposed in this regard. We report on a study at a day-care centre that was conducted to compare cursor and mouse control to the prototype. Furthermore the evaluation examined whether a transfer of knowledge from a virtual environment to a real world situation is discernible. It became obvious that cursor and mouse control is too difficult for children at the predefined age. A transfer of knowledge might be facilitated by using tangible user interfaces. Copyright 2007 ACM.","Education; Navigational knowledge; Tangible user interface; Virtual learning environment","E-learning; Knowledge based systems; Problem solving; User interfaces; Virtual reality; Navigational knowledge; Software environment; Tangible user interface; Virtual learning environment; Data transfer",Conference Paper,"Final","",Scopus,2-s2.0-41149144746
"López Silva B.A., Renambot L.","20434058900;6602580367;","CytoViz: An artistic mapping of network measurements as living organisms in a VR application",2007,"Proceedings of SPIE - The International Society for Optical Engineering","6490",, 64901U,"","",,,"10.1117/12.711637","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548233859&doi=10.1117%2f12.711637&partnerID=40&md5=6fa03c848c4d3bba975e682c0b3af5d6","University of Illinois at Chicago, Electronic Visualization Laboratory, Department of Computer Science, Chicago, IL 60607","López Silva, B.A., University of Illinois at Chicago, Electronic Visualization Laboratory, Department of Computer Science, Chicago, IL 60607; Renambot, L., University of Illinois at Chicago, Electronic Visualization Laboratory, Department of Computer Science, Chicago, IL 60607","CytoViz is an artistic, real-time information visualization driven by statistical information gathered during gigabit network transfers to the Scalable Adaptive Graphical Environment (SAGE) at various events. Data streams are mapped to cellular organisms defining their structure and behavior as autonomous agents. Network bandwidth drives the growth of each entity and the latency defines its physics-based independent movements. The collection of entity is bound within the 3D representation of the local venue. This visual and animated metaphor allows the public to experience the complexity of high-speed network streams that are used in the scientific community. Moreover, CytoViz displays the presence of discoverable Bluetooth devices carried by nearby persons. The concept is to generate an event-specific, real-time visualization that creates informational 3D patterns based on actual local presence. The observed Bluetooth traffic is put in opposition of the wide-area networking traffic by overlaying 2D animations on top of the 3D world. Each device is mapped to an animation fading over time while displaying the name of the detected device and its unique physical address. CytoViz was publicly presented at two major international conferences in 2005 (iGrid2005 in San Diego, CA and SC05 in Seattle, WA). © 2007 SPIE-IS&T.","Bluetooth; Information visualization; Network performance; Visualization","Autonomous agents; Bandwidth; Bluetooth; Living systems studies; Statistical methods; Virtual reality; Visualization; Cellular organisms; Information visualization; Network performance; Real time systems",Conference Paper,"Final","",Scopus,2-s2.0-34548233859
"Mathis K.L., Wiegmann D.A.","15848772200;7004122515;","Construct validation of a laparoscopic surgical simulator",2007,"Simulation in Healthcare","2","3",,"178","182",,11,"10.1097/SIH.0b013e318137aba1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547941419&doi=10.1097%2fSIH.0b013e318137aba1&partnerID=40&md5=3a8a5f10a4a67bd4dd71b37ffbc16ed4","Department of Surgery, Mayo Clinic, College of Medicine, Rochester, MN, United States; Department of Surgery, Mayo Clinic, 200 First Street, SW, Rochester, MN 55905, United States","Mathis, K.L., Department of Surgery, Mayo Clinic, College of Medicine, Rochester, MN, United States, Department of Surgery, Mayo Clinic, 200 First Street, SW, Rochester, MN 55905, United States; Wiegmann, D.A., Department of Surgery, Mayo Clinic, College of Medicine, Rochester, MN, United States","BACKGROUND: Laparoscopic simulators are increasingly used to train and evaluate surgical skill, and validating laparoscopic simulators for these purposes is paramount. Our goal was to determine if the SurgicalSIM laparoscopic surgical simulator can discriminate between novices and experts and to assess learning curves among novices. METHODS: Twenty novices and five experts performed five repetitions on the following modules: place arrow, retract, dissect, and traverse tube. For each module, median baseline performance was calculated. Novices performed 35 additional repetitions to assess learning with practice. RESULTS: Experts outperformed novices at baseline for time to completion on the dissect, place arrow, and traverse tube modules, as well as for error frequency on the traverse tube and retract modules. Novices' performance improved significantly with practice, approaching the experts' baseline in all modules. CONCLUSION: The SurgicalSIM laparoscopic simulator exhibits construct validity on three of four basic-skills modules when considering completion time and on two modules when considering error frequency. Among novices, learning occurred with additional repetitions. Whether acquired skills transfer to the actual surgical environment has yet to be determined. © 2007 Lippincott Williams & Wilkins, Inc.",,"article; clinical education; clinical practice; construct validity; human; human experiment; laparoscopic surgery; learning; priority journal; simulation; task performance; Clinical Competence; Computer Simulation; Education, Medical, Undergraduate; Educational Measurement; Educational Status; Humans; Laparoscopy; Models, Educational",Article,"Final","",Scopus,2-s2.0-34547941419
"Ieronutti L., Chittaro L.","6507168127;7004119007;","Employing virtual humans for education and training in X3D/VRML worlds",2007,"Computers and Education","49","1",,"93","109",,62,"10.1016/j.compedu.2005.06.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846491809&doi=10.1016%2fj.compedu.2005.06.007&partnerID=40&md5=72b0939bb3209509b6f9ba37613071ac","HCI Laboratory, Department of Math and Computer Science, University of Udine, via delle Scienze 206, 33100 Udine, Italy","Ieronutti, L., HCI Laboratory, Department of Math and Computer Science, University of Udine, via delle Scienze 206, 33100 Udine, Italy; Chittaro, L., HCI Laboratory, Department of Math and Computer Science, University of Udine, via delle Scienze 206, 33100 Udine, Italy","Web-based education and training provides a new paradigm for imparting knowledge; students can access the learning material anytime by operating remotely from any location. Web3D open standards, such as X3D and VRML, support Web-based delivery of Educational Virtual Environments (EVEs). EVEs have a great potential for learning and training purposes, by allowing one to circumvent physical, safety, and cost constraints. Unfortunately, EVEs often leave to the user the onus of taking the initiative both in exploring the environment and interacting with its parts. A possible solution to this problem is the exploitation of virtual humans acting as informal coaches or more formal instructors. For example, virtual humans can be employed to show and explain maintenance procedures, allowing learners to receive more practical explanations which are easier to understand. However, virtual humans are rarely used in Web3D EVEs, since the programming effort to develop and re-use them in different environments can be considerable. In this paper, we present a general architecture that allows content creators to easily integrate virtual humans into Web3D EVEs. To test the generality of our solution, we present two practical examples showing how the proposed architecture has been used in different educational contexts. © 2005 Elsevier Ltd. All rights reserved.","Distance education and telelearning; Human-computer interface; Interactive learning environments; Virtual Reality","Human computer interaction; Interactive computer graphics; Learning systems; Virtual reality; World Wide Web; Cost constraints; Interactive learning environments; Telelearning; Virtual humans; Distance education",Article,"Final","",Scopus,2-s2.0-33846491809
"Strickland D.C., McAllister D., Coles C.D., Osborne S.","7101782936;57214539590;7005495059;7102780238;","An evolution of virtual reality training designs for children with autism and fetal alcohol spectrum disorders",2007,"Topics in Language Disorders","27","3",,"226","241",,51,"10.1097/01.TLD.0000285357.95426.72","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548458920&doi=10.1097%2f01.TLD.0000285357.95426.72&partnerID=40&md5=3087522d533d447fe110a3041a3be736","Do2Learn, Raleigh, NC; Departments of Computer Science; North Carolina State University, Raleigh, NC; Department of Psychiatry and Behavioral Sciences, Emory University, School of Medicine, Atlanta, GA; Do2Learn, 3204 Churchill Rd., Raleigh, NC 27607","Strickland, D.C., Do2Learn, Raleigh, NC, Do2Learn, 3204 Churchill Rd., Raleigh, NC 27607; McAllister, D., Departments of Computer Science; Coles, C.D., North Carolina State University, Raleigh, NC, Department of Psychiatry and Behavioral Sciences, Emory University, School of Medicine, Atlanta, GA; Osborne, S., Departments of Computer Science","This article describes an evolution of training programs to use first-person interaction in virtual reality (VR) situations to teach safety skills to children with autism spectrum disorder (ASD) and fetal alcohol spectrum disorder (FASD). Multiple VR programs for children aged 2 to 9 were built and tested between 1992 and 2007. Based on these results, a learning design evolved that uses practice in virtual space with guidance and correction by an animated character, strategic limitations on allowed actions to force correct patterning, and customization of worlds and responses to simplify user controls. This article describes program evolution by comparing design details and results as variations in behavioral responses between disorders, differences in skill set complexity between different safety skills being taught, and improved technology required changes in the virtual training methodology. A series of research projects are summarized in which the VR programs proved effective for teaching children with ASD and FASD new skills in the virtual space and, where measured, most children generalized the actions to the real world. Copyright © 2007 Wolters Kluwer Health.","Autism; Children; Fetal alcohol; Fire safety; Street crossing; Virtual reality",,Article,"Final","",Scopus,2-s2.0-34548458920
"Self T., Scudder R.R., Weheba G., Crumrine D.","16640059200;6603292760;55920884600;35864209300;","A virtual approach to teaching safety skills to children with autism spectrum disorder",2007,"Topics in Language Disorders","27","3",,"242","253",,54,"10.1097/01.TLD.0000285358.33545.79","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548403806&doi=10.1097%2f01.TLD.0000285358.33545.79&partnerID=40&md5=6ec797f4f5bc2c50eeb1795d34dedffa","Department of Communication Sciences and Disorders; Wichita State University, Wichita Public Schools; Department of Communication Sciences and Disorders, Wichita State University, 1845 Fairmount, Wichita, KS 67260","Self, T., Department of Communication Sciences and Disorders, Department of Communication Sciences and Disorders, Wichita State University, 1845 Fairmount, Wichita, KS 67260; Scudder, R.R., Department of Communication Sciences and Disorders; Weheba, G.; Crumrine, D., Wichita State University, Wichita Public Schools, ","Recent advancements in the development of hardware/software configurations for delivering virtual reality (VR) environments to individuals with disabilities have included approaches for children with autism spectrum disorder (ASD). This article describes a study comparing benefits of using VR to benefits of an integrated/visual treatment model when teaching safety skills to children with ASD in a public school setting. Participants were 8 children diagnosed with ASD who were randomly assigned to receive either VR or an integrated/visual treatment model to learn fire and tornado safety skills. Both groups improved in their learning and transfer of safety skills. The VR group, however, learned these skills in considerably less time. Implications and suggestions for the use of VR in educational settings are presented. Copyright © 2007 Wolters Kluwer Health.","Autism spectrum disorder; Educational settings; Integrated treatment approach; Safety skills; Virtual reality",,Article,"Final","",Scopus,2-s2.0-34548403806
"Jimeno A., Puerta A.","57200400092;17435762700;","State of the art of the virtual reality applied to design and manufacturing processes",2007,"International Journal of Advanced Manufacturing Technology","33","9-10",,"866","874",,51,"10.1007/s00170-006-0534-2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547241548&doi=10.1007%2fs00170-006-0534-2&partnerID=40&md5=dd83223015082c2a38dae7cb28c99106","Department of Computer Technology and Computation, Alicante University, San Vicente del Raspeig s/n, 03001 Alicante, Spain","Jimeno, A., Department of Computer Technology and Computation, Alicante University, San Vicente del Raspeig s/n, 03001 Alicante, Spain; Puerta, A., Department of Computer Technology and Computation, Alicante University, San Vicente del Raspeig s/n, 03001 Alicante, Spain","The idea that technology can transfer a person to a different environment without any physical movement and create the illusion of interaction with the artificial environment is not new. Scientists and engineers have been dedicating their efforts to its progressive development over the last fifty years. However, most of the technological advances have been made in the last ten years, undoubtedly thanks to improvements in computer efficiency and the miniaturization of sensorization devices. Nowadays, virtual reality is successfully applied in different fields, such as telemedicine, robotics or cinematography. Following on from this success, the question arises of whether we are ready to apply it to industrial design and manufacturing processes. The lack of recent reviews on this technology applied to CAD/CAM, together with its rapid evolution over the last decade, have been the primary motivations for carrying out this study. © 2006 Springer-Verlag London Limited.","Virtual environments; Virtual prototyping; Virtual reality","Computer aided design; Computer aided manufacturing; Photography; Robotics; Technology transfer; Telemedicine; Sensorization devices; Virtual prototyping; Virtual reality",Article,"Final","",Scopus,2-s2.0-34547241548
"Berry M., Lystig T., Beard J., Klingestierna H., Reznick R., Lönn L.","55694628800;8333929100;7201799641;16230910600;7006153860;7003833263;","Porcine transfer study: Virtual reality simulator training compared with porcine training in endovascular novices",2007,"CardioVascular and Interventional Radiology","30","3",,"455","461",,49,"10.1007/s00270-006-0161-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247106391&doi=10.1007%2fs00270-006-0161-1&partnerID=40&md5=f166d288fe49a7ee3c8cfaf5f3e731c1","Department of Interventional Radiology, Sahlgrenska Hospital, Gothenburg, Sweden; Astra-Zeneca AB, Mölndal, Sweden; Department of Vascular Surgery, Northern General Hospital, Sheffield, United Kingdom; Department of Radiology, Boras Hospital, Boras, Sweden; Department of Surgery, University of Toronto, Toronto, Canada; Vesterbrogade 100A, t.v., 1620 Copenhagen V, Denmark","Berry, M., Department of Interventional Radiology, Sahlgrenska Hospital, Gothenburg, Sweden, Vesterbrogade 100A, t.v., 1620 Copenhagen V, Denmark; Lystig, T., Astra-Zeneca AB, Mölndal, Sweden; Beard, J., Department of Vascular Surgery, Northern General Hospital, Sheffield, United Kingdom; Klingestierna, H., Department of Radiology, Boras Hospital, Boras, Sweden; Reznick, R., Department of Surgery, University of Toronto, Toronto, Canada; Lönn, L., Department of Interventional Radiology, Sahlgrenska Hospital, Gothenburg, Sweden","Purpose: To compare the learning of endovascular interventional skills by training on pig models versus virtual reality simulators. Methods: Twelve endovascular novices participated in a study consisting of a pig laboratory (P-Lab) and a virtual reality laboratory (VR-Lab). Subjects were stratified by experience and randomized into four training groups. Following 1 hr of didactic instruction, all attempted an iliac artery stenosis (IAS) revascularization in both laboratories. Onsite proctors evaluated performances using task-specific checklists and global rating scales, yielding a Total Score. Participants completed two training sessions of 3 hr each, using their group's assigned method (P-Lab × 2, P-Lab + VR-Lab, VR-Lab + P-Lab, or VR-Lab × 2) and were re-evaluated in both laboratories. A panel of two highly experienced interventional radiologists performed assessments from video recordings. ANCOVA analysis of Total Score against years of surgical, interventional radiology (IR) experience and cumulative number of P-Lab or VR-Lab sessions was conducted. Inter-rater reliability (IRR) was determined by comparing proctored scores with the video assessors in only the VR-Lab. Results: VR-Lab sessions improved the VR-Lab Total Score (β = 3.029, p = 0.0015) and P-Lab Total Score (β = 1.814, p = 0.0452). P-Lab sessions increased the P-Lab Total Score (β = 4.074, p < 0.0001) but had no effect on the VR-Lab Total Score. In the general statistical model, both P-Lab sessions (β = 2.552, p = 0.0010) and VR-Lab sessions (β = 2.435, p = 0.0032) significantly improved Total Score. Neither previous surgical experience nor IR experience predicted Total Score. VR-Lab scores were consistently higher than the P-Lab scores (Δ = 6.659, p < 0.0001). VR-Lab IRR was substantial (r = 0.649, p < 0.0008). Conclusions: Endovascular skills learned in the virtual environment may be transferable to the real catheterization laboratory as modeled in the P-Lab. © 2007 Springer Science+Business Media, Inc.","Endovascular skills training; Iliac artery stenosis; Pig model; Virtual reality simulator","analysis of covariance; article; catheterization; controlled study; endovascular surgery; evaluation; human; iliac artery obstruction; interrater reliability; interventional radiology; learning; normal human; prediction; priority journal; rating scale; revascularization; scoring system; simulator; skill; statistical model; statistical significance; surgeon; surgical training; swine; task performance; videorecording; virtual reality; Adult; Angioplasty, Balloon; Animals; Arterial Occlusive Diseases; Attitude of Health Personnel; Computer Simulation; Curriculum; Disease Models, Animal; Female; Humans; Iliac Artery; Male; Middle Aged; Radiology, Interventional; Stents; Swine; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-34247106391
"Munz Y., Almoudaris A.M., Moorthy K., Dosis A., Liddle A.D., Darzi A.W.","6602197387;16306484100;7005014119;6507543369;36840164900;14633357600;","Curriculum-based solo virtual reality training for laparoscopic intracorporeal knot tying: objective assessment of the transfer of skill from virtual reality to reality",2007,"American Journal of Surgery","193","6",,"774","783",,76,"10.1016/j.amjsurg.2007.01.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34248337111&doi=10.1016%2fj.amjsurg.2007.01.022&partnerID=40&md5=e91d91ea2e5b4c043730d1e2a16fba29","Department of General Surgery and Tranplantion, The Chaim Sheba Medical Centre, MSR, Tel Hashomer, 52621 Ramat Gan, Israel; The Department for Surgical Oncology and Technology, St. Mary's Hospital, Imperial College, Pread Street, London, W2 1NY, United Kingdom","Munz, Y., Department of General Surgery and Tranplantion, The Chaim Sheba Medical Centre, MSR, Tel Hashomer, 52621 Ramat Gan, Israel, The Department for Surgical Oncology and Technology, St. Mary's Hospital, Imperial College, Pread Street, London, W2 1NY, United Kingdom; Almoudaris, A.M., The Department for Surgical Oncology and Technology, St. Mary's Hospital, Imperial College, Pread Street, London, W2 1NY, United Kingdom; Moorthy, K., The Department for Surgical Oncology and Technology, St. Mary's Hospital, Imperial College, Pread Street, London, W2 1NY, United Kingdom; Dosis, A., The Department for Surgical Oncology and Technology, St. Mary's Hospital, Imperial College, Pread Street, London, W2 1NY, United Kingdom; Liddle, A.D., The Department for Surgical Oncology and Technology, St. Mary's Hospital, Imperial College, Pread Street, London, W2 1NY, United Kingdom; Darzi, A.W., The Department for Surgical Oncology and Technology, St. Mary's Hospital, Imperial College, Pread Street, London, W2 1NY, United Kingdom","Background: Very few studies have addressed the transferability of skills from virtual reality (VR) to real life. The aim of this study was to assess the feasibility and effectiveness of teaching intracorporeal knot tying (ICKT) by VR simulation only. Methods: Twenty novices underwent structured training of basic skills training on the Minimally Invasive Surgical Trainer simulator (Mentice AB, Gothenburg, Sweden) followed by knot tying training on the LapSim simulator (Surgical Science, Gothenburg, Sweden). They were assessed pre- and post-training on a video trainer. Assessment of performance included motion tracking and video-based checklist. Nonparametric statistical analysis was used, and P < .05 was deemed significant. Results: All participants completed a correct knot as compared with only 25% before VR training. Time to completion was 66% faster and knot quality 45% better after VR training. Significant reduction in number of movements (P = .006) and distance traveled (P < .000) by both hands after VR training. Conclusions: Teaching ICKT by VR simulators only is feasible and effective. Furthermore, this study highlights the complementary use of different VR simulators within a structured curriculum. © 2007 Excerpta Medica Inc. All rights reserved.","Curriculum; Intracorporeal knot tying; Laparoscopic training; Objective assessment; Virtual reality","adult; article; controlled study; course content; curriculum; female; human; intracorporeal knot tying; laparoscopic surgery; male; medical education; normal human; priority journal; simulation; surgical technique; virtual reality; Adult; Clinical Competence; Curriculum; Education, Medical, Undergraduate; Educational Measurement; Humans; Laparoscopy; Male; Patient Simulation; Students, Medical; Suture Techniques; User-Computer Interface; Video Recording",Article,"Final","",Scopus,2-s2.0-34248337111
"Neequaye S.K., Aggarwal R., Brightwell R., Van Herzeele I., Darzi A., Cheshire N.J.W.","16199911300;8616911800;14059692300;22942703800;14633357600;7003912230;","Identification of Skills Common to Renal and Iliac Endovascular Procedures Performed on a Virtual Reality Simulator",2007,"European Journal of Vascular and Endovascular Surgery","33","5",,"525","532",,48,"10.1016/j.ejvs.2006.12.022","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34047266655&doi=10.1016%2fj.ejvs.2006.12.022&partnerID=40&md5=c066b897837cfea8ee3f42bf741b383c","Department of Biosurgery and Surgical Technology, Imperial College, London, United Kingdom; Regional Vascular Unit, St. Mary's Hospital, London, United Kingdom","Neequaye, S.K., Department of Biosurgery and Surgical Technology, Imperial College, London, United Kingdom, Regional Vascular Unit, St. Mary's Hospital, London, United Kingdom; Aggarwal, R., Department of Biosurgery and Surgical Technology, Imperial College, London, United Kingdom; Brightwell, R., Department of Biosurgery and Surgical Technology, Imperial College, London, United Kingdom, Regional Vascular Unit, St. Mary's Hospital, London, United Kingdom; Van Herzeele, I., Department of Biosurgery and Surgical Technology, Imperial College, London, United Kingdom, Regional Vascular Unit, St. Mary's Hospital, London, United Kingdom; Darzi, A., Department of Biosurgery and Surgical Technology, Imperial College, London, United Kingdom; Cheshire, N.J.W., Department of Biosurgery and Surgical Technology, Imperial College, London, United Kingdom, Regional Vascular Unit, St. Mary's Hospital, London, United Kingdom","Introduction: There is a learning curve in the acquisition of endovascular skills for the treatment of vascular disease. Integration of Virtual reality (VR) simulator based training into the educational training curriculum offers a potential solution to overcome this learning curve. However evidence-based training curricula that define which tasks, how often and in which order they should be performed have yet to be developed. The aim of this study was to determine the nature of skills acquisition on the renal and iliac modules of a commercially-available VR simulator. Method: 20 surgical trainees without endovascular experience were randomised to complete eight sessions on a VR iliac (group A) or renal (group B) training module. To determine skills transferability across the two procedures, all subjects performed two further VR cases of the other procedure. Performance was recorded by the simulator for parameters such as time taken, contrast fluid usage and stent placement accuracy. Results: During training, both groups demonstrated statistically significant VR learning curves: group A for procedure time (p < 0.001) and stent placement accuracy (p = 0.013) group B for procedure time (p < 0.001), fluoroscopy time (p = 0.003) and volume of contrast fluid used (p < 0.001). At crossover, subjects in group B (renal trained) performed to the same level of skill on the simulated iliac task as group A. However, those in group A (iliac trained) had a significantly higher fluoroscopy time (median 118 vs 72 secs, p = 0.020) when performing their first simulated renal task than for group B. Conclusion: Novice endovascular surgeons can significantly improve their performance of simulated procedures through repeated practice on VR simulators. Skills transfer between tasks was demonstrated but complex task training, such as selective arterial cannulation in simulators and possibly in the real world appears to involve a separate skill. It is thus suggested that a stepwise and hierarchical training curriculum is developed for acquisition of endovascular skill using VR simulation to supplement training on patients. © 2007.","Computer simulation; Interventional radiology; Motor skills; Vascular surgical procedures","adult; artery catheterization; article; computer simulation; controlled study; education program; endovascular surgery; fluoroscopy; human; iliac artery; kidney artery; learning; operation duration; priority journal; resident; skill; statistical significance; stent; surgeon; surgical technique; surgical training; task performance; virtual reality; Angioplasty, Balloon; Clinical Competence; Computer Simulation; Constriction, Pathologic; Humans; Iliac Artery; Radiography, Interventional; Renal Artery Obstruction; Task Performance and Analysis; Time Factors; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-34047266655
"Egges A., Papagiannakis G., Magnenat-Thalmann N.","6506510837;23051855400;24762992500;","Presence and interaction in mixed reality environments",2007,"Visual Computer","23","5",,"317","333",,12,"10.1007/s00371-007-0113-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34147138907&doi=10.1007%2fs00371-007-0113-z&partnerID=40&md5=947de4fd3e826d561fe1a1ce007b8875","Center for Advanced Gaming and Simulation, Department of Information and Computing Sciences, Utrecht University, PO Box 80.089, Utrecht 3508TB, Netherlands; MIRALab., University of Geneva, Geneva, Switzerland","Egges, A., Center for Advanced Gaming and Simulation, Department of Information and Computing Sciences, Utrecht University, PO Box 80.089, Utrecht 3508TB, Netherlands; Papagiannakis, G., MIRALab., University of Geneva, Geneva, Switzerland; Magnenat-Thalmann, N., MIRALab., University of Geneva, Geneva, Switzerland","In this paper, we present a simple and robust mixed reality (MR) framework that allows for real-time interaction with virtual humans in mixed reality environments under consistent illumination. We will look at three crucial parts of this system: interaction, animation and global illumination of virtual humans for an integrated and enhanced presence. The interaction system comprises of a dialogue module, which is interfaced with a speech recognition and synthesis system. Next to speech output, the dialogue system generates face and body motions, which are in turn managed by the virtual human animation layer. Our fast animation engine can handle various types of motions, such as normal key-frame animations, or motions that are generated on-the-fly by adapting previously recorded clips. Real-time idle motions are an example of the latter category. All these different motions are generated and blended on-line, resulting in a flexible and realistic animation. Our robust rendering method operates in accordance with the previous animation layer, based on an extended for virtual humans precomputed radiance transfer (PRT) illumination model, resulting in a realistic rendition of such interactive virtual characters in mixed reality environments. Finally, we present a scenario that illustrates the interplay and application of our methods, glued under a unique framework for presence and interaction in MR. © Springer-Verlag 2007.","Animation; Interaction; Mixed reality; Presence; Real-time rendering","Animation; Human computer interaction; Motion estimation; Online systems; Real time systems; Speech recognition; Mixed reality (MR) framework; Precomputed radiance transfer (PRT); Real-time rendering; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-34147138907
"Tichon J.","6603714327;","Training cognitive skills in virtual reality: Measuring performance",2007,"Cyberpsychology and Behavior","10","2",,"286","289",,18,"10.1089/cpb.2006.9957","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34249054433&doi=10.1089%2fcpb.2006.9957&partnerID=40&md5=22e4725f173aa31e03b882f166ce94a0","Perception and Motor Systems Laboratory, School of Human Movement Studies, University of Queensland, St. Lucia, QLD, Australia; Perception and Motor Systems Laboratory, School of Human Movement Studies, University of Queensland, St. Lucia, QLD 4072, Australia","Tichon, J., Perception and Motor Systems Laboratory, School of Human Movement Studies, University of Queensland, St. Lucia, QLD, Australia, Perception and Motor Systems Laboratory, School of Human Movement Studies, University of Queensland, St. Lucia, QLD 4072, Australia","Across a variety of operational environments, virtual reality (VR) is being increasingly used as a means of simulating hazardous work conditions in order to allow trainees to practice advanced cognitive skills such as problem-solving and decision-making. Replicating dangerous conditions particularly involving heavy machinery in the real world can be dangerous and costly. The use of VR is therefore appealing across many industries such as aviation, mining, and rail. However, while the number of training prototypes increase less focus is being given to appropriate evaluation of the training provided via this technology. Increasing skills acquisition and performance does not depend solely on the appropriate design of simulation training. Of equal importance are strong performance measures which can ultimately feedback on the success or otherwise of training and highlight any deficits to guide ongoing improvements. To ensure cognitive skills acquired in a virtual training environment (VTE) are transferable to the real world, training objectives need to be tied directly to realistic scenario events which in turn are directly linked to measures of specific required behaviors. © Mary Ann Liebert, Inc.",,"article; aviation; behavior; decision making; human; machine; measurement; mining; performance; problem solving; railway; skill; technology; training; virtual reality; Computer Simulation; Computer-Assisted Instruction; Decision Making; Feedback, Psychological; Humans; Inservice Training; Practice (Psychology); Problem Solving; Safety Management; Transfer (Psychology); User-Computer Interface",Article,"Final","",Scopus,2-s2.0-34249054433
"Krepki R., Blankertz B., Curio G., Müller K.-R.","6504739308;6602925771;7006032218;15042362900;","The Berlin Brain-Computer Interface (BBCI) - Towards a new communication channel for online control in gaming applications",2007,"Multimedia Tools and Applications","33","1",,"73","90",,123,"10.1007/s11042-006-0094-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33947274548&doi=10.1007%2fs11042-006-0094-3&partnerID=40&md5=57686a455b6650b957325b32df77acde","Fraunhofer Institute for Computer Architecture and Software Technology (FhG-FIRST), Research Group for Intelligent Data Analysis (IDA), Bergweg 6, 61462 Koenigstein i.Ts., Germany; Department of Neurology, Neurophysics Group, Freie Universität Berlin, Hindenburgdamm 30, 12203 Berlin, Germany; Computer Science Department, University of Potsdam, August-Bebel-Strasse-89, 14482 Potsdam, Germany","Krepki, R., Fraunhofer Institute for Computer Architecture and Software Technology (FhG-FIRST), Research Group for Intelligent Data Analysis (IDA), Bergweg 6, 61462 Koenigstein i.Ts., Germany; Blankertz, B., Fraunhofer Institute for Computer Architecture and Software Technology (FhG-FIRST), Research Group for Intelligent Data Analysis (IDA), Bergweg 6, 61462 Koenigstein i.Ts., Germany; Curio, G., Department of Neurology, Neurophysics Group, Freie Universität Berlin, Hindenburgdamm 30, 12203 Berlin, Germany; Müller, K.-R., Fraunhofer Institute for Computer Architecture and Software Technology (FhG-FIRST), Research Group for Intelligent Data Analysis (IDA), Bergweg 6, 61462 Koenigstein i.Ts., Germany, Computer Science Department, University of Potsdam, August-Bebel-Strasse-89, 14482 Potsdam, Germany","The investigation of innovative Human-Computer Interfaces (HCI) provides a challenge for future multimedia research and development. Brain-Computer Interfaces (BCI) exploit the ability of human communication and control bypassing the classical neuromuscular communication channels. In general, BCIs offer a possibility of communication for people with severe neuromuscular disorders, such as Amyotrophic Lateral Sclerosis (ALS) or spinal cord injury. Beyond medical applications, a BCI conjunction with exciting multimedia applications, e.g., a dexterity game, could define a new level of control possibilities also for healthy customers decoding information directly from the user's brain, as reflected in electroencephalographic (EEG) signals which are recorded non-invasively from user's scalp. This contribution introduces the Berlin Brain-Computer Interface (BBCI) and presents setups where the user is provided with intuitive control strategies in plausible gaming applications that use biofeedback. Yet at its beginning, BBCI thus adds a new dimension in multimedia research by offering the user an additional and independent communication channel based on brain activity only. First successful experiments already yielded inspiring proofs-of-concept. A diversity of multimedia application models, say computer games, and their specific intuitive control strategies, as well as various Virtual Reality (VR) scenarios are now open for BCI research aiming at a further speed up of user adaptation and increase of learning success and transfer bit rates. © Springer Science+Business Media, LLC 2007.","Biofeedback; Brain-computer interface; Brain-gaming; Digital signal processing; Electroencephalography; Human-computer interaction; Machine learning","Animation; Biofeedback; Brain; Communication channels (information theory); Digital signal processing; Electroencephalography; Interfaces (computer); Learning systems; Multimedia services; Online searching; Berlin Brain Computer Interface (BBCI); Brain gaming; Control strategies; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-33947274548
"Fried M.P., Sadoughi B., Weghorst S.J., Zeltsan M., Cuellar H., Uribe J.I., Sasaki C.T., Ross D.A., Jacobs J.B., Lebowitz R.A., Satava R.M.","7201877303;12788763100;6701668245;8273941300;8273941400;7005499141;7102210895;35332851900;35586159300;7006990636;7006711764;","Construct validity of the endoscopic sinus surgery simulator II. Assessment of discriminant validity and expert benchmarking",2007,"Archives of Otolaryngology - Head and Neck Surgery","133","4",,"350","357",,62,"10.1001/archotol.133.4.350","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247338433&doi=10.1001%2farchotol.133.4.350&partnerID=40&md5=d2b8a8235a021d9c3573e6e95aff285b","Department of Otorhinolaryngology-Head and Neck Surgery, Montefiore Medical Center, Albert Einstein College of Medicine, Bronx, NY, United States; Human Interface Technology Laboratory, University of Washington Medical Center, Seattle, WA, United States; Department of Surgery, University of Washington Medical Center, Seattle, WA, United States; Department of Surgery, Section of Otolaryngology, Yale University School of Medicine, New Haven, CT, United States; Department of Otolaryngology, New York University Medical Center, New York, NY, United States; Department of Otorhinolaryngology-Head and Neck Surgery, Montefiore Medical Center, Albert Einstein College of Medicine, 3400 Bainbridge Ave, Bronx, NY 10467, United States","Fried, M.P., Department of Otorhinolaryngology-Head and Neck Surgery, Montefiore Medical Center, Albert Einstein College of Medicine, Bronx, NY, United States, Department of Otorhinolaryngology-Head and Neck Surgery, Montefiore Medical Center, Albert Einstein College of Medicine, 3400 Bainbridge Ave, Bronx, NY 10467, United States; Sadoughi, B., Department of Otorhinolaryngology-Head and Neck Surgery, Montefiore Medical Center, Albert Einstein College of Medicine, Bronx, NY, United States; Weghorst, S.J., Human Interface Technology Laboratory, University of Washington Medical Center, Seattle, WA, United States; Zeltsan, M., Department of Otorhinolaryngology-Head and Neck Surgery, Montefiore Medical Center, Albert Einstein College of Medicine, Bronx, NY, United States; Cuellar, H., Department of Otorhinolaryngology-Head and Neck Surgery, Montefiore Medical Center, Albert Einstein College of Medicine, Bronx, NY, United States; Uribe, J.I., Department of Otorhinolaryngology-Head and Neck Surgery, Montefiore Medical Center, Albert Einstein College of Medicine, Bronx, NY, United States; Sasaki, C.T., Department of Surgery, Section of Otolaryngology, Yale University School of Medicine, New Haven, CT, United States; Ross, D.A., Department of Surgery, Section of Otolaryngology, Yale University School of Medicine, New Haven, CT, United States; Jacobs, J.B., Department of Otolaryngology, New York University Medical Center, New York, NY, United States; Lebowitz, R.A., Department of Otolaryngology, New York University Medical Center, New York, NY, United States; Satava, R.M., Department of Surgery, University of Washington Medical Center, Seattle, WA, United States","Objectives: To establish discriminant validity of the endoscopic sinus surgery simulator (ES3) (Lockheed Martin, Akron, Ohio) between various health care provider experience levels and to define benchmarking criteria for skills assessment. Design: Prospective multi-institutional comparison study. Setting: University-based tertiary care institution. Participants: Ten expert otolaryngologists, 14 otolaryngology residents, and 10 medical students. Interventions: Subjects completed the ES3's virtual reality curriculum (10 novice mode, 10 intermediate mode, and 3 advanced mode trials). Performance scores were recorded on each trial. Performance differences were analyzed using analysis of variance for repeated measures (experience level as between-subjects factor). Main Outcome Measures: Simulator performance scores, accuracy, time to completion, and hazard disruption. Results: The novice mode accurately distinguished the 3 groups, particularly at the onset of training (mean scores: senior otolaryngologists, 66.0; residents, 42.7; students, 18.3; for the paired comparisons between groups 1 and 2 and groups 1 and 3, P=.04 and .03, respectively). Subjects were not distinguished beyond trial 5. The intermediate mode only discriminated students from other subjects (P = .008). The advanced mode did not show performance differences between groups. Scores on the novice mode predicted those on the intermediate mode, which predicted advanced mode scores (r=0.687), but no relationship was found between novice and advanced scores. All groups performed equally well and with comparable consistency at the outset of training. Expert scores were used to define benchmark criteria of optimal performance. Conclusions: This study completes the construct validity assessment of the ES3 by demonstrating its discriminant capabilities. It establishes expert surgeon benchmark performance criteria and shows that the ES3 can train novice subjects to attain those. The refined analysis of trial performance scores could serve educational and skills assessment purposes. Current studies are evaluating the transfer of surgical skills acquired on the ES3 to the operating room (predictive validity). ©2007 American Medical Association. All rights reserved.",,"article; endoscopic surgery; health care personnel; medical student; quality control; residency education; scoring system; simulator; surgical instrument; tertiary health care; Analysis of Variance; Benchmarking; Clinical Competence; Computer Simulation; Computer-Assisted Instruction; Educational Measurement; Educational Technology; Endoscopy; Humans; Paranasal Sinus Diseases; Prospective Studies; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-34247338433
"Hua H., Ahuja N., Gao C.","7103212541;35515078200;7402617624;","Design analysis of a high-resolution panoramic camera using conventional imagers and a mirror pyramid",2007,"IEEE Transactions on Pattern Analysis and Machine Intelligence","29","2",,"356","361",,10,"10.1109/TPAMI.2007.33","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247232623&doi=10.1109%2fTPAMI.2007.33&partnerID=40&md5=e5a05868149499e1659c87aea257f917","College of Optical Sciences, The University of Arizona, 1630 E University Blvd., Tucson, AZ 85721, United States; Beckman Institute, University of Illinois at Urbana-Champaign, 450 N Mathews Ave., Urbana, IL 61801, United States","Hua, H., College of Optical Sciences, The University of Arizona, 1630 E University Blvd., Tucson, AZ 85721, United States; Ahuja, N., Beckman Institute, University of Illinois at Urbana-Champaign, 450 N Mathews Ave., Urbana, IL 61801, United States; Gao, C., Beckman Institute, University of Illinois at Urbana-Champaign, 450 N Mathews Ave., Urbana, IL 61801, United States","Wide field of view (FOV) and high-resolution image acquisition is highly desirable in many vision-based applications. Several systems have reported the use of reflections off mirror pyramids to capture high-resolution, single-viewpoint, and wide-FOV images. Using a dual mirror pyramid (DMP) panoramic camera as an example, in this paper, we examine how the pyramid geometry, and the selection and placement of imager clusters can be optimized to maximize the overall panoramic FOV, sensor utilization efficiency, and image uniformity. The analysis can be generalized and applied to other pyramid-based designs. © 2007 IEEE.","Catadioptric systems; Mirror pyramids; Omnidirectional imaging; Panoramic camera","Cameras; Geometry; Image sensors; Mirrors; Optimization; Reflection; Catadioptric systems; High-resolution image acquisition; Mirror pyramids; Omnidirectional imaging; Panoramic camera; Wide field of view (FOV); Image analysis; algorithm; article; computer aided design; computer assisted diagnosis; computer simulation; equipment; equipment design; image enhancement; instrumentation; methodology; optical instrumentation; photography; theoretical model; Algorithms; Computer Simulation; Computer-Aided Design; Equipment Design; Equipment Failure Analysis; Image Enhancement; Image Interpretation, Computer-Assisted; Lenses; Models, Theoretical; Photography",Article,"Final","",Scopus,2-s2.0-34247232623
"Van Sickle K.R., Ritter E.M., McClusky III D.A., Lederman A., Baghai M., Gallagher A.G., Smith C.D.","11739729300;35518395300;6701531190;57210235705;15724630400;7101915089;35467972600;","Attempted establishment of proficiency levels for laparoscopic performance on a national scale using simulation: The results from the 2004 SAGES Minimally Invasive Surgical Trainer-Virtual Reality (MIST-VR) learning center study",2007,"Surgical Endoscopy and Other Interventional Techniques","21","1",,"5","10",,53,"10.1007/s00464-006-0011-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845683744&doi=10.1007%2fs00464-006-0011-x&partnerID=40&md5=56ab18754e995d98a90292d71d86f22c","Department of Surgery, University of Texas, Health Science Center San Antonio, San Antonio, TX, United States; NCA Medical Simulation Center, Uniformed Services University of the Health Sciences, Bethesda, MD, United States; Department of Surgery, H-124, Emory Simulation Training and Robotics (ESTAR), Emory University School of Medicine, 1364 Clifton Road, Atlanta, GA 30322, United States; Berkshire Medical Center, Pittsfield, MA, United States","Van Sickle, K.R., Department of Surgery, University of Texas, Health Science Center San Antonio, San Antonio, TX, United States; Ritter, E.M., NCA Medical Simulation Center, Uniformed Services University of the Health Sciences, Bethesda, MD, United States; McClusky III, D.A., Department of Surgery, H-124, Emory Simulation Training and Robotics (ESTAR), Emory University School of Medicine, 1364 Clifton Road, Atlanta, GA 30322, United States; Lederman, A., Berkshire Medical Center, Pittsfield, MA, United States; Baghai, M., Department of Surgery, H-124, Emory Simulation Training and Robotics (ESTAR), Emory University School of Medicine, 1364 Clifton Road, Atlanta, GA 30322, United States; Gallagher, A.G., Department of Surgery, University of Texas, Health Science Center San Antonio, San Antonio, TX, United States; Smith, C.D., Department of Surgery, H-124, Emory Simulation Training and Robotics (ESTAR), Emory University School of Medicine, 1364 Clifton Road, Atlanta, GA 30322, United States","Background: The Minimally Invasive Surgical Trainer-Virtual Reality (MIST-VR) has been well validated as a training device for laparoscopic skills. It has been demonstrated that training to a level of proficiency on the simulator significantly improves operating room performance of laparoscopic cholecystectomy. The purpose of this project was to obtain a national standard of proficiency using the MIST-VR based on the performance of experienced laparoscopic surgeons. Methods: Surgeons attending the Society of American Gastrointestinal Endoscopic Surgeons (SAGES) 2004 Annual Scientific Meeting who had performed more than 100 laparoscopic procedures volunteered to participate. All the subjects completed a demographic questionnaire assessing laparoscopic and MIST-VR experience in the learning center of the SAGES 2004 meeting. Each subject performed two consecutive trials of the MIST-VR Core Skills 1 program at the medium setting. Each trial involved six basic tasks of increasing difficulty: acquire place (AP), transfer place (TP), traversal (TV), withdrawal insert (WI), diathermy task (DT), and manipulate diathermy (MD). Trial 1 was considered a ""warm-up,"" and trial 2 functioned as the test trial proper. Subject performance was scored for time, errors, and economy of instrument movement for each task, and a cumulative total score was calculated. Results: Trial 2 data are expressed as mean time in seconds in Table 2. Conclusion: Proficiency levels for laparoscopic skills have now been established on a national scale by experienced laparoscopic surgeons using the MIST-VR simulator. Residency programs, training centers, and practicing surgeons can now use these data as guidelines for performance criterion during MIST-VR skills training. © 2006 Springer Science+Business Media, Inc.","Laparoscopic skills; Proficiency levels; Simulation; Validation; Virtual reality","adult; article; clinical assessment tool; controlled study; data analysis; diathermy; endoscopic surgery; gastrointestinal endoscopy; human; laparoscopic surgery; medical practice; medical society; minimally invasive surgery; minimally invasive surgical trainer virtual reality; priority journal; rating scale; residency education; scoring system; simulation; Adult; Clinical Competence; Computer Simulation; Educational Measurement; Humans; Laparoscopy; Middle Aged; Questionnaires; Surgical Procedures, Minimally Invasive; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-33845683744
"Gonzalez D., Carnahan H., Praamsma M., Dubrowski A.","24471476300;7004489168;8544930800;6602597937;","Control of laparoscopic instrument motion in an inanimate bench model: Implications for the training and the evaluation of technical skills",2007,"Applied Ergonomics","38","2",,"123","132",,5,"10.1016/j.apergo.2006.03.011","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750581688&doi=10.1016%2fj.apergo.2006.03.011&partnerID=40&md5=c65c97794c4b99c7f001ee660e693e1c","Department of Kinesiology, University of Waterloo, Canada; Department of Surgery, University of Toronto, 200 Elizabeth St., Toronto, Ont. M5G 2C5, Canada","Gonzalez, D., Department of Kinesiology, University of Waterloo, Canada; Carnahan, H., Department of Kinesiology, University of Waterloo, Canada; Praamsma, M., Department of Kinesiology, University of Waterloo, Canada; Dubrowski, A., Department of Surgery, University of Toronto, 200 Elizabeth St., Toronto, Ont. M5G 2C5, Canada","Computer-assisted analysis of wrist movement has recently emerged as an objective laparoscopic performance evaluation method. The first purpose of this study was to assess the differences in motion characteristics between the tip of the instrument and the wrist. The second purpose was to describe the control strategies used to move laparoscopic instruments. During a bead transfer task, motions of a laparoscopic needle driver's tip, heel, and the participants' wrist were monitored. Results showed that large amplitude movements were best described by movements of the wrist, and small amplitude movements were evidenced by motions of the instrument tip. Thus, for describing expertise, and for evaluation and feedback, motion of the tip of the laparoscopic instrument should be quantified, in addition to motion of the wrist. The motions of the instrument were controlled by utilizing the flexibility of the skin of the laparoscopic trainer in addition to using the fulcrum, and sliding through the trocar. In order to increase fidelity, virtual reality trainers should simulate the flexibility of the real structures around the insertion of the instrument. © 2006 Elsevier Ltd. All rights reserved.","Laparoscopy; Movement control; Virtual reality design","Ergonomics; Gait analysis; Mathematical models; Virtual reality; Fidelity; Laparoscopy; Movement control; Virtual reality design; Motion estimation; adult; article; controlled study; female; human; human experiment; instrumentation; laparoscope; male; movement (physiology); normal human; simulation; training; trocar; wrist",Article,"Final","",Scopus,2-s2.0-33750581688
"Teistler M., Breiman R.S., Liong S.M., Ho L.Y., Shahab A., Nowinski W.L.","16426722900;7005543605;16425928800;16425933700;11142016600;7006449926;","Interactive definition of transfer functions in volume rendering based on image markers",2007,"International Journal of Computer Assisted Radiology and Surgery","2","1",,"55","64",,10,"10.1007/s11548-007-0079-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34249866166&doi=10.1007%2fs11548-007-0079-3&partnerID=40&md5=b8ee5d048d777f8c027d59a2fc56dfed","Biomedical Imaging Lab, Agency for Science Technology and Research (A STAR), Singapore, Singapore; Department of Radiology, University of California, San Francisco, CA, United States; Bioinformatics Institute, Agency for Science Technology and Research (A STAR), Singapore, Singapore","Teistler, M., Biomedical Imaging Lab, Agency for Science Technology and Research (A STAR), Singapore, Singapore; Breiman, R.S., Department of Radiology, University of California, San Francisco, CA, United States; Liong, S.M., Bioinformatics Institute, Agency for Science Technology and Research (A STAR), Singapore, Singapore; Ho, L.Y., Bioinformatics Institute, Agency for Science Technology and Research (A STAR), Singapore, Singapore; Shahab, A., Bioinformatics Institute, Agency for Science Technology and Research (A STAR), Singapore, Singapore; Nowinski, W.L., Biomedical Imaging Lab, Agency for Science Technology and Research (A STAR), Singapore, Singapore","Objectives: A user interface for transfer function (TF) definition in volume rendering (VR) was developed that allows the user to intuitively assign color and opacity to the original image intensities. This software may surpass solutions currently deployed in clinical practice by simplifying the use of TFs beyond predefined settings that are not always applicable. Materials and methods: The TF definition is usually a cumbersome task that requires the user to manipulate graphical representations of the TF (e.g. trapezoids). A new method that allows the user to place markers at points of interest directly on CT and MRI images or orthogonal reformations was developed based on two-dimensional region growing and a few user-definable marker-related parameters. For each user defined image marker, a segment of the transfer function is computed. The resulting TF can also be applied to the slice image views. Results were judged subjectively. Results: Each individualized TF can be defined interactively in a few simple steps. For every user interaction, immediate visual feedback is given. Clinicians who tested the application appreciated being able to directly work on familiar slice images to generate the desired 3D views. Conclusion: Interactive TF definition can increase the actual utility of VR, help to understand the role of the TF with its variations, and increase the acceptance of VR as a clinical tool. © CARS 2007.","Magnetic resonance imaging; Three-dimensional imaging; Transfer function; Volume rendering; X-ray computed tomography","article; clinical practice; computer assisted tomography; computer graphics; computer interface; computer program; feedback system; image analysis; imaging system; nuclear magnetic resonance imaging; priority journal",Article,"Final","",Scopus,2-s2.0-34249866166
"Sebok A., Nystad E.","6701790629;15926058300;","Procedural training in virtual reality: A comparison of technology types",2006,"5th International Topical Meeting on Nuclear Plant Instrumentation Controls, and Human Machine Interface Technology (NPIC and HMIT 2006)","2006",,,"1240","1248",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-34047163611&partnerID=40&md5=ed9be34a0b4e793f61f481de5fff2243","Alion Science and Technology, MA and D Operation, 4949 Pearl East Circle, Boulder, CO 80301, United States; OECD Halden Reactor Project, PO Box 173, N-1751 Halden, Norway","Sebok, A., Alion Science and Technology, MA and D Operation, 4949 Pearl East Circle, Boulder, CO 80301, United States, OECD Halden Reactor Project, PO Box 173, N-1751 Halden, Norway; Nystad, E., Alion Science and Technology, MA and D Operation, 4949 Pearl East Circle, Boulder, CO 80301, United States, OECD Halden Reactor Project, PO Box 173, N-1751 Halden, Norway","This paper describes a study investigating questions of learning effectiveness in different VR technology types. Four VR display technology types were compared in terms of their ability to support procedural learning. The VR systems included two desktop displays (monoscopic and stereoscopic view), a large screen stereoscopic display, and a monoscopic head-mounted display. Twenty-four participants completed procedural training scenarios on these different display types. Training effectiveness was assessed in terms of objective task performance. Following the training session, participants performed the procedure they had just learned using the same VR display type they used for training. Time to complete the procedure and errors were recorded. Retention and transfer of training were evaluated in a talk-through session 24 hours after the training. In addition, subjective questionnaire data were gathered to investigate perceived workload, Sense of Presence, simulator sickness, perceived usability, and ease of navigation. While no difference was found for the short-term learning, the study results indicate that retention and transfer of training were better supported by the large screen stereoscopic condition.",,"Head-mounted display; Procedural training; Simulator sickness; Display devices; Error analysis; Personnel training; Simulators; Stereo vision; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-34047163611
"Wierinck E., Puttemans V., van Steenberghe D.","8243408900;6506533201;7101895992;","Effect of tutorial input in addition to augmented feedback on manual dexterity training and its retention",2006,"European Journal of Dental Education","10","1",,"24","31",,23,"10.1111/j.1600-0579.2006.00392.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33645803204&doi=10.1111%2fj.1600-0579.2006.00392.x&partnerID=40&md5=32100c14d78f52eeade41d3b31e7c11a","Selfteaching and Skills Training Centre, School of Dentistry, Oral Pathology and Maxillofacial Surgery, Katholieke Universiteit, Leuven, Belgium; Motor Control Laboratory, Department of Kinesiology, Katholieke Universiteit, Leuven, Belgium; Department of Periodontology, School of Dentistry, Oral Pathology and Maxillofacial Surgery, Katholieke Universiteit Leuven, Leuven, Belgium","Wierinck, E., Selfteaching and Skills Training Centre, School of Dentistry, Oral Pathology and Maxillofacial Surgery, Katholieke Universiteit, Leuven, Belgium; Puttemans, V., Motor Control Laboratory, Department of Kinesiology, Katholieke Universiteit, Leuven, Belgium; van Steenberghe, D., Department of Periodontology, School of Dentistry, Oral Pathology and Maxillofacial Surgery, Katholieke Universiteit Leuven, Leuven, Belgium","Virtual reality (VR) simulators can be used as tools in manual dexterity training. The visual feedback guides the subject towards proper performance but creates, at the same time, some dependency on this feedback. To overcome this drawback, the effect of adjunct tutorial input on motor learning behaviour was examined. Novice dental students were randomly assigned to one of two training groups or to a nontraining control group, given the task of preparing a geometrical class 1 cavity in phantom teeth. The feedback (FB) group trained under augmented visual feedback conditions, provided by the VR system (DentSimTM). The feedback-plus (FB+) group received, in addition, standardised expert input to enrich the augmented feedback information. The control group, consisting of same year students, did not participate in any training programme. All preparations were evaluated by the VR scoring system. Performance analyses revealed an overall trend towards significant improvement with practice for the training groups. Performance of the FB+ group was most accurate across training. After 1 day and 3 weeks of no practice, both training groups outperformed the control group. After 4 months, however, only the FB+ condition was significantly more accurate than the control group. The same tendency was noted for the transfer tests. Consequently, cavity preparation experience on a VR system under the condition of frequently provided feedback supplemented with expert input was most beneficial to long time learning. © Blackwell Munksgaard, 2006.","Augmented feedback; Dental training; Retention; Skill acquisition; Transfer; Virtual reality","article; audiovisual equipment; clinical trial; comparative study; computer interface; computer simulation; controlled clinical trial; controlled study; dental education; dental student; dental surgery; feedback system; follow up; human; learning; long term memory; methodology; motor performance; physiology; randomized controlled trial; teaching; Computer Simulation; Dental Cavity Preparation; Education, Dental; Feedback; Follow-Up Studies; Humans; Learning; Models, Anatomic; Motor Skills; Retention (Psychology); Students, Dental; Teaching; Transfer (Psychology); User-Computer Interface",Article,"Final","",Scopus,2-s2.0-33645803204
"Standen P.J., Brown D.J.","55804645200;55553726573;","Virtual reality and its role in removing the barriers that turn cognitive impairments into intellectual disability",2006,"Virtual Reality","10","3-4",,"241","252",,34,"10.1007/s10055-006-0042-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33751080387&doi=10.1007%2fs10055-006-0042-6&partnerID=40&md5=be86c3d6a15682316056fda0e09ef2a8","Division of Rehabilitation and Ageing, School of Community Health Sciences, University of Nottingham, Nottingham NG7 2UH, United Kingdom; School of Computing and Informatics, Nottingham Trent University, Clifton Lane, Nottingham NG11 8NS, United Kingdom","Standen, P.J., Division of Rehabilitation and Ageing, School of Community Health Sciences, University of Nottingham, Nottingham NG7 2UH, United Kingdom; Brown, D.J., School of Computing and Informatics, Nottingham Trent University, Clifton Lane, Nottingham NG11 8NS, United Kingdom","Early expectations of the contribution that virtual reality (VR) could make to education far exceeded actual applications. This was largely due to the initial immaturity of the technology and a lack of evidence base on which to base design and utilisation. While the early developments in computer based learning largely concentrated on mainstream education, leaving those with special needs behind, the potential of VR as an educational tool was exploited for those with intellectual disabilities right from the start. This paper describes the empirical evidence that has contributed to the development of educational virtual reality for those with intellectual disabilities: studies on transfer of learning from the virtual to the real world; how teachers might support those using VR; the design of virtual environments and what input/control devices best facilitate use of desktop VR. Future developments and ethical issues are also considered. © Springer-Verlag London Limited 2006.","Cognitive impairments; Education; Intellectual disability; Tutor; User sensitive inclusive design; Virtual reality",,Article,"Final","",Scopus,2-s2.0-33751080387
"Shendarkar A., Vasudevan K., Lee S., Son Y.-J.","24173932000;24345730200;55716384000;7102761609;","Crowd simulation for emergency response using bdi agent based on virtual reality",2006,"Proceedings - Winter Simulation Conference",,, 4117652,"545","553",,75,"10.1109/WSC.2006.323128","https://www.scopus.com/inward/record.uri?eid=2-s2.0-46149109297&doi=10.1109%2fWSC.2006.323128&partnerID=40&md5=40ab357c0e5fb5577e4b22c475fe7c8a","Dept. of Computer Science, University of Arizona, Tucson, AZ 85719, United States; Dept. of Systems and Industrial Engineering, University of Arizona, Tucson, AZ 85719, United States","Shendarkar, A., Dept. of Computer Science, University of Arizona, Tucson, AZ 85719, United States; Vasudevan, K., Dept. of Systems and Industrial Engineering, University of Arizona, Tucson, AZ 85719, United States; Lee, S., Dept. of Systems and Industrial Engineering, University of Arizona, Tucson, AZ 85719, United States; Son, Y.-J., Dept. of Systems and Industrial Engineering, University of Arizona, Tucson, AZ 85719, United States","This paper presents a novel VR (Virtual Reality) trained BDI (belief, desire, intention) software agent used to construct crowd simulations for emergency response. The BDI framework allows modeling of human behavior with a high degree of fidelity. The proposed simulation has been developed using AnyLogic software to mimic crowd evacuation from an area under a terrorist bomb attack. The attributes that govern the BDI characteristics of the agent are studied by conducting human in the loop experiments in VR using the CAVE (Cave Automatic Virtual Environment). To enhance generality and interoperability of the proposed crowd simulation modeling scheme, input data models have been developed to define environment attributes. Experiments are also conducted to demonstrate the effect of various parameters on key performance indicators such as crowd evacuation rate and densities. © 2006 IEEE.",,"Behavioral research; Benchmarking; Caves; Computer software; Experiments; Landforms; Software agents; BDI agents; crowd simulation; Degree of fidelity; Emergency responses; human behaviors; Human-in-the-loop (HITL); Input data; Key performance indicator (KPI); Virtual environment (VE); Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-46149109297
"Watanuki K., Kojima K.","7005697643;35305266700;","Virutal reality based knowledge acquisition and job training for advanced casting skills",2006,"Proceedings - 16th International Conference on Artificial Reality and Telexistence - Workshops, ICAT 2006",,, 4089335,"666","671",,4,"10.1109/ICAT.2006.147","https://www.scopus.com/inward/record.uri?eid=2-s2.0-46449101698&doi=10.1109%2fICAT.2006.147&partnerID=40&md5=4910526f0345a0b470e53b70943a8b4c","Saitama University, Graduate School of Science and Engineering, 255 Shimo-Okubo, Sakura-Ku, Saitama-Shi, Saitama 338-8570, Japan","Watanuki, K., Saitama University, Graduate School of Science and Engineering, 255 Shimo-Okubo, Sakura-Ku, Saitama-Shi, Saitama 338-8570, Japan; Kojima, K., Saitama University, Graduate School of Science and Engineering, 255 Shimo-Okubo, Sakura-Ku, Saitama-Shi, Saitama 338-8570, Japan","The environment where Japanese industry has been paid with respect is changing tremendously due to the globalization of economics, where Asian countries are undergoing economical and technical development as well as advancing in information technology. For example, in the design of custom-made casting product, a designer whom lacking of casting knowledge may not be able to produce a good design. In order to obtain a good design and manufacturing result, it is necessary to equip the designer and manufacturer with a support system related to casting design or so called, knowledge transfer and creation system. In recent years, the design supporting system using VR technology is developed, and introduced in the manufacturing industry. The merit of using VR system is being able to carry out the stereoscopy of the product model drawn by 3D CAD, and to carry out the design review of the product model in the same size as thing. However, since many systems extend the display of the conventional 3D CAD, they cannot input annotation and so on directly in VR. environment. In this paper, the system which can input and display the annotation in VR environment is developed. By drawing annotation to the product model displayed on VR environment, sharing of technical tacit knowledge and engineers' communication are promoted, and engineers becomes possible gaining physical tacit knowledge. © 2006 IEEE.",,"Computer aided design; Industry; Information management; Knowledge management; Manufacture; Multi agent systems; Technology transfer; Three dimensional; Virtual reality; (OTDR) technology; asian countries; casting designs; design reviews; In order; international conferences; Japanese industries; Knowledge transfer (KT); Manufacturing industries; Product modeling; support systems; Supporting systems; Tacit knowledge; Technical developments; Three dimensional (3D) CAD; VR technology; Knowledge acquisition",Conference Paper,"Final","",Scopus,2-s2.0-46449101698
"Egges A., Papagiannakis G., Magnenat-Thalmann N.","6506510837;23051855400;24762992500;","An interactive mixed reality framework for virtual humans",2006,"2006 International Conference on Cyberworlds, CW'06",,, 4030841,"165","172",,2,"10.1109/CW.2006.15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-36949022686&doi=10.1109%2fCW.2006.15&partnerID=40&md5=603e5d0d745b7e30fa57a4622c6325d7","MIRALab., University of Geneva, 7 route de Drize, 1227 Geneva, Switzerland","Egges, A., MIRALab., University of Geneva, 7 route de Drize, 1227 Geneva, Switzerland; Papagiannakis, G., MIRALab., University of Geneva, 7 route de Drize, 1227 Geneva, Switzerland; Magnenat-Thalmann, N., MIRALab., University of Geneva, 7 route de Drize, 1227 Geneva, Switzerland","In this paper, we present a simple and robust Mixed Reality (MR) framework that allows for real-time interaction with Virtual Humans in real and virtual environments under consistent illumination. We will look at three crucial parts of this system: interaction, animation and global illumination of virtual humans for an integrated and enhanced presence. The interaction system comprises of a dialogue module, which is interfaced with a speech recognition and synthesis system. Next to speech output, the dialogue system generates face and body motions, which are in turn managed by the virtual human animation layer. Our fast animation engine can handle various types of motions, such as normal key-frame animations, or motions that are generated on-the-fly by adapting previously recorded clips. All these different motions are generated and blended on-line, resulting in a flexible and realistic animation. Our robust rendering method operates in accordance with the previous animation layer, based on an extended for virtual humans Precomputed Radiance Transfer (PRT) illumination model, resulting in a realistic display of such interactive virtual characters in mixed reality environments. Finally, we present a scenario that illustrates the interplay and application of our methods, glued under a unique framework for presence and interaction in MR. © 2006 IEEE.",,"Animation; Human computer interaction; Mathematical models; Robust control; Speech recognition; Dialogue module; Global illumination; Robust Mixed Reality (MR); Virtual humans; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-36949022686
"Hongjun S., Xin M., Fengyu Z., Yibin L.","57220287131;16178805100;12646806200;35307602900;","The design and implementation of OpenGL-based comprehensive educational robot system",2006,"Proceedings of IEEE ICIA 2006 - 2006 IEEE International Conference on Information Acquisition",,, 4097992,"522","527",,6,"10.1109/ICIA.2006.305788","https://www.scopus.com/inward/record.uri?eid=2-s2.0-46249097355&doi=10.1109%2fICIA.2006.305788&partnerID=40&md5=3d1b568ae8c9994f6411dadfcdd86fbc","School of Control Science and Engineering, University of Shandong, JingShiLu 73#, 250061 Jinan, Shandong Province, China","Hongjun, S., School of Control Science and Engineering, University of Shandong, JingShiLu 73#, 250061 Jinan, Shandong Province, China; Xin, M., School of Control Science and Engineering, University of Shandong, JingShiLu 73#, 250061 Jinan, Shandong Province, China; Fengyu, Z., School of Control Science and Engineering, University of Shandong, JingShiLu 73#, 250061 Jinan, Shandong Province, China; Yibin, L., School of Control Science and Engineering, University of Shandong, JingShiLu 73#, 250061 Jinan, Shandong Province, China","In this paper, we present the design and implementation of MountTai, a cost effective OpenGL based comprehensive educational robot system for China's primary and high school education. Firstly the system's goal and framework is introduced, then it is described the MountTai robot's functions and construction in hardware. The paper expatiates at length how VR technology is used to implement the system software as well as how the software's functions are designed to illustrate robotics in different perspectives relating to mechanics, electronics, communication, artificial intelligence, language programming. The web-based teaching course dedicated to robot-DIY tutorials is also shown. Finally, concluding remarks for future works are given. © 2006 IEEE.","Educational robot; OpenGL; Virtual reality","Artificial intelligence; Automation; Bionics; Computer programming languages; Computer software; Cost effectiveness; Education; Mergers and acquisitions; Robot programming; Robotics; Robots; Teaching; Technology transfer; (min ,max ,+) functions; High schools; Information acquisitions; international conferences; robot system; System softwares; VR technology; Web-based teaching; Machine design",Conference Paper,"Final","",Scopus,2-s2.0-46249097355
"Kavakli M.","6602420178;","Training simulations for crime risk assessment",2006,"7th International Conference on Information Technology Based Higher Education and Training, ITHET",,, 4141628,"203","210",,5,"10.1109/ITHET.2006.339765","https://www.scopus.com/inward/record.uri?eid=2-s2.0-46949096083&doi=10.1109%2fITHET.2006.339765&partnerID=40&md5=6607487c70d4b83690b6ab0a01858feb","Macquarie University, Sydney, NSW 2109, Australia; Department of Computing, Macquarie University","Kavakli, M., Macquarie University, Sydney, NSW 2109, Australia, Department of Computing, Macquarie University","The purpose of this paper is to review training simulations for crime risk assessment and to discuss the system architecture of a Training Simulation (RiskMan). Computer aided training systems offer a flexible and cost-effective method for learning new skills. The satisfactory management of risk situations involves risk identification, the development of risk handling strategies and plans and the conduct and monitoring of those plans. Recognising the importance of tacit knowledge, scenario-based training has gained importance in recent years. For example, USA General Accounting Office (GAO) released a report on Homeland security titled Risk Management approach can guide preparedness efforts. This report provides a list of risk assessment measurements for contingency plan development and a matrix for risk-based scenario development. In this paper, integrating traditional scenario-based training with desktop VR systems using game engineering, we investigate how a virtual reality training system, which draws on research in the areas of computer games, knowledge acquisition, agent technology and natural language processing, can provide a safe learning experience to assist acquisition of the necessary tacit knowledge. The aim of RiskMan is to train police officers to handle high-risk situations. RiskMan is an ARC Discovery project carried out by the Department of Computing in Macquarie University. RiskMan has been developed using a very-high level scripting language of a game engine, Unreal Tournament 2004. It is composed of modules such as a Scenario-based Expert System, a Narrative Engine, a Game Engine, and a CAD package. RiskMan uses socket connections to feed information between the Narrative Engine and Sim Master to Unreal Tournament Game Engine (UT2004).. © 2006 IEEE.","Games; Risk analysis; Simulation; Training","Administrative data processing; Artificial intelligence; Computational linguistics; Computer systems; Cost effectiveness; Costs; Decision support systems; Education; Engineering research; Engines; Expert systems; Finance; Game theory; Industrial research; Information technology; Insurance; Knowledge acquisition; Knowledge engineering; Law enforcement; Linguistics; Management; Management information systems; Mergers and acquisitions; Multi agent systems; Natural language processing systems; Planning; Quality assurance; Reliability; Research; Risk analysis; Risk management; Risks; Safety engineering; Strategic planning; Technology; Technology transfer; Virtual reality; (p ,p ,t) measurements; agent technologies; computer games; game engines; General Accounting Office (GAO); High-risk situations; Higher education (HE); Homeland security (HLS); international conferences; Learning experiences; Natural Language Processing (NLP); Police officers; risk handling; risk identification; Scenario development; Scenario-based training; Scripting languages; Socket connections; System architectures; Tacit knowledge; Technology based; training simulation; training systems; Unreal Tournament (TM); VR systems; Risk assessment",Conference Paper,"Final","",Scopus,2-s2.0-46949096083
"Steinicke F., Hinrichs K.","8883314100;7004845251;","Grab-and-throw metaphor: Adapting desktop-based interaction paradigms to virtual reality",2006,"3DUI 2006: IEEE Symposium on 3D User Interfaces 2006 - Proceedings","2006",, 1647512,"83","86",,4,"10.1109/VR.2006.65","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750798526&doi=10.1109%2fVR.2006.65&partnerID=40&md5=2c7b23cf53d6a8e0bf0cfdd66825a1d0","Institut für Informatik, Westfälische Wilhelms-Universität Münster, Einsteinstraße 62, 48149 Münster, Germany","Steinicke, F., Institut für Informatik, Westfälische Wilhelms-Universität Münster, Einsteinstraße 62, 48149 Münster, Germany; Hinrichs, K., Institut für Informatik, Westfälische Wilhelms-Universität Münster, Einsteinstraße 62, 48149 Münster, Germany","The drag-and-drop metaphor is one of the most common direct interaction metaphors used in desktop-based environments. This direct interaction paradigm enables an intuitive method to apply actions by associating iconic representation of objects to each other. Since dragging of these iconic representations is the most time-consuming subtask of the drag-and-drop metaphor, many extensions of this approach have been proposed to enhance this process. However, a transfer of these concepts to virtual reality (VR) systems has not been realized. In this paper we propose the grab-and-throw metaphor which is a VR-based analogon to the drag-and-drop metaphor. The proposed concepts enable users to select a virtual object by grabbing it and to throw the object within a virtual environment (VE) in the direction of another object. As soon as the object hits another object, an associated action is performed. The trajectory of the thrown object is based on physical motions adapted from the real-world. In order to ease hitting a desired target object, snapping strategies are used such that the aimed object attracts the thrown object. We give a technical description of the grab-and-throw metaphor and discuss example application scenarios which benefit from the usage of the described metaphor. © 2006 IEEE.",,"Graphical user interfaces; Interactive computer systems; Object recognition; Personal computers; Virtual reality; Adapting desktop based interaction paradigms; Grab and throw metaphor; Iconic representations; Virtual reality (VR) systems; Adaptive systems",Conference Paper,"Final","",Scopus,2-s2.0-33750798526
"Steed A.","18435050200;","Towards a general model for selection in virtual environments",2006,"3DUI 2006: IEEE Symposium on 3D User Interfaces 2006 - Proceedings","2006",, 1647515,"103","110",,42,"10.1109/VR.2006.134","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750812463&doi=10.1109%2fVR.2006.134&partnerID=40&md5=0262d76e8f21cb5424ce7ae58cdaecb5","Department of Computer Science, University College London, United Kingdom","Steed, A., Department of Computer Science, University College London, United Kingdom","Selection is one of the fundamental building blocks of all interactive virtual environment systems. Selection is the ability of the user to specify which object, or sub-part of an object in the environment, is the target for subsequent actions. Examples include selecting 3D buttons thus invoking an action or selecting a target upon which an action will occur. Selection is also an implicit or explicit part of manipulation techniques. In a virtual environment selection can be performed in many different ways. In this paper we develop a generalized model of how interaction is and could be performed in virtual environments using 3D gestures. The purpose of this model is to highlight some potential areas for development and evaluation of novel selection techniques. The model is based on an analysis of the complexity of selection. We develop a model for selection that is based on time-varying scalar fields (TVSFs) that encompasses a very broad range of existing techniques. This model will be abstract, in that a direct implementation will be prohibitively complex, but we show how some standard implementation strategies are good approximations to the formal model. © 2006 IEEE.","3D interaction; Selection; Virtual environments","Interactive virtual environment systems; Three dimensional gestures; Three dimensional interaction; Virtual environment selection; Abstracting; Mathematical models; Object recognition; Selection; Three dimensional computer graphics; User interfaces; Virtual reality; Interactive computer systems",Conference Paper,"Final","",Scopus,2-s2.0-33750812463
"Brundage S.B., Graap K., Gibbons K.F., Ferrer M., Brooks J.","14035095900;6602808254;15053039800;8962881800;8962881700;","Frequency of stuttering during challenging and supportive virtual reality job interviews",2006,"Journal of Fluency Disorders","31","4",,"325","339",,30,"10.1016/j.jfludis.2006.08.003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750607887&doi=10.1016%2fj.jfludis.2006.08.003&partnerID=40&md5=aa6a719e377ecd93b11ae34ff34bdfb9","The George Washington University, Speech and Hearing Science Department, 1922 F Street NW, Suite 400, Washington, DC 20052, United States; Virtually Better, Inc., Decatur, GA, United States","Brundage, S.B., The George Washington University, Speech and Hearing Science Department, 1922 F Street NW, Suite 400, Washington, DC 20052, United States; Graap, K., Virtually Better, Inc., Decatur, GA, United States; Gibbons, K.F., The George Washington University, Speech and Hearing Science Department, 1922 F Street NW, Suite 400, Washington, DC 20052, United States; Ferrer, M., Virtually Better, Inc., Decatur, GA, United States; Brooks, J., Virtually Better, Inc., Decatur, GA, United States","This paper seeks to demonstrate the possibility of manipulating the frequency of stuttering using virtual reality environments (VREs). If stuttering manifests itself in VREs similarly to the way it manifests itself in real world interactions, then VREs can provide a controlled, safe, and confidential method for treatment practice and generalization. Though many researchers and clinicians recognize the need for generalization activities in the treatment of stuttering, achieving generalization in a clinical setting poses challenges to client confidentiality, safety, and the efficient use of a professionals' time. Virtual reality (VR) technology may allow professionals the opportunity to enhance and assess treatment generalization while protecting the safety and confidentiality of their clients. In this study, we developed a VR job interview environment which allowed experimental control over communication style and gender of interviewers. In this first trial, persons who stutter (PWS) experienced both challenging and supportive VR job interview conditions. The percentage of stuttered syllables was calculated for both interviews for each participant. Self-reported ratings of communication apprehension and confidence were also obtained, and were not significantly correlated with stuttering severity. Results indicated that interviewer communication style affected the amount of stuttering produced by participants, with more stuttering observed during challenging virtual interviews. Additionally, the amount of stuttering observed during the VR job interviews was significantly, positively correlated with the amount of stuttering observed during an interview with the investigator prior to VR exposure. Participants' subjective reports of the VR experience indicate reactions similar to those they report experiencing in the real world. Possible implications for the use of VR in the assessment and treatment of stuttering are discussed. Educational objectives: After reading this article, the reader will be able to-(1) list some of the challenges to treatment generalization; (2) describe how virtual reality technology can assist in alleviating some of these challenges; (3) describe how the frequency of stuttering varies across two different virtual environments. © 2006.","Adults; Software validation; Stuttering; Virtual reality","adult; article; controlled study; correlation analysis; disease severity; experience; exposure; female; human; job interview; male; self report; stuttering; verbal communication; virtual reality; Adult; Environment; Female; Humans; Interviews; Job Application; Male; Middle Aged; Stuttering; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-33750607887
"Mizuguchi N., Tamura Y., Imagawa S., Sagara A., Hayashi T.","6603417912;57201887415;7006803109;7005514842;8598601500;","Development of reactor design aid tool using virtual reality technology",2006,"Fusion Engineering and Design","81","23-24",,"2755","2759",,5,"10.1016/j.fusengdes.2006.07.043","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846028533&doi=10.1016%2fj.fusengdes.2006.07.043&partnerID=40&md5=ed7d11760cb05db3ba04d88ed11329bd","National Institute for Fusion Science, 322-6 Orochi-cho, Toki, Gifu, 509-5292, Japan","Mizuguchi, N., National Institute for Fusion Science, 322-6 Orochi-cho, Toki, Gifu, 509-5292, Japan; Tamura, Y., National Institute for Fusion Science, 322-6 Orochi-cho, Toki, Gifu, 509-5292, Japan; Imagawa, S., National Institute for Fusion Science, 322-6 Orochi-cho, Toki, Gifu, 509-5292, Japan; Sagara, A., National Institute for Fusion Science, 322-6 Orochi-cho, Toki, Gifu, 509-5292, Japan; Hayashi, T., National Institute for Fusion Science, 322-6 Orochi-cho, Toki, Gifu, 509-5292, Japan","A new type of aid system for fusion reactor design, to which the virtual reality (VR) visualization and sonification techniques are applied, is developed. This system provides us with an intuitive interaction environment in the VR space between the observer and the designed objects constructed by the conventional 3D computer-aided design (CAD) system. We have applied the design aid tool to the heliotron-type fusion reactor design activity FFHR2m [A. Sagara, S. Imagawa, O. Mitarai, T. Dolan, T. Tanaka, Y. Kubota, et al., Improved structure and long -life blanket concepts for heliotron reactors, Nucl. Fusion 45 (2005) 258-263] on the virtual reality system CompleXcope [Y. Tamura, A. Kageyama, T. Sato, S. Fujiwara, H. Nakamura, Virtual reality system to visualize and auralize numerical imulation data, Comp. Phys. Comm. 142 (2001) 227-230] of the National Institute for Fusion Science, Japan, and have evaluated its performance. The tool includes the functions of transfer of the observer, translation and scaling of the objects, recording of the operations and the check of interference. © 2006 Elsevier B.V. All rights reserved.","Reactor design; Sonification; Virtual reality","Computer aided design; Computer aided software engineering; Computer simulation; Three dimensional computer graphics; Virtual reality; Object scaling; Reactor design; Sonification; Fusion reactors",Article,"Final","",Scopus,2-s2.0-33846028533
"Steinicke F., Hinrichs K.","8883314100;7004845251;","Grab-and-throw metaphor: Adapting desktop-based interaction paradigms to virtual reality",2006,"Proceedings - IEEE Virtual Reality","2006",, 1624166,"128","",,,"10.1109/VR.2006.65","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750104816&doi=10.1109%2fVR.2006.65&partnerID=40&md5=c61a4b6afc75e3f7dc3cb465818c6c20","Institut für Informatik, Westfälische Wilhelms-Universität Münster, Einsteinstraße 62, 48149 Münster, Germany","Steinicke, F., Institut für Informatik, Westfälische Wilhelms-Universität Münster, Einsteinstraße 62, 48149 Münster, Germany; Hinrichs, K., Institut für Informatik, Westfälische Wilhelms-Universität Münster, Einsteinstraße 62, 48149 Münster, Germany","The drag-and-drop metaphor is one of the most common direct interaction metaphors used in desktop-based environments. This direct interaction paradigm enables an intuitive method to apply actions by associating iconic representation of objects to each other. Since dragging of these iconic representations is the most time-consuming subtask of the drag-and-drop metaphor, many extensions of this approach have been proposed to enhance this process. However, a transfer of these concepts to virtual reality (VR) systems has not been realized. In this paper we propose the grab-and-throw metaphor which is a VR-based analogon to the drag-and-drop metaphor. The proposed concepts enable users to select a virtual object by grabbing it and to throw the object within a virtual environment (VE) in the direction of another object. As soon as the object hits another object, an associated action is performed. The trajectory of the thrown object is based on physical motions adapted from the real-world. In order to ease hitting a desired target object, snapping strategies are used such that the aimed object attracts the thrown object. We give a technical description of the grab-and-throw metaphor and discuss example application scenarios which benefit from the usage of the described metaphor. © 2006 IEEE.",,"Computer selection and evaluation; Graphical user interfaces; Human computer interaction; Object recognition; Personal computers; Targets; Grab and throw metaphors; Iconic representations; Interaction paradigms; Target objects; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-33750104816
"Steed A.","18435050200;","Towards a general model for selection in virtual environments",2006,"Proceedings - IEEE Virtual Reality","2006",, 1624169,"131","",,9,"10.1109/VR.2006.134","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750121589&doi=10.1109%2fVR.2006.134&partnerID=40&md5=5d01929678a1bcb442e6d80311923d1f","Department of Computer Science, University College London, United Kingdom","Steed, A., Department of Computer Science, University College London, United Kingdom","Selection is one of the fundamental building blocks of all interactive virtual environment systems. Selection is the ability of the user to specify which object, or sub-part of an object in the environment, is the target for subsequent actions. Examples include selecting 3D buttons thus invoking an action or selecting a target upon which an action will occur. Selection is also an implicit or explicit part of manipulation techniques. In a virtual environment selection can be performed in many different ways. In this paper we develop a generalized model of how interaction is and could be performed in virtual environments using 3D gestures. The purpose of this model is to highlight some potential areas for development and evaluation of novel selection techniques. The model is based on an analysis of the complexity of selection. We develop a model for selection that is based on time-varying scalar fields (TVSFs) that encompasses a very broad range of existing techniques. This model will be abstract, in that a direct implementation will be prohibitively complex, but we show how some standard implementation strategies are good approximations to the formal model. © 2006 IEEE.","3D interaction; Selection; Virtual environments","3D interaction; Manipulation; Virtual environment selection; Virtual environment systems; Computational complexity; Computer selection and evaluation; Graphical user interfaces; Human computer interaction; Mathematical models; Three dimensional computer graphics; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-33750121589
"Glencross M., Chalmers A.G., Lin M.C., Otaduy M.A., Gutierrez D.","12790427400;7102938771;57202428958;6507451572;7005194565;","Exploiting perception in high-fidelity virtual environments",2006,"SIGGRAPH 2006 - ACM SIGGRAPH 2006 Courses",,, 1,"","",,10,"10.1145/1185657.1185814","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961784838&doi=10.1145%2f1185657.1185814&partnerID=40&md5=17070b6b6b5e67e8db5422cb0547eee0",,"Glencross, M.; Chalmers, A.G.; Lin, M.C.; Otaduy, M.A.; Gutierrez, D.","The objective of this course is to provide an introduction to the issues that must be considered when building high-fidelity 3D engaging shared virtual environments. The principles of human perception guide important development of algorithms and techniques in collaboration, graphical, auditory, and haptic rendering. We aim to show how human perception is exploited to achieve realism in high fidelity environments within the constraints of available finite computational resources. In this course we address the challenges faced when building such high-fidelity engaging shared virtual environments, especially those that facilitate collaboration and intuitive interaction. We present real applications in which such high-fidelity is essential. With reference to these, we illustrate the significant need for the combination of high-fidelity graphics in real time, better modes of interaction, and appropriate collaboration strategies. After introducing the concept of high-fidelity virtual environments and why these convey important information to the user, we cover the main issues in two parts linked by the common thread of exploiting human perception. First we explore perceptually driven techniques that can be employed to achieve high-fidelity graphical rendering in real-time, and how incorporating authentic lighting effects helps to convey a sense of realism and scale in virtual re-constructions of historical sites. Secondly, we examine how intuitive interaction between participants, and with objects in the environment, also plays a key role in the overall experience. How perceptual methods can be used to guide interest management and distribution choices, is considered with an emphasis on avoiding potential pitfalls when distributing physically-based simulations. An analysis of real network conditions and the implications of these for distribution strategies that facilitate collaboration is presented. Furthermore, we describe technologies necessary to provide intuitive interaction in virtual environments, paying particular attention to engaging multiple sensory modalities, primarily through physically-based sound simulation and perceptually high-fidelity haptic interaction. The combination of realism and intuitive compelling interaction can lead to engaging virtual environments capable of exhibiting skills transfer, an illusive goal of many virtual environment applications.","Collaborative environments; Haptics; High-fidelity rendering; Human-computer interaction; Multi-user; Networked applications; Perception; Virtual reality","Computer graphics; Curricula; Distributed computer systems; Haptic interfaces; Human computer interaction; Interactive computer graphics; Sensory perception; Virtual addresses; Collaborative environments; Haptics; High-fidelity renderings; Multi-user; Networked applications; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84961784838
"Merians A.S., Poizner H., Boian R., Burdea G., Adamovich S.","6603018031;7005963417;6603659582;35612697900;6603916707;","Sensorimotor training in a virtual reality environment: Does it improve functional recovery poststroke?",2006,"Neurorehabilitation and Neural Repair","20","2",,"252","267",,167,"10.1177/1545968306286914","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646536087&doi=10.1177%2f1545968306286914&partnerID=40&md5=f8c1c430902d6561ec66dced59014fd4","Graduate Programs in Physical Therapy, University of Medicine and Dentistry of New Jersey, School of Health Related Professions, Newark, NJ, United States; Institute for Neural Computation, University of California, San Diego, San Diego, CA, United States; Center for Advanced Information Processing, Rutgers University, Piscataway, NJ, United States; Department of Biomedical Engineering, New Jersey Institute of Technology, Newark, NJ, United States; University of Medicine and Dentistry of New Jersey, 65 Bergen Street, Newark, NJ 07107, United States","Merians, A.S., Graduate Programs in Physical Therapy, University of Medicine and Dentistry of New Jersey, School of Health Related Professions, Newark, NJ, United States, University of Medicine and Dentistry of New Jersey, 65 Bergen Street, Newark, NJ 07107, United States; Poizner, H., Institute for Neural Computation, University of California, San Diego, San Diego, CA, United States; Boian, R., Center for Advanced Information Processing, Rutgers University, Piscataway, NJ, United States; Burdea, G., Center for Advanced Information Processing, Rutgers University, Piscataway, NJ, United States; Adamovich, S., Department of Biomedical Engineering, New Jersey Institute of Technology, Newark, NJ, United States","Objective. To investigate the effectiveness of computerized virtual reality (VR) training of the hemiparetic hand of patients poststroke using a system that provides repetitive motor reeducation and skill reacquisition. Methods. Eight subjects in the chronic phase poststroke participated in a 3-week program using their hemiparetic hand in a series of interactive computer games for 13 days of training, weekend breaks, and pretests and posttests. Each subject trained for about 2 to 2.5 h per day. Outcome measures consisted of changes in the computerized measures of thumb and finger range of motion, thumb and finger velocity, fractionation (the ability to move fingers independently), thumb and finger strength, the Jebsen Test of Hand Function, and a Kinematic reach to grasp test. Results. Subjects as a group improved in fractionation of the fingers, thumb and finger range of motion, and thumb and finger speed, retaining those gains at the 1-week retention test. Transfer of these improvements was demonstrated through changes in the Jebsen Test of Hand Function and a decrease after the therapy in the overall time from hand peak velocity to the moment when an object was lifted from the table. Conclusions. It is difficult in current service delivery models to provide the intensity of practice that appears to be needed to effect neural reorganization and functional changes poststroke. Computerized exercise systems may be a way to maximize both the patients' and the clinicians' time. The data in this study add support to the proposal to explore novel technologies for incorporation into current practice. Copyright © 2006 The American Society of Neurorehabilitation.","Haptics; Motor learning; Recovery; Rehabilitation; Stroke; Virtual reality","adult; aged; article; clinical article; female; hand function; hemiparesis; human; male; motor activity; range of motion; sensorimotor function; stroke; virtual reality; Aged; Aged, 80 and over; Cerebrovascular Accident; Exercise; Female; Hand; Humans; Male; Middle Aged; Paresis; Psychomotor Performance; Recovery of Function; Treatment Outcome; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-33646536087
"Pingjun X., Yingxue Y., Jiangsheng L., Jianguang L.","15833181300;55722539100;6506663513;6505756729;","Optimising assembly planning based on virtual reality and bionic algorithm",2006,"International Journal of Manufacturing Technology and Management","9","3-4",,"265","293",,9,"10.1504/IJMTM.2006.010058","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846509810&doi=10.1504%2fIJMTM.2006.010058&partnerID=40&md5=4cac69343686c8583868ee29efb7c576","School of Mechanical and Electrical Engineering, Harbin Institute of Technology, P.O. Box 422, Harbin 150001, China","Pingjun, X., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, P.O. Box 422, Harbin 150001, China; Yingxue, Y., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, P.O. Box 422, Harbin 150001, China; Jiangsheng, L., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, P.O. Box 422, Harbin 150001, China; Jianguang, L., School of Mechanical and Electrical Engineering, Harbin Institute of Technology, P.O. Box 422, Harbin 150001, China","Virtual assembly, as a typical application of Virtual Reality (VR), provides an efficient tool to optimise assembly planning and evaluation. In this paper, a VR-based Assembly Planning and Training System (VR-APTS) is introduced. Using a Computer-Aided Design (CAD) assembly model as input, the system can output one or several good assembly sequences with the application of an intelligent bionic algorithm. Key techniques in the development of VR-APTS are discussed. A novel information decomposition and transformation method is put forward to transform data from CAD to VR, and a geometric constraint-based virtual environment is set up to support interactive assembly planning and evaluation. First, an initial optimal assembly sequence is generated by virtual disassembly and ant colony optimisation algorithm. Then, this initial sequence is evaluated by virtual assembly simulation, a more practical and optimal assembly sequence is replaned. This is an iterative process until the best assembly sequence is obtained. An application case is studied to demonstrate the basic advantages of the system for assembly planning and training. Copyright © 2006 Inderscience Enterprises Ltd.","Ant colony optimisation algorithm; Assembly planning and training; Bionics; Data transformation; Virtual Reality (VR)","Algorithms; Assembly; Bionics; Computer aided design; Data transfer; Optimization; Strategic planning; Ant colony optimisation algorithm; Assembly planning; Data transformation; Virtual reality",Article,"Final","",Scopus,2-s2.0-33846509810
"Mirelman A., Deutsch J.E., Bonato P.","35332484600;7201985389;7006225560;","Greater transfer to walking of lower extremity training with robotics and virtual reality than robotics training alone: Preliminary findings",2006,"Fifth International Workshop on Virtual Rehabilitation, IWVR 2006",,, 1707545,"155","159",,1,"10.1109/iwvr.2006.1707545","https://www.scopus.com/inward/record.uri?eid=2-s2.0-41649103893&doi=10.1109%2fiwvr.2006.1707545&partnerID=40&md5=89ca3d6cf0576b14463c46cf948c1d31","School of Health Related Professions, University of Medicine and Dentistry of New Jersey, Newark, NJ 07107, United States; Motion Analysis Lab., Spaulding Rehabilitation Hospital, Boston, MA, United States; RiVERS Lab. (Research in Virtual Environments and Rehabilitation Sciences Laboratory), School of Health Related Professions, University of Medicine and Dentistry of New Jersey, Newark, NJ, United States","Mirelman, A., School of Health Related Professions, University of Medicine and Dentistry of New Jersey, Newark, NJ 07107, United States, Motion Analysis Lab., Spaulding Rehabilitation Hospital, Boston, MA, United States; Deutsch, J.E., RiVERS Lab. (Research in Virtual Environments and Rehabilitation Sciences Laboratory), School of Health Related Professions, University of Medicine and Dentistry of New Jersey, Newark, NJ, United States; Bonato, P., Motion Analysis Lab., Spaulding Rehabilitation Hospital, Boston, MA, United States","Virtual reality systems have been used to deliver goal directed repetitive training to promote rehabilitation of individuals post-stroke. Lower extremity training of individuals post-stroke who used a robot coupled with virtual environment has been shown to transfer to improved overground locomotion. To isolate the active components of training in this study we compared the outcomes of training with the robot-virtual reality (VR) system to the robot alone. Four individuals post-stroke participated in a four-week training protocol. One group trained with the robot-VR system and the other group with the robot alone. The improvement in walking speed and endurance for the robot- VR group was greater than the robot group alone. Adherence as well as the number of exercises performed in each session was comparable for the two groups. The duration of training sessions was comparable at the beginning of the study. However, subjects in the robot group reported higher fatigue and produced 16% fewer minutes of training towards the end of the study. These findings support the use of virtual environments coupled with a robot for transfer of training from the virtual to the real world environment. © 2006 IEEE.",,"Medical problems; Patient rehabilitation; Personnel training; Robotics; Training protocols; Training sessions; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-41649103893
"Bart O., Katz N., Weiss P.L., Josman N.","12805969300;7202995938;55435137100;6602849581;","Street crossing by typically developed children in real and virtual environments",2006,"Fifth International Workshop on Virtual Rehabilitation, IWVR 2006",,, 1707525,"42","46",,1,"10.1109/iwvr.2006.1707525","https://www.scopus.com/inward/record.uri?eid=2-s2.0-41649095719&doi=10.1109%2fiwvr.2006.1707525&partnerID=40&md5=8985dfcbafe269db5781b5566df9f055","Department of Occupational Therapy, School of Allied Health, Tel Aviv University, Tel Aviv 69978, Israel; School of Occupational Therapy, Hebrew University and Hadassah, Mount Scopus, Jerusalem 91905, Israel; Department of Occupational Therapy, Faculty of Social Welfare and Health Studies, University of Haifa, Mount Carmel, Haifa, 31905, Israel","Bart, O., Department of Occupational Therapy, School of Allied Health, Tel Aviv University, Tel Aviv 69978, Israel; Katz, N., School of Occupational Therapy, Hebrew University and Hadassah, Mount Scopus, Jerusalem 91905, Israel; Weiss, P.L., Department of Occupational Therapy, Faculty of Social Welfare and Health Studies, University of Haifa, Mount Carmel, Haifa, 31905, Israel; Josman, N., Department of Occupational Therapy, Faculty of Social Welfare and Health Studies, University of Haifa, Mount Carmel, Haifa, 31905, Israel","Objectives: Pedestrian injury is the second leading cause of death and serious injury among children between the ages of 5 and 14. The existing methods for teaching children how to cross the street safely are difficult to transfer to real life situations. The objective of this study was to evaluate the effectiveness of a Virtual Reality (VR) environment in teaching children how to cross a street safely. Method: Eighty-six children (55 girls and 31 boys), aged 7-12 years, participated in the study. The children were observed while crossing a real street and tested on a test in the virtual environment (VE) prior to and following VR training. Results: The children in the training group significantly improved their street crossing abilities in the VR simulation as well as in the real street crossing in comparison to the control group. Street crossing became safer with age however, no differences were found between boys and girls. Conclusions: This low-cost and readily available street crossing simulation had a positive effect on children's street crossing behavior and on their self-reported satisfaction. ©2006 IEEE.",,"Cost effectiveness; Medical problems; Roads and streets; Street crossing; Street crossing behavior; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-41649095719
"Figueroa P., Dachselt R., Lindt I.","7003967572;6507253418;15035603600;","A uniform specification of mixed reality interface components",2006,"Proceedings - IEEE Virtual Reality","2006",, 1624084,"289","290",,,"10.1109/VR.2006.22","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750115645&doi=10.1109%2fVR.2006.22&partnerID=40&md5=ce87f5abe7b548dd04538f44f5b72b0f","Universidad de los Andes, Colombia; Dresden University of Technology, Germany; Fraunhofer FIT, St. Augustin, Germany","Figueroa, P., Universidad de los Andes, Colombia; Dachselt, R., Dresden University of Technology, Germany; Lindt, I., Fraunhofer FIT, St. Augustin, Germany","This is a short presentation of a uniform approach for specifying mixed reality user interfaces, including 3D interaction techniques and 3D widgets. Our main goal is to facilitate the process of reusing previous work, so more complex applications can be built and documented in a formal and uniform way. We describe here the conceptual model of user interface components, which allows us to generalize user interface components and to port them to different hardware settings and application contexts. An XML-based specification language implements the conceptual model and allows for automatic processing and tool support. © 2006 IEEE.","3D Interaction Techniques; 3D User Interfaces; 3D Widgets; AR; Desktop VR; Interface Description Language; Mixed Reality; VR","Computer hardware; Computer hardware description languages; Computer software reusability; Human computer interaction; Personal computers; XML; 3D Interaction Techniques; 3D User Interfaces; 3D Widgets; Desktop VR; Interface Description Languages; Mixed Reality; User interfaces",Conference Paper,"Final","",Scopus,2-s2.0-33750115645
"Sadasivan S., Vembar D., Stringfellow P., Washburn C., Duchowski A., Gramopadhye A.","7005476735;14822811300;14822492400;23096821100;6701824388;7005569103;","Aircraft maintenance technology education: Integrating asynchronous technology & virtual reality",2006,"ASEE Annual Conference and Exposition, Conference Proceedings",,,,"","",10,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029123984&partnerID=40&md5=a0c2d232244bcc32450a32eaa8fe8d59","Cemson University; Department of Industrial Engineering, Clemson University, SC, United States; Department of Computer Science, Clemson University, SC, United States; Greenville Tech, United States; Aircraft Maintenance Program, Greenville Technical College, United States; Department of Computer Science, Clemson University, United States; Industrial Engineering Department; Advanced Technology Systems Laboratory, Clemson University, SC, United States","Sadasivan, S., Cemson University, Department of Industrial Engineering, Clemson University, SC, United States; Vembar, D., Cemson University, Department of Computer Science, Clemson University, SC, United States; Stringfellow, P., Cemson University, Department of Industrial Engineering, Clemson University, SC, United States; Washburn, C., Greenville Tech, United States, Aircraft Maintenance Program, Greenville Technical College, United States; Duchowski, A., Cemson University, Department of Computer Science, Clemson University, United States; Gramopadhye, A., Cemson University, Industrial Engineering Department, Advanced Technology Systems Laboratory, Clemson University, SC, United States","This paper describes a research program with an objective to develop and implement an interactive virtual reality (VR) model of the aircraft inspection maintenance process for asynchronous delivery. Existing approaches have not been able to mimic accurately the complexity of the aircraft maintenance process, reporting limited transfer capabilities and student preparedness for the workplace. This use of virtual reality technology will enable educators to create and students to experience the complex aircraft maintenance environment in an educational classroom, a setting where it has not yet been successfully created using traditional multimedia-based technologies. This model will emphasize the curriculum development and workplace preparedness needed by modern aircraft maintenance technology for local, state and national audiences. The primary objectives of this research are curriculum enhancement and assessment of VR as a pedagogical tool. This innovative approach is the first effort to extend tested VR technology to the aircraft maintenance technology curriculum in a two-year college. The outcome of this research will lead to the following: an innovative, high-impact model for curriculum application in aircraft maintenance technology for college students and industry employees; an increased workplace pool of aircraft maintenance technicians prepared for the transition from learning to workforce; a program providing the use of VR technology as a pedagogical tool. The successful completion of this effort will fill a state and national need for well-prepared students entering the aircraft maintenance industry and will provide a better understanding of the use of VR as a pedagogical tool. © American Society for Engineering Education, 2006.",,"Curricula; Engineering education; Engineering technology; Inspection; Maintenance; Students; Virtual reality; Asynchronous delivery; Curriculum development; Educational classrooms; Transfer capabilities; Aircraft",Conference Paper,"Final","",Scopus,2-s2.0-85029123984
"Herrera G., Jordan R., Veraa L.","56368923300;7401610771;15752361000;","Abstract concept and imagination teaching through Virtual Reality in people with Autism Spectrum Disorders",2006,"Technology and Disability","18","4",,"173","180",,11,"10.3233/tad-2006-18403","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845775241&doi=10.3233%2ftad-2006-18403&partnerID=40&md5=628cf3c3dc5695c93a079c49f2689d1c","Autism and Learning Difficulties Group, Robotics Institute, University of Valencia, 46071 Paterna, Valencia, Spain; Autism Team, School of Education, University of Birmingham, Birmingham, United Kingdom","Herrera, G., Autism and Learning Difficulties Group, Robotics Institute, University of Valencia, 46071 Paterna, Valencia, Spain; Jordan, R., Autism Team, School of Education, University of Birmingham, Birmingham, United Kingdom; Veraa, L., Autism and Learning Difficulties Group, Robotics Institute, University of Valencia, 46071 Paterna, Valencia, Spain","Virtual Reality (VR) has been claimed to provide a particularly facilitatory environment for people with Autistic Spectrum Disorders (ASD) in that it offers structure, opportunities for repetition, affective engagement and, control of the learning environment. Virtual reality shares the advantages of computer-based learning, and has the additional advantage of making it more likely that the results will generalise to real-word settings, in that it is a simulation of them. For concept development and imagination training, VR offers its exclusive advantage of making it possible to explicitly show imaginary/ magic transformations of how an object can act as if it were a different one, which is useful for training in both abstract concepts and imagination understanding. This paper reviews the relevant issues that need to be addressed when designing and experimentally assessing a tool for this purpose, and concludes with the results of the more relevant research outcomes obtained in this field. © 2006 IOS Press. All rights reserved.","Autistic Spectrum Disorders; Imagination; Play; Virtual Reality","affect; autism; computer aided design; computer language; computer program; computer simulation; concept formation; conference paper; facilitation; human; human computer interaction; imagination; learning environment; medical research; play; quality control; symbolism; virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-33845775241
"Padgett L.S., Strickland D., Coles C.D.","57220432277;7101782936;7005495059;","Case study: Using a virtual reality computer game to teach fire safety skills to children diagnosed with fetal alcohol syndrome",2006,"Journal of Pediatric Psychology","31","1",,"65","70",,69,"10.1093/jpepsy/jsj030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-29444451271&doi=10.1093%2fjpepsy%2fjsj030&partnerID=40&md5=a47dffe88a23f5c6f916edf13b197de0","Marcus Institute, Division of Kennedy-Krieger Institute, Emory University, United States; Do2Learn.org, Virtual Reality Aids, Inc., United States; Marcus Institute, Division of Kennedy-Krieger, Emory University, 1920 Briarcliff Road, Atlanta, GA 30329, United States","Padgett, L.S., Marcus Institute, Division of Kennedy-Krieger Institute, Emory University, United States, Do2Learn.org, Virtual Reality Aids, Inc., United States, Marcus Institute, Division of Kennedy-Krieger, Emory University, 1920 Briarcliff Road, Atlanta, GA 30329, United States; Strickland, D., Do2Learn.org, Virtual Reality Aids, Inc., United States; Coles, C.D., Marcus Institute, Division of Kennedy-Krieger Institute, Emory University, United States","Objective: To assess the effectiveness of a computer-based virtual reality (VR) game in teaching five children diagnosed with fetal alcohol syndrome (FAS) fire safety skills and to generalize these skills to a real world simulation. Method: Children participated in a study by using a multiple baseline, multiple probe design. Before the game, no child could correctly describe what actions to take during a home fire. A computerized game allowed them to learn the recommended safety steps in a virtual world. Skill learning and real-world generalization were tested immediately after the intervention and at 1-week post-test. Results: All children reached 100% accuracy on the computer intervention, defined as successfully completing each of the safety steps. At the 1-week follow-up, all the children were able to perform the steps correctly in a real world simulation. Conclusions: The results suggest that this method of intervention warrants further study as an educational delivery system for children with FAS. © The Author 2005. Published by Oxford University Press on behalf of the Society of Pediatric Psychology. All rights reserved.","Fetal alcohol syndrome; Fire safety; Injury prevention; Intervention","accuracy; article; child; clinical article; computer; education; female; fetal alcohol syndrome; fire protection; follow up; game; human; intellect; learning; male; skill; task performance; teaching; virtual reality; Child; Child, Preschool; Computers; Female; Fetal Alcohol Syndrome; Health Promotion; Humans; Male; Pregnancy; Safety; Teaching; User-Computer Interface; Video Games",Article,"Final","",Scopus,2-s2.0-29444451271
"Lam Y.S., Man D.W.K., Tam S.F., Weiss P.L.","36340111700;7006360144;7202037317;55435137100;","Virtual reality training for stroke rehabilitation",2006,"NeuroRehabilitation","21","3",,"245","253",,58,"10.3233/nre-2006-21308","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33845485888&doi=10.3233%2fnre-2006-21308&partnerID=40&md5=03282fd7c7f659f4f80af53a6e81f293","Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong; Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong; Department of Occupational Therapy, University of Haifa, Israel","Lam, Y.S., Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong; Man, D.W.K., Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong, Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong; Tam, S.F., Department of Rehabilitation Sciences, Hong Kong Polytechnic University, Hong Kong; Weiss, P.L., Department of Occupational Therapy, University of Haifa, Israel","Objective: To evaluate the effectiveness of a 2-D virtual reality (2DVR) programme in the training of people with stroke on how to access and use the station facilities of the Mass Transit Railway (MTR). Method: A flat-screen 2DVR based training programme and a corresponding, typical psycho-educational programme with video modelling were developed for comparison through a research design that involved a randomised control group pre-test and post-test. Results: Twenty and sixteen subjects respectively received 10 training sessions using the 2DVR strategy and a video-based psycho-educational programme. An additional 22 subjects formed the control group. They were assessed by using a behavioural checklist of MTR skills and a newly validated MTR self-efficacy scale. The subjects of both training groups showed a significant improvement in their knowledge, skills and self-efficacy in using the MTR (p<0.01), whereas, the MTR skills and self-efficacy of the control group remained stable over a four-week interval. Conclusion: Though both training programmes were effective in training the patients with stroke, they demonstrated differential improvements in MTR skills and related self-efficacy. Additional studies are recommended to identify the most effective training procedures for maintaining these skills and the best transfer ratio in the training of VR-based community living skills of people with stroke. © 2006 - IOS Press and the authors. All rights reserved.","Community; Independence; Orientation; Rehabilitation; Stroke; Virtual reality","adult; aged; analysis of variance; article; behavior; clinical article; clinical trial; controlled clinical trial; controlled study; demography; female; health education; health program; human; male; psychoeducation; railway; randomized controlled trial; self concept; statistical analysis; stroke; training; videorecording; virtual reality",Article,"Final","",Scopus,2-s2.0-33845485888
"Yi S.Y., Woo H.S., Ahn W.J., Kwon J.Y., Lee D.Y.","7201404669;8551464000;9334513400;9336291000;7409922325;","New colonoscopy simulator with improved haptic fidelity",2006,"Advanced Robotics","20","3",,"349","365",,29,"10.1163/156855306776014330","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646005247&doi=10.1163%2f156855306776014330&partnerID=40&md5=594dc14d4eb3f6c13050da9f7480f4f2","Department of Internal Medicine, Ewha Womans University, Seoul, South Korea; Department of Mechanical Engineering, KAIST, Daejeon, South Korea; Department of Internal Medicine, College of Medicine, Ewha Womans University, Seoul, South Korea; American Gastrointestinal Association, United States; Korean Association of Internal Medicine, South Korea; Korean Society of Gastroenterology, South Korea; Korean Society of Gastrointestinal Motility, South Korea; Agency for Defense Development, Daejeon, South Korea; Institute of Electrical and Electronics Engineers, South Korea; Society of Manufacturing Engineers, South Korea; Korean Society of Mechanical Engineers, South Korea; Institute of Control, Automation and Systems Engineers, South Korea","Yi, S.Y., Department of Internal Medicine, Ewha Womans University, Seoul, South Korea, Department of Internal Medicine, College of Medicine, Ewha Womans University, Seoul, South Korea, American Gastrointestinal Association, United States, Korean Association of Internal Medicine, South Korea, Korean Society of Gastroenterology, South Korea, Korean Society of Gastrointestinal Motility, South Korea; Woo, H.S., Department of Mechanical Engineering, KAIST, Daejeon, South Korea; Ahn, W.J., Department of Mechanical Engineering, KAIST, Daejeon, South Korea; Kwon, J.Y., Department of Mechanical Engineering, KAIST, Daejeon, South Korea, Agency for Defense Development, Daejeon, South Korea; Lee, D.Y., Department of Mechanical Engineering, KAIST, Daejeon, South Korea, Institute of Electrical and Electronics Engineers, South Korea, Society of Manufacturing Engineers, South Korea, Korean Society of Mechanical Engineers, South Korea, Institute of Control, Automation and Systems Engineers, South Korea","Colonoscopy is a safe and effective procedure to diagnose and treat the large bowel with the help of the flexible endoscope. This paper presents a new colonoscopy training simulator to help trainees practice and acquire the necessary skills and experiences with no risk to the patients and possibly less cost. The simulator includes a specialized haptic interface to transfer force feedback through a long and flexible tube, and graphics algorithms to display the virtual colon realistically while managing the large number of polygons. A new 2-d.o.f. haptic device with folding guides is developed to transmit large decoupled forces of the colonoscopy simulation to the user. The physicians apply a jiggling motion to the colonoscopy tube to advance the scope. This jiggling is an important skill of colonoscopy and is incorporated for the first time by using the new sensor mechanism. A colonoscope handle that shares the look, feel and functions with an actual colonoscope is developed with the necessary electronics inside. The simulator contains controllers to compensate for the inertia and friction effects, and is evaluated by physicians. New graphics algorithms including polygon reduction, navigation and collision detection are developed to compute the deformation and the corresponding reflective force in real-time.","Colonoscopy; Haptic interface; Haptics; Medical simulation; Virtual reality","Computer graphics; Feedback; Sensors; Simulators; Virtual reality; Colonoscopy; Graphics algorithms; Haptics; Medical simulation; Haptic interfaces",Article,"Final","",Scopus,2-s2.0-33646005247
"Dähne P., Seibert H.","6507191408;7004142744;","Managing data flow in interactive MR environments",2005,"13th International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision 2005, WSCG'2005 - In Co-operation with EUROGRAPHICS, Full Papers",,,,"173","176",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861040059&partnerID=40&md5=5eedd27a43dd6ca2aa4205bbdb8e5fc9","Computer Graphics Center (ZGDV), Fraunhoferstraße 5, D-64283 Darmstadt, Germany","Dähne, P., Computer Graphics Center (ZGDV), Fraunhoferstraße 5, D-64283 Darmstadt, Germany; Seibert, H., Computer Graphics Center (ZGDV), Fraunhoferstraße 5, D-64283 Darmstadt, Germany","In this paper the concept and design of a software framework which provides a transparent data flow for interactive Mixed Reality (MR) applications is discussed. The design was affected by our demands on platform independency, simplicity, network transparency, maximum performance and availability of runtime debugging facilities. Our software framework tries to simplify the development of MR applications by using the concept of a data flow graph. The developer builds such a graph from a library of small software components that communicate via the edges of the graph. Copyright UNION Agency - Science Press.","Augmented reality; Device management; Interaction; Mixed Reality; Tracking; Virtual reality","Data flow; Device management; Interaction; Mixed reality; Runtimes; Software component; Software frameworks; Augmented reality; Computer programming; Data flow analysis; Data flow graphs; Data transfer; Surface discharges; Virtual reality; Visualization; Computer vision",Conference Paper,"Final","",Scopus,2-s2.0-84861040059
"Yoo B., Cha M., Han S.","7102851883;23987479200;7405945481;","A framework for a multi-sensory VR effect system with motional display",2005,"Proceedings - 2005 International Conference on Cyberworlds, CW 2005","2005",, 1587539,"237","244",,7,"10.1109/CW.2005.5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33745158632&doi=10.1109%2fCW.2005.5&partnerID=40&md5=6ad0895e885ebe6f12de12dbeda38878","Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, South Korea","Yoo, B., Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, South Korea; Cha, M., Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, South Korea; Han, S., Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, South Korea","Virtual reality simulators have been developed as tools for the transfer of knowledge and education. Concurrently, the demand for exhibition systems of science education and cultural experiences has also increased. Existing VR (virtual reality) simulators, which are based on the calculation of dynamics equations, cannot easily be adapted to changes in simulation content. In order to transfer knowledge and maintain interest through educational applications, an experiential system that has multi-sensory effects as well as motion effects is needed. The authors proposed a method for motion generation that is tailored to riding systems and multi-sensory VR effects. In this study, both sense of motion, which is generated from movement of the viewpoint of the visual image, and motion effects, which are prepared in advance, are blended to realize motion simulation by the proposed method. Motion effects can easily be added by interaction between the user and the riding system. Various sensory cues are also implemented to the riding system. © 2005 IEEE.",,"Dynamics equations; Motional display; Virtual reality simulators; Visual images; Computer simulation; Data transfer; Education; Knowledge engineering; Motion estimation; Sensor data fusion; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-33745158632
"Benölken P., Graf H.","7801583876;27567700900;","Direct volume rendering of unstructured grids in a PC based VR environment",2005,"13th International Conference in Central Europe on Computer Graphics, Visualization and Computer Vision 2005, WSCG'2005 - In Co-operation with EUROGRAPHICS, Full Papers",,,,"25","32",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861070236&partnerID=40&md5=f0b619e9308b7b5d202727a43ccdffb5","Fraunhofer IWU, Reichenhainer Straße 88, 09126 Chemnitz, Germany; Fraunhofer IGD, Fraunhofer Straße 5, 64283 Darmstadt, Germany","Benölken, P., Fraunhofer IWU, Reichenhainer Straße 88, 09126 Chemnitz, Germany; Graf, H., Fraunhofer IGD, Fraunhofer Straße 5, 64283 Darmstadt, Germany","In this paper we present our solution for fast, direct volume rendering of unstructured grids on standard PC workstations. We describe our modification of the incremental slicing approach for achieving high performance as well as the application of geometry-compression methods for minimizing the memory requirements. Furthermore, we show our implementation for the interactive modification of transfer functions (classification) in a virtual reality environment by using 3D interaction widgets. Finally we present and discuss the results, we achieved with our application in a VR environment. Copyright UNION Agency - Science Press.","Direct volume rendering; Geometry compression; Unstructured grids; Virtual reality","3D interactions; Direct volume rendering; Geometry compression; Memory requirements; PC-based; Unstructured grid; Virtual-reality environment; Virtual reality; Visualization; Computer vision",Conference Paper,"Final","",Scopus,2-s2.0-84861070236
"Wierinck E., Puttemans V., Swinnen S., van Steenberghe D.","8243408900;6506533201;7005154622;7101895992;","Effect of augmented visual feedback from a virtual reality simulation system on manual dexterity training",2005,"European Journal of Dental Education","9","1",,"10","16",,50,"10.1111/j.1600-0579.2004.00351.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-14544298450&doi=10.1111%2fj.1600-0579.2004.00351.x&partnerID=40&md5=456dfc2bb2ed0629d188260ba7d4366e","Selfteaching and Skills Training Centre, School of Dentistry, Oral Pathology and Maxillofacial Surgery, Katholieke Universiteit Leuven, Leuven, Belgium; Motor Control Laboratory, Department of Kinesiology, School of Dentistry, Oral Pathology and Maxillofacial Surgery Katholieke Universiteit Leuven, Leuven, Belgium; Department of Periodontology, School of Dentistry,Oral Pathology and Maxillofacial Surgery, Katholieke Universiteit Leuven, Leuven, Belgium","Wierinck, E., Selfteaching and Skills Training Centre, School of Dentistry, Oral Pathology and Maxillofacial Surgery, Katholieke Universiteit Leuven, Leuven, Belgium; Puttemans, V., Motor Control Laboratory, Department of Kinesiology, School of Dentistry, Oral Pathology and Maxillofacial Surgery Katholieke Universiteit Leuven, Leuven, Belgium; Swinnen, S., Motor Control Laboratory, Department of Kinesiology, School of Dentistry, Oral Pathology and Maxillofacial Surgery Katholieke Universiteit Leuven, Leuven, Belgium; van Steenberghe, D., Department of Periodontology, School of Dentistry,Oral Pathology and Maxillofacial Surgery, Katholieke Universiteit Leuven, Leuven, Belgium","Little research has been published about the impact of simulation technology on the learning process of novel motor skills. Especially the role of augmented feedback (FB) on the quality of performance and the transfer of the acquired behaviour to a no-augmented FB condition require further investigation. Therefore, novice dental students were randomly assigned to one of three groups and given the task of drilling a geometrical class 1 cavity. The FB group trained under augmented visual FB conditions, provided by the virtual reality (VR) system (DentSim™). The no-FB group practised under normal vision conditions, in the absence of augmented FB. A control group performed the test sessions without participating in any training programme. All preparations were evaluated by the VR grading system according to four traditional (outline shape, floor depth, floor smoothness and wall inclination), and two critical, criteria (pulp exposure and damage to adjacent teeth). Performance analyses revealed an overall trend towards significant improvement with training for the experimental groups. The FB group obtained the highest scores. It scored better for floor depth (P < 0.001), whilst the no-FB group was best for floor smoothness (P < 0.005). However, at the retention tests, the FB group demonstrated inferior performance in comparison with the no-FB group. The transfer test on a traditional unit revealed no significant differences between the training groups. Consequently, drilling experience on a VR system under the condition of frequently provided FB and lack of any tutorial input was considered to be not beneficial to learning. The present data are discussed in view of the guidance hypothesis of FB, which refers to the apprentice's dependence on FB. © Blackwell Munksgaard, 2005.","Augmented feedback; Guidance; Skill acquisition; Transfer; Virtual reality","adolescent; adult; article; classification; clinical trial; comparative study; computer interface; computer simulation; controlled clinical trial; controlled study; dental surgery; education; endodontics; feedback system; human; learning; long term memory; methodology; motor performance; randomized controlled trial; teaching; tooth injury; vision; Adolescent; Adult; Computer Simulation; Dental Cavity Preparation; Dental Pulp Exposure; Dentistry, Operative; Feedback; Humans; Learning; Motor Skills; Retention (Psychology); Teaching; Tooth Injuries; Transfer (Psychology); User-Computer Interface; Visual Perception",Article,"Final","",Scopus,2-s2.0-14544298450
"Fuhrmann A.L., Splechtna R.C., Mroz L., Hauser H.","7004448962;55481478800;6603388015;7202841889;","Distributed software-based volume visualization in a virtual environment",2005,"9th International Workshop on Immersive Projection Technology - 11th Eurographics Symposium on Virtual Environments, IPT/EGVE 2005",,,,"129","139",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878689138&partnerID=40&md5=8471fd68a6473911e998e41b5587efad","VRVis Research Center, Austria; TIANI MedGraph, Austria","Fuhrmann, A.L., VRVis Research Center, Austria; Splechtna, R.C., VRVis Research Center, Austria; Mroz, L., TIANI MedGraph, Austria; Hauser, H., VRVis Research Center, Austria","In this paper we present our integration of volume rendering into virtual reality, combining a fast and flexible software implementation of direct volume rendering with the intuitive manipulation and navigation techniques of a virtual environment. By distributing the visualization and interaction tasks to two low-end PCs we managed to realize a highly interactive, yet inexpensive set-up. The volume objects are seamlessly integrated into the polygonal virtual environment through image-based rendering. The interaction techniques include scalar parameterization of transfer functions, direct 3D selection, 3D highlighting of volume objects and clipping cubes and cutting planes. These methods combined with the interaction and display devices of virtual reality form a powerful yet intuitive environment for the investigation of volume data sets. As main application areas we propose training and education. © The Eurographics Association 2005.",,"Direct volume rendering; Image-Based Rendering; Interaction techniques; Navigation techniques; Software implementation; Training and education; Volume data sets; Volume visualization; Display devices; Image reconstruction; Optical projectors; Sensory perception; Visualization; Volume rendering; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84878689138
"Asano T., Ishibashi Y., Minezawa S., Fujimoto M.","7402943966;7402603568;15072031800;36117581300;","Surveys of exhibition planners and visitors about a distributed haptic museum",2005,"ACM International Conference Proceeding Series","265",,,"246","249",,8,"10.1145/1178477.1178518","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953492426&doi=10.1145%2f1178477.1178518&partnerID=40&md5=9585e04100fd26dfae518523140a50e3","NTT Service Integration Laboratories, NTT Corporation, Nakanoshima Center Bldg., 6-2-27 Nakanoshima, Kita-ku, Osaka 530-6691, Japan; Department of Computer Science and Engineering, Nagoya Institute of Technology, Gokiso-cho, Showa-ku, Nagoya 466-8555, Japan","Asano, T., NTT Service Integration Laboratories, NTT Corporation, Nakanoshima Center Bldg., 6-2-27 Nakanoshima, Kita-ku, Osaka 530-6691, Japan; Ishibashi, Y., Department of Computer Science and Engineering, Nagoya Institute of Technology, Gokiso-cho, Showa-ku, Nagoya 466-8555, Japan; Minezawa, S., Department of Computer Science and Engineering, Nagoya Institute of Technology, Gokiso-cho, Showa-ku, Nagoya 466-8555, Japan; Fujimoto, M., Department of Computer Science and Engineering, Nagoya Institute of Technology, Gokiso-cho, Showa-ku, Nagoya 466-8555, Japan","This paper presents the results of surveys of exhibition planners and visitors about our distributed haptic museum, which is a distributed virtual museum with touchable exhibits. We visited 15 museums and talked with 23 exhibition planners such as curators and researchers in various types of museums and art galleries after explaining our system and its exhibits. In addition, a questionnaire was given to 75 students acting as visitors. The students experienced our system after a similar presentation to the one given to the exhibition planners. We studied the availability and directionality of the distributed haptic museum based on these discussions and questionnaire results in terms of the concept, haptic interface device, usage, contents, and so on.","contents; distributed virtual environment; haptic media; survey; virtual museums","Art gallery; distributed virtual environment; Distributed Virtual Environments; Haptic media; Virtual museum; Adaptive filtering; Data transfer; Exhibitions; Haptic interfaces; Planning; Surveys; Virtual reality; Museums",Conference Paper,"Final","",Scopus,2-s2.0-77953492426
"Boukerche A., McGraw N.J., Araujo R.B.","7005819374;14018311600;9132347700;","A novel data distribution management scheme to support synchronization in large-scale distributed virtual environments",2005,"VECIMS 2005 - IEEE International Conference onVirtual Environments, Human-Computer Interfaces, and Measurement Systems","2005",, 1567565,"67","72",,1,"10.1109/VECIMS.2005.1567565","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846584171&doi=10.1109%2fVECIMS.2005.1567565&partnerID=40&md5=b42144126a219573f8ab8ef7a18a332c","PARADISE Research Laboratory, SITE, University of Ottawa, Ottawa, Canada; University of North Texas, Denton, TX, United States; Networked Virtual Reality Laboratory, Federal University of São Carlos, São Carlos, SP, Brazil","Boukerche, A., PARADISE Research Laboratory, SITE, University of Ottawa, Ottawa, Canada; McGraw, N.J., University of North Texas, Denton, TX, United States; Araujo, R.B., Networked Virtual Reality Laboratory, Federal University of São Carlos, São Carlos, SP, Brazil","In Large-Scale Distributed Virtual Environments LDVEs extensive and/or multidimensional virtual 3D environments can be shared by thousands of participant users in applications ranging from multiplayer games to virtual cities, virtual shopping mall, open space military training etc. In such systems, distribution seems inherent. The world geometric data of an extensive region or terrain may need to be divided in areas, which are distributed across the network. By distributing the data, host memory use and processing power are reduced since less data needs to be received, processed and stored. However, these gains can be easily surpassed by the amount of traffic generated by the synchronization messages transmitted, as well as the processing time due to the control infrastructure and the bulky data transmission of parts of the distributed VE. So, good mechanisms for data distribution management (DDM) are an important requirement for LDVEs. This paper describes the Grid Filtered Region-Based (GFRB) DDM scheme, which combines the positive aspects of both Region-Based and Grid-Based DDM methods to reduce network traffic and latency in LDVEs using a minimum number of multicast groups. GFRB scheme is unique because it provides a finer grained mechanism to exact match publishers to subscribers with intersecting regions. It does that with a reduced number of messages and multicast groups, by taking into consideration the percentage of overlap of a region on a cell. Experimental results show that GFRB scheme can be a potential solution to data synchronization in Large Distributed Virtual Environments.","Data distribution managament; Data filtering; Data synchronization; Large-scale distributed virtual environments","Data processing; Data transfer; Information management; Multicasting; Telecommunication traffic; Virtual reality; Data distribution managament; Data synchronization; Large-scale distributed virtual environments; Distributed computer systems",Conference Paper,"Final","",Scopus,2-s2.0-33846584171
"Heying M., Oliver J., Sundararajan S., Shrotyria P., Zou Q., Sannier A.","12545325000;7401628559;8640898600;12239256700;7103094245;8410080700;","Virtual Probe Microscope",2005,"2005 NSTI Nanotechnology Conference and Trade Show - NSTI Nanotech 2005 Technical Proceedings",,,,"753","756",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-32144459141&partnerID=40&md5=0c42ed98e94657eddbea86576406e1b2","Human Computer Interaction Program, 1620 Howe Hall, Iowa State University, Ames, IA 50011, United States; Mechanical Engineering Department, 2025 H. M. Black Engineering Building, Iowa State University, Ames, IA, 50011, United States","Heying, M., Human Computer Interaction Program, 1620 Howe Hall, Iowa State University, Ames, IA 50011, United States; Oliver, J., Human Computer Interaction Program, 1620 Howe Hall, Iowa State University, Ames, IA 50011, United States; Sundararajan, S., Mechanical Engineering Department, 2025 H. M. Black Engineering Building, Iowa State University, Ames, IA, 50011, United States; Shrotyria, P., Mechanical Engineering Department, 2025 H. M. Black Engineering Building, Iowa State University, Ames, IA, 50011, United States; Zou, Q., Mechanical Engineering Department, 2025 H. M. Black Engineering Building, Iowa State University, Ames, IA, 50011, United States; Sannier, A., Human Computer Interaction Program, 1620 Howe Hall, Iowa State University, Ames, IA 50011, United States","Virtual Probe Microscope (VPM) is a tool that has been developed to train users on Atomic Force Microscope (AFM) operation. The benefits from training with VPM include: reduced cost of training and increased transfer of training. The graphical user interface of VPM is laid out similar to common commercial AFM software packages. Along with standard AFM controls, users are given an additional graphical 3D window to view the probe traversing across a surface. Users are also allowed to manipulate probe geometry variable to increase understanding of AFM operation. VPM will be used in a graduate level scanning probe microscopy class in the spring of 2005 at Iowa State University to supplement traditional lab and classroom instruction.","Atomic force microscope; Scanning probe microscope; Simulation; Simulator","Atomic force microscopy; Computer software; Cost effectiveness; Electronic communities; Scanning electron microscopy; Scanning probe microscopy; Simulator; Software packages; Microscopic examination",Conference Paper,"Final","",Scopus,2-s2.0-32144459141
"Langelotz C., Kilian M., Paul C., Schwenk W.","6602927522;10143344000;57205940077;7102506661;","LapSim virtual reality laparoscopic simulator reflects clinical experience in German surgeons",2005,"Langenbeck's Archives of Surgery","390","6",,"534","537",,20,"10.1007/s00423-005-0571-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-27744560421&doi=10.1007%2fs00423-005-0571-6&partnerID=40&md5=4bc3c8c9ba2092e962adf0a387c55ed0","Department of General, Visceral, Vascular and Thoracic Surgery, Universitätsmedizin Berlin-Charité, Campus Mitte, Schumannstrasse 20/21, 10117 Berlin, Germany","Langelotz, C., Department of General, Visceral, Vascular and Thoracic Surgery, Universitätsmedizin Berlin-Charité, Campus Mitte, Schumannstrasse 20/21, 10117 Berlin, Germany; Kilian, M., Department of General, Visceral, Vascular and Thoracic Surgery, Universitätsmedizin Berlin-Charité, Campus Mitte, Schumannstrasse 20/21, 10117 Berlin, Germany; Paul, C., Department of General, Visceral, Vascular and Thoracic Surgery, Universitätsmedizin Berlin-Charité, Campus Mitte, Schumannstrasse 20/21, 10117 Berlin, Germany; Schwenk, W., Department of General, Visceral, Vascular and Thoracic Surgery, Universitätsmedizin Berlin-Charité, Campus Mitte, Schumannstrasse 20/21, 10117 Berlin, Germany","Background and aims: The aim of this study was to analyze the ability of a training module on a virtual laparoscopic simulator to assess surgical experience in laparoscopy. Methods: One hundred and fifteen participants at the 120th annual convent of the German surgical society took part in this study. All participants were stratified into two groups, one with laparoscopic experience of less than 50 operations (group 1, n=61) and one with laparoscopic experience of more than 50 laparoscopic operations (group 2, n=54). All subjects completed a laparoscopic training module consisting of five different exercises for navigation, coordination, grasping, cutting and clipping. The time to perform each task was measured, as were the path lengths of the instruments and their respective angles representing the economy of the movements. Results between groups were compared using χ 2 or Mann-Whitney U-test. Results: Group 1 needed more time for completion of the exercises (median 424 s, range 99-1,376 s) than group 2 (median 315 s, range 168-625 s) (P&lt;0.01). Instrument movements were less economic in group 1 with larger angular pathways, e.g. in the cutting exercise (median 352°, range 104-1,628° vs median 204°, range 107-444°, P&lt;0.01), and longer path lengths (each instrument P&lt;0.05). Conclusion: As time for completion of exercises, instrument path lengths and angular paths are indicators of clinical experience, it can be concluded that laparoscopic skills acquired in the operating room transfer into virtual reality. A laparoscopic simulator can serve as an instrument for the assessment of experience in laparoscopic surgery. © Springer-Verlag 2005.","Education; Laparoscopic surgery; Simulator training; Skills assessment","adult; article; competence; controlled study; female; human; laparoscopic surgery; male; priority journal; simulator; skill; surgeon; surgical technique; surgical training; task performance; virtual reality; Chi-Square Distribution; Clinical Competence; Computer Simulation; Education, Medical, Graduate; Germany; Humans; Laparoscopy; Statistics, Nonparametric; Surgery; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-27744560421
"Latoschik M.E., Biermann P., Wachsmuth I.","6602976914;7004339578;35581983300;","Knowledge in the loop: Semantics representation for multimodal simulative environments",2005,"Lecture Notes in Computer Science","3638",,,"25","39",,23,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-26944478544&partnerID=40&md5=49f52a7d20aa888858a2f71f106530a4","AI and VR Lab., University of Bielefeld, Germany","Latoschik, M.E., AI and VR Lab., University of Bielefeld, Germany; Biermann, P., AI and VR Lab., University of Bielefeld, Germany; Wachsmuth, I., AI and VR Lab., University of Bielefeld, Germany","This article describes the integration of knowledge based techniques into simulative Virtual Reality (VR) applications. The approach is motivated using multimodal Virtual Construction as an example domain. An abstract Knowledge Representation Layer (KRL) is proposed which is expressive enough to define all necessary data for diverse simulation tasks and which additionally provides a base formalism for the integration of Artificial Intelligence (AI) representations. The KRL supports two different implementation methods. The first method uses XSLT processing to transform the external KRL format into the representation formats of the diverse target systems. The second method implements the KRL using a functionally extendable semantic network. The semantic net library is tailored for real time simulation systems where it interconnects the required simulation modules and establishes access to the knowledge representations inside the simulation loop. The KRL promotes a novel object model for simulated objects called Semantic Entities which provides a uniform access to the KRL and which allows extensive system modularization. The KRL approach is demonstrated in two simulation areas. First, a generalized scene graph representation is presented which introduces an abstract definition and implementation of geometric node interrelations. It supports scene and application structures which can not be expressed using common scene hierarchies or field route concepts. Second, the KRL's expressiveness is demonstrated in the design of multimodal interactions. Here, the KRL defines the knowledge particularly required during the semantic analysis of muitimodal user utterances. © Springer-Verlag Berlin Heidelberg 2005.",,"Knowledge representation layer (KRL); Object models; Semantic network; Virtual construction; Computer simulation; Data reduction; Graph theory; Knowledge based systems; Mathematical models; Modal analysis; Virtual reality; Semantics",Conference Paper,"Final","",Scopus,2-s2.0-26944478544
"Grossman T., Wigdor D., Balakrishnan R.","7003520062;6507569914;7006221860;","Exploring interaction with 3D volumetric displays",2005,"Proceedings of SPIE - The International Society for Optical Engineering","5664",, 35,"323","331",,2,"10.1117/12.587714","https://www.scopus.com/inward/record.uri?eid=2-s2.0-21944443996&doi=10.1117%2f12.587714&partnerID=40&md5=673ea419c25b0f8f5ebb26f8176ed2c3","Dept. of Computer Science, Univ. of Toronto, 40 St. George St, Toronto, Ont. M5S 3G4, Canada","Grossman, T., Dept. of Computer Science, Univ. of Toronto, 40 St. George St, Toronto, Ont. M5S 3G4, Canada; Wigdor, D., Dept. of Computer Science, Univ. of Toronto, 40 St. George St, Toronto, Ont. M5S 3G4, Canada; Balakrishnan, R., Dept. of Computer Science, Univ. of Toronto, 40 St. George St, Toronto, Ont. M5S 3G4, Canada","Volumetric displays generate true volumetric 3D images by actually illuminating points in 3D space. As a result, viewing their contents is similar to viewing physical objects in the real world. These displays provide a 360 degree field of view, and do not require the user to wear hardware such as shutter glasses or head-trackers. These properties make them a promising alternative to traditional display systems for viewing imagery in 3D. Because these displays have only recently been made available commercially (e.g., www.actuality-systems.com), their current use tends to be limited to non-interactive output-only display devices. To take full advantage of the unique features of these displays, however, it would be desirable if the 3D data being displayed could be directly interacted with and manipulated. We investigate interaction techniques for volumetric display interfaces, through the development of an interactive 3D geometric model building application. While this application area itself presents many interesting challenges, our focus is on the interaction techniques that are likely generalizable to interactive applications for other domains. We explore a very direct style of interaction where the user interacts with the virtual data using direct finger manipulations on and around the enclosure surrounding the displayed 3D volumetric image. © 2005 SPIE and IS&T.","3D interaction; Multi-finger and two-handed gestural input; Volumetric display","Image quality; Liquid crystal displays; Mathematical models; Stereo vision; Three dimensional; Virtual reality; Microscopic patterns; Multi-finger and two-handed gestural input; Three dimensional (3D) interaction; Volumetric display; Image processing",Conference Paper,"Final","",Scopus,2-s2.0-21944443996
"Dauster B., Steinberg A.P., Vassiliou M.C., Bergman S., Stanbridge D.D., Feldman L.S., Fried G.M.","8616638700;7202522694;8616638200;8616638300;9638375800;7202789490;7102886850;","Validity of the MISTELS simulator for laparoscopy training in urology",2005,"Journal of Endourology","19","5",,"541","545",,71,"10.1089/end.2005.19.541","https://www.scopus.com/inward/record.uri?eid=2-s2.0-22244467760&doi=10.1089%2fend.2005.19.541&partnerID=40&md5=5da4df8f8edf860ac925f6c42ee6614c","Department of Urology, McGill University, Montréal, Que., Canada; Steinberg-Bernstein Centre for Minimally Invasive Surgery, Department of Surgery, McGill University, Montréal, Que., Canada; Dept. of Urology, McGill University Health Center, 1650 Cedar Ave., Montréal, Que. H3G 1A4, Canada","Dauster, B., Department of Urology, McGill University, Montréal, Que., Canada; Steinberg, A.P., Department of Urology, McGill University, Montréal, Que., Canada, Dept. of Urology, McGill University Health Center, 1650 Cedar Ave., Montréal, Que. H3G 1A4, Canada; Vassiliou, M.C., Steinberg-Bernstein Centre for Minimally Invasive Surgery, Department of Surgery, McGill University, Montréal, Que., Canada; Bergman, S., Steinberg-Bernstein Centre for Minimally Invasive Surgery, Department of Surgery, McGill University, Montréal, Que., Canada; Stanbridge, D.D., Steinberg-Bernstein Centre for Minimally Invasive Surgery, Department of Surgery, McGill University, Montréal, Que., Canada; Feldman, L.S., Steinberg-Bernstein Centre for Minimally Invasive Surgery, Department of Surgery, McGill University, Montréal, Que., Canada; Fried, G.M., Steinberg-Bernstein Centre for Minimally Invasive Surgery, Department of Surgery, McGill University, Montréal, Que., Canada","Background and Purpose: The McGill Inanimate System for Training and Evaluation of Laparoscopic Skills (MISTELS) consists of a series of five laparoscopic exercises performed in an endotrainer box. MISTELS has been validated for use in both training and evaluation of general surgery residents in fundamental laparoscopic skills. The purpose of this study was to demonstrate the construct validity of MISTELS for urology residents. Subjects and Methods: Seventeen participants were evaluated during performance of the five MISTELS tasks (peg transfer, pattern cutting, ligating loop, and suturing with extracorporeal and intracorporeal knots) using the standardized scoring system, which rewards both speed and precision. Participants included 13 urology residents (PGY 1-5), 1 fellow, and 3 urologists experienced in laparoscopy. Results are expressed as median (range). The Mann-Whitney U-test was used to compare MISTELS scores for 9 novice (PGY 1-4) and 8 experienced urologists (PGY 5-attending). P < 0.05 was considered statistically significant. Results: The median MISTELS total normalized score for novices was 52.3 (range 15-68.9) compared with 71.7 (range 56.3-82.9) for experienced urologists (P = 0.007). Although the experienced group achieved higher scores in all five individual tasks, statistically significant differences were demonstrated for the peg transfer and intracorporeal suture tasks only. Conclusion: These data provide evidence for construct validity of the MISTELS system for urology residents. © Mary Ann Liebert, Inc.",,"camera; conference paper; education program; laparoscopic surgery; laparoscopy; learning; minimally invasive surgery; monitor; priority journal; scoring system; statistical analysis; surgeon; surgical training; task performance; urologic surgery; videorecording; virtual reality; Education, Medical, Graduate; Humans; Internship and Residency; Laparoscopy; Models, Structural; Reproducibility of Results; Surgery; Teaching Materials; Ureteroscopy; Urology",Conference Paper,"Final","",Scopus,2-s2.0-22244467760
"Deutsch J.A., Lewis J.A., Whitworth E., Boian R., Burdea G., Tremaine M.","7201985389;8693257800;23398901100;6603659582;35612697900;6603562993;","Formative evaluation and preliminary findings of a virtual reality telerehabilitation system for the lower extremity",2005,"Presence: Teleoperators and Virtual Environments","14","2",,"198","213",,14,"10.1162/1054746053967030","https://www.scopus.com/inward/record.uri?eid=2-s2.0-20344398182&doi=10.1162%2f1054746053967030&partnerID=40&md5=d45e784d253dce8ded280a45dc484183","Department of Developmental and Rehabilitative Sciences, University of Medicine and Dentistry of New Jersey, School of Health Related Professions, Newark, NJ, United States; VR LAB, Center for Advanced Information Processing, Rutgers University, Piscataway, NJ, United States; Department of Information Systems, New Jersey Institute of Technology, Newark, NJ, United States","Deutsch, J.A., Department of Developmental and Rehabilitative Sciences, University of Medicine and Dentistry of New Jersey, School of Health Related Professions, Newark, NJ, United States; Lewis, J.A., Department of Developmental and Rehabilitative Sciences, University of Medicine and Dentistry of New Jersey, School of Health Related Professions, Newark, NJ, United States, VR LAB, Center for Advanced Information Processing, Rutgers University, Piscataway, NJ, United States; Whitworth, E., Department of Information Systems, New Jersey Institute of Technology, Newark, NJ, United States; Boian, R., VR LAB, Center for Advanced Information Processing, Rutgers University, Piscataway, NJ, United States; Burdea, G., VR LAB, Center for Advanced Information Processing, Rutgers University, Piscataway, NJ, United States; Tremaine, M., Department of Information Systems, New Jersey Institute of Technology, Newark, NJ, United States","Usability studies are an essential and iterative component of technology development and ease its transfer from the laboratory to the clinic. Although such studies are standard methodology in today's graphical user-interface applications, it is not clear that current methods apply to new technologies such as virtual reality. Thus experimentation is needed to examine what existing methods can be viably transferred to the new user-interaction situations. In this paper, 5 integrated interfaces with 3 simultaneous users are evaluated via a set of usability studies, which adapt traditional methods for assessing the ease of use of the interface design. A single expert domain user was run in an intensive study that examined the therapist manual and interfaces of the Rutgers Ankle Rehabilitation System (RARS). The interface and manual were extensively modified based on this evaluation. A second study involving 5 therapists was then conducted to evaluate the telerehabilitation component of the RARS system. In both studies, the tester and developer's observations, along with the session videotapes and therapist-user questionnaires, were triangulated to identify user problems and suggest design changes expected to increase the usability of the system. Changes that resulted from the analysis with the domain expert are described and recommendations for how to conduct usability studies in such multiuser remote virtual reality situations are proposed. Results from the pilot usability telemonitoring studies are also presented. The validity of usability studies in the development and refinement of rehabilitation technology is highlighted. © 2005 by the Massachusetts Institute of Technology.",,"Ankle; Domain users; Real time monitors; Videotapes; Biological organs; Graphical user interfaces; Human computer interaction; Patient rehabilitation; Problem solving; Real time systems; Visualization; Virtual reality",Article,"Final","",Scopus,2-s2.0-20344398182
"Mouloua M., Smither J., Kennedy R.C., Kennedy R.S., Compton D.E., Drexler J.M.","6701614142;6603999134;13406461800;7402555615;16314916200;7006657013;","Training effects in a sickness-inducing environment",2005,"Proceedings of the Human Factors and Ergonomics Society",,,,"2206","2210",,,"10.1177/154193120504902519","https://www.scopus.com/inward/record.uri?eid=2-s2.0-44349192006&doi=10.1177%2f154193120504902519&partnerID=40&md5=03b280ddde1154685e6bf357ba20b8c0","University of Central Florida, Orlando, FL, United States; RSK Assessments, Inc., Orlando, FL, United States","Mouloua, M., University of Central Florida, Orlando, FL, United States; Smither, J., University of Central Florida, Orlando, FL, United States; Kennedy, R.C., University of Central Florida, Orlando, FL, United States; Kennedy, R.S., RSK Assessments, Inc., Orlando, FL, United States; Compton, D.E., RSK Assessments, Inc., Orlando, FL, United States; Drexler, J.M., RSK Assessments, Inc., Orlando, FL, United States","The present study was conducted to empirically examine the effect of adaptation training and transfer of training on simulation sickness by inducing graded motion sickness through the systematic distortion of the relevant characteristics of three VR devices (VE, OKN, and Real-World Entertainment Ride). It was hypothesized that for people who are highly susceptible to motion-induced sickness, the perceptual adaptation training method would transfer from a controlled laboratory environment to a real-world situation. Ten participants from a previous laboratory study were tested on a real-world virtual reality entertainment device. The results showed that subjects who had experienced adaptation training on the optokinetic OKN device had lower dizziness scores on the real world game. However, subjects who had experienced adaptation training on the VE device (HMD) did not have lower dizziness scores. This pattern of results suggests that crossover training from controlled laboratory environments to real-world environments is likely to be one-directional and platform specific. Our present findings imply a technique for mitigating sickness through pre-adaptation training in sensory re-arrangement that is feasible and has major practical implications in business, industry, the military and the private sector, where motion sickness symptoms limit previous exposure.",,"Behavioral research; Computer simulation; Personnel training; Adaptation training; Graded motion sickness; Human engineering",Conference Paper,"Final","",Scopus,2-s2.0-44349192006
"Heying M.J., Oliver J.H., Sundararajan S., Shrotrlya P., Zou Q.","12545325000;7401628559;8640898600;12545620500;7103094245;","Virtual training simulator for atomic force microscopy",2005,"Proceedings of the ASME International Design Engineering Technical Conferences and Computers and Information in Engineering Conference - DETC2005","3 A",,,"567","574",,,"10.1115/detc2005-85477","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33144457110&doi=10.1115%2fdetc2005-85477&partnerID=40&md5=b88e44a4124e2463b14186efaa0d8999","Virtual Reality Application Center, Department of Mechanical Engineering, Iowa State University, Amesa, IA 50011-2274, United States; Department of Mechanical Engineering, Iowa State University, Ames, IA 50011-2274, United States","Heying, M.J., Virtual Reality Application Center, Department of Mechanical Engineering, Iowa State University, Amesa, IA 50011-2274, United States; Oliver, J.H., Virtual Reality Application Center, Department of Mechanical Engineering, Iowa State University, Amesa, IA 50011-2274, United States; Sundararajan, S., Department of Mechanical Engineering, Iowa State University, Ames, IA 50011-2274, United States; Shrotrlya, P., Department of Mechanical Engineering, Iowa State University, Ames, IA 50011-2274, United States; Zou, Q., Department of Mechanical Engineering, Iowa State University, Ames, IA 50011-2274, United States","Training novice users how to operate an Atomic Force Microscope (AFM) is expensive due to the cost of equipment and the time required to train users in a hands-on learning environment. Training large groups of users simultaneously presents a problem because usually only one AFM is available for use. To alleviate this problem, a virtual training simulator for AFM training has been developed. The training simulator is a Windows-based software program designed to allow users to simulate basic AFM operation on a PC. Instructors can use this tool to demonstrate the exact same instruction that a user would receive in an AFM lab within the confines of a classroom or computer lab. The graphical user interface (GUI) of the simulator replicates the interface of one of the most popular commercial AFM models to aid learning transfer from the simulator to the actual AFM. The goal of this paper is to provide a brief overview of the work that has been completed towards creating this virtual training simulator. The virtual AFM simulator modeling, design, and implementation are described. Copyright © 2005 by ASME.","AFM; Atomic force microscope; Scanning probe microscope; Simulation; Simulator; SPM; Trainer; Training","Affinity chromatography; Atomic force microscopy; Computer programming; Cost accounting; Graphical user interfaces; Personnel training; Virtual reality; Scanning probe microscope; SPM; Trainer; Windows based software program; Simulators",Conference Paper,"Final","",Scopus,2-s2.0-33144457110
"Tatekura Y., Urata S., Saruwatari H., Shikano K.","6507187643;8892276800;7003918936;35499945000;","On-line relaxation algorithm applicable to acoustic fluctuation for inverse filter in multichannel sound reproduction system",2005,"IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences","E88-A","7",,"1747","1755",,9,"10.1093/ietfec/e88-a.7.1747","https://www.scopus.com/inward/record.uri?eid=2-s2.0-26044479457&doi=10.1093%2fietfec%2fe88-a.7.1747&partnerID=40&md5=61f7f72d25a9b41cfad2557baefaaf0e","Faculty of Engineering, Shizuoka University, Hamamatsu-shi 432-8561, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma-shi, 630-0101, Japan; Shizuoka University, Japan; Acoustical Society of Japan, Japan; VR Society of Japan, Japan; Nara Institute of Science and Technology (NAIST), Japan; Information Processing Society of Japan, Japan; Japan VR Society, Japan; Institute of Electrical and Electronics, Engineers (IEEE), Japan; International Speech Communication Society","Tatekura, Y., Faculty of Engineering, Shizuoka University, Hamamatsu-shi 432-8561, Japan, Shizuoka University, Japan, Acoustical Society of Japan, Japan, VR Society of Japan, Japan; Urata, S., Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma-shi, 630-0101, Japan, Acoustical Society of Japan, Japan; Saruwatari, H., Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma-shi, 630-0101, Japan, Acoustical Society of Japan, Japan, VR Society of Japan, Japan, Nara Institute of Science and Technology (NAIST), Japan, Institute of Electrical and Electronics, Engineers (IEEE), Japan; Shikano, K., Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma-shi, 630-0101, Japan, Acoustical Society of Japan, Japan, Nara Institute of Science and Technology (NAIST), Japan, Information Processing Society of Japan, Japan, Japan VR Society, Japan, Institute of Electrical and Electronics, Engineers (IEEE), Japan, International Speech Communication Society","In this paper, we propose a new on-line adaptive relaxation algorithm for an inverse filter in a multichannel sound reproduction system. The fluctuation of room transfer functions degrades reproduced sound in conventional sound reproduction systems in which the coefficients of the inverse filter are fixed. In order to resolve this problem, an iterative relaxation algorithm for an inverse filter performed by truncated singular value decomposition (adaptive TSVD) has been proposed. However, it is difficult to apply this method within the time duration of the sound of speech or music in the original signals. Therefore, we extend adaptive TSVD to an on-line-type algorithm based on the observed signal at only one control point, normalizing the observed signal with the original sound. The result of the simulation using real environmental data reveals that the proposed method can always carry out the relaxation process against acoustic fluctuation, for any time duration. Also, subjective evaluation in the real acoustic environment indicates that the sound quality improves without degrading the localization. Copyright © 2005 The Institute of Electronics, Information and Communication Engineers.","Inverse filter; On-line adaptation; Relaxation of inverse filter; Room transfer function; Sound reproduction","Algorithms; Computer music; Computer simulation; Signal processing; Transfer functions; Wave filters; Inverse filters; On-line adaptation; Relaxation of inverse filters; Room transfer functions; Sound reproduction",Article,"Final","",Scopus,2-s2.0-26044479457
"Streit A., Christie R., Boud A.","8948758200;57215471529;6505890731;","Understanding next-generation VR: Classifying commodity clusters for immersive virtual reality",2004,"Proceedings GRAPHITE 2004 - 2nd International Conference on Computer Graphics and Interactive Techniques in Australasia and Southeast Asia",,,,"222","229",,5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-12344255082&partnerID=40&md5=36507f2a5412384f9e9974519a3be5f0","QUT, Australia; VR Solutions, Australia","Streit, A., QUT, Australia; Christie, R., QUT, Australia; Boud, A., VR Solutions, Australia","Commodity clusters offer the ability to deliver higher performance computer graphics at lower prices than traditional graphics supercomputers. Immersive virtual reality systems demand notoriously high computational requirements to deliver adequate real-time graphics, leading to the emergence of commodity clusters for immersive virtual reality. Such clusters deliver the graphics power needed by leveraging the combined power of several computers to meet the demands of real-time interactive immersive computer graphics. However, the field of commodity cluster-based virtual reality is still in early stages of development and the field is currently adhoc in nature and lacks order. There is no accepted means for comparing approaches and implementers are left with instinctual or trial-and-error means for selecting an approach. This paper provides a classification system that facilitates understanding not only of the nature of different clustering systems but also the interrelations between them. The system is built from a new model for generalized computer graphics applications, which is based on the flow of data through a sequence of operations over the entire context of the application. Prior models and classification systems have been too focused in context and application whereas the system described here provides a unified means for comparison of works within the field.","Computer Clusters; Real-time Graphics; Virtual and Augmented reality","Classification systems; Computer clusters; Real-time graphics; Scalable capacity; Classification (of information); Computer graphics; Computer hardware; Data acquisition; Interactive computer systems; Mathematical models; Supercomputers; User interfaces; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-12344255082
"Adamovich S.V., Merians A.S., Boian R., Tremaine M., Burdea G.S., Recce M., Poizner H.","6603916707;6603018031;6603659582;6603562993;35612697900;6603906003;7005963417;","A virtual reality based exercise system for hand rehabilitation post-stroke: Transfer to function",2004,"Annual International Conference of the IEEE Engineering in Medicine and Biology - Proceedings","26 VII",,,"4936","4939",,61,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-11144291509&partnerID=40&md5=cf82af860c1c7d7732e82784d82a9477","Dept. of Biomedical Engineering, New Jersey Institute of Technology, Newark, NJ, United States; College of Computer Science, New Jersey Institute of Technology, Newark, NJ, United States; Dept. of Developmental Science, Univ. Med. and Dent. of New Jersey, Newark, NJ, United States; Ctr. for Molec. and Behav. Neurosci., Rutgers University, Newark, NJ, United States; School of Engineering, Ctr. for Adv. Information Processing, Rutgers University, Piscataway, NJ, United States","Adamovich, S.V., Dept. of Biomedical Engineering, New Jersey Institute of Technology, Newark, NJ, United States, Dept. of Developmental Science, Univ. Med. and Dent. of New Jersey, Newark, NJ, United States, Ctr. for Molec. and Behav. Neurosci., Rutgers University, Newark, NJ, United States; Merians, A.S., Dept. of Developmental Science, Univ. Med. and Dent. of New Jersey, Newark, NJ, United States; Boian, R., School of Engineering, Ctr. for Adv. Information Processing, Rutgers University, Piscataway, NJ, United States; Tremaine, M., College of Computer Science, New Jersey Institute of Technology, Newark, NJ, United States; Burdea, G.S., School of Engineering, Ctr. for Adv. Information Processing, Rutgers University, Piscataway, NJ, United States; Recce, M., College of Computer Science, New Jersey Institute of Technology, Newark, NJ, United States; Poizner, H., Ctr. for Molec. and Behav. Neurosci., Rutgers University, Newark, NJ, United States","We present preliminary results from a virtual reality (VR)-based system for hand rehabilitation that uses a CyberGlove and a Rutgers Master II-ND haptic glove. This system trains finger range of motion, finger flexion speed, independence of finger motion and finger strength. Eight chronic post-stroke subjects participated. In keeping with variability in both the lesion site and in initial upper extremity function, each subject showed improvement on a unique combination of movement parameters in VR training. These improvements transferred to gains on clinical tests, as well as to significant reductions in task completion times for the prehension of real objects. These results are indicative of the potential feasibility of this exercise system for rehabilitation in patients with hand dysfunction resulting from neurological impairment.","CyberGlove; Grasping; Hand function; Rutgers Master II-ND; Stroke; Virtual reality (VR)","CyberGlove; Grasping; Hand function; Rutgers Master II-ND; Stroke; Data reduction; Haptic interfaces; Information retrieval; Joints (anatomy); Object recognition; Virtual reality; Patient rehabilitation",Conference Paper,"Final","",Scopus,2-s2.0-11144291509
"Lindeman R.W., Page R., Yanagida Y., Sibert J.L.","7006360047;8590672100;7007057059;7004270269;","Towards full-body haptic feedback: The design and deployment of a spatialized vibrotactile feedback system",2004,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,,,"146","149",,67,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-21644452820&partnerID=40&md5=cdbf05359f1cf9e22437ff7cf68ec1c2","Department of Computer Science, George Washington University, 801 22nd St., NW, Washington, DC 20052, United States; Code 5511, Naval Research Laboratory, 4555 Overlook Ave., SW, Washington, DC 20375, United States; ATR International, MIS Labs, IRC Labs, Keihanna Sci. City, Kyoto 619-0288, Japan","Lindeman, R.W., Department of Computer Science, George Washington University, 801 22nd St., NW, Washington, DC 20052, United States, ATR International, MIS Labs, IRC Labs, Keihanna Sci. City, Kyoto 619-0288, Japan; Page, R., Code 5511, Naval Research Laboratory, 4555 Overlook Ave., SW, Washington, DC 20375, United States; Yanagida, Y., ATR International, MIS Labs, IRC Labs, Keihanna Sci. City, Kyoto 619-0288, Japan; Sibert, J.L., Department of Computer Science, George Washington University, 801 22nd St., NW, Washington, DC 20052, United States","This paper presents work we have done on the design and implementation of an untethered system to deliver haptic cues for use in immersive virtual environments through a body-worn garment. Our system can control a large number of body-worn vibration units, each with individually controllable vibration intensity. Several design iterations have helped us to refine the system and improve such aspects as robustness, ease of donning and doffing, weight, power consumption, cable management, and support for many different types of feedback units, such as pager motors, solenoids, and muffin fans. In addition, experience integrating the system into an advanced virtual reality system has helped define some of the design constraints for creating wearable solutions, and to further refine our implementation. Copyright 2004 ACM.","CQB; Full-body; Haptic feedback; Virtual reality","Ethers; Haptic interfaces; Product design; Technology transfer; Vibrations (mechanical); Virtual reality; CQB; Full-body; Haptic feedback; Vibrotactile feedback system; Feedback control",Conference Paper,"Final","",Scopus,2-s2.0-21644452820
"Mania K.","6602471750;","Simulating perception with interactive virtual environments",2004,"Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics","3",,,"2770","2776",,1,"10.1109/ICSMC.2004.1400752","https://www.scopus.com/inward/record.uri?eid=2-s2.0-15744384180&doi=10.1109%2fICSMC.2004.1400752&partnerID=40&md5=36dc03e7212642f9136db0fd49217f5f","Department of Informatics, University of Sussex, Falmer, Brighton BN1 9QT, United Kingdom","Mania, K., Department of Informatics, University of Sussex, Falmer, Brighton BN1 9QT, United Kingdom","Computer graphics algorithms have for long dealt with simulation of physics: simulation of the geometry of a real-world space, simulation of the light propagation in a real environment and simulation of motor actions with appropriate tracking. Perception principles have subsequently been incorporated into rendering algorithms in order to save rendering computation and produce photorealistic images from a human rather than a machine point of view. With Virtual Environment (VE) simulator technologies simulating real-world task situations mainly for transfer of training, the research community is challenged to produce a complex system. Furthermore, accurate simulation of physics is often not required in order to 'induce' reality. Much less detail is adequate. This paper is going to review research literature exploring behavioral fidelity and reality benchmarking in interactive VEs focusing on results from two studies aiming to simulate perceptual processes. Study 1 investigates spatial awareness based on merging episodic information with spatial preconceptions and Study 2 looks at subjective impressions of illumination. © 2004 IEEE.","Computer graphics imulations; Illumination; Perceptually-based fidelity metrics","Computer graphics imulations; Functional realism; Human visual systems (HVS); Perceptually-based fidelity metrics; Benchmarking; Computer simulation; Illuminating engineering; Large scale systems; Lighting; Psychology computing; Virtual reality; Visibility; Vision; Interactive computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-15744384180
"Kim H.K., Rattner D.W., Srinivasan M.A.","57206210546;7005252901;7203044605;","Virtual-reality-based laparoscopic surgical training: The role of simulation fidelity in haptic feedback",2004,"Computer Aided Surgery","9","5",,"227","234",,35,"10.1080/10929080500066997","https://www.scopus.com/inward/record.uri?eid=2-s2.0-23644444625&doi=10.1080%2f10929080500066997&partnerID=40&md5=7024d1ef906b09fc0251fecd322e632f","Department of Mechanical Engineering, Massachusetts Institute of Technology, Massachusetts General Hospital, Boston, MA, United States; Division of Gastrointestinal and General Surgery, Massachusetts General Hospital, Boston, MA, United States; Touch Lab., Massachusetts Institute of Technology, Department of Mechanical Engineering, 50 Vassar St., Boston, MA 02139, United States","Kim, H.K., Department of Mechanical Engineering, Massachusetts Institute of Technology, Massachusetts General Hospital, Boston, MA, United States, Touch Lab., Massachusetts Institute of Technology, Department of Mechanical Engineering, 50 Vassar St., Boston, MA 02139, United States; Rattner, D.W., Division of Gastrointestinal and General Surgery, Massachusetts General Hospital, Boston, MA, United States; Srinivasan, M.A., Department of Mechanical Engineering, Massachusetts Institute of Technology, Massachusetts General Hospital, Boston, MA, United States","Although there have been significant advances in the development of virtual-reality-based surgical simulations, there remain fundamental questions concerning the fidelity required for effective surgical training. A dual-station experimental platform was built for the purpose of investigating these fidelity requirements. Analogous laparoscopic surgical tasks were implemented on a virtual station and a real station, with the virtual station modeling the real environment with various degrees of fidelity. After measuring the subjects' initial performance on the real station, different groups of subjects were trained on the virtual station under a variety of conditions and finally tested on the real station. Experiments involved bimanual pushing and cutting tasks on a nonlinear elastic object. The results showed that force feedback results in significantly improved training transfer as compared to training without force feedback. The training effectiveness of a linear approximation model was approximately the same as that of a more accurate nonlinear model. ©2004 Taylor & Francis.","Force feedback; Haptic fidelity; Laparoscopy; Surgical simulation; Virtual reality","conference paper; human; human experiment; laparoscopy; linear system; minimally invasive surgery; nonlinear system; normal human; priority journal; simulation; surgical training; virtual reality; Analysis of Variance; Computer Simulation; Feedback; Humans; Laparoscopy; Linear Models; Surgical Procedures, Minimally Invasive; User-Computer Interface",Conference Paper,"Final","",Scopus,2-s2.0-23644444625
"Neely III H.E., Belvin R.S., Fox J.R., Daily M.J.","6701371933;6506208977;8873510200;7004965218;","Multimodal interaction techniques for situational awareness and command of robotic combat entities",2004,"IEEE Aerospace Conference Proceedings","5",,,"3297","3305",,3,"10.1109/AERO.2004.1368136","https://www.scopus.com/inward/record.uri?eid=2-s2.0-11244279823&doi=10.1109%2fAERO.2004.1368136&partnerID=40&md5=08d3ebf4aee9d9d17e540cac23773d63","HRL Laboratories, LLC, 3011 Malibu Canyon Road, Malibu, CA 90265, United States","Neely III, H.E., HRL Laboratories, LLC, 3011 Malibu Canyon Road, Malibu, CA 90265, United States; Belvin, R.S., HRL Laboratories, LLC, 3011 Malibu Canyon Road, Malibu, CA 90265, United States; Fox, J.R., HRL Laboratories, LLC, 3011 Malibu Canyon Road, Malibu, CA 90265, United States; Daily, M.J., HRL Laboratories, LLC, 3011 Malibu Canyon Road, Malibu, CA 90265, United States","In the next generation of Army combat vehicles, the Future Combat System (PCS), lightly-armored robotic vehicles will be commanded by human commanders operating from within moving command vehicles, and well back from the forward edge of the battle area. Two key questions to be answered for the successful realization of PCS are how can the commander maintain situational awareness and what methods will best allow the commander to interact with these robotic forces to achieve the mission goals. In our research, our approach is to immerse the commander in a virtual battlespace, with capability to directly interact with visual representations of the robotic entities. We developed a multimodal (visual, speech, and gesture) interaction method and specific techniques that allow the commander to navigate the virtual battlespace and command robotic entities while seated in a vehicle and without use of a keyboard.",,"Beyond line-of-sight (BLOS); Future combat systems (FCS); Robot control; Robotic vehicles; Bandwidth; Computer keyboards; Constraint theory; Cybernetics; Data transfer; Helmet mounted displays; Human computer interaction; Mice (computer peripherals); Navigation; Reliability; Robotics; Virtual reality; Wireless telecommunication systems; Aerospace vehicles",Conference Paper,"Final","",Scopus,2-s2.0-11244279823
"Raghupathi L., Grisoni L., Faure F., Marchai D., Cani M.-P., Chaillou C.","26644248700;11441057800;7006416778;11440214500;12759759600;56585793300;","An intestinal surgery simulator: Real-time collision processing and visualization",2004,"IEEE Transactions on Visualization and Computer Graphics","10","6",,"708","718",,43,"10.1109/TVCG.2004.36","https://www.scopus.com/inward/record.uri?eid=2-s2.0-16544387210&doi=10.1109%2fTVCG.2004.36&partnerID=40&md5=c991590fa82d672990945485310b7e0e","GRAVIR/IMAG Lab., 655 ave. de l'Europe, 38334 Montbonnet, France; LIFL Lab., University of Lille 1, 59655 Villeneuve d'Ascq, France; GRAVIR/IMAG Laboratory, France; Tau Beta Pi, United States; Eta Kappa Nu, United States; Polytech'Lille Engineering School, University of Lille 1, Grenoble, France; INRIA ALCOVE Project, United States; University of Joseph Fourier, Grenoble, France; Department of Computer Science, Institut National Polytechnique de Grenoble, France","Raghupathi, L., GRAVIR/IMAG Lab., 655 ave. de l'Europe, 38334 Montbonnet, France, GRAVIR/IMAG Laboratory, France, Tau Beta Pi, United States, Eta Kappa Nu, United States; Grisoni, L., LIFL Lab., University of Lille 1, 59655 Villeneuve d'Ascq, France, Polytech'Lille Engineering School, University of Lille 1, Grenoble, France, INRIA ALCOVE Project, United States; Faure, F., GRAVIR/IMAG Lab., 655 ave. de l'Europe, 38334 Montbonnet, France, University of Joseph Fourier, Grenoble, France; Marchai, D., LIFL Lab., University of Lille 1, 59655 Villeneuve d'Ascq, France, INRIA ALCOVE Project, United States; Cani, M.-P., GRAVIR/IMAG Lab., 655 ave. de l'Europe, 38334 Montbonnet, France, Department of Computer Science, Institut National Polytechnique de Grenoble, France; Chaillou, C., LIFL Lab., University of Lille 1, 59655 Villeneuve d'Ascq, France, Polytech'Lille Engineering School, University of Lille 1, Grenoble, France, INRIA ALCOVE Project, United States","This research work is aimed toward the development of a VR-based trainer for colon cancer removal. It enables the surgeons to interactively view and manipulate the concerned virtual organs as during a real surgery. First, we present a method for animating the small intestine and the mesentery (the tissue that connects it to the main vessels) in real-time, thus enabling user interaction through virtual surgical tools during the simulation. We present a stochastic approach for fast collision detection in highly deformable, self-colliding objects. A simple and efficient response to collisions is also introduced in order to reduce the overall animation complexity. Second, we describe a new method based on generalized cylinders for fast rendering of the intestine. An efficient curvature detection method, along with an adaptive sampling algorithm, is presented. This approach, while providing improved tessellation without the classical self-intersection problem, also allows for high-performance rendering thanks to the new 3D skinning feature available in recent GPUs. The rendering algorithm is also designed to ensure a guaranteed frame rate. Finally, we present the quantitative results of the simulations and describe the qualitative feedback obtained from the surgeons. © 2004 IEEE.","Animation; Curve and surface representation; Physically-based modeling; Virtual reality","Curve and surface representation; Physically-based algorithms; Algorithms; Animation; Color image processing; Problem solving; Random processes; User interfaces; Virtual reality; Visualization; Real time systems; abdominal surgery; algorithm; article; audiovisual equipment; biomedical engineering; colon tumor; computer graphics; computer interface; computer simulation; computer system; histology; human; methodology; small intestine; statistics; teaching; Algorithms; Biomedical Engineering; Colonic Neoplasms; Computer Graphics; Computer Simulation; Computer Systems; Computer-Assisted Instruction; Digestive System Surgical Procedures; Humans; Intestine, Small; Models, Anatomic; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-16544387210
"Doulatov S., Hodes A., Dal L., Mandhana N., Liu M., Deora R., Simons R.W., Zimmerly S., Miller J.F.","57221970285;7801320740;6506081579;6506883674;7406300697;6603223306;57210720543;6701660778;35237764000;","Tropism switching in Bordetella bacteriophage defines a family of diversity-generating retroelements",2004,"Nature","431","7007",,"476","481",,121,"10.1038/nature02833","https://www.scopus.com/inward/record.uri?eid=2-s2.0-4644280174&doi=10.1038%2fnature02833&partnerID=40&md5=dad3d29127086c257fdd22913727c502","Dept. Microbiol., Immunol. Molec. G., David Geffen Sch. of Med. at UCLA, University of California, Los Angeles, CA 90095, United States; Molecular Biology Institute, University of California, Los Angeles, CA 90095, United States; Department of Biological Sciences, University of Calgary, Calgary, Alta. T2N 1N4, Canada","Doulatov, S., Dept. Microbiol., Immunol. Molec. G., David Geffen Sch. of Med. at UCLA, University of California, Los Angeles, CA 90095, United States; Hodes, A., Dept. Microbiol., Immunol. Molec. G., David Geffen Sch. of Med. at UCLA, University of California, Los Angeles, CA 90095, United States; Dal, L., Department of Biological Sciences, University of Calgary, Calgary, Alta. T2N 1N4, Canada; Mandhana, N., Dept. Microbiol., Immunol. Molec. G., David Geffen Sch. of Med. at UCLA, University of California, Los Angeles, CA 90095, United States; Liu, M., Dept. Microbiol., Immunol. Molec. G., David Geffen Sch. of Med. at UCLA, University of California, Los Angeles, CA 90095, United States; Deora, R., Dept. Microbiol., Immunol. Molec. G., David Geffen Sch. of Med. at UCLA, University of California, Los Angeles, CA 90095, United States; Simons, R.W., Dept. Microbiol., Immunol. Molec. G., David Geffen Sch. of Med. at UCLA, University of California, Los Angeles, CA 90095, United States, Molecular Biology Institute, University of California, Los Angeles, CA 90095, United States; Zimmerly, S., Department of Biological Sciences, University of Calgary, Calgary, Alta. T2N 1N4, Canada; Miller, J.F., Dept. Microbiol., Immunol. Molec. G., David Geffen Sch. of Med. at UCLA, University of California, Los Angeles, CA 90095, United States, Molecular Biology Institute, University of California, Los Angeles, CA 90095, United States","Bordetella bacteriophages generate diversity in a gene that specifies host tropism1. This microevolutionary adaptation is produced by a genetic element that combines the basic retroelement life cycle of transcription, reverse transcription and integration with site-directed, adenine-specific mutagenesis. Central to this process is a reverse transcriptase-mediated exchange between two repeats; one serving as a donor template (TR) and the other as a recipient of variable sequence information (VR)1. Here we describe the genetic basis for diversity generation. The directionality of information transfer is determined by a 21-base-pair sequence present at the 3′ end of VR. On the basis of patterns of marker transfer in response to variant selective pressures, we propose that a TR reverse transcript is mutagenized, integrated into VR as a single non-coding strand, and then partially converted to the parental VR sequence. This allows the diversity-generating system to minimize variability to the subset of bases under selection. Using the Bordetella phage cassette as a signature, we have identified numerous related elements in diverse bacteria. These elements constitute a new family of retroelements with the potential to confer selective advantages to their host genomes.",,"Biodiversity; Data transfer; Genes; Life cycle; Mutagenesis; Diversity generation; Donor template; Genomes; Bacteriophages; genetics; amino acid substitution; article; bacteriophage; Bordetella bronchiseptica; controlled study; gene cassette; gene switching; genetic variability; in vitro study; nonhuman; nucleotide sequence; polymerase chain reaction; priority journal; retroposon; virus DNA cell DNA interaction; adaptation; bacteriophage; biology; Bordetella; classification; enzymology; evolution; genetic polymorphism; genetic selection; genetic transcription; genetic variability; genetics; host parasite interaction; metabolism; mutagenesis; phylogeny; physiology; species difference; virology; virus gene; virus genome; Bordetella; Bordetella bronchiseptica; insertion sequences; Negibacteria; Prokaryota; transposons; unidentified bacteriophage; RNA directed DNA polymerase; Adaptation, Physiological; Bacteriophages; Base Sequence; Bordetella; Computational Biology; Evolution; Genes, Viral; Genome, Viral; Host-Parasite Relations; Mutagenesis; Phylogeny; Polymorphism, Genetic; Retroelements; RNA-Directed DNA Polymerase; Selection (Genetics); Species Specificity; Transcription, Genetic; Variation (Genetics)",Article,"Final","",Scopus,2-s2.0-4644280174
"Parush A., Berman D.","8603061300;7201609508;","Navigation and orientation in 3D user interfaces: The impact of navigation aids and landmarks",2004,"International Journal of Human Computer Studies","61","3",,"375","395",,53,"10.1016/j.ijhcs.2003.12.018","https://www.scopus.com/inward/record.uri?eid=2-s2.0-3242699662&doi=10.1016%2fj.ijhcs.2003.12.018&partnerID=40&md5=fc23e5f8dd042aff955da5961614eb88","Department of Psychology, Carleton University, B552 Loeb Building, 1125 Colonel By Drive, Ottawa, Ont. K1S 5B6, Canada; Indust. Engineering and Management, Technion-Israel Inst. of Technology, Haifa 32000, Israel","Parush, A., Department of Psychology, Carleton University, B552 Loeb Building, 1125 Colonel By Drive, Ottawa, Ont. K1S 5B6, Canada; Berman, D., Indust. Engineering and Management, Technion-Israel Inst. of Technology, Haifa 32000, Israel","The way users acquire spatial cognition in three dimensional user interfaces depicting an on-screen virtual environment was examined. The study consisted of learning phase and a test of learning transfer phase. The findings were discussed in terms of the impact of navigations aids and landmarks on the acquisition of route and survey knowledge in spatial cognition. Some gender differences were discussed in terms of different strategies in spatial cognition acquisition.",,"Data reduction; Human computer interaction; Personal computers; Research; Strategic planning; Virtual reality; Websites; Learning transfer; Spatial cognition; Virtual environments; User interfaces",Article,"Final","",Scopus,2-s2.0-3242699662
"Bao P., Gourlay D.","7005902332;24824547800;","Remote walkthrough over mobile networks using 3-D image warping and streaming",2004,"IEE Proceedings: Vision, Image and Signal Processing","151","4",,"329","336",,17,"10.1049/ip-vis:20040749","https://www.scopus.com/inward/record.uri?eid=2-s2.0-4544382184&doi=10.1049%2fip-vis%3a20040749&partnerID=40&md5=a634b67431bea19f6200935dee8f1e74","School of Computer Engineering, Nanyang Technological University, Nanyang Avenue, Singapore 639798, Singapore; Dept. of Information Engineering, Chinese University of Hong Kong, Shatin, New Territories, Hong Kong","Bao, P., School of Computer Engineering, Nanyang Technological University, Nanyang Avenue, Singapore 639798, Singapore; Gourlay, D., Dept. of Information Engineering, Chinese University of Hong Kong, Shatin, New Territories, Hong Kong","A mobile walkthrough environment based on 3-D superview warping and view compensation streaming is presented. In this environment, 3-D views are rendered on the remote clients using 3-D oversized reference views and compensated on a view-on-demand basis by the graphically rendered views from the server. The view compensations (hole residuals and the depth map) are coded using a layered joint source-channel coding with unequal error corrections to protect the significant packets on noisy and erasure mobile channels. The new compensated view will then serve as a reference view for the subsequent rendering on the clients. This environment enables numerous mobile virtual applications, such as remote m-gaming, remote m-design, m-learning, m-CAD/CAM, etc., scalable to different network capabilities. © IEE, 2004.",,"Communication channels (information theory); Computer networks; Computer simulation; Error correction; Finite automata; Servers; Channel coding; Genealogy graph representation; Generalized finite automata; Image streaming; Image warping; Mobile networks; Image coding",Article,"Final","",Scopus,2-s2.0-4544382184
"Sugita K., Takahashi K., Naemura T., Harashima H.","55017112200;55513826200;7003840523;7101805792;","Focus measurement on programmable graphics hardware for all in-focus rendering from light fields",2004,"Proceedings - Virtual Reality Annual International Symposium",,,,"255","256",,5,"10.1109/VR.2004.1310096","https://www.scopus.com/inward/record.uri?eid=2-s2.0-3042544614&doi=10.1109%2fVR.2004.1310096&partnerID=40&md5=231936780ee78d335f9173a2935437cf","Sch. of Info. Science and Technology, University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656, Japan","Sugita, K., Sch. of Info. Science and Technology, University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656, Japan; Takahashi, K., Sch. of Info. Science and Technology, University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656, Japan; Naemura, T., Sch. of Info. Science and Technology, University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656, Japan; Harashima, H., Sch. of Info. Science and Technology, University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656, Japan","This paper deals with a method for interactive rendering of photorealistic images, which is a fundamental technology in the field of virtual reality. Since the latest graphics processing units (GPUs) are programmable, they are expected to be useful for various applications including numerical computation and image processing. This paper proposes a method for focus measurement on light field rendering using a GPU as a fast processing unit for image processing and image-based rendering. It is confirmed that the proposed method enables interactive all in-focus rendering from light fields. This is because the latest DirectX 9 generation GPUs are much faster than CPUs in solving optimization problems, and a GPU implementation can eliminate the latency for data transmission between video memory and system memory. Experimental results show that the GPU implementation outperforms its CPU implementation.",,"Graphics processing units (GPU); Light field rendering (LFR); Multi-camera systems; Video memory; Algorithms; Computation theory; Computer graphics; Data communication systems; Data transfer; Image processing; Optimization; Problem solving; Program compilers; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-3042544614
"Kuang A.B., Payandeh S., Zheng B., Henigman F., MacKenzie C.L.","7005836026;7006688369;35294347300;6507506609;7202852924;","Assembling virtual fixtures for guidance in training environments",2004,"Proceedings - 12th International Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems, HAPTICS",,,,"367","374",,39,"10.1109/HAPTIC.2004.1287223","https://www.scopus.com/inward/record.uri?eid=2-s2.0-2942633661&doi=10.1109%2fHAPTIC.2004.1287223&partnerID=40&md5=4d216540bec483f7a3a4a79d12040c8f","Human Motor Systems Laboratory, School of Kinesiology, Simon Fraser University, Burnaby, BC V5A 1S6, Canada","Kuang, A.B., Human Motor Systems Laboratory, School of Kinesiology, Simon Fraser University, Burnaby, BC V5A 1S6, Canada; Payandeh, S., Human Motor Systems Laboratory, School of Kinesiology, Simon Fraser University, Burnaby, BC V5A 1S6, Canada; Zheng, B., Human Motor Systems Laboratory, School of Kinesiology, Simon Fraser University, Burnaby, BC V5A 1S6, Canada; Henigman, F., Human Motor Systems Laboratory, School of Kinesiology, Simon Fraser University, Burnaby, BC V5A 1S6, Canada; MacKenzie, C.L., Human Motor Systems Laboratory, School of Kinesiology, Simon Fraser University, Burnaby, BC V5A 1S6, Canada","We set up a library of virtual fixtures with both haptic and graphic properties and behaviors. For a given task, Virtual Fixture Assembly Language (VFAL) could be used to construct various virtual fixture series, with graphic and force guidance rules, making the low-level haptic and graphic rendering details transparent to the developers. An experiment evaluated the application of virtual fixtures as an aid for guiding a user in a path navigation task. The task was performed with or without force field guidance of virtual fixtures, and then transferred to the condition with no virtual fixtures. Results showed significant learning and transfer effects measured by performance time and path length. However, training using virtual fixtures with force guidance had comparable results to training with graphic only fixtures representing the path. Results are discussed in terms of motor learning theory, future work and applications for the design of better VR training environments.",,"Collaborative manipulation; Haptic contact point (HCP); Transfer effects; Virtual fixture assembly language (VFAL); Blood vessels; Computer programming; Constraint theory; Feedback; Graphic methods; Information analysis; Learning systems; Personnel training; Haptic interfaces",Conference Paper,"Final","",Scopus,2-s2.0-2942633661
"Oprea S.F., Zaidi N., Donabedian S.M., Balasubramaniam M., Hershberger E., Zervos M.J.","8305657600;57213995557;35478673600;7004078834;6602819640;35481634900;","Molecular and clinical epidemiology of vancomycin-resistant Enterococcus faecalis",2004,"Journal of Antimicrobial Chemotherapy","53","4",,"626","630",,31,"10.1093/jac/dkh138","https://www.scopus.com/inward/record.uri?eid=2-s2.0-10844278511&doi=10.1093%2fjac%2fdkh138&partnerID=40&md5=6c1b77ba41c8c567117fb085b8badda7","William Beaumont Hospital, 3811 W 13 Mile Road, Royal Oak, MI 48073, United States; Wayne State Univ. School of Medicine, Detroit, MI, United States","Oprea, S.F., William Beaumont Hospital, 3811 W 13 Mile Road, Royal Oak, MI 48073, United States; Zaidi, N., William Beaumont Hospital, 3811 W 13 Mile Road, Royal Oak, MI 48073, United States; Donabedian, S.M., William Beaumont Hospital, 3811 W 13 Mile Road, Royal Oak, MI 48073, United States; Balasubramaniam, M., William Beaumont Hospital, 3811 W 13 Mile Road, Royal Oak, MI 48073, United States; Hershberger, E., William Beaumont Hospital, 3811 W 13 Mile Road, Royal Oak, MI 48073, United States; Zervos, M.J., William Beaumont Hospital, 3811 W 13 Mile Road, Royal Oak, MI 48073, United States, Wayne State Univ. School of Medicine, Detroit, MI, United States","Objectives: With the recent emergence of vancomycin-resistant (VR) Staphylococcus aureus, subsequent to the suggested transfer of the vanA resistance gene from Enterococcus faecalis, we sought to determine risk factors for acquisition of VR E. faecalis and to evaluate the molecular epidemiology of this less-prevalent and less-studied species of VR enterococcus. Methods: We compared clinical isolates of VR E. faecalis from 71 patients, collected over 12 years in a large community teaching hospital, with isolates from 126 patients with vancomycin-susceptible E. faecalis. Results: Risk factors for VR E. faecalis acquisition by multivariate analysis were nursing home residence (P = 0.0005), haemodialysis (P = 0.009), decubitus ulcers (P = 0.03) and receipt of parenteral vancomycin (P=0.0002). Twenty-one percentof VR E. faecalis demonstrated vanA and 79% vanB resistance. The number of VanA isolates increased over time. Molecular analysis showed vanA or vanB in multiple PFGE groups. Conclusions: The results of this study suggest gene dissemination among some isolates and intra-hospital spread of other isolates. The risk factors identified clearly suggest that VR E. faecalis is a nosocomial pathogen and should be considered in infection control practices. Further surveillance of VR E. faecalis is warranted, due to the potential spread of vancomycin resistance among enterococci and staphylococci. © The British Society for Antimicrobial Chemotherapy 2004; all rights reserved.","E. faecalis; Pulse-field gel electrophoresis; Risk factors","aminoglycoside antibiotic agent; azathioprine; aztreonam; carbapenem derivative; cephalosporin derivative; clindamycin; cyclophosphamide; cyclosporin; methotrexate; metronidazole; penicillin G; prednisolone; quinoline derived antiinfective agent; tacrolimus; vancomycin; antibiotic resistance; antibiotic sensitivity; article; bacterial infection; bacterial strain; bacterium identification; bacterium isolate; confidence interval; controlled study; decubitus; Enterococcus faecalis; hemodialysis; human; infection control; multivariate analysis; nonhuman; nursing home; polymerase chain reaction; pulsed field gel electrophoresis; risk factor; statistical analysis; Confidence Intervals; Enterococcus faecalis; Gram-Positive Bacterial Infections; Humans; Multivariate Analysis; Odds Ratio; Retrospective Studies; Risk Factors; Vancomycin; Vancomycin Resistance",Article,"Final","",Scopus,2-s2.0-10844278511
"Laurell C.-G., Söderberg P., Nordh L., Skarman E., Nordqvist P.","7005063965;35599189300;6603608786;6507750094;6701617647;","Computer-simulated phacoemulsification",2004,"Ophthalmology","111","4",,"693","698",,45,"10.1016/j.ophtha.2003.06.023","https://www.scopus.com/inward/record.uri?eid=2-s2.0-1842528791&doi=10.1016%2fj.ophtha.2003.06.023&partnerID=40&md5=15eb0bd8def789c6653f943cd9e35aa8","St. Erik's Eye Hospital, Stockholm, Sweden; Melerit AB, Berzelius Science Park, Linköping, Sweden; St. Erik's Eye Hospital, SE-112 82 Stockholm, Sweden","Laurell, C.-G., St. Erik's Eye Hospital, Stockholm, Sweden, St. Erik's Eye Hospital, SE-112 82 Stockholm, Sweden; Söderberg, P., St. Erik's Eye Hospital, Stockholm, Sweden; Nordh, L., Melerit AB, Berzelius Science Park, Linköping, Sweden; Skarman, E., Melerit AB, Berzelius Science Park, Linköping, Sweden; Nordqvist, P., Melerit AB, Berzelius Science Park, Linköping, Sweden","Objective To develop a simulator for training in phacoemulsification to be used as a learning device for both beginners and experienced surgeons to shorten the learning curve. Design Experimental study. Methods The system consists of a personal computer, a 3-dimensional visual interface, a phacoemulsification handpiece, and a nucleus manipulator and foot pedals for control of the phacoemulsification procedure and microscope adjustments. The simulation is based on generalized simulation software that can be also used for the development of other medical simulations. Main outcome measures Qualitative statements given in a questionnaire. Medical students and ophthalmic surgeons with varying experience of phacoemulsification were tested. Results A simulator for training in phacoemulsification has been developed. The surgical procedures can be practiced any number of times, and there is no risk to patients. The efforts of the surgeon can be evaluated objectively. Conclusions Studies have shown that the number of complications for an ophthalmic surgeon learning phacoemulsification decreases exponentially, reaching close to the asymptote only after several hundred procedures. Simulator training might shorten the learning period, reduce expensive supervision by an experienced surgeon, and maintain and improve the skills of experienced surgeons. © 2004 by the American Academy of Ophthalmology.",,"article; computer interface; computer program; computer simulation; device; medical education; medical practice; medical student; ophthalmology; outcomes research; phacoemulsification; priority journal; qualitative analysis; questionnaire; risk assessment; surgeon; surgical technique; system analysis; training; Computer Simulation; Computer-Assisted Instruction; Education, Medical; Humans; Internship and Residency; Models, Anatomic; Phacoemulsification; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-1842528791
"Wang P., Kreutzer I.A., Bjärnemo R., Davies R.C.","55718488800;6507773751;6506617082;8154177000;","A Web-based cost-effective training tool with possible application to brain injury rehabilitation",2004,"Computer Methods and Programs in Biomedicine","74","3",,"235","243",,18,"10.1016/j.cmpb.2003.08.001","https://www.scopus.com/inward/record.uri?eid=2-s2.0-2342544737&doi=10.1016%2fj.cmpb.2003.08.001&partnerID=40&md5=36b498a0101cb019b364991172cb1ff3","Department of Design Sciences, Division of Machine Design, Lund University, Lund, Sweden; Department of Mechanical Engineering, Southwest Jiaotong University, Jiaotong, China; Department of Design Sciences, Div. Ergonom. and Aerosol Technol., Lund University, Sölvegatan 26, Lund SE 223 62, Sweden; Department of Computer Science, Univ. of Applied Sciences Konstanz, Konstanz, Germany","Wang, P., Department of Design Sciences, Division of Machine Design, Lund University, Lund, Sweden, Department of Mechanical Engineering, Southwest Jiaotong University, Jiaotong, China; Kreutzer, I.A., Department of Design Sciences, Div. Ergonom. and Aerosol Technol., Lund University, Sölvegatan 26, Lund SE 223 62, Sweden, Department of Computer Science, Univ. of Applied Sciences Konstanz, Konstanz, Germany; Bjärnemo, R., Department of Design Sciences, Division of Machine Design, Lund University, Lund, Sweden; Davies, R.C., Department of Design Sciences, Div. Ergonom. and Aerosol Technol., Lund University, Sölvegatan 26, Lund SE 223 62, Sweden","Virtual reality (VR) has provoked enormous interest in the medical community. In particular, VR offers therapists new approaches for improving rehabilitation effects. However, most of these VR assistant tools are not very portable, extensible or economical. Due to the vast amount of 3D data, they are not suitable for Internet transfer. Furthermore, in order to run these VR systems smoothly, special hardware devices are needed. As a result, existing VR assistant tools tend to be available in hospitals but not in patients' homes. To overcome these disadvantages, as a case study, this paper proposes a Web-based Virtual Ticket Machine, called WBVTM, using VRML [VRML Consortium, The Virtual Reality Modeling Language: International Standard ISO/IEC DIS 14772-1, 1997, available at http://www.vrml.org/Specifications/VRML97], Java and EAI (External Authoring Interface) [Silicon Graphics, Inc., The External Authoring Interface (EAI), available at http://cosmosoftware.com/developer/eai.html], to help people with acquired brain injury (ABI) to relearn basic living skills at home at a low cost. As these technologies are open standard and feature usability on the Internet, WBVTM achieves the goals of portability, easy accessibility and cost-effectiveness. © 2003 Elsevier Ireland Ltd. All rights reserved.","Acquired brain injury; Internet; Rehabilitation; Virtual reality; VRML","Biomedical equipment; Brain; Computer hardware; Computer software portability; Cost effectiveness; Internet; Virtual reality; Medical community; Rehabilitation effects; Therapists; Biomedical engineering; adult; brain injury; computer; computer aided design; cost effectiveness analysis; dynamic exercise; economic aspect; evaluation; female; home; hospital; human; human experiment; Internet; interpersonal communication; language; learning; male; normal human; performance; rehabilitation; review; skill; task performance; technology; training; virtual reality",Article,"Final","",Scopus,2-s2.0-2342544737
"Daqaq M.F., Nayfeh A.H.","6507760023;56045324100;","A virtual environment for ship-mounted cranes",2004,"International Journal of Modelling and Simulation","24","4",,"272","279",,7,"10.1080/02286203.2004.11442312","https://www.scopus.com/inward/record.uri?eid=2-s2.0-5144220406&doi=10.1080%2f02286203.2004.11442312&partnerID=40&md5=87f12642a8bd1997cbdfc2eee6051317","Department of Engineering Science, MC 0219, Virginia Polytech. Inst./State Univ., Blacksburg, VA 24061, United States","Daqaq, M.F., Department of Engineering Science, MC 0219, Virginia Polytech. Inst./State Univ., Blacksburg, VA 24061, United States; Nayfeh, A.H., Department of Engineering Science, MC 0219, Virginia Polytech. Inst./State Univ., Blacksburg, VA 24061, United States","The authors present a virtual simulation of ships and ship-mounted cranes. The simulation is carried out in a Cave Automated Virtual Environment (CAVE). This simulation serves as a training platform for ship-mounted crane operators and as a platform to study the dynamics of ships and ship-mounted cranes under dynamic sea environments. A model of the (Auxiliary Crane Ship) T-ACS 4-6 was built, converted into an OpenGL C++ API, and then ported into the CAVE using DiverseGL (DGL). A six-degrees-of-freedom motion base was used to simulate the actual motion of the ship. The equations of motion of the ship are solved using the Large Amplitude Motion Program (LAMP), and the equations of motion of the crane payload are numerically integrated; the interaction between the payload and the ship is taken into consideration. A nonlinear delayed-position feedback-control system is applied to the crane, and the resulting simulation is used to compare the controlled and uncontrolled pendulations of the cargo. Our Simulator shows a great deal of realism and was used to simulate different ship-motion and cargo transfer scenarios.","Crane operator; Motion platform; Ship motion; Virtual reality","Animation; Computer simulation; Electronic communities; Motion compensation; Robotics; Software prototyping; Visualization; Crane operator; Motion platform; Pendulations; Ship motion; Ship cranes",Article,"Final","",Scopus,2-s2.0-5144220406
"Zhou Z., Cheok A.D., Yang X., Qiu Y.","23986510500;7003447496;22236065700;36724983800;","An experimental study on the role of 3D sound in augmented reality environment",2004,"Interacting with Computers","16","6",,"1043","1068",,23,"10.1016/j.intcom.2004.06.016","https://www.scopus.com/inward/record.uri?eid=2-s2.0-9944230931&doi=10.1016%2fj.intcom.2004.06.016&partnerID=40&md5=c593a65389cf3e596874fc1cfe187c82","Department of Electrical Engineering, National University of Singapore, Singapore 119260, Singapore","Zhou, Z., Department of Electrical Engineering, National University of Singapore, Singapore 119260, Singapore; Cheok, A.D., Department of Electrical Engineering, National University of Singapore, Singapore 119260, Singapore; Yang, X., Department of Electrical Engineering, National University of Singapore, Singapore 119260, Singapore; Qiu, Y., Department of Electrical Engineering, National University of Singapore, Singapore 119260, Singapore","Investigation of augmented reality (AR) environments has become a popular research topic for engineers, computer and cognitive scientists. Although application oriented studies focused on audio AR environments have been published, little work has been done to vigorously study and evaluate the important research questions of the effectiveness of three-dimensional (3D) sound in the AR context, and to what extent the addition of 3D sound would contribute to the AR experience. Thus, we have developed two AR environments and performed vigorous experiments with human subjects to study the effects of 3D sound in the AR context. The study concerns two scenarios. In the first scenario, one participant must use vision only and vision with 3D sound to judge the relative depth of augmented virtual objects. In the second scenario, two participants must cooperate to perform a joint task in a game-based AR environment. Hence, the goals of this study are (1) to access the impact of 3D sound on depth perception in a single-camera AR environment, (2) to study the impact of 3D sound on task performance and the feeling of 'human presence and collaboration', (3) to better understand the role of 3D sound in human-computer and human-human interactions, (4) to investigate if gender can affect the impact of 3D sound in AR environments. The outcomes of this research can have a useful impact on the development of audio AR systems, which provide more immersive, realistic and entertaining experiences by introducing 3D sound. Our results suggest that 3D sound in AR environment significantly improves the accuracy of depth judgment and improves task performance. Our results also suggest that 3D sound contributes significantly to the feeling of human presence and collaboration and helps the subjects to 'identify spatial objects'. © 2004 Elsevier B.V. All rights reserved.","3D sound; Augmented reality; User study","Acoustic waves; Cameras; Cognitive systems; Feedback; Human computer interaction; Multiprocessing systems; Three dimensional; Three dimensional computer graphics; Transfer functions; Head related transfer functions (HRTF); Human-human interactions; Three-dimensional (3D) sound; User study; Virtual reality",Article,"Final","",Scopus,2-s2.0-9944230931
"Dmitriev K., Annen T., Krawczyk G., Myszkowski K., Seidel H.-P.","6601978085;12799489000;8608802400;55888212000;7202927645;","A CAVE system for interactive modeling of global illumination in car interior",2004,"Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST",,,,"137","145",,14,"10.1145/1077534.1077560","https://www.scopus.com/inward/record.uri?eid=2-s2.0-21644434577&doi=10.1145%2f1077534.1077560&partnerID=40&md5=fe31ce6a2e03a55d49920e66f21dd1b7","MPI Informatik, Saarbrücken, Germany","Dmitriev, K., MPI Informatik, Saarbrücken, Germany; Annen, T., MPI Informatik, Saarbrücken, Germany; Krawczyk, G., MPI Informatik, Saarbrücken, Germany; Myszkowski, K., MPI Informatik, Saarbrücken, Germany; Seidel, H.-P., MPI Informatik, Saarbrücken, Germany","Global illumination dramatically improves realistic appearance of rendered scenes, but usually it is neglected in VR systems due to its high costs. In this work we present an efficient global illumination solution specifically tailored for those CAVE applications, which require an immediate response for dynamic light changes and allow for free motion of the observer, but involve scenes with static geometry. As an application example we choose the car interior modeling under free driving conditions. We illuminate the car using dynamically changing High Dynamic Range (HDR) environment maps and use the Precomputed Radiance Transfer (PRT) method for the global illumination computation. We leverage the PRT method to handle scenes with non-trivial topology represented by complex meshes. Also, we propose a hybrid of PRT and final gathering approach for high-quality rendering of objects with complex Bi-directional Reflectance Distribution Function (BRDF). We use this method for predictive rendering of the navigation LCD panel based on its measured BRDF. Since the global illumination computation leads to HDR images we propose a tone mapping algorithm tailored specifically for the CAVE. We employ head tracking to identify the observed screen region and derive for it proper luminance adaptation conditions, which are then used for tone mapping on all walls in the CAVE. We distribute our global illumination and tone mapping computation on all CPUs and CPUs available in the CAVE, which enables us to achieve interactive performance even for the costly final gathering approach. Copyright 2004 ACM.","BRDF; CAVE; LCD panel; Virtual Reality","Costs; Imaging techniques; Lighting; Liquid crystal displays; Object recognition; Three dimensional computer graphics; Virtual reality; BRDF; CAVE; High dynamic range (HDR); LCD panel; Precomputed radiance transfer (PRT); Light weight vehicles",Conference Paper,"Final","",Scopus,2-s2.0-21644434577
"Ström P., Kjellin A., Hedman L., Wredmark T., Felländer-Tsai L.","7005305055;6603625212;7007166091;7003813097;6603715643;","Training in tasks with different visual-spatial components does not improve virtual arthroscopy performance",2004,"Surgical Endoscopy and Other Interventional Techniques","18","1",,"115","120",,34,"10.1007/s00464-003-9023-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-1642540013&doi=10.1007%2fs00464-003-9023-y&partnerID=40&md5=990b78871b09d5d89577ef1ec77b220a","Division of Orthopaedics, Karolinska Institute, Huddinge University Hospital, SE-141 86 Stockholm, Sweden; Division of Surgery, Karolinska Institutet, Huddinge University Hospital, SE-141 86 Stockholm, Sweden; Department of Psychology, Umeå University, SE-901 87 Umeå, Sweden","Ström, P., Division of Orthopaedics, Karolinska Institute, Huddinge University Hospital, SE-141 86 Stockholm, Sweden; Kjellin, A., Division of Surgery, Karolinska Institutet, Huddinge University Hospital, SE-141 86 Stockholm, Sweden; Hedman, L., Department of Psychology, Umeå University, SE-901 87 Umeå, Sweden; Wredmark, T., Division of Orthopaedics, Karolinska Institute, Huddinge University Hospital, SE-141 86 Stockholm, Sweden; Felländer-Tsai, L., Division of Orthopaedics, Karolinska Institute, Huddinge University Hospital, SE-141 86 Stockholm, Sweden","Background: We earlier showed that training in the Procedicus KSA Simulator improves the performance of tasks done later in the same simulator. However, it is still unclear how performance in a specific visual-spatial simulator context may change after training in other simulators with different visual-spatial components. In particular, the aim of this study was to test whether performance in the Procedicus Virtual Arthroscopy (VA) Knee Simulator would remain unchanged after a training session in three other simulators with different visual-spatial components. Methods: Twenty-eight medical students participated in a quasi-transfer study. They were randomly allocated to an experimental group (n = 14) and a control group (n = 14). Results: Performance in the Procedicus VA Knee Simulator did not improve after training in other simulators with different visual-spatial components (t-test p = NS). No significant correlation was found between the Procedicus VA Knee and the Minimally Invasive Surgical Trainer (MIST) simulators. Conclusion: One hour of training in different visual-spatial contexts was not enough to improve the performance in virtual arthroscopy tasks. It cannot be excluded, however, that experienced trainees could improve their performance, because perceived similarity between different situations is influenced by many psychological factors. Such as the knowledge or expertise of the person performing the transfer task.","Arthroscopy; Minimally invasive surgery; Simulator; Surgical training; Virtual reality","adult; arthroscopy; article; clinical article; controlled study; female; human; male; medical student; minimally invasive surgery; priority journal; psychological aspect; simulator; surgical training; task performance; virtual reality; Adult; Arthroscopy; Computer Simulation; Educational Measurement; Female; Humans; Knee Joint; Learning; Male; Models, Anatomic; Orthopedics; Physicians; Psychomotor Performance; Spatial Behavior; Students, Medical; Surgery; Surgical Procedures, Minimally Invasive; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-1642540013
"Raskar R., Van Baar J., Beardsley P., Willwacher T., Rao S., Forlines C.","6602886524;6603929342;7005022858;57190524639;36142023900;8594330700;","iLamps: Geometrically aware and self-configuring projectors",2003,"ACM SIGGRAPH 2003 Papers, SIGGRAPH '03",,,,"809","818",,120,"10.1145/1201775.882349","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953997133&doi=10.1145%2f1201775.882349&partnerID=40&md5=ddeec34fea4160ab956debbdf3cf0255","Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, United States","Raskar, R., Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, United States; Van Baar, J., Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, United States; Beardsley, P., Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, United States; Willwacher, T., Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, United States; Rao, S., Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, United States; Forlines, C., Mitsubishi Electric Research Labs. (MERL), Cambridge, MA, United States","Projectors are currently undergoing a transformation as they evolve from static output devices to portable, environment-aware, communicating systems. An enhanced projector can determine and respond to the geometry of the display surface, and can be used in an ad-hoc cluster to create a self-configuring display. Information display is such a prevailing part of everyday life that new and more flexible ways to present data are likely to have significant impact. This paper examines geometrical issues for enhanced projectors, relating to customized projection for different shapes of display surface, object augmentation, and co-operation between multiple units.We introduce a new technique for adaptive projection on nonplanar surfaces using conformal texture mapping. We describe object augmentation with a hand-held projector, including interaction techniques. We describe the concept of a display created by an ad-hoc cluster of heterogeneous enhanced projectors, with a new global alignment scheme, and new parametric image transfer methods for quadric surfaces, to make a seamless projection. The work is illustrated by several prototypes and applications. © 2003 ACM.","ad-hoc clusters; augmented reality; calibration; projector; quadric transfer; seamless display","ad-hoc clusters; Display surface; Global alignment; Hand-held projectors; Information display; Interaction techniques; Non-planar surfaces; Parametric image; Quadric surfaces; Self-configuring; Significant impacts; Static output; Texture mapping; Augmented reality; Calibration; Interactive computer graphics; Software prototyping; Virtual reality; Flexible displays",Conference Paper,"Final","",Scopus,2-s2.0-77953997133
"Stephenson P., Encarnação L.M., Branco P., Tesch J., Zeltzer D.","57203270064;6603063224;7005118624;57191993914;6701417238;","StudyDesk: Semi-immersive volumetric data analysis",2003,"Proceedings of the 1st International Conference on Computer Graphics and Interactive Techniques in Australasia and South East Asia, GRAPHITE '03",,,,"251","252",,2,"10.1145/604471.604520","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953183448&doi=10.1145%2f604471.604520&partnerID=40&md5=9caa0a9f66b8fd52d997a0e1357c3f80","Fraunhofer CRCG, United States","Stephenson, P., Fraunhofer CRCG, United States; Encarnação, L.M., Fraunhofer CRCG, United States; Branco, P., Fraunhofer CRCG, United States; Tesch, J., Fraunhofer CRCG, United States; Zeltzer, D., Fraunhofer CRCG, United States","The StudyDesk system provides a workbench environment that is well suited to work with multi-dimensional volumetric data in a semi-immersive virtual-reality setting. Using the StudyDesk system, we have implemented two example volume-rendering applications. The first visualises medical volumetric data using its implicit correspondence to physical space. The second is used to visualise and analyse sonar data described by time, range, bearing and frequency dimensions, in which correlations between sub-volumes is important. Therefore an abstract representation of the dataset is used to identify important regions in the data, which are then analysed using more traditional volume visualisation techniques. Interaction is implemented through the use of personal interaction props based on a pen and pad metaphor. Props include a transparent pen and pad that carry virtual shapes and a PDA system that is also used to transfer data and contexts between various systems. © 2003 ACM.","Acoustic visualization; Human-computer interaction; Information visualization; Medical imaging; Scientific visualization; Volume visualization","Abstract representation; Data sets; Frequency dimensions; Immersive; Information visualization; Personal interaction; Scientific visualizations; Sonar data; Volume visualisation; Volume visualization; Volumetric data; Data reduction; Graphite; Information analysis; Information systems; Interactive computer graphics; Knowledge management; Medical imaging; Underwater acoustics; Visualization; Volumetric analysis; Human computer interaction",Conference Paper,"Final","",Scopus,2-s2.0-77953183448
"Dos Santo Machado L., Marcos de Moraes R.","7801514135;7003717947;","An online evaluation of training in virtual reality simulators using fuzzy Gaussian mixture models and fuzzy relaxation labeling",2003,"Proceedings of the IASTED International Conference on Computers and Advanced Technology in Education",,,,"192","196",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-1542537544&partnerID=40&md5=ce6093d3b9ebbddab8c88334554a3110","Laboratory of Integrated Systems, Polytechnic School, University of São Paulo, 158. Trav.3, São Paulo - SP. CEP: 05508-900, Brazil; Department of Statistics-CCEN, Federal University of Paraíba, Cidade Universitária s/n, Joao Pessoa - PB CEP 58.051-900, Brazil","Dos Santo Machado, L., Laboratory of Integrated Systems, Polytechnic School, University of São Paulo, 158. Trav.3, São Paulo - SP. CEP: 05508-900, Brazil; Marcos de Moraes, R., Department of Statistics-CCEN, Federal University of Paraíba, Cidade Universitária s/n, Joao Pessoa - PB CEP 58.051-900, Brazil","Nowadays, virtual reality environments have been constructed with training objectives to provide realistic training. In this kind of system is important to know the quality of training to give a status of the user performance. Online evaluation allows the user to improve his learning because he can identify, immediately after the training, where he committed mistakes or presented low efficiency. In this paper we propose the use of a two-stage evaluator and to generalize the approach proposed by Moraes and Machado using fuzzy extensions of those algorithms: Fuzzy Gaussian Mixture Models (FGMM) in the first stage and Fuzzy Relaxation Labeling (FRL) in the second stage.","Fuzzy Gaussian Mixture Models; Fuzzy Relaxation Labeling; Fuzzy Sets; Online Evaluation Training; Virtual Reality","Algorithms; Computer simulation; Deformation; Fuzzy sets; Learning systems; Markov processes; Mathematical models; Personnel training; Relaxation processes; Simulators; Torque; Fuzzy Gaussian mixture models (FGMM); Fuzzy relaxation labeling (FRL); Online evaluation training; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-1542537544
"Mantovani F., Castelnuovo G., Gaggioli A., Riva G.","7006190897;6603562167;6603138127;56962750600;","Virtual reality training for health-care professionals",2003,"Cyberpsychology and Behavior","6","4",,"389","395",,119,"10.1089/109493103322278772","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041384533&doi=10.1089%2f109493103322278772&partnerID=40&md5=77a35283a9eadb04f9bf5fa966225618","Appl. Technol. Neuro-Psychol. Lab., Istituto Auxologico Italiano, Milan, Italy; Department of Psychology, Universita Cattolica del Sacro Cuore, Milan, Italy; Department of Psychology, Catholic University of Milan, Milan, Italy","Mantovani, F., Appl. Technol. Neuro-Psychol. Lab., Istituto Auxologico Italiano, Milan, Italy, Department of Psychology, Universita Cattolica del Sacro Cuore, Milan, Italy, Department of Psychology, Catholic University of Milan, Milan, Italy; Castelnuovo, G., Appl. Technol. Neuro-Psychol. Lab., Istituto Auxologico Italiano, Milan, Italy; Gaggioli, A., Appl. Technol. Neuro-Psychol. Lab., Istituto Auxologico Italiano, Milan, Italy; Riva, G., Appl. Technol. Neuro-Psychol. Lab., Istituto Auxologico Italiano, Milan, Italy, Department of Psychology, Universita Cattolica del Sacro Cuore, Milan, Italy","Emerging changes in health-care delivery are having a significant impact on the structure of health-care professionals' education. Today it is recognized that medical knowledge doubles every 6-8 years, with new medical procedures emerging everyday. While the half-life of medical information is so short, the average physician practices 30 years and the average nurse 40 years. Continuing education thus represents an important challenge to face. Recent advances in educational technology are offering an increasing number of innovative learning tools. Among these, Virtual Reality represents a promising area with high potential of enhancing the training of health-care professionals. Virtual Reality Training can provide a rich, interactive, engaging educational context, thus supporting experiential learning-by-doing; it can, in fact, contribute to raise interest and motivation in trainees and to effectively support skills acquisition and transfer, since the learning process can be settled within an experiential framework. Current virtual training applications for health-care differ a lot as to both their technological/multimedia sophistication and to the types of skills trained, varying for example from telesurgical applications to interactive simulations of human body and brain, to virtual worlds for emergency training. Other interesting applications include the development of immersive 3D environments for training psychiatrists and psychologists in the treatment of mental disorders. This paper has the main aim of discussing the rationale and main benefits for the use of virtual reality in health-care education and training. Significant research and projects carried out in this field will also be presented, followed by discussion on key issues concerning current limitations and future development directions.",,"computer simulation; conference paper; continuing education; health care delivery; health care personnel; human; medical education; medical informatics; mental disease; multimedia; nurse; psychiatrist; psychologist; skill; staff training; treatment planning; validation process; virtual reality; Computer Simulation; Computer-Assisted Instruction; Education, Professional; Educational Technology; Forecasting; Health Personnel; Humans; User-Computer Interface",Conference Paper,"Final","",Scopus,2-s2.0-0041384533
"Weiss P.L.T., Naveh Y., Katz N.","55435137100;7004434627;7202995938;","Design and testing of a virtual environment to train stroke patients with unilateral spatial neglect to cross a street safely",2003,"Occupational Therapy International","10","1",,"39","55",,71,"10.1002/oti.176","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0038441657&doi=10.1002%2foti.176&partnerID=40&md5=ff665a14606eecfca9e6d549c4887d2b","Department of Occupational Therapy, Fac. of Social Welfare/Hlth. Studies, University of Haifa, Mount Carmel, Haifa 31905, Israel; School of Occupational Therapy, Hadassah-Hebrew University, Jerusalem, Israel","Weiss, P.L.T., Department of Occupational Therapy, Fac. of Social Welfare/Hlth. Studies, University of Haifa, Mount Carmel, Haifa 31905, Israel; Naveh, Y., School of Occupational Therapy, Hadassah-Hebrew University, Jerusalem, Israel; Katz, N., School of Occupational Therapy, Hadassah-Hebrew University, Jerusalem, Israel","Virtual reality (VR) entails the use of advanced technologies, including computers and various multimedia peripherals, to produce a simulated (that is, virtual) environment that users perceive as comparable to real world objects and events. In recent years, virtual reality technologies have begun to be used as an assessment and treatment tool in occupational therapy, in part because of the ability to create environments that provide patients with opportunities to engage in meaningful, purposeful tasks that are related to real-life interests and activities. The objective of this study was to determine the suitability and feasibility of using a PC-based, non-immersive, VR system (that is, a system in which the user has a reduced sense of actual presence in and control over the simulated environment) for training individuals with unilateral spatial neglect to cross streets in a safe and vigilant manner. A virtual environment, consisting of a typical city street, was programmed using Superscape's™ 3D-Webmaster, a 3D web-authoring tool. Twelve subjects, aged 55 to 75 years, participated in the initial feasibility study and, to date, a further eight subjects have participated in the intervention study. Six of the initial subjects and all eight of the intervention subjects had sustained a right hemispheric stroke at least 6 weeks prior to the study. The remaining subjects were healthy age-matched adults who were independently mobile and had no difficulty in crossing streets. The results show that this virtual environment was suitable in both its cognitive and motor demands for the targeted population and indicate that the virtual reality training is likely to prove beneficial to people who have difficulty with crossing streets. The generalizability of these results, and recommendations regarding the use of virtual reality as an occupational therapy intervention, must be substantiated by further studies using a range of VR platforms with people with different cognitive and motor disabilities.","Stroke rehabilitation; Unilateral spatial neglect; Virtual reality","adult; aged; alertness; article; automation; body equilibrium; cerebrovascular accident; clinical article; cognition; cognitive defect; computer interface; computer program; controlled study; daily life activity; depth perception; disorientation; environmental planning; equipment design; feasibility study; female; human; Internet; male; mass medium; medical technology; mobilization; motor coordination; motor dysfunction; motor performance; nausea; occupational therapy; pathophysiology; right hemisphere; safety; stroke; traffic accident; training; urban area; virtual reality; visual impairment; walking; Accidents, Traffic; Activities of Daily Living; Aged; Cerebrovascular Accident; Feasibility Studies; Female; Humans; Male; Middle Aged; Space Perception; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-0038441657
"Brooks B.M., Rose F.D.","7201573008;7102651672;","The use of virtual reality in memory rehabilitation: Current findings and future directions",2003,"NeuroRehabilitation","18","2",,"147","157",,50,"10.3233/nre-2003-18207","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037810473&doi=10.3233%2fnre-2003-18207&partnerID=40&md5=aad776e020b6113e772dd1d8409762eb","University of East London, London, E15 4LZ, United Kingdom; School of Psychology, University of East London, Romford Road, London E15 4LZ, United Kingdom","Brooks, B.M., University of East London, London, E15 4LZ, United Kingdom, School of Psychology, University of East London, Romford Road, London E15 4LZ, United Kingdom; Rose, F.D., University of East London, London, E15 4LZ, United Kingdom","There is considerable potential for using virtual reality (VR) in memory rehabilitation which is only just beginning to be realized. PC-based virtual environments are probably better suited for this purpose than more immersive virtual environments because they are relatively inexpensive and portable, and less frightening to patients. Those exploratory studies that have so far been performed indicate that VR involvement would be usefully directed towards improving assessments of memory impairments and in memory remediation using reorganization techniques. In memory assessment, the use of VR could provide more comprehensive, ecologically-valid, and controlled evaluations of prospective, incidental, and spatial memory in a rehabilitation setting than is possible using standardized assessment tests. The additional knowledge gained from these assessments could more effectively direct rehabilitation towards specific impairments of individual patients. In memory remediation, VR training has been found to promote procedural learning in people with memory impairments, and this learning has been found to transfer to improved real-world performance. Future research should investigate ways in which the procedural knowledge gained during VR interaction can be adapted to offset the many disabilities which result from different forms of memory impairment.","Memory; Rehabilitation; Virtual reality","article; cognition; computer system; cost benefit analysis; evaluation; human; learning; memory disorder; mental deficiency; spatial memory; technique; treatment outcome; validation process; virtual reality",Article,"Final","",Scopus,2-s2.0-0037810473
"Höll D., Leplow B., Schönfeld R., Mehdorn M.","56953607800;56086907900;7003809631;7006783173;","Is it possible to learn and transfer spatial information from virtual to real worlds?",2003,"Lecture Notes in Artificial Intelligence (Subseries of Lecture Notes in Computer Science)","2685",,,"143","156",,3,"10.1007/3-540-45004-1_9","https://www.scopus.com/inward/record.uri?eid=2-s2.0-8344234240&doi=10.1007%2f3-540-45004-1_9&partnerID=40&md5=5e2be3c4182ed7deb9d3d37f5c4c1e60","Clinic for Neurosurgery, Chrstn.-Albrechts-University of Kiel, Weimarer Str. 8, 24106 Kiel, Germany; Department of Psychology, Martin-Luther-University of Halle, Brandbergweg 23, 06099 Halle (Saale), Germany","Höll, D., Clinic for Neurosurgery, Chrstn.-Albrechts-University of Kiel, Weimarer Str. 8, 24106 Kiel, Germany; Leplow, B., Department of Psychology, Martin-Luther-University of Halle, Brandbergweg 23, 06099 Halle (Saale), Germany; Schönfeld, R., Department of Psychology, Martin-Luther-University of Halle, Brandbergweg 23, 06099 Halle (Saale), Germany; Mehdorn, M., Clinic for Neurosurgery, Chrstn.-Albrechts-University of Kiel, Weimarer Str. 8, 24106 Kiel, Germany","In the present study spatial behavior was assessed by utilization of a desktop virtual environment and a locomotor maze task. In the first phase of the experiment, two groups of healthy middle-aged participants had to learn and remember five out of 20 target locations either in a ""real"" locomotor maze or an equivalent VR-version of this maze. The group with the VR-training was also confronted with the task in the real maze after achieving a learning criterion. Though acquisition rates were widely equivalent in the VR- and locomotor groups, VR participants had more problems learning the maze in the very first learning trials. Good transfer was achieved from the virtual to the real version of the maze by this group and they were significantly better in the acquisition phase of the locomotor task than the group that had not received VR-training. In the second phase of the experiment -the probe trials- when the cue configuration was changed the group with the VR-training seemed to have specific problems. A considerable number of participants of this group were not able to transfer information.","Memory; Orientation; Spatial cognition; Spatial memory; Spatial orientation; VR-environment","Data acquisition; Ecology; Learning systems; Personnel training; Problem solving; Virtual reality; Memory orientation; Spatial cognition; Spatial memory; Spatial orientation; Cognitive systems",Conference Paper,"Final","",Scopus,2-s2.0-8344234240
"Youngblut C., Huie O.","6508015016;6504593312;","The relationship between presence and performance in virtual environments: Results of a VERTS study",2003,"Proceedings - Virtual Reality Annual International Symposium",,,,"277","278",,11,"10.1109/VR.2003.1191158","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0038648233&doi=10.1109%2fVR.2003.1191158&partnerID=40&md5=00e67115175e4c73533ea5b366c287eb",,"Youngblut, C.; Huie, O.","A study was performed on the relationship between presence and performance in virtual environments (VE). The goal was to see whether the sense of presence experienced during VE-based training was related to the learning of mission procedures, as exhibited by performance on the training transfer tests. It was found that the addition of VE training did not improve the task performance over study of written mission procedures alone.",,"Data acquisition; Interfaces (computer); Software prototyping; Human cognition; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-0038648233
"Hernández L., Taibo J., Seoane A., López R., López R.","55511555400;6507592553;7003406149;57213074028;55578883100;","The empty museum. Multi-user interaction in an immersive and physically walkable VR space",2003,"Proceedings - 2003 International Conference on Cyberworlds, CW 2003",,, 1253488,"446","452",,5,"10.1109/CYBER.2003.1253488","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946202504&doi=10.1109%2fCYBER.2003.1253488&partnerID=40&md5=170c016c3b0fe366e21be66f6dd98f7a","Architecture and Urban Design Visualisation Group, VideaLAB, Universidade Da Coruña, E.T.S. de Ingenieros de Caminos, Canales y Puertos, Campus de Elviña, Spain","Hernández, L., Architecture and Urban Design Visualisation Group, VideaLAB, Universidade Da Coruña, E.T.S. de Ingenieros de Caminos, Canales y Puertos, Campus de Elviña, Spain; Taibo, J., Architecture and Urban Design Visualisation Group, VideaLAB, Universidade Da Coruña, E.T.S. de Ingenieros de Caminos, Canales y Puertos, Campus de Elviña, Spain; Seoane, A., Architecture and Urban Design Visualisation Group, VideaLAB, Universidade Da Coruña, E.T.S. de Ingenieros de Caminos, Canales y Puertos, Campus de Elviña, Spain; López, R., Architecture and Urban Design Visualisation Group, VideaLAB, Universidade Da Coruña, E.T.S. de Ingenieros de Caminos, Canales y Puertos, Campus de Elviña, Spain; López, R., Architecture and Urban Design Visualisation Group, VideaLAB, Universidade Da Coruña, E.T.S. de Ingenieros de Caminos, Canales y Puertos, Campus de Elviña, Spain","Until quite recently, virtual reality systems consisted of fixed devices which enabled the user to feel immersed in a spot of the virtual space by means of the adequate hardware. The recent emergence of wireless systems for motion capture, together with the increase in graphic power of laptops, and the generalisation of wireless networks has allowed the appearance of the first systems in which at last the user is able to walk physically within a given space framed in the real one, and containing the objects and elements of the virtual space [2][5][6]. Some examples of this hybrid space have already been accomplished worldwide. However, beyond the technical problems with the development of these systems, we must bear in mind the types of contents to be shown, making the most of the possibilities offered by the fact that the user him/herself is the pointer in this kind of virtual reality, while the space itself is the interface. The authors have recently developed a system similar to the ones described. This is a totally immersive, walkable and wireless system called the Empty Museum [7]. This paper outlines its enlargement with the purpose of making it simultaneously usable by several persons. Besides, an example of content is provided which has been specifically designed in order to be experienced in multi-user mode with this equipment: the Virtual Art Gallery. © 2003 IEEE.",,"Virtual reality; Wireless networks; First systems; Generalisation; Motion capture; Multi-user interaction; Virtual art gallery; Virtual reality system; Virtual spaces; Wireless systems; Museums",Conference Paper,"Final","",Scopus,2-s2.0-84946202504
"Kaufmann H., Schmalstieg D.","7203004662;55101019100;","Mathematics and geometry education with collaborative augmented reality",2003,"Computers and Graphics (Pergamon)","27","3",,"339","345",,298,"10.1016/S0097-8493(03)00028-1","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037681614&doi=10.1016%2fS0097-8493%2803%2900028-1&partnerID=40&md5=add781c3fa93f1470a43aaaef5034eaf","Interactive Media Systems Group, Vienna University of Technology, Favoritenstrasse 9-11/188, Vienna A-1040, Austria","Kaufmann, H., Interactive Media Systems Group, Vienna University of Technology, Favoritenstrasse 9-11/188, Vienna A-1040, Austria; Schmalstieg, D., Interactive Media Systems Group, Vienna University of Technology, Favoritenstrasse 9-11/188, Vienna A-1040, Austria","Construct3D is a 3D geometric construction tool specifically designed for mathematics and geometry education. It is based on the mobile collaborative augmented reality system ""Studierstube"". We describe our efforts in developing a system for the improvement of spatial abilities and maximization of transfer of learning. In order to support various teacher-student interaction scenarios we implemented flexible methods for context and user dependent rendering of parts of the construction. Together with hybrid hardware setups they allow the use of Construct3D in today's classrooms and provide a testbed for future evaluations. Means of application and integration in mathematics and geometry education at high school as well as university level are being discussed. Anecdotal evidence supports our claim that Construct3D is easy to learn, encourages experimentation with geometric constructions and improves spatial skills. © 2003 Elsevier Science Ltd. All rights reserved.","Augmented reality; Geometry education; Mathematics education; Spatial intelligence","Education; Learning systems; Societies and institutions; Students; Geometry education; Computer supported cooperative work",Conference Paper,"Final","",Scopus,2-s2.0-0037681614
"Peng X., Chi X., Ochoa J.A., Leu M.C.","35270024100;8666844400;35335038100;7101764823;","Bone surgery simulation with virtual reality",2003,"Proceedings of the ASME Design Engineering Technical Conference","1 B",,,"1105","1113",,12,"10.1115/detc2003/cie-48292","https://www.scopus.com/inward/record.uri?eid=2-s2.0-1842662422&doi=10.1115%2fdetc2003%2fcie-48292&partnerID=40&md5=ee973fae9ee40d1ae0bb857551653e8a","Department of Mechanical Engineering, University of Missouri-Rolla, Rolla, MO 65409, United States; DePuy Orthoped., Johnson/Johnson Co., 700 Orthopaedic Drive, Warsaw, IN 46581, United States","Peng, X., Department of Mechanical Engineering, University of Missouri-Rolla, Rolla, MO 65409, United States; Chi, X., Department of Mechanical Engineering, University of Missouri-Rolla, Rolla, MO 65409, United States; Ochoa, J.A., DePuy Orthoped., Johnson/Johnson Co., 700 Orthopaedic Drive, Warsaw, IN 46581, United States; Leu, M.C., Department of Mechanical Engineering, University of Missouri-Rolla, Rolla, MO 65409, United States","Precise bone preparation is a key element for the successful long-term fixation of orthopaedic implants. Initial stability leading to reduced micromotion and direct apposition of the bone against the implant are mainly responsible for proper load transfer and bone remodeling. The fit and fill of the implant is created by shaping and sizing a cavity within the bone to accommodate the implant, which is usually accomplished by standard machining operations such as broaching, milling and drilling. This paper presents our initial study of developing a bone drilling simulation system, with the goal of guiding a novice surgeon to practice the bone drilling operation. A virtual reality approach is taken to provide force feedback, in order to make the simulation system more intuitive and interactive. Octree is used to organize and manipulate the volumetric data representing the bone model. Adaptive surface rendering is chosen as the graphics display algorithm. Multithreading is used to address the different update rates required in the real-time graphic and haptic displays.","Bone drilling; Bone surgery simulation; Haptics; Octree","Algorithms; Biomechanics; Bone; Broaching; Computer graphics; Computer simulation; Computerized tomography; Drilling; Haptic interfaces; Implants (surgical); Magnetic resonance imaging; Orthopedics; Personnel training; Real time systems; Simulators; Surgery; Bone drilling; Bone surgery simulation; Octree haptics; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-1842662422
"Braun A., Musse S.R., De Oliveira L.P.L., Bodmann B.E.J.","14618965200;6508070752;7102852865;7003437043;","Modeling individual behaviors in crowd simulation",2003,"Proceedings - IEEE Workshop on Program Comprehension","2003-January",, 1199317,"143","148",,135,"10.1109/CASA.2003.1199317","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943384978&doi=10.1109%2fCASA.2003.1199317&partnerID=40&md5=bd8c385c85600562ee4bec1480843e09","University of Vale do Rio dos Sinos, Masters in Applied Computing, Av. Unisinos, 950, São Leopoldo, RS, Brazil","Braun, A., University of Vale do Rio dos Sinos, Masters in Applied Computing, Av. Unisinos, 950, São Leopoldo, RS, Brazil; Musse, S.R., University of Vale do Rio dos Sinos, Masters in Applied Computing, Av. Unisinos, 950, São Leopoldo, RS, Brazil; De Oliveira, L.P.L., University of Vale do Rio dos Sinos, Masters in Applied Computing, Av. Unisinos, 950, São Leopoldo, RS, Brazil; Bodmann, B.E.J., University of Vale do Rio dos Sinos, Masters in Applied Computing, Av. Unisinos, 950, São Leopoldo, RS, Brazil","This paper presents a model for studying the impact of individual agent characteristics in emergent groups, based on the evacuation efficiency as a result of local interactions. We used the physically based model of crowd simulation proposed by Helbing et al. (2000) and generalized it in order to deal with different individualities for agent and group behaviors. In addition, we present a framework to visualize the virtual agents and discuss the obtained results. A variety of simulations with different parameter sets shows significant impact on the evacuation scenario. © 2003 IEEE.","Animation; Application software; Birds; Computational modeling; History; Humans; Motion control; Psychology; Resource management; Visualization","Animation; Application programs; Birds; Flow visualization; History; Motion control; Computational model; Humans; Individual agent; Individual behavior; Local interactions; Physically based modeling; Psychology; Resource management; Behavioral research",Conference Paper,"Final","",Scopus,2-s2.0-84943384978
"Akgunduz A., Banerjee P.","57203259871;35580367600;","A supervisory data-traffic controller in collaborative virtual reality simulations",2002,"American Society of Mechanical Engineers, Manufacturing Engineering Division, MED","13",,,"71","78",,,"10.1115/IMECE2002-32470","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0348144609&doi=10.1115%2fIMECE2002-32470&partnerID=40&md5=252611062ea2bba9d86d63b0ed909a53","Analyst-Res./Devmt. Info. Syst. D., United Airlines, P.O. Box 66100, Chicago, IL 60666-0100, United States; Department of Mechanical Engineering, 2039 Engineering Research Facility, University of Illinois at Chicago, 842 W. Taylor St., Chicago, IL 60607, United States","Akgunduz, A., Analyst-Res./Devmt. Info. Syst. D., United Airlines, P.O. Box 66100, Chicago, IL 60666-0100, United States; Banerjee, P., Department of Mechanical Engineering, 2039 Engineering Research Facility, University of Illinois at Chicago, 842 W. Taylor St., Chicago, IL 60607, United States","In this paper an efficient technique for distributing the data in collaborative virtual reality is presented. The described technique incorporates the culling and level of detail concepts in virtual reality to obtain cell based bounding volumes in each virtual environment. Defined bounding volumes are utilized in filtering the data that is transferred between different virtual environments in the simulation system. To orchestrate the communication between virtual environments and their bounding volumes, a supervisory control system is presented in the paper.",,"Data traffic controllers; Real time simulation; Algorithms; Computer simulation; Computer workstations; Control system analysis; Data acquisition; Data transfer; Internet; Personnel training; Product design; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-0348144609
"Seymour N.E., Gallagher A.G., Roman S.A., O'Brien M.K., Bansal V.K., Andersen D.K., Satava R.M., Pellegrini C.A., Sachdeva A.K., Meakins J.L., Blumgart L.H.","7004355854;7101915089;10044651100;13609932800;57200776635;7202231941;7006711764;7101984946;7003532148;55396539500;7102332844;","Virtual reality training improves operating room performance results of a randomized, double-blinded study",2002,"Annals of Surgery","236","4",,"458","464",,1891,"10.1097/00000658-200210000-00008","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036785870&doi=10.1097%2f00000658-200210000-00008&partnerID=40&md5=43735ffaa06985f2dd1a283bb185da72","Department of Surgery, Yale University School of Medicine, TMP 202, 330 Cedar Street, New Haven, CT 06520-8062, United States","Seymour, N.E., Department of Surgery, Yale University School of Medicine, TMP 202, 330 Cedar Street, New Haven, CT 06520-8062, United States; Gallagher, A.G., Department of Surgery, Yale University School of Medicine, TMP 202, 330 Cedar Street, New Haven, CT 06520-8062, United States; Roman, S.A., Department of Surgery, Yale University School of Medicine, TMP 202, 330 Cedar Street, New Haven, CT 06520-8062, United States; O'Brien, M.K., Department of Surgery, Yale University School of Medicine, TMP 202, 330 Cedar Street, New Haven, CT 06520-8062, United States; Bansal, V.K., Department of Surgery, Yale University School of Medicine, TMP 202, 330 Cedar Street, New Haven, CT 06520-8062, United States; Andersen, D.K., Department of Surgery, Yale University School of Medicine, TMP 202, 330 Cedar Street, New Haven, CT 06520-8062, United States; Satava, R.M., Department of Surgery, Yale University School of Medicine, TMP 202, 330 Cedar Street, New Haven, CT 06520-8062, United States; Pellegrini, C.A., Department of Surgery, Yale University School of Medicine, TMP 202, 330 Cedar Street, New Haven, CT 06520-8062, United States; Sachdeva, A.K., Department of Surgery, Yale University School of Medicine, TMP 202, 330 Cedar Street, New Haven, CT 06520-8062, United States; Meakins, J.L., Department of Surgery, Yale University School of Medicine, TMP 202, 330 Cedar Street, New Haven, CT 06520-8062, United States; Blumgart, L.H., Department of Surgery, Yale University School of Medicine, TMP 202, 330 Cedar Street, New Haven, CT 06520-8062, United States","Objective: To demonstrate that virtual reality (VR) training transfers technical skills to the operating room (OR) environment. Summary Background Data: The use of VR surgical simulation to train skills and reduce error risk in the OR has never been demonstrated in a prospective, randomized, blinded study. Methods: Sixteen surgical residents (PGY 1-4) had baseline psychomotor abilities assessed, then were randomized to either VR training (MIST VR simulator diathermy task) until expert criterion levels established by experienced laparoscopists were achieved (n = 8), or control non-VR-trained (n = 8). All subjects performed laparoscopic cholecystectomy with an attending surgeon blinded to training status, Videotapes of gallbladder dissection were reviewed independently by two investigators blinded to subject identity and training, and scored for eight predefined errors for each procedure minute (interrater reliability of error assessment r > 0.80). Results: No differences in baseline assessments were found between groups. Gallbladder dissection was 29% faster for VR-trained residents. Non-VR-trained residents were nine times more likely to transiently fail to make progress (P < .007, Mann-Whitney test) and five times more likely to injure the gallbladder or burn nontarget tissue (chi-square = 4.27, P < .04). Mean errors were six times less likely to occur in the VR-trained group (1.19 vs. 7.38 errors per case; P < .008, Mann-Whitney test). Conclusions The use of VR surgical simulation to reach specific target criteria significantly improved the OR performance of residents during laparoscopic cholecystectomy. This validation of transfer of training skills from VR to OR sets the stage for more sophisticated uses of VR in assessment, training, error reduction, and certification of surgeons.",,"chi square distribution; cholecystectomy; clinical trial; conference paper; controlled clinical trial; controlled study; double blind procedure; human; laparoscopic surgery; laparoscopy; operating room; performance; peroperative complication; priority journal; randomized controlled trial; rank sum test; reliability; resident; scoring system; simulator; surgeon; surgical injury; surgical training; videotape; virtual reality; Cholecystectomy, Laparoscopic; Clinical Competence; Double-Blind Method; Female; Gallbladder Diseases; Humans; Internship and Residency; Male; Observer Variation; Prospective Studies; Reproducibility of Results; Surgery; Time Factors; User-Computer Interface",Conference Paper,"Final","",Scopus,2-s2.0-0036785870
"Hyltander A., Liljegren E., Rhodin P.H., Lönroth H.","6603924833;6603477232;6504763734;7003560474;","The transfer of basic skills learned in a laparoscopic simulator to the operating room",2002,"Surgical Endoscopy and Other Interventional Techniques","16","9",,"1324","1328",,245,"10.1007/s00464-001-9184-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036733679&doi=10.1007%2fs00464-001-9184-5&partnerID=40&md5=a7f56f40ea789c8ec1d4bd281e9402f8","Department of Surgery, Sahlgrenska University Hospital, S-413 45 Göteborg, Sweden; Departmem of Human Factors Engineering, Chalmers University of Technology, S-412 96 Göteborg, Sweden","Hyltander, A., Department of Surgery, Sahlgrenska University Hospital, S-413 45 Göteborg, Sweden; Liljegren, E., Departmem of Human Factors Engineering, Chalmers University of Technology, S-412 96 Göteborg, Sweden; Rhodin, P.H., Departmem of Human Factors Engineering, Chalmers University of Technology, S-412 96 Göteborg, Sweden; Lönroth, H., Department of Surgery, Sahlgrenska University Hospital, S-413 45 Göteborg, Sweden","Background: The aim of the study was to evaluate whether basic surgical skills achieved by training in LapSim, a computerbased laparoscopic simulator, could be transferred to the operating room. Methods: For this study, 24 medical students undergoing courses in surgery were randomly assigned to train with LapSim or to serve as control subjects. After they had undergone simulator training 2 h per week for 5 weeks, their basic skills in laparoscopic surgery were assessed in a porcine model. The time to perform each task was measured, and four senior surgeons independently graded the overall performance on a 9-step differential rating scale. Results: The participants randomized to train with LapSim showed significantly better results for all tasks in both parts of the study than the untrained participants, according to the expert evaluation. Time consumption was accordingly lower in the training group in the control group. Conclusions: The results show that basic skills achieved by systematic training with a laparoscopic simulator such as LapSim can be transferred to the operating room.","Education; Laparoscopic surgery; Laparoscopic training; Simulator training; Skills assessment; Surgical skills","article; computer system; controlled study; laparoscopic surgery; learning; medical student; operating room; performance; priority journal; rating scale; simulator; skill; surgeon; surgical training; Animals; Clinical Competence; Computer-Assisted Instruction; Educational Measurement; Female; Functional Laterality; Humans; Laparoscopy; Male; Models, Anatomic; Psychomotor Performance; Random Allocation; Swine; Task Performance and Analysis; Time Factors; Video-Assisted Surgery",Article,"Final","",Scopus,2-s2.0-0036733679
"McComas J., MacKay M., Pivik J.","7004559519;35615432500;6603316182;","Effectiveness of virtual reality for teaching pedestrian safety",2002,"Cyberpsychology and Behavior","5","3",,"185","190",,97,"10.1089/109493102760147150","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036019962&doi=10.1089%2f109493102760147150&partnerID=40&md5=392a0c613a7c4d7322f0269bdf56a557","School of Rehabilitation Sciences, University of Ottawa, 451 Smyth Rd., Ottawa, Ont. KIH 8M5, Canada","McComas, J., School of Rehabilitation Sciences, University of Ottawa, 451 Smyth Rd., Ottawa, Ont. KIH 8M5, Canada; MacKay, M., School of Rehabilitation Sciences, University of Ottawa, 451 Smyth Rd., Ottawa, Ont. KIH 8M5, Canada; Pivik, J., School of Rehabilitation Sciences, University of Ottawa, 451 Smyth Rd., Ottawa, Ont. KIH 8M5, Canada","Sixty percent to 70% of pedestrian injuries in children under the age of 10 years are the result of the child either improperly crossing intersections or dashing out in the street between intersections. The purpose of this injury prevention research study was to evaluate a desktop virtual reality (VR) program that was designed to educate and train children to safely cross intersections. Specifically, the objectives were to determine whether children can learn pedestrian safety skills while working in a virtual environment and whether pedestrian safety learning in VR transfers to real world behavior. Following focus groups with a number of key experts, a virtual city with eight interactive intersections was developed. Ninety-five children participated in a community trial from two schools (urban and suburban). Approximately half were assigned to a control group who received an unrelated VR program, and half received the pedestrian safety VR intervention. Children were identified by group and grade by colored tags on their backpacks, and actual street crossing behavior of all children was observed 1 week before and 1 week after the interventions. There was a significant change in performance after three trials with the VR intervention. Children learned safe street crossing within the virtual environment. Learning, identified as improved street-crossing behavior, transferred to real world behavior in the suburban school children but not in the urban school. The results are discussed in relation to possibilities for future VR interventions for injury prevention.",,"accident prevention; child behavior; computer program; conference paper; female; human; injury; learning; major clinical study; male; pedestrian; preschool child; preventive medicine; safety; school child; teaching; traffic accident; urban area; virtual reality; article; child; clinical trial; computer interface; evaluation; health education; methodology; psychological aspect; safety; traffic accident; Accidents, Traffic; Child; Female; Health Education; Human; Male; Programmed Instruction; Safety; Software; Software Validation; Support, Non-U.S. Gov't; User-Computer Interface; Wounds and Injuries; Child; Female; Humans; Male; Programmed Instruction; Safety; Software; Software Validation; Wounds and Injuries",Conference Paper,"Final","",Scopus,2-s2.0-0036019962
"Rose F.D., Brooks B.M., Attree E.A.","7102651672;7201573008;6603053737;","An exploratory investigation into the usability and usefulness of training people with learning disabilities in a virtual environment",2002,"Disability and Rehabilitation","24","11-12",,"627","633",,32,"10.1080/09638280110111405","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037142868&doi=10.1080%2f09638280110111405&partnerID=40&md5=0b350e839b02ae69c5fb916a59549196","School of Psychology, University of East London, London E15 4LZ, United Kingdom","Rose, F.D., School of Psychology, University of East London, London E15 4LZ, United Kingdom; Brooks, B.M., School of Psychology, University of East London, London E15 4LZ, United Kingdom; Attree, E.A., School of Psychology, University of East London, London E15 4LZ, United Kingdom","Purpose: Two studies sought to answer the following questions. Are people with learning disabilities capable of using a virtual environment? Are they motivated to learn using this training method? Do they show any benefit from using a virtual environment? Does any benefit transfer to improved real world performance? Method: In the first study, 30 students with learning disabilities were sequentially allocated to an active or a passive experimental group. Active participants explored a virtual bungalow searching for a toy car. Passive participants watched the exploration undertaken by the preceding active participant and searched for the toy car. All participants then performed spatial and object recognition tests of their knowledge of the virtual environment. In the second study, the errors of 45 participants on a real steadiness tester task were noted before they were randomly allocated to three groups-a real training group, a virtual training group and a no training group. After training, the participants performed a second test trial on the real steadiness tester. Results: The students were capable of using a virtual environment and were motivated to use this training method. Active exploration of a virtual environment was found to enhance their memory of the spatial layout of the bungalow but not their memory of the virtual objects. In the second study, virtual training was found to transfer to real task performance. Conclusions: These two laboratory-based studies provide answers to four important questions concerning virtual training of people with learning disabilities. Hopefully, the findings will encourage this training aid to be used more widely.",,"adolescent; adult; article; clinical trial; computer program; computer simulation; controlled clinical trial; controlled study; female; human; learning disorder; major clinical study; male; motivation; priority journal; psychologic test; randomized controlled trial; recognition; spatial memory; student; task performance; virtual reality; vocational education; Achievement; Adolescent; Adult; Cohort Studies; Education, Special; Educational Measurement; Female; Great Britain; Humans; Learning Disorders; Male; Middle Aged; Program Evaluation; Sampling Studies; Task Performance and Analysis; Teaching; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-0037142868
"Yang U., Kim G.J.","7006006027;7403061980;","Implementation and evaluation of ""just follow me"": An immersive, VR-based, motion-training system",2002,"Presence: Teleoperators and Virtual Environments","11","3",,"304","323",,91,"10.1162/105474602317473240","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036625537&doi=10.1162%2f105474602317473240&partnerID=40&md5=5a670f3cffae5bb3c1b2a98769e0a833","Virtual Reality Laboratory, Dept. of Comp. Sci. and Engineering, Pohang Univ. of Sci. and Technology, San 31 Hyoja-dong, Pohang, Kyungbuk 790-784, South Korea","Yang, U., Virtual Reality Laboratory, Dept. of Comp. Sci. and Engineering, Pohang Univ. of Sci. and Technology, San 31 Hyoja-dong, Pohang, Kyungbuk 790-784, South Korea; Kim, G.J., Virtual Reality Laboratory, Dept. of Comp. Sci. and Engineering, Pohang Univ. of Sci. and Technology, San 31 Hyoja-dong, Pohang, Kyungbuk 790-784, South Korea","Training is usually regarded as one of the most natural application areas of virtual reality (VR). To date, most VR-based training systems have been situation based, but this paper examines the utility of VR for a different class of training: learning to execute exact motions, which are often required in sports and the arts. In this paper, we propose an interaction method, called Just Follow Me (JFM), that uses an intuitive ""ghost"" metaphor and a first-person viewpoint for effective motion training. Using the ghost metaphor (GM), JFM visualizes the motion of the trainer in real time as a ghost (initially superimposed on the trainee) that emerges from one's own body. The trainee who observes the motion from the first-person viewpoint ""follows"" the ghostly master as closely as possible to learn the motion. Our basic hypothesis is that such a VR system can help a student learn motion effectively and quickly, comparably to the indirect real-world teaching methods. Our evaluation results show that JFM produces training and transfer effects as good as - and, in certain situations, better than - in the real world. We believe that this is clue to the more direct and correct transfer of proprioceptive information from the trainer to the trainee.",,"Ghost metaphor; Human computer interaction; Motion planning; Personnel training; Students; Virtual reality",Article,"Final","",Scopus,2-s2.0-0036625537
"Arnold P., Farrell M.J., Pettifer S., West A.J.","7202944024;7202679231;6602097064;7202674494;","Performance of a skilled motor task in virtual and real environments",2002,"Ergonomics","45","5",,"348","361",,10,"10.1080/00140130110120510","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037091920&doi=10.1080%2f00140130110120510&partnerID=40&md5=134b431ac4de031b9630b406988c9e9b","Department of Psychology, University of Manchester, Oxford Road, Manchester M13 9PL, United Kingdom; Advanced Interfaces Group, Department of Computer Science, University of Manchester, Oxford Road, Manchester M13 9PL, United Kingdom","Arnold, P., Department of Psychology, University of Manchester, Oxford Road, Manchester M13 9PL, United Kingdom; Farrell, M.J., Department of Psychology, University of Manchester, Oxford Road, Manchester M13 9PL, United Kingdom; Pettifer, S., Advanced Interfaces Group, Department of Computer Science, University of Manchester, Oxford Road, Manchester M13 9PL, United Kingdom; West, A.J., Advanced Interfaces Group, Department of Computer Science, University of Manchester, Oxford Road, Manchester M13 9PL, United Kingdom","Three experiments compared the performances of adult participants (three groups of 10) on a perceptuo-motor task in both real world (RW) and virtual environments (VEs). The task involved passing a hoop over a bent wire course, and three versions of the task were used: a 3-D wire course with no background, a flattened version of the 3-D course (2 1/2-D course) with no background, and the 2 1/2-D course with added background to provide spatial context. In all three experiments the participants had to prevent the hoop from touching the wire as they moved it. In the first experiment, the VE condition produced about 18 times more errors than the RW task. The VE 2 1/2-D task was found to be as difficult as the 3-D, and the 2 1/2-D with the added background produced more errors than the other two experiments. Taken together, the experiments demonstrate the difficulty of performing fine motor tasks in VEs, a phenomenon that has not been given due attention in many previous studies of motor control in VEs.","Head mounted display (HMD); Motor skill; Real world analogue; Virtual environment","Motors; Virtual reality; Motor task; Ergonomics; adult; article; comparative study; controlled study; human; human experiment; motor activity; motor control; motor performance; movement perception; perception; physical performance; sensorimotor function; skill; spatial summation; task performance; virtual reality; work environment; Adolescent; Adult; Analysis of Variance; Depth Perception; Humans; Psychomotor Performance; Regression Analysis; Transfer (Psychology); User-Computer Interface",Article,"Final","",Scopus,2-s2.0-0037091920
"Hartling P., Bierbaum A., Cruz-Neira C.","6507457478;6602548125;57203797818;","Virtual reality interfaces using Tweek",2002,"ACM SIGGRAPH 2002 Conference Abstracts and Applications, SIGGRAPH 2002",,,,"278","",,7,"10.1145/1242073.1242291","https://www.scopus.com/inward/record.uri?eid=2-s2.0-32644461902&doi=10.1145%2f1242073.1242291&partnerID=40&md5=900161c3c17e448628671b4d451d6150","Virtual Reality Applications Center (VRAC), Iowa State University, United States","Hartling, P., Virtual Reality Applications Center (VRAC), Iowa State University, United States; Bierbaum, A., Virtual Reality Applications Center (VRAC), Iowa State University, United States; Cruz-Neira, C., Virtual Reality Applications Center (VRAC), Iowa State University, United States","Developers of virtual environments often face a difficult problem: users must have some way to interact with the virtual world. The application developers must determine how to map available inputs (buttons, gestures, etc.) to actions within the virtual environment (VE). As a result, user interfaces may be limited by the input hardware available with a given virtual reality (VR) system. To address such limitations, we have developed Tweek, a middleware tool that presents users with an extensible Java graphical user interface (GUI) capable of communicating with VR applications. Tweek can run on desktop computers, on palmtop computers in projection-based virtual reality systems, or in a three-dimensional virtual space. We use Tweek to address some limitations of input and interaction within virtual environments (VEs) by designing GUIs that utilize familiar two-dimensional (2D) components. Interaction techniques that require fine-grained control or high-precision input are often better suited to 2D interfaces than the use of gestures or buttons on a wand [Hill 2000]. The use of Java-based GUIs for interaction within VEs has been investigated in previous works at the VRAC. The first such work investigated the usability of a palmtop system with a Java GUI to interact with and manipulate a virtual space [Hill 2000]. Tweek extends this research by generalizing the interaction capabilities and the dynamic GUI component loading. Tweek is a collection of multiple technologies: C++, Java, JavaBeans, and CORBA. Combined, these allow a Java GUI composed of plug-ins to communicate with a C++ application. Our implementation aims to simplify the inter-language communication so that programmers can make use of Tweek in their VR applications without knowing all the details of the individual technologies. At the heart of the inter-language communication is CORBA, the Common Object Request Broker Architecture [OMG 2001]. It provides a cross-platform, language-independent method for distributed objects to communicate. In Tweek, it manages all communication between the Java GUI and the C++ VR application. Because CORBA is language-independent, there exists the potential for use of other languages besides Java and C++. The Java GUI itself is a generalized framework that loads JavaBeans [JavaSoft 1997] dynamically using XML-based descriptions. The JavaBeans may encapsulate any functionality, but those that extend the GUI are crucial to the use of Tweek in a VE. Such graphical JavaBeans are written by the VR application developers and are customized for use with a given application. Dynamic extension of the GUI allows the VR application to add components to the interface while the user is active within the virtual space. Through dynamically extensible input, we can explore new possibilities for interactivity in VEs.",,"C++ (programming language); Common object request broker architecture (CORBA); Computational linguistics; Computer graphics; Fasteners; Graphical user interfaces; Interactive computer graphics; Middleware; Personal computers; User interfaces; Virtual addresses; Virtual reality; Application developers; Individual technology; Interaction techniques; Java graphical user interface; Language communication; Two Dimensional (2 D); Virtual reality interfaces; Virtual reality system; Java programming language",Conference Paper,"Final","",Scopus,2-s2.0-32644461902
"McComas J., Sveistrup H.","7004559519;55986144000;","Virtual reality applications for prevention, disability awareness, and physical therapy rehabilitation in neurology: Our Recent Work",2002,"Neurology Report","26","2",,"55","61",,26,"10.1097/01253086-200226020-00002","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85010363257&doi=10.1097%2f01253086-200226020-00002&partnerID=40&md5=f191646c6fd0393ac7aa5b81a3de075f","School of Rehabilitation Sciences, University of Ottawa, 451 Smyth Road, Ottawa, ON, Canada","McComas, J., School of Rehabilitation Sciences, University of Ottawa, 451 Smyth Road, Ottawa, ON, Canada; Sveistrup, H., School of Rehabilitation Sciences, University of Ottawa, 451 Smyth Road, Ottawa, ON, Canada","Virtual reality VR is a relatively new technology that may be useful for physical therapists working in neurology. In this paper our recent work related to the development and evaluation ofVR applications for demonstrating transfer of training, improvement of spatial memory, teaching disability awareness, prevention of pedestrian injuries, and improvement of balance is discussed. Our experiences as researchers in this area are discussed including collaboration with industry and the limitations and strengths of the technology. Our research and the research of others have shown that skills can be learned in VR, that these skills can transfer to similar tasks in the real world, that patient consumer involvement is essential in making VR environments meaningful, and that collaboration with industry requires special knowledge and skills. We conclude that VR has a future in neurologic physical therapy but that it may be some time before strong evidence for each possible application is available to clinicians. As this evidence becomes available, VR may provide physical therapists with interesting and innovative ways to extend evaluation and treatment in neurology. © 2002 Lippincott Williams & Wilkins, Inc.","Brain injury; Disability prevention; Virtual reality",,Article,"Final","",Scopus,2-s2.0-85010363257
"Fogli D., Mussio P., Celentano A., Pittarello F.","8950090800;7004471038;7005178701;15137084500;","Toward a model-based approach to the specification of virtual reality environments",2002,"Proceedings - 4th International Symposium on Multimedia Software Engineering, MSE 2002",,, 1181607,"148","155",,5,"10.1109/MMSE.2002.1181607","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646218427&doi=10.1109%2fMMSE.2002.1181607&partnerID=40&md5=8a1de459f89a9027962ae1e6cbcce166","Dipartimento di Elettronica per l'Automazione, Università degli Studi di Brescia, Via Branze 38, Brescia, 25123, Italy; Dipartimento di Informatica, Università Ca' Foscari di Venezia, via Torino 155, Mestre, VE  30172, Italy","Fogli, D., Dipartimento di Elettronica per l'Automazione, Università degli Studi di Brescia, Via Branze 38, Brescia, 25123, Italy; Mussio, P., Dipartimento di Elettronica per l'Automazione, Università degli Studi di Brescia, Via Branze 38, Brescia, 25123, Italy; Celentano, A., Dipartimento di Informatica, Università Ca' Foscari di Venezia, via Torino 155, Mestre, VE  30172, Italy; Pittarello, F., Dipartimento di Informatica, Università Ca' Foscari di Venezia, via Torino 155, Mestre, VE  30172, Italy","An approach to the specification of a virtual reality (VR) interactive environment is presented, which merges and generalizes two recently proposed methods: the PCL characteristic pattern approach to WIMP system design and the interaction locus approach to interactive navigation in 3D virtual spaces. Merging the two points of view allows refinement of the model of interaction of a user with a virtual environment and leads to the definition of ""real"" and ""virtual"" characteristic patterns, which the discussion shows to be important for the designer to properly undertake the design of complex virtual reality systems. © 2002 IEEE.",,"Software engineering; Specifications; Virtual reality; 3D virtual spaces; Interactive Environments; Interactive navigations; Model based approach; Two-point; Virtual reality system; Virtual-reality environment; Air navigation",Conference Paper,"Final","",Scopus,2-s2.0-33646218427
"Kaufmann H., Schmalstieg D.","7203004662;55101019100;","Mathematics and geometry education with collaborative augmented reality",2002,"ACM SIGGRAPH 2002 Conference Abstracts and Applications, SIGGRAPH 2002",,,,"37","41",,79,"10.1145/1242073.1242086","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945962878&doi=10.1145%2f1242073.1242086&partnerID=40&md5=cd3ae11246c24f1a573439d80740e178","Vienna University of Technology, Austria","Kaufmann, H., Vienna University of Technology, Austria; Schmalstieg, D., Vienna University of Technology, Austria","Construct3D is a three-dimensional geometric construction tool specifically designed for mathematics and geometry education. It is based on the mobile collaborative augmented reality system ""Studierstube."" We describe our efforts in developing a system for the improvement of spatial abilities and maximization of transfer of learning. In order to support various teacher-student interaction scenarios we implemented flexible methods for context and user dependent rendering of parts of the construction. Together with hybrid hardware setups they allow the use of Construct3D in today's classrooms and provide a test bed for future evaluations. Means of application and integration in mathematics and geometry education at the high school, as well as the university, level are being discussed. Anecdotal evidence supports our claim that Construct3D is easy to learn, encourages experimentation with geometric constructions, and improves spatial skills.","Augmented reality; Geometry education; Mathematics education; Spatial intelligence","Augmented reality; Computer graphics; Geometry; Interactive computer graphics; Teaching; Anecdotal evidences; Collaborative augmented realities; Geometric construction; Mathematics education; Spatial abilities; Spatial intelligence; Student interactions; Transfer of learning; Education",Conference Paper,"Final","",Scopus,2-s2.0-84945962878
"McMillan D.E., Hardwick W.C., Li M.","7201699611;7004024653;8531417900;","Drug discrimination under concurrent variable-ratio variable-ratio schedules",2002,"Journal of the Experimental Analysis of Behavior","77","1",,"91","104",,3,"10.1901/jeab.2002.77-91","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036365362&doi=10.1901%2fjeab.2002.77-91&partnerID=40&md5=37c7c657cbef92a5d09498504e4abfcd","Dept. of Pharmacology and Toxicology, College of Medicine, Univ. of Arkansas for Med. Sciences, 4301 West Markham Street, Little Rock, AR 72205, United States","McMillan, D.E., Dept. of Pharmacology and Toxicology, College of Medicine, Univ. of Arkansas for Med. Sciences, 4301 West Markham Street, Little Rock, AR 72205, United States; Hardwick, W.C.; Li, M.","Pigeons were trained to discriminate 5 mg/kg pentobarbital from saline under concurrent variable-ratio (VR) VR schedules, in which responses on the pentobarbital-biased lever were reinforced under the VR schedule with the smaller response requirements when pentobarbital was given before the session, and responses on the saline-biased key were reinforced under the VR schedule with the larger response requirements. When saline was administered before the session, the reinforcement contingencies associated with the two response keys were reversed. When responding stabilized under concurrent VR 20 VR 30, concurrent VR 10 VR 40, or concurrent VR 5 VR 50 schedules pigeons responded almost exclusively on the key on which fewer responses were required to produce the reinforcer. When other doses of pentobarbital and other drugs were substituted for the training dose, low doses of all drugs produced responding on the saline-biased key. Higher doses of pentobarbital and chlordiazepoxide produced responding only on the pentobarbital-biased key, whereas higher doses of ethanol and phencyclidine produced responding only on this key less often. d-Amphetamine produced responding primarily on the saline-biased key. When drugs generalized to pentobarbital, the shape of the generalization curve under concurrent VR VR schedules was more often graded than quantal in shape. Thus, drug discrimination can be established under concurrent VR VR schedules, but the shapes of drug-discrimination dose-response curves under concurrent VR VR schedules more closely resemble those seen under interval schedules than those seen under fixed-ratio schedules. Graded dose-response curves under concurrent VR VR schedules may relate to probability matching and difficulty in discriminating differences in reinforcement frequency.","Concurrent fixed-ratio schedules; Concurrent variable-ratio schedules; Dose-response curves; Drug discrimination; Key peck; Pentobarbital; Pigeons","alcohol; chlordiazepoxide; dexamphetamine; pentobarbital; phencyclidine; animal; article; comparative study; discrimination learning; dose response; drug effect; male; motivation; pigeons and doves; psychomotor performance; reinforcement; Animals; Chlordiazepoxide; Columbidae; Dextroamphetamine; Discrimination Learning; Dose-Response Relationship, Drug; Ethanol; Male; Motivation; Pentobarbital; Phencyclidine; Psychomotor Performance; Reinforcement Schedule",Article,"Final","",Scopus,2-s2.0-0036365362
"Torkington J., Smith S.G.T., Rees B.I., Darzi A.","7004517964;14634905700;7006116871;14633357600;","Skill transfer from virtual reality to a real laparoscopic task",2001,"Surgical Endoscopy","15","10",,"1076","1079",,193,"10.1007/s004640000233","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034805147&doi=10.1007%2fs004640000233&partnerID=40&md5=42023582e9d70586d22bd59c50a6b290","Academic Surgical Unit, Imperial College School of Medicine, St Mary's Hospital, London, W2 1NY, United Kingdom; Welsh Institute for Minimal Access Therapy, Medicentre, University Hospital of Wales, Cardiff CF14 4XW, United States","Torkington, J., Academic Surgical Unit, Imperial College School of Medicine, St Mary's Hospital, London, W2 1NY, United Kingdom; Smith, S.G.T., Academic Surgical Unit, Imperial College School of Medicine, St Mary's Hospital, London, W2 1NY, United Kingdom; Rees, B.I., Welsh Institute for Minimal Access Therapy, Medicentre, University Hospital of Wales, Cardiff CF14 4XW, United States; Darzi, A., Academic Surgical Unit, Imperial College School of Medicine, St Mary's Hospital, London, W2 1NY, United Kingdom","Background: To validate the usefulness of virtual reality surgical simulators, we investigated the transfer of skills achieved by their use to real tasks. Methods: Thirty medical students underwent a pretest using a real laparoscopic trainer. They were then randomized to the following three groups: group I received no training; group II received training using the Minimal Invasive Surgical Trainer in Virtual Reality (MIST-VR); and group III received training using conventional training exercises. Each group then underwent a posttest. Using the Imperial College Surgical Assessment Device (ICSAD), scores were generated for time taken, distance traveled, number of movements made, and speed of instrument movement. Results: Significant changes between the MIST-VR group (group II) and the conventionally trained group (group III), were observed in the speed of movement of the left hand and the numbers of movements taken by each hand, when compared to the untrained group (group I). Conclusion: The training of novices using MIST-VR yields quantifiable changes in skill that are transferable to a simple real task and are similar to the results achieved with conventional training.","Laparoscopy; MIST-VR; Skill transfer; Training; Virtual reality","article; clinical trial; computer simulation; controlled clinical trial; controlled study; education program; human; laparoscopic surgery; priority journal; randomized controlled trial; skill; surgeon; surgical training; task performance; training; virtual reality; Clinical Competence; Computer Simulation; Educational Technology; Humans; Laparoscopy; Surgery; Surgical Procedures, Minimally Invasive",Article,"Final","",Scopus,2-s2.0-0034805147
"Torkington J., Smith S.G.T., Rees B., Darzi A.","7004517964;14634905700;7006116871;14633357600;","The role of the Basic Surgical Skills course in the acquisition and retention of laparoscopic skill",2001,"Surgical Endoscopy","15","10",,"1071","1075",,81,"10.1007/s004640000183","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034810671&doi=10.1007%2fs004640000183&partnerID=40&md5=a22b0fc6496aa5a3841923830acdf9cf","Academic Surgical Unit, Imperial College School of Medicine, St. Mary's Hospital, London W2 1NY, United Kingdom; Welsh Institute for Minimal Access Therapy, Medicentre, University Hospital of Wales, Cardiff CF14 4XW, United Kingdom","Torkington, J., Academic Surgical Unit, Imperial College School of Medicine, St. Mary's Hospital, London W2 1NY, United Kingdom; Smith, S.G.T., Academic Surgical Unit, Imperial College School of Medicine, St. Mary's Hospital, London W2 1NY, United Kingdom; Rees, B., Welsh Institute for Minimal Access Therapy, Medicentre, University Hospital of Wales, Cardiff CF14 4XW, United Kingdom; Darzi, A., Academic Surgical Unit, Imperial College School of Medicine, St. Mary's Hospital, London W2 1NY, United Kingdom","Background: This study assesses the transfer of laparoscopic skills to a group of Basic Surgical Trainees (BST) attending the Basic Surgical Skills (BSS) course. Methods: The virtual reality simulator MIST-VR was used to assess 13 trainees before and after the course and again 3 weeks and 3 months later. Analysis of kinematic data using the Imperial College Surgical Assessment Device gave measures of distance traveled, distance efficiency ratio, time taken, number of errors made, and number of movements made in completing a virtual laparoscopic task. The performance of the group was compared to a control group who underwent no training. Results: All parameters improved significantly after the course, with the exception of distance traveled by the instruments. All outcome measures were significantly improved at 3 weeks. The control group showed a nonsignificant trend toward improvement in all parameters. Conclusions: The Basic Surgical Skills course produces quantifiable improvements in laparoscopic skill that are measurable by MIST-VR. There is a learning effect associated with using MIST-VR alone.","Assessment; Laparoscopy; MIST-VR; Surgical skills; Training; Virtual reality","article; computer simulation; controlled study; education program; human; laparoscopic surgery; priority journal; skill; surgeon; surgical training; task performance; training; virtual reality; Case-Control Studies; Clinical Competence; Computer Simulation; Educational Technology; Humans; Laparoscopy; Surgery; Surgical Procedures, Minimally Invasive; Teaching",Article,"Final","",Scopus,2-s2.0-0034810671
"Patterson P.E.","7201502940;","Employing 3D virtual reality games to develop ANN for device control: A pilot study",2001,"Biomedical Sciences Instrumentation","37",,,"475","478",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035031919&partnerID=40&md5=acec96bb583f7f78bff483b0e855f6ff","College of Engineering, Iowa State University, Ames, IA 50011, United States","Patterson, P.E., College of Engineering, Iowa State University, Ames, IA 50011, United States","Non-immersive virtual reality (VR) game scenarios were developed to aid in the collection of EMG parameters from the biceps and triceps while subjects performed a sequenced series of tasks in the virtual environment. For each subject the best ANN configuration (combination of hidden layers and transfer functions) was chosen, with the resulting optimized algorithms used to classify the sequence of contractions and the function type of the subjects while playing new game scenarios. The wide variety of individually configured ANN developed show why it is difficult to train new users of myoelectric devices with a single algorithm. The use of VR-based games shows promise as a training technique for individuals needing to develop control for prosthetic limbs.","Myoelectric signal; Pattern recognition; Prosthetic control","Algorithms; Biomechanics; Computer simulation; Electromyography; Muscle; Neural networks; Virtual reality; Non immersive virtual reality; Myoelectrically controlled prosthetics; adult; algorithm; artificial neural network; conference paper; device; electromyogram; game; human; human experiment; male; pattern recognition; virtual reality; Adult; Artificial Limbs; Electromyography; Games, Experimental; Humans; Male; Muscle Contraction; Muscle, Skeletal; Neural Networks (Computer); Patient Education; Pilot Projects; User-Computer Interface",Conference Paper,"Final","",Scopus,2-s2.0-0035031919
"Kaiser S., Toborek M.","7103104994;7006770411;","Liposome-mediated high-efficiency transfection of human endothelial cells",2001,"Journal of Vascular Research","38","2",,"133","143",,45,"10.1159/000051040","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035057973&doi=10.1159%2f000051040&partnerID=40&md5=9cadae2a37b273d2bc2d4295dd226937","University of Potsdam, Potsdam, Germany; Department of Surgery, University of Kentucky, Lexington, KY, United States; Department of Surgery, Division of Neurosurgery, University of Kentucky Medical Center, 800 Rose Street, Lexington, KY 40536, United States","Kaiser, S., University of Potsdam, Potsdam, Germany, Department of Surgery, University of Kentucky, Lexington, KY, United States; Toborek, M., Department of Surgery, University of Kentucky, Lexington, KY, United States, Department of Surgery, Division of Neurosurgery, University of Kentucky Medical Center, 800 Rose Street, Lexington, KY 40536, United States","Liposome-mediated transfection of endothelial cells provides a valuable experimental technique to study cellular gene expression and may also be adapted for gene therapy studies. However, the widely recognized disadvantage of liposome-mediated transfection is low efficiency. Therefore, studies were performed to optimize transfection techniques in human endothelial cells. The majority of the experiments were performed with primary cultures of human umbilical vein endothelial cells (HUVEC). In addition, selected experiments were performed using human brain microvascular endothelial cells and human dermal microvascular endothelial cells. To study transfection rates, HUVEC were transfected with the pGL3 vector, containing the luciferase reporter gene, complexed with several currently available liposomes, such as different Perfect Lipid (pFx) mixtures, DMRIE-C, or lipofectin. The optimal transfection rate was achieved in HUVEC transfected for 1.5 h with 5 μg/ml of DNA plasmid in the presence of 36 μg/ml of pFx-7. In addition, transfection with the VR-3301 vector encoding for human placental alkaline phosphatase revealed that, under the described conditions, transfection efficiency in HUVEC was approximately 32%. Transfections mediated by other liposomes were less efficient. The usefulness of the optimized transfection technique was confirmed in HUVEC transfected with NF-κB or AP-1-responsive constructs and stimulated with TNF or LPS. We conclude that among several currently available liposomes, pFx-7 appears to be the most suitable for transfections of cultured human endothelial cells. Copyright © 2001 S. Karger AG, Basel.","Cell culture; Gene transfer; Vasculature","immunoglobulin enhancer binding protein; liposome; transcription factor AP 1; article; cell culture; endothelium cell; gene expression; gene therapy; gene transfer; genetic transfection; human; human cell; priority journal; Alkaline Phosphatase; Cell Line, Transformed; Endothelium, Vascular; Humans; Lipids; Liposomes; Luciferases; NF-kappa B; Phosphatidylethanolamines; Plasmids; Promoter Regions (Genetics); Quaternary Ammonium Compounds; Transcription Factor AP-1; Transfection; Umbilical Veins",Article,"Final","",Scopus,2-s2.0-0035057973
"Tay F.E.H., Ming C.","55663595800;36928047000;","A shared multi-media design environment for concurrent engineering over the internet",2001,"Concurrent Engineering Research and Applications","9","1",,"55","63",,15,"10.1106/DYCB-CKXW-VN6L-6KET","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035266532&doi=10.1106%2fDYCB-CKXW-VN6L-6KET&partnerID=40&md5=43f295598f4baa3afbeb4c302e16a852","Department of Mechanical Engineering, National University of Singapore, 10 Kent Ridge Crescent, Singapore 119260, Singapore","Tay, F.E.H., Department of Mechanical Engineering, National University of Singapore, 10 Kent Ridge Crescent, Singapore 119260, Singapore; Ming, C., Department of Mechanical Engineering, National University of Singapore, 10 Kent Ridge Crescent, Singapore 119260, Singapore","The Internet is currently an important resource for businesses to conduct activities ranging from basic communication to data exchange. In addition, the Internet is fast becoming an important portal for concurrent engineering applications. The Virtual Design Studio (VDS) presented in this paper is to construct a virtual design environment over the Internet in order to overcome geographical constraints, and satisfy the major issues of concurrent engineering. Traditional design activities have been studied and implemented in the VDS to enable effective and efficient collaborative design. In addition, the proposed virtual design environment also supports both the product design and distributed communication tools used by designers. The aim of VDS is to integrate the existing information technologies (such as remote file transfer, multimedia and virtual reality among others) into the design process and to explore the possibility of extending collaborative design system over the Internet. This infrastructure will enable the establishment of distributed design offices in a global environment by means of the Internet. As such, collaborative design resources can be made readily available to industries, research institutions and educational institutions. CyberCAD is the application developed to support the realization of VDS. Remote file transfer and platform independence have been implemented in CyberCAD to enable the sharing of resources. CyberCAD provides a powerful collaborative CAD system running on a PC based platform. A multimedia communication enabled CAD conference module has been integrated into CyberCAD. Video and audio communications provide the collaborative multimedia environment, which overcome the geographical limitation in traditional ""face to face"" collaboration and enhances interaction between designers. Drag and drop method has been adopted in the proposed CAD conference module for remote design information sharing.","CAD conference; Collaborative Multimedia Environment; Synchronous and Asynchronous collaborative design; Virtual Design Studio","Computer aided design; Internet; Multimedia systems; Virtual reality; Virtual design studio (VDS); Concurrent engineering",Article,"Final","",Scopus,2-s2.0-0035266532
"Stedmon A.W., Stone R.J.","6507120158;7402456435;","Re-viewing reality: Human factors of synthetic training environments",2001,"International Journal of Human Computer Studies","55","4",,"675","698",,40,"10.1006/ijhc.2001.0498","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035497284&doi=10.1006%2fijhc.2001.0498&partnerID=40&md5=c830af567662fa8dc99db5ea3953cd89","HUSAT Research Institute, Loughborough University, Loughborough, LE11 1RG, United Kingdom; Virtual Presence Ltd, Chester House, 79 Dane Road, Sale M33 7BP, United Kingdom; Virutal Reality Appl. Res. Team, University of Nottingham, University Park, Nottingham NG7 2RD, United Kingdom","Stedmon, A.W., HUSAT Research Institute, Loughborough University, Loughborough, LE11 1RG, United Kingdom, Virutal Reality Appl. Res. Team, University of Nottingham, University Park, Nottingham NG7 2RD, United Kingdom; Stone, R.J., Virtual Presence Ltd, Chester House, 79 Dane Road, Sale M33 7BP, United Kingdom","Computer-based training (CBT) has become an important training tool and is used effectively in providing part-task activities. In the military domain virtual environments (VEs) have long been exploited, mainly through virtual reality (VR), to create realistic working environments. More recently, augmented reality (AR) and advanced embedded training (AET) concepts have also emerged and the development of ""AR-AET"" and ""VR-CBT"" concepts promise to become essential tools within military training. Whilst the advantages of both AR and VR are attractive, the challenges for delivering such applications are, generally, technology led. Equally as important, however, is the incorporation of human factors design and implementation techniques and this has been recognized by the development and publication of International Standard ISO 13407, Human-Centred Design Processes for Interactive Systems. Examples described in this paper serve to review Human Factors issues associated With the use of both AR and VR training systems. Whilst there are common issues between AR and VR applications in considering the potential of synthetic training environments, it is also necessary to address particular human-centred design issues within each application domain. © 2001 Academic Press.","Augmented reality; Computer based training; Human factors of synthetic training; Virtual environments; Virtual reality","Computer aided design; Personnel training; Technology transfer; Virtual reality; Computer-based training (CBT); Human engineering",Conference Paper,"Final","",Scopus,2-s2.0-0035497284
"Elkind J.S., Rubin E., Rosenthal S., Skoff B., Prather P.","6603963465;37093791700;57192665431;57192663131;7003715620;","A simulated reality scenario compared with the computerized Wisconsin Card Sorting Test: An analysis of preliminary results",2001,"Cyberpsychology and Behavior","4","4",,"489","496",,54,"10.1089/109493101750527042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034802753&doi=10.1089%2f109493101750527042&partnerID=40&md5=d44aeeb14865dd4bd8b67b6db86ae95b","Jewish Family and Children’s Service, Boston, MA, United States; Center for Counseling and Student Development, Northeastern University, Boston, MA, United States; Massachusetts School of Professional Psychology, West Roxbury, MA, United States; North Shore Children’s Hospital, Salem, MA, United States; Educational Enhancement Center, Department of Neurology and Neuropsychology, Boston University School of Medicine, Boston, MA, United States","Elkind, J.S., Jewish Family and Children’s Service, Boston, MA, United States; Rubin, E., Center for Counseling and Student Development, Northeastern University, Boston, MA, United States; Rosenthal, S., Massachusetts School of Professional Psychology, West Roxbury, MA, United States; Skoff, B., North Shore Children’s Hospital, Salem, MA, United States; Prather, P., Educational Enhancement Center, Department of Neurology and Neuropsychology, Boston University School of Medicine, Boston, MA, United States","Neuropsychologists and other clinicians often comment on the minimal relationship that frequently exists between formal assessments of executive functions, analysis of findings, recommendations, and the person’s real-life functioning. The authors’ believe that current assessments of executive functions do not transfer easily to real-world behavior. There are limitations in the current examinations and in the settings in which they are given. The tests are artificial and the test settings lack the usual stresses, distractions, and multiple demands common to real life. The interactions are unlike what they experience in everyday life. The examiner often, but unintentionally orients the participant to relevant information that in turn can help the person compensate for the difficulties with executive control processes and bias the findings. We believe that virtual reality (VR) more closely approximates real life settings, the distractions, and the common interchanges (VR) provides a ""life-like,"" three-dimensional (3-D) highly interactive environment, and safety from potential dangers that could arise in actual situations. VR can increase motivation because of its gaming, interactive, and immersive qualities and features are easily modified and allow for multiple applications. Our goal is to develop VR assessments that can be administered under controlled and safe conditions, but which are more sensitive to difficulties with executive control processes critical to safe, independent living. This initial study compares several functions assessed by the Wisconsin Card Sorting Test (WCST) with our three-dimensional, stereographic scenario, Look for a Match (LFAM) Study participants completed questionnaires, alternately began with either the WCST or LFAM, and then took the second test. All participants completed motion sickness and follow-up questionnaires. The results demonstrated that the study participants found LFAM to be more enjoyable and interesting, but found the WCST to be easier. While there is an effect of order with participants doing relatively better on the assessment tool administered second, overall the LFAM performance was inferior to that on the WCST. However, even considering the order effect, LFAM seemed to be more difficult than the WCST.",,"article; cognition; computer; experience; human; motion sickness; motivation; neuropsychological test; neuropsychology; psychologic assessment; questionnaire; safety; virtual reality; wisconsin card sorting test; Adolescent; Adult; Aged; Attitude to Computers; Computer Systems; Diagnosis, Computer-Assisted; Female; Humans; Imaging, Three-Dimensional; Male; Middle Aged; Neuropsychological Tests; Psychometrics; Reproducibility of Results; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-0034802753
"Frank A.O., Twombly I.A., Barth T.J., Smith J.D.","7401661096;6508302129;56232127500;56909047500;","Finite element methods for real-time haptic feedback of soft-tissue models in virtual reality simulators",2001,"Proceedings - Virtual Reality Annual International Symposium",,,,"257","263",,26,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035064610&partnerID=40&md5=16a8d20384aa3c0242662856bcfdf398","Center for Bioinformatics, NASA Ames Research Center, Moffet Field, CA 94035, United States","Frank, A.O., Center for Bioinformatics, NASA Ames Research Center, Moffet Field, CA 94035, United States; Twombly, I.A., Center for Bioinformatics, NASA Ames Research Center, Moffet Field, CA 94035, United States; Barth, T.J., Center for Bioinformatics, NASA Ames Research Center, Moffet Field, CA 94035, United States; Smith, J.D., Center for Bioinformatics, NASA Ames Research Center, Moffet Field, CA 94035, United States","We have applied the linear elastic finite element method to compute haptic force feedback and domain deformations of soft tissue models for use in virtual reality simulators. Our results show that, for virtual object models of high-resolution 3D data (> 10, 000 nodes), haptic real time computations (> 500 Hz) are not currently possible using traditional methods. Current research efforts are focused in the following areas: 1) efficient implementation of fully adaptive multi-resolution methods and 2) multi-resolution methods with specialized basis functions to capture the singularity at the haptic interface (point loading). To achieve real time computations, we propose parallel processing of a Jacobi preconditioned conjugate gradient method applied to a reduced system of equations resulting from surface domain decomposition. This can effectively be achieved using reconfigurable computing systems such as field programmable gate arrays (FPGA), thereby providing a flexible solution that allows for new FPGA implementations as improved algorithms become available. The resulting soft tissue simulation system would meet NASA Virtual Glovebox requirements and, at the same time, provide a generalized simulation engine for any immersive environment application, such as biomedical/surgical procedures or interactive scientific applications.",,"Algorithms; Computation theory; Computer simulation; Feedback; Field programmable gate arrays; Finite element method; Haptic interfaces; Parallel processing systems; Real time systems; Conjugate gradient methods; Soft-tissue models; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-0035064610
"Söderman M.","56439297700;","Product representations: Exploring computer-based technologies and customers' understanding of product concepts",2001,"Doktorsavhandlingar vid Chalmers Tekniska Hogskola",,"1771",,"1","65",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035196824&partnerID=40&md5=b561449350322748634ca69ec87ae84f","Dept. of Product and Production Dev., Division of Human Factors Eng., Chalmers University of Technology, Göteborg 2001, Sweden","Söderman, M., Dept. of Product and Production Dev., Division of Human Factors Eng., Chalmers University of Technology, Göteborg 2001, Sweden","A large proportion of new products does not succeed on the market. One explanation is that companies have misinterpreted, or not succeeded in identifying the needs and requirements of their customers. A focus on the customer, especially in the early stages in the product development, has been argued to improve product quality and customer satisfaction. A prerequisite of achieving knowledge about the customer is that developers and customers communicate on the basis of a shared understanding. For this purpose, product representations, e.g. sketches, mock-ups and virtual reality representations can function as communication tools. The demands for efficient product development have resulted in an interest in new computer-based technologies and arguments that virtual reality can replace costly physical prototypes. However, little is known about what customers understand of product concepts through different product representations. Thus, knowledge of product representations can be of importance to manage a product concept evaluation in an efficient way. This thesis has aimed at gaining knowledge for an efficient use of product representations in communication with customers. One question concerned the use of product representations in industry for communication with customers. The studies indicated that product representations were used between the developers for evaluations of technical matters and not used as tools in communication with customers. Moreover, virtual reality was widely considered as very effective for the understanding of product concepts, even though most companies had not used virtual reality in product development. Thus, the conception of virtual reality reflected high expectations rather than actual experiences. The main question in this research concerned computer-based technologies' and conventional product representations' effect on customers' understanding of product concepts. A series of exploratory studies revealed that an increasing degree of realism in the product representations was not always reflected in an increased understanding of the products. This implies that the information provided by a product representation was not necessarily the information required by the participants for enhanced understanding. Certain product aspects were more important than others for enhanced understanding, in this case, tactile interaction and scale. This thesis argues that customers' understanding of product concepts through product representations is determined by several interrelating factors and that the type of product representation is but one factor. Other important factors are the participants' product knowledge and the participants' product representation knowledge.","Customer communication; Product concepts; Product development; Product knowledge; Product representation knowledge; Product representations; Understanding","Computer aided engineering; Customer satisfaction; Marketing; Quality control; Technology transfer; Virtual reality; Customer communication; Product concepts; Product knowledge; Product representations; Product development",Article,"Final","",Scopus,2-s2.0-0035196824
"Picinbono Guillaume, Lombardo Jean-Christophe, Delingette Herve, Ayache Nicholas","6602940188;7007061465;7004183160;7006015230;","Anisotropic elasticity and force extrapolation to improve realism of surgery simulation",2000,"Proceedings - IEEE International Conference on Robotics and Automation","1",,,"596","602",,46,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033726619&partnerID=40&md5=b1b867e95c3fcc81db8f2a5c07f64851","I.N.R.I.A., Sophia-Antipolis, France","Picinbono, Guillaume, I.N.R.I.A., Sophia-Antipolis, France; Lombardo, Jean-Christophe, I.N.R.I.A., Sophia-Antipolis, France; Delingette, Herve, I.N.R.I.A., Sophia-Antipolis, France; Ayache, Nicholas, I.N.R.I.A., Sophia-Antipolis, France","In this paper, we describe the latest developments of the minimally invasive hepatic surgery simulator prototype developed at INRIA. The goal of this simulator is to provide a realistic training test-bed for performing laparoscopic procedures. Therefore, its main functionality is to simulate the deformation and cutting of tri-dimensional anatomical models with the help of two virtual laparoscopic surgical instruments. Throughout this paper, we present the general features of the simulator including the implementation of different bio-mechanical models based on linear elasticity and finite element theory and the integration of two force-feedback devices in the simulation platform. More precisely, we describe two new important developments that improve the overall realism of the simulator. First, we can create bio-mechanical models that include the notion of anisotropic deformation. Indeed, we have generalized the linear elastic behavior of anatomical models to 'transversally isotropic' materials, i.e. materials having one privileged direction of deformation. The second improvement is related to the problem of haptic rendering. Currently, we are able to achieve a simulation frequency of 25Hz (visual real-time) with anatomical models of complex geometry and behavior. But to achieve a good haptic feedback and behavior. But to achieve a good haptic feedback requires a frequency update of applied forces typically above 300Hz (haptic real-time). Thus, we propose a force extrapolation algorithm in order to reach haptic real-time.",,"Finite element theory; Force feedback devices; Invasive hepatic surgery simulator; Laparoscopic procedures; Linear elasticity; Tri dimensional anatomical models; Algorithms; Biomechanics; Extrapolation; Feedback; Finite element method; Surgery; Computer simulation",Conference Paper,"Final","",Scopus,2-s2.0-0033726619
"Gourlay D., Lun K.C., Lee Y.N., Tay J.","15739566700;7004523484;15739807900;57196704926;","Virtual reality for relearning daily living skills",2000,"International Journal of Medical Informatics","60","3",,"255","261",,42,"10.1016/S1386-5056(00)00100-3","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034532146&doi=10.1016%2fS1386-5056%2800%2900100-3&partnerID=40&md5=e662b908faaf96c9ec30e221d781378e","Medical Informatics Programme, Department of Community, Occupational and Family Medicine, National University of Singapore, Lower Kent Ridge Road, 119260 Singapore, Singapore","Gourlay, D., Medical Informatics Programme, Department of Community, Occupational and Family Medicine, National University of Singapore, Lower Kent Ridge Road, 119260 Singapore, Singapore; Lun, K.C., Medical Informatics Programme, Department of Community, Occupational and Family Medicine, National University of Singapore, Lower Kent Ridge Road, 119260 Singapore, Singapore; Lee, Y.N., Medical Informatics Programme, Department of Community, Occupational and Family Medicine, National University of Singapore, Lower Kent Ridge Road, 119260 Singapore, Singapore; Tay, J., Medical Informatics Programme, Department of Community, Occupational and Family Medicine, National University of Singapore, Lower Kent Ridge Road, 119260 Singapore, Singapore","The explosive increase in the power of computers has enabled the creation of fast, interactive 3D environments, sometimes called virtual reality (VR). This technology, often associated with arcade games, is increasingly being used for more serious applications. This paper describes research showing transfer of skills from a virtual environment to the real world. We then describe our VR authoring tool and an application to help cognitively impaired individuals relearn important daily living skills. Additionally we describe the development of a prototype networked system to enable a doctor to monitor remotely the rehabilitation of a group of patients. © 2000 Elsevier Science Ireland Ltd.",,"Computer applications; Health care; Patient monitoring; Patient rehabilitation; Telemedicine; Head mounted display; Traumatic brain injury; Virtual reality; cognitive defect; computer; daily life activity; human; learning; patient monitoring; physician attitude; priority journal; rehabilitation medicine; review; technology; virtual reality; Activities of Daily Living; Brain Injuries; Cerebrovascular Accident; Cognition Disorders; Humans; Learning; Therapy, Computer-Assisted",Article,"Final","",Scopus,2-s2.0-0034532146
"Peter J., Jaszczak R.J.","7202157073;7006434901;","©Monte Carlo simulation of radiological imaging systems and the recovery of the Poisson distribution",2000,"IEEE Nuclear Science Symposium and Medical Imaging Conference","3",,,"20/105","20/109",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034593869&partnerID=40&md5=f9369bf8fce5be205f0d73b60a060584","Duke University Medical Center, Durham, NC, United States","Peter, J., Duke University Medical Center, Durham, NC, United States; Jaszczak, R.J., Duke University Medical Center, Durham, NC, United States","The Monte Carlo (MC) method is impracticable for simulating the physical processes of particle transport in three-dimensional imaging systems without the use of variance reduction (VR) techniques. As a consequence of VR, not photon counts but weights are accumulated which do not generate a Poisson mixture. In this paper, we analyze MC simulated data regarding a) the type of distribution generated, b) the problem of Poisson mixture recovery, c) quantitative MC and d) a stopping criteria for MC simulations. In order to perform this investigation, a MC simulation program which includes photon-specific forced detection/interaction VR techniques is used. By computing generalized linear model estimates and moments of simulated distributions, we found that there exists a scaling factor which scales any uni-variate un-attenuated distribution into a corresponding Poisson distribution. If attenuation is present, we extend the simulated exponential mixture by an un-attenuated population and use the moments of this reference sample to calculate a scaling factor which recovers a complete finite Poisson mixture. The presented results could increase the potential applicability of MC simulations in nuclear medicine by performing quantitative simulations and by reducing computational load by a count-based stopping criteria. As a further result of this investigation, we confirmed that the error introduced by the included VR techniques is marginal for the simulated systems.",,"Calculations; Computer simulation; Error analysis; Imaging systems; Monte Carlo methods; Poisson distribution; Radiology; Poisson mixture recovery; Radiological imaging systems; Variance reduction techniques; Nuclear medicine",Conference Paper,"Final","",Scopus,2-s2.0-0034593869
"Lu T., Lee C., Hsia W., Lin M.","8985653300;7410149423;6701585386;26660011200;","Supporting Large-Scale Distributed Simulation Using HLA",2000,"ACM Transactions on Modeling and Computer Simulation","10","3",,"268","294",,28,"10.1145/361026.361034","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0344462458&doi=10.1145%2f361026.361034&partnerID=40&md5=b21c542f2ace050d09b97ce58d27655e","Inst. of Comp./Info. Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; Dept. of Mgmt. Information Systems, Chin Min College, Miaoli, Taiwan","Lu, T., Inst. of Comp./Info. Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; Lee, C., Inst. of Comp./Info. Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; Hsia, W., Inst. of Comp./Info. Engineering, National Sun Yat-Sen University, Kaohsiung, Taiwan; Lin, M., Dept. of Mgmt. Information Systems, Chin Min College, Miaoli, Taiwan","This article describes the design of a Web-based environment to support large-scale distributed simulation using Java and IEEE standard P1516 high level architecture (HLA) framework and rules. Based on the run-time infrastructure (RTI) services within the HLA and Java application programmer's interfaces (APIs) of the RTI, the proposed HLA-based environment provides an architectural foundation to enhance interactivity, portability, and interoperability for Web-based simulations. In addition, the proposed architectural design not only provides a client/server mechanism for simulation on the Web, but also supports a distributed federation execution over the network. A 3-level control mechanism (3LCM) was implemented to HLA-based middleware federateServer, in order to adaptively maintain information consistency and minimize message traffic for distributing information among client hosts and the federateServers. A dynamic filtering strategy (DFS), associated with the data distribution management (DDM) in the HLA RTI, is proposed to minimize false positive updates and enhance the filtering efficiency of subscription regions within an HLA federation. To verify the feasibility of this prototype, a distributed discrete event simulation application in Java was developed and performance of the proposed modeling design and Java RMI's distributed object model presented. From the experimental results, we show that the proposed environment based on HLA using 3LCM and DFS is workable and practical for supporting a large-scale distributed simulation.","Data distribution management (DDM); Distributed interactive simulation (DIS); High level architecture (HLA); Modeling and simulation; Networked virtual environment; Run-time infrastructure (RTI)","Computer simulation; Data transfer; Interfaces (computer); Java programming language; Middleware; World Wide Web; Data distribution management (DDM); Distributed interactive simulation (DIS); Run time infrastructure (RTI); Distributed computer systems",Article,"Final","",Scopus,2-s2.0-0344462458
"Rose F.D., Attree E.A., Brooks B.M., Parslow D.M., Penn P.R.","7102651672;6603053737;7201573008;6603112047;7004825531;","Training in virtual environments: Transfer to real world tasks and equivalence to real task training",2000,"Ergonomics","43","4",,"494","511",,208,"10.1080/001401300184378","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033998093&doi=10.1080%2f001401300184378&partnerID=40&md5=7384a9e1602bfb8d9eab17626a26382d","Department of Psychology, University of East London, Romford Road, London, E15 4LZ, United Kingdom","Rose, F.D., Department of Psychology, University of East London, Romford Road, London, E15 4LZ, United Kingdom; Attree, E.A., Department of Psychology, University of East London, Romford Road, London, E15 4LZ, United Kingdom; Brooks, B.M., Department of Psychology, University of East London, Romford Road, London, E15 4LZ, United Kingdom; Parslow, D.M., Department of Psychology, University of East London, Romford Road, London, E15 4LZ, United Kingdom; Penn, P.R., Department of Psychology, University of East London, Romford Road, London, E15 4LZ, United Kingdom","Virtual environments (VEs) are extensively used in training but there have been few rigorous scientific investigations of whether and how skills learned in a VE are transferred to the real world. This research aimed to measure and evaluate what is transferring from training a simple sensorimotor task in a VE to real world performance. In experiment 1, real world performances after virtual training, real training and no training were compared. Virtual and real training resulted in equivalent levels of post-training performance, both of which significantly exceeded task performance without training. Experiments 2 and 3 investigated whether virtual and real trained real world performances differed in their susceptibility to cognitive and motor interfering tasks (experiment 2) and in terms of spare attentional capacity to respond to stimuli and instructions which were not directly related to the task (experiment 3). The only significant difference found was that real task performance after training in a VE was less affected by concurrently performed interference tasks than was real task performance after training on the real task. This finding is discussed in terms of the cognitive load characteristics of virtual training. Virtual training therefore resulted in equivalent or even better real world performance than real training in this simple sensorimotor task, but this finding may not apply to other training tasks. Future research should be directed towards establishing a comprehensive knowledge of what is being transferred to real world performance in other tasks currently being trained in VEs and investigating the equivalence of virtual and real trained performances in these situations. © 2000 Taylor & Francis Group, LLC.","Training; Transfer; Virtual reality","Computer aided instruction; Personnel training; Virtual reality; Sensorimotor task; Virtual training; Human computer interaction; adult; article; attention; cognition; female; human; human experiment; male; motor coordination; normal human; sensorimotor function; task performance; training; virtual reality",Article,"Final","",Scopus,2-s2.0-0033998093
"Torkington J., Smith S.G.T., Rees B.I., Darzi A.","7004517964;14634905700;7006116871;14633357600;","The role of simulation in surgical training",2000,"Annals of the Royal College of Surgeons of England","82","2",,"88","94",,117,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034053303&partnerID=40&md5=cceea2b22f0bdfde51cbf2e554b12c8f","Academic Surgical Unit, Imperial College School of Medicine, St Mary's Hospital, London, United Kingdom; Welsh Inst. for Minimal Access Ther., Medicentre, University Hospital of Wales, Cardiff, United Kingdom; Academic Surgical Unit, Imperial College School of Medicine, St Mary's Hospital, Paddington, London W2 1PG, United Kingdom","Torkington, J., Academic Surgical Unit, Imperial College School of Medicine, St Mary's Hospital, London, United Kingdom; Smith, S.G.T., Academic Surgical Unit, Imperial College School of Medicine, St Mary's Hospital, London, United Kingdom; Rees, B.I., Welsh Inst. for Minimal Access Ther., Medicentre, University Hospital of Wales, Cardiff, United Kingdom; Darzi, A., Academic Surgical Unit, Imperial College School of Medicine, St Mary's Hospital, London, United Kingdom, Academic Surgical Unit, Imperial College School of Medicine, St Mary's Hospital, Paddington, London W2 1PG, United Kingdom","Surgical training has undergone many changes in the last decade. One outcome of these changes is the interest that has been generated in the possibility of training surgical skills outside the operating theatre. Simulation of surgical procedures and human tissue, if perfect, would allow complete transfer of techniques learnt in a skills laboratory directly to the operating theatre. Several techniques of simulation are available including artificial tissues, animal models and virtual reality computer simulation. Each is discussed in this article and their advantages and disadvantages considered.","Simulation; Surgical training; Virtual reality","article; computer simulation; human; surgical training; virtual reality; Computer Simulation; Disease Models, Animal; Education, Medical, Graduate; Educational Technology; Humans; Models, Biological; Surgery",Article,"Final","",Scopus,2-s2.0-0034053303
"Diplas C.N., Pintelas P.E.","25030106400;6701867219;","Design of interactivity in virtual reality applications with emphasis on educational software using formal interaction specification",2000,"Education and Information Technologies","5","4",,"291","304",,2,"10.1023/A:1012053507785","https://www.scopus.com/inward/record.uri?eid=2-s2.0-52849109877&doi=10.1023%2fA%3a1012053507785&partnerID=40&md5=f73eb5a3356b480b7ffee8d7ace4d11a","Educational Software Development Laboratory, Department of Mathematics, University of Patra, Greece; ESDLab., University of Patra, P.O. BOX 1399, 265 00, Patra, Greece","Diplas, C.N., Educational Software Development Laboratory, Department of Mathematics, University of Patra, Greece, ESDLab., University of Patra, P.O. BOX 1399, 265 00, Patra, Greece; Pintelas, P.E., Educational Software Development Laboratory, Department of Mathematics, University of Patra, Greece","Virtual Reality (VR) technology has already entered into the area of the educational software and delivers systems where the trainees can use interactive virtual microworlds and benefit by transfer of experience, interacting directly with the learning domain. This paper describes the Virtual Multi Flow Graph (Virtual-MFG) graphical formal model and the Interaction Specification Workspace (ISW) software architecture for the interaction specification and design of VR applications with emphasis on educational software. The interaction designer specifies the interaction issues of the final system formally, using the tools of ISW The virtual microworld's objects database is updated with these interaction specifications which include both the virtual objects' dynamic properties and their tutoring capabilities. The model is validated by applying it on an existing VR educational software (EIKON). The Virtual-MFG graphs specifying a learning scenario of EIKON along with the application of ISW on EIKON are also presented. © 2000 Kluwer Academic Publishers.","Educational software; Formal specification; Interaction design; Interaction specification; Virtual reality",,Article,"Final","",Scopus,2-s2.0-52849109877
"Gallagher A.G., Hughes C., Reinhardt-Rutland A.H., McGuigan J., McClure N.","7101915089;57213008370;7006546647;57197429836;7005748030;","A case-control comparison of traditional and virtual-reality training in laparoscopic psychomotor performance",2000,"Minimally Invasive Therapy and Allied Technologies","9","5",,"347","352",,14,"10.3109/13645700009061457","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034532102&doi=10.3109%2f13645700009061457&partnerID=40&md5=587365ac79621c5f836362432ca4261e","School of Psychology, Queen's University of Belfast, Belfast BT7 1NN, United Kingdom","Gallagher, A.G., School of Psychology, Queen's University of Belfast, Belfast BT7 1NN, United Kingdom; Hughes, C., School of Psychology, Queen's University of Belfast, Belfast BT7 1NN, United Kingdom; Reinhardt-Rutland, A.H., School of Psychology, Queen's University of Belfast, Belfast BT7 1NN, United Kingdom; McGuigan, J., School of Psychology, Queen's University of Belfast, Belfast BT7 1NN, United Kingdom; McClure, N., School of Psychology, Queen's University of Belfast, Belfast BT7 1NN, United Kingdom","Learning hand-eye coordination is a crucial part of the training programme for junior laparoscopic surgeons. This study compares laparoscopic psychomotor performance from traditional standard abdominal box-training and virtual-reality training. Twenty-four right-hand dominant subjects with no experience in laparoscopy were required to complete a novel laparoscopic task. Eight subjects completed all six tasks on the Minimally Invasive Surgical Trainer Virtual Reality (MIST VR) training program. Another 16 subjects were case-matched to these subjects for gender, sight-corrected status and age (± 2 years). Eight of these subjects spent the same amount of time as their yoked MIST VR counterpart training on a traditional laparoscopic cutting task. The other eight subjects, the control group, received no training. Individuals who trained on the MIST VR program made significantly more correct incisions than their case-matched counterparts in the standard trained group (p < 0.05) and control group (p < 0.0001) and were also significantly more likely to use both hands to perform the task (p < 0.02). Virtual reality appears to offer potential as a laparoscopic laboratory-training tool for the acquisition of psychomotor skills that transfer to novel laparoscopic tasks.","Fulcrum effect; Psychomotor; Virtual reality","adult; article; clinical practice; comparative study; controlled study; experience; eye hand coordination; female; human; human experiment; laparoscopy; male; normal human; priority journal; psychomotor performance; right hemisphere; skill; staff training; standardization; surgeon; task performance",Article,"Final","",Scopus,2-s2.0-0034532102
"Peng Q., Loftus M.","7202851741;7004153143;","An image-based fast three-dimensional modelling method for virtual manufacturing",2000,"Proceedings of the Institution of Mechanical Engineers, Part B: Journal of Engineering Manufacture","214","8",,"709","721",,3,"10.1243/0954405001518080","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033658899&doi=10.1243%2f0954405001518080&partnerID=40&md5=f97c6227ae3006045e2faaf561163b5a","Department of Mechanical and Industrial Engineering, University of Manitoba, Winnipeg, Man., Canada; School of Manufacturing and Mechanical Engineering, University of Birmingham, United Kingdom; Department of Mechanical and Industrial Engineering, University of Manitoba, Winnipeg, Man. R3T 5V6, Canada","Peng, Q., Department of Mechanical and Industrial Engineering, University of Manitoba, Winnipeg, Man., Canada, Department of Mechanical and Industrial Engineering, University of Manitoba, Winnipeg, Man. R3T 5V6, Canada; Loftus, M., School of Manufacturing and Mechanical Engineering, University of Birmingham, United Kingdom","This paper focuses on a quick way to extract geometric information from an object and transfer the information into a virtual reality (VR) system. Considering the problems associated with the construction of VR environments, different three-dimensional modelling methods are analysed in this paper, and the authors report an effective methodology to construct virtual manufacturing environments. A three-dimensional surface reconstruction system, based on image analysis, forms a new approach to data acquisition and promises to be a competitive technique for VR applications. This three-dimensional surface reconstruction system integrates the binocular stereo principle and the shape from shading technique. Experimental results are encouraging and the performance of the system has been evaluated by simulation procedures. © IMechE 2000.","CAD; Reverse engineering; Virtual manufacturing","Computational geometry; Computer aided design; Computer simulation; Data acquisition; Feature extraction; Image analysis; Image quality; Image reconstruction; Mathematical models; Reverse engineering; Virtual reality; Image-based fast three-dimensional modeling; Three-dimensional surface reconstruction systems; Virtual manufacturing; Computer integrated manufacturing",Article,"Final","",Scopus,2-s2.0-0033658899
"McGee J.S., Van Der Zaag C., Buckwalter J.G., Thiebaux M., Van Rooyen A., Neumann U., Sisemore D., Rizzo A.A.","7102023121;6507558646;7103071789;6701770846;6701803717;7103378063;55297389800;57189943380;","Issues for the assessment of visuospatial skills in older adults using virtual environment technology",2000,"Cyberpsychology and Behavior","3","3",,"469","482",,26,"10.1089/10949310050078931","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033922544&doi=10.1089%2f10949310050078931&partnerID=40&md5=1fcd853f3831221f78ca63d182897805","Andrus Gerontology Center, University of Southern California, Los Angeles, CA, United States; Integrated Media Systems Center, University of Southern California, Los Angeles, CA, United States; Information Sciences Institute, University of Southern California, Los Angeles, CA, United States; Grad. Sch. Psychol. Fuller Theol. S., Pasadena, CA, United States; Integrated Media Systems Center, University of Southern California, 3715 McClintock Avenue, Los Angeles, CA 90089-0191, United States","McGee, J.S., Andrus Gerontology Center, University of Southern California, Los Angeles, CA, United States, Grad. Sch. Psychol. Fuller Theol. S., Pasadena, CA, United States; Van Der Zaag, C., Andrus Gerontology Center, University of Southern California, Los Angeles, CA, United States; Buckwalter, J.G., Andrus Gerontology Center, University of Southern California, Los Angeles, CA, United States; Thiebaux, M., Information Sciences Institute, University of Southern California, Los Angeles, CA, United States; Van Rooyen, A., Grad. Sch. Psychol. Fuller Theol. S., Pasadena, CA, United States; Neumann, U., Integrated Media Systems Center, University of Southern California, Los Angeles, CA, United States; Sisemore, D., Andrus Gerontology Center, University of Southern California, Los Angeles, CA, United States; Rizzo, A.A., Andrus Gerontology Center, University of Southern California, Los Angeles, CA, United States, Integrated Media Systems Center, University of Southern California, Los Angeles, CA, United States, Integrated Media Systems Center, University of Southern California, 3715 McClintock Avenue, Los Angeles, CA 90089-0191, United States","Virtual Environment (VE) technology offers clinical assessment and rehabilitation options that are currently not available using traditional neuropsychological methods. Advancements in this type of immersive information technology could produce tools that enhance the scientific study of human cognitive/functional processes and improve our capacity to more accurately assess and treat impairments found in persons with central nervous system (CNS) dysfunction. Through the creation of dynamic three-dimensional (3D) stimulus environments, in which all behavioral responding can be recorded, VE technology offers the possibility to more sensitively address a range of age-related CNS disorders including Alzheimer's Disease, Vascular Dementia, Parkinson's Disease, and stroke. Advances in this area could impact quality of life issues for an increasingly aging world population. The VE Laboratory at the University of Southern California has developed a suite of ImmersaDesk-format, 3D projection-based VEs. These scenarios target assessment of visuospatial skills including visual field-specific reaction time, depth perception, 3D field dependency (virtual rod and frame test), static and dynamic manual target tracking in 3D space, and spatial rotation. The current project tested healthy older adults (ages of 65 and 92). Participants were administered a standard neuropsychological battery and a suite of VE-delivered visuospatial tasks. Issues addressed in this project include: the occurrence of VE-related side effects in healthy older adults; the relationship between performance on VE measures and standard neuropsychological tests; the assessment of gender specific performance differences; the relationship between immersive tendencies, presence ratings, and VE performance in older adults; learning and generalization; and VE visuospatial performance differences between younger and older participants. This article will address the motivation, rationale, and relevant issues for use of VEs with older adults. A description of our VE system/methodology in the context of a recent study targeting assessment and possible rehabilitation of visuospatial skills with this population will then be detailed.",,"Alzheimer disease; central nervous system; conference paper; depth perception; information; neuropsychological test; psychologic assessment; rating scale; reaction time; virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-0033922544
"Ziv A., Small S.D., Wolpe P.R.","7005936898;57190081306;7003284182;","Patient safety and simulation-based medical education",2000,"Medical Teacher","22","5",,"489","495",,169,"10.1080/01421590050110777","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033835606&doi=10.1080%2f01421590050110777&partnerID=40&md5=4a36829031915a6c4b6f8d7643516940","Center for Bioethics, University of Pennsylvania, 3401 Market Street, Philadelphia, PA 19104-3308, United States","Ziv, A., Center for Bioethics, University of Pennsylvania, 3401 Market Street, Philadelphia, PA 19104-3308, United States; Small, S.D., Center for Bioethics, University of Pennsylvania, 3401 Market Street, Philadelphia, PA 19104-3308, United States; Wolpe, P.R., Center for Bioethics, University of Pennsylvania, 3401 Market Street, Philadelphia, PA 19104-3308, United States","Continuous quality improvement is an accepted mandate in healthcare services. The delivery of the best, evidence-based quality of care ultimately depends on the competences of practitioners as well as the system that supports their work. Medical education has been increasingly called upon to insure providers possess the skills and understanding necessary to fulfill the quality mission. Patient safety has in the past five years rapidly risen to the top of the healthcare policy agenda, and been incorporated into quality initiatives. Demand for curricula in patient safety and transfer of safety lessons learned in other risky industries have created new responsibilities for medical educators. Simulation-based medical education will help fill these needs. Simulation offers ethical benefits, increased precision and relevance of training and competency assessment, and new methods of teaching error management and safety culture. Established and successful simulation methods such as standardized patients and task trainers are being joined by newer approaches enabled by improved technology.",,"accuracy; animal model; article; cadaver; competence; computer simulation; controlled study; curriculum; health care quality; human; job performance; medical education; methodology; patient care; responsibility; safety; simulation; skill; teaching; technology; training; virtual reality",Article,"Final","",Scopus,2-s2.0-0033835606
"Herzberg A., Kutten S.","7006812302;7004028111;","Early detection of message forwarding faults",2000,"SIAM Journal on Computing","30","4",,"1169","1196",,15,"10.1137/S0097539796312745","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034848036&doi=10.1137%2fS0097539796312745&partnerID=40&md5=29bdd730db6f42035784b62cffbbb077","IBM Haifa Reserach Lab., IBM, 2 Weizmann Street, Tel Aviv, 52960, Israel; Faculty of Industrial Engineering and Management, Technion, Haifa 32000, Israel","Herzberg, A., IBM Haifa Reserach Lab., IBM, 2 Weizmann Street, Tel Aviv, 52960, Israel; Kutten, S., Faculty of Industrial Engineering and Management, Technion, Haifa 32000, Israel","In most communication networks, pairs of processors communicate by sending messages over a path connecting them. We present communication-efficient protocols that quickly detect and locate any failure along the path. Whenever there is excessive delay in forwarding messages along the path, the protocols detect a failure (even when the delay is caused by maliciously programmed processors). The protocols ensure optimal time for either message delivery or failure detection. We observe that the actual delivery time δ of a message over a link is usually much smaller than the a priori known upper bound D on that delivery time. The main contribution of this paper is the way to model and take advantage of this observation. We introduce the notion of asynchronously early-terminating protocols, as well as protocols that are asynchronously early-terminating, i.e., time optimal in both worst case and typical cases. More precisely, we present a time complexity measure according to which one evaluates protocols both in terms of D and δ. We observe that asynchronously early termination is a form of competitiveness. The protocols presented here are asynchronously early terminating since they are time optimal both in terms of D and of δ. Previous communication-efficient solutions were slow in the case where δ ≪ D. We observe that this is the most typical case. It is suggested that the time complexity measure introduced, as well as the notion of asynchronously early-terminating, can be useful when evaluating protocols for other tasks in communication networks. The model introduced can be a useful step towards a formal analysis of real-time systems. Our protocols have O(n log n) worst-case communication complexity. We show that this is the best possible for protocols that send immediately any acknowledgment they ever send. Then we show an early-terminating protocol which uses timing and delay to reduce the communication complexity in the typical executions where the number of failures is small and δ ≪ D. In such executions, its message complexity is linear, as is the complexity of nonfault tolerant protocols. © 2000 Society for Industrial and Applied Mathematics.","Competitive algorithms; Distributed algorithms; Fault tolerance; Network protocols; Real time; Time adaptive","Algorithms; Asynchronous transfer mode; Boundary conditions; Computational complexity; Computer simulation; Data communication systems; Fault tolerant computer systems; Network protocols; Real time systems; Telecommunication links; Competitive algorithms; Distributed algorithms; Fault detection; Message forwarding; Time adaptive; Failure analysis",Article,"Final","",Scopus,2-s2.0-0034848036
"Yoneda M., Arai F., Fukuda T., Miyata K., Naito T.","7202342356;7102069340;36037263500;7201750472;36641561600;","VR training system with adaptive operational assistance considering straight-line transfer operation",1999,"Robot and Human Communication - Proceedings of the IEEE International Workshop",,,,"142","147",,1,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033487867&partnerID=40&md5=bfb8dbc69dfb62cccc284f0c6b8cdd44","Nagoya University, Dept. of Micro System Engineering, Furo-cho 1, Chikusa-ku, Nagoya 464-8603, Japan","Yoneda, M., Nagoya University, Dept. of Micro System Engineering, Furo-cho 1, Chikusa-ku, Nagoya 464-8603, Japan; Arai, F., Nagoya University, Dept. of Micro System Engineering, Furo-cho 1, Chikusa-ku, Nagoya 464-8603, Japan; Fukuda, T., Nagoya University, Dept. of Micro System Engineering, Furo-cho 1, Chikusa-ku, Nagoya 464-8603, Japan; Miyata, K., Nagoya University, Dept. of Micro System Engineering, Furo-cho 1, Chikusa-ku, Nagoya 464-8603, Japan; Naito, T., Nagoya University, Dept. of Micro System Engineering, Furo-cho 1, Chikusa-ku, Nagoya 464-8603, Japan","This paper deals with an operational assistance system of a rough terrain crane. A proper control rule to operate the payload in the straight-line motion is proposed. The system assists straight-line operation with force display based on the rule. The strength of assistance can be adapted to operator's skill level by changing the gain of force display. We present some experiments on a crane simulator, and show the effectiveness of the proposed operational assistance system.",,"Adaptive systems; Artificial intelligence; Control system analysis; Cranes; Display devices; Motion control; Simulators; Straight-line transfer operation; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-0033487867
"Jayaram Sankar, Wang Yong, Jayaram Uma, Lyons Kevin, Hart Peter","7006370060;56790199700;6603551395;7102474056;57214383101;","Virtual assembly design environment",1999,"Proceedings - Virtual Reality Annual International Symposium",,,,"172","179",,47,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032651028&partnerID=40&md5=6d316de6778c5067cc7947b3e7ee0ebc","Washington State Univ, Pullman, United States","Jayaram, Sankar, Washington State Univ, Pullman, United States; Wang, Yong, Washington State Univ, Pullman, United States; Jayaram, Uma, Washington State Univ, Pullman, United States; Lyons, Kevin, Washington State Univ, Pullman, United States; Hart, Peter, Washington State Univ, Pullman, United States","The Virtual Assembly Design Environment (VADE) is a Virtual Reality (VR) based engineering application which allows engineers to evaluate, analyze, and plan the assembly of mechanical systems. This system focuses on utilizing an immersive virtual environment tightly coupled with commercial Computer Aided Design (CAD) systems. Salient features of VADE include: 1) data integration (two-way) with a parametric CAD system, 2) realistic interaction of user with parts in the virtual environment, 3) creation of valued design information in the virtual environment, 4) reverse data transfer of design information back to the CAD system, 5) significant interactivity in the virtual environment, 6) collision detection, and 7) physically-based modeling. This paper describes the functionality and applications of VADE. A discussion of the limitations of virtual assembly and a comparison with automated assembly planning systems are presented. Experiments conducted using real-world engineering models are also described.",,"Assembly; Computer aided design; Data transfer; Planning; Collision detection; Virtual assembly design environment; Virtual reality",Article,"Final","",Scopus,2-s2.0-0032651028
"Prystowsky J.B., Regehr G., Rogers D.A., Loan J.P., Hiemenz L.L., Smith K.M.","7005084385;7006675108;57220661069;6602280109;6507805417;55704544900;","A virtual reality module for intravenous catheter placement",1999,"American Journal of Surgery","177","2",,"171","175",,72,"10.1016/S0002-9610(98)00328-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033043026&doi=10.1016%2fS0002-9610%2898%2900328-6&partnerID=40&md5=0512ce891941565460d914f62890d99a","Department of Surgery, NW. University Medical School, Chicago, IL, United States; Department of Surgery, University of Toronto Medical School, Toronto, Ont., Canada; Department of Surgery, Medical College of Georgia, Augusta, GA, United States; MusculoGraphics, Inc., Evanston, IL, United States","Prystowsky, J.B., Department of Surgery, NW. University Medical School, Chicago, IL, United States; Regehr, G., Department of Surgery, University of Toronto Medical School, Toronto, Ont., Canada; Rogers, D.A., Department of Surgery, Medical College of Georgia, Augusta, GA, United States; Loan, J.P., MusculoGraphics, Inc., Evanston, IL, United States; Hiemenz, L.L., MusculoGraphics, Inc., Evanston, IL, United States; Smith, K.M., MusculoGraphics, Inc., Evanston, IL, United States","BACKGROUND: Virtual reality (VR) is a potential tool for technical skills training. We tested the validity and instructional effectiveness of a prototype VR module for learning intravenous (IV) catheter placement. METHODS: First-year medical students (n = 37), third-year medical students (n = 14), and surgical residents (n = 9) attempted two pretest IVs into each other, used the VR module for 12 minutes, and subsequently attempted two posttest IVs. Success or failure were recorded for each attempt. For each successful attempt, time and global rating of IV insertion were also recorded. RESULTS: The pretest success rate was significantly different between groups (chi square = 28.71, P &lt;0.01). VR success rate was not significantly different between groups (F2,57 = 1.47, ns). Although there was improvement in all groups during VR training (F2,114 = 44.16, P &lt;0.01), this did not result in improvement in posttest performance. CONCLUSIONS: Significant differences between groups were observed in performance of IV insertion in physical reality. However, no significant difference was observed in performance in VR. Thus, performance in VR demonstrated neither construct nor concurrent validity. While performance improved in VR, transfer of skill from VR to physical reality was not observed. Additional development and testing of VR as a training tool is warranted before its widespread use can be recommended.",,"article; clinical practice; health care personnel; intravenous catheter; medical student; priority journal; surgical training; virtual reality",Article,"Final","",Scopus,2-s2.0-0033043026
"Arthur J.G., McCarthy A.D., Baber C., Harley P.J.","8265762500;12786131300;7003871960;7003394941;","Virtual risks: Rich domain risk and technology transfer failure as design criteria in the sheffield knee arthroscopy trainer (SKATS)",1999,"Virtual Reality","4","3",,"192","202",,,"10.1007/BF01418155","https://www.scopus.com/inward/record.uri?eid=2-s2.0-53149123618&doi=10.1007%2fBF01418155&partnerID=40&md5=5352179f2801aeedaaa7533c9cc5ae8c","Risk Initiative Department: of Stats, University of Warwick, Coventry, United Kingdom; Department of Medical Physics and Clinical Engineering, University of Sheffield, Sheffield, United Kingdom; University of Birmingham, Sensory Neuroscience Group, Birmingham, United Kingdom; School of Mathematics and Statistics, University of Sheffield, Sheffield, United Kingdom; University of Warwick Risk Initiative, Department of Stats, Warwick University, Coventry CV4 7AL, United Kingdom","Arthur, J.G., Risk Initiative Department: of Stats, University of Warwick, Coventry, United Kingdom, University of Warwick Risk Initiative, Department of Stats, Warwick University, Coventry CV4 7AL, United Kingdom; McCarthy, A.D., Department of Medical Physics and Clinical Engineering, University of Sheffield, Sheffield, United Kingdom; Baber, C., University of Birmingham, Sensory Neuroscience Group, Birmingham, United Kingdom; Harley, P.J., School of Mathematics and Statistics, University of Sheffield, Sheffield, United Kingdom","In this paper an example of Virtual Reality (VR) system design in a safety-critical training domain is discussed, in particular, a model for design is presented. This model seeks to create operational definitions of risk in the surgical domain. Perhaps more importantly, it also seeks to discover operational predictors of the risk of technology-transfer failure as a fundamental requisite for the early design. Typically both of these activities do take place in some form in most designs, but they are frequently ill-conceived due to inappropriate timing, low importance, insufficient methodological rigour and the absence of a pre-existent integration model. Using examples from the Sheffield Knee Arthroscopy Training System (SKATS), we will discuss the contention that equal research effort needs to be spent on core design issues as on the technological VR design. Specifically, we will propose a set of guidelines for the research and development of risk metrics in Virtual Environment (VE) design and technology-transfer for safety-critical training. © Springer-Verlag London Ltd.","Design; Risk; Simulation; Surgical training; Technology-transfer; Virtual reality",,Article,"Final","",Scopus,2-s2.0-53149123618
"Mills S., Madalena T De Araújo M.","57214023510;6503887125;","Learning through virtual reality: A preliminary investigation",1999,"Interacting with Computers","11","4",,"453","462",,16,"10.1016/S0953-5438(98)00061-7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0345580807&doi=10.1016%2fS0953-5438%2898%2900061-7&partnerID=40&md5=52c069dbb6b92b0474cbdbeceeada817","Department of IT, Cheltenham Gloucester CHE, Pk., P., Cheltenham, United Kingdom; Dept. de Sist. e Produccao, Univ. Do Minho, Azurém, 4800, Guimarães, Portugal","Mills, S., Department of IT, Cheltenham Gloucester CHE, Pk., P., Cheltenham, United Kingdom; Madalena T De Araújo, M., Dept. de Sist. e Produccao, Univ. Do Minho, Azurém, 4800, Guimarães, Portugal","Our understanding of learning through the use of Virtual Reality (VR) is still in its infancy but a small core of work is emerging that is of growing importance. The literature is utilized to derive three design principles that are pertinent to VR systems used for learning. These principles form the basis for the design of a small VR world which was used for teaching a management technique to students in Higher Education (HE). Thus, this project naturally divided into two stages: first, software was developed for Portuguese HE students to learn the basic concept of apportioning resources subject to constraints, while Stage 2 comprised a formative experiment to test for differences in the learning of the technique. The conclusion was that overall the traditionally taught group faired better, but not statistically significantly better, than the software based group. Issues of enjoyment and learning were also raised. More studies are needed before any generalities can be drawn.",,"Computer aided instruction; Computer systems programming; Software engineering; Teaching; Apportioning resources concept; Virtual reality",Article,"Final","",Scopus,2-s2.0-0345580807
"Riva G., Rizzo A., Alpini D., Attree E.A., Barbieri E., Bertella L., Buckwalter J.G., Davies R.C., Gamberini L., Johansson G., Katz N., Marchi S., Mendozzi L., Molinari E., Pugnetti L., Rose F.D., Weiss P.L.","56962750600;57189943380;7003946189;6603053737;56649962700;6602670210;7103071789;57213467582;6603650210;57200771908;7202995938;57196855203;6603592012;7102949553;6701836144;7102651672;55435137100;","Virtual environments in the diagnosis, prevention, and intervention of age-related diseases: A review of VR scenarios proposed in the EC VETERAN project",1999,"Cyberpsychology and Behavior","2","6",,"577","591",,22,"10.1089/cpb.1999.2.577","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0033393299&doi=10.1089%2fcpb.1999.2.577&partnerID=40&md5=06f09ec1cf6d9d60468c24a6f5c6d7a9","Appl. Technol. Neuro-Psychol. Lab., Instituto Auxologico Italiano, Verbania, Italy; Dipartimento di Psicologia, Univ. Cattol. del Sacro Cuore, Milan, Italy; IMSC, School of Gerontology, University of Southern California, Los Angeles, CA, United States; Scientific Institute, S. Maria Nascente, Don Gnocchi Foundation, Milan, Italy; Department of Psychology, University of East London, London, United Kingdom; Lab. Sperim. di Ric. Psicologiche, Istituto Auxologico Italiano, Milan, Italy; Division of Ergonomics, Department of Design Sciences, Lund University, Sweden; Dipartimento di Psicologia Generale, Univ. degli Studi di Padova, Padova, Italy; Hadassah Hospital, Hebrew University, School of Occupational Therapy, Israel; Intgd. Media Syst. Ctr. Sch. G., University of Southern California, MC-0191, 3715 McClintock Avenue, Los Angeles, CA 90089-0191, United States","Riva, G., Appl. Technol. Neuro-Psychol. Lab., Instituto Auxologico Italiano, Verbania, Italy, Dipartimento di Psicologia, Univ. Cattol. del Sacro Cuore, Milan, Italy; Rizzo, A., IMSC, School of Gerontology, University of Southern California, Los Angeles, CA, United States, Intgd. Media Syst. Ctr. Sch. G., University of Southern California, MC-0191, 3715 McClintock Avenue, Los Angeles, CA 90089-0191, United States; Alpini, D., Scientific Institute, S. Maria Nascente, Don Gnocchi Foundation, Milan, Italy; Attree, E.A., Department of Psychology, University of East London, London, United Kingdom; Barbieri, E., Scientific Institute, S. Maria Nascente, Don Gnocchi Foundation, Milan, Italy; Bertella, L., Lab. Sperim. di Ric. Psicologiche, Istituto Auxologico Italiano, Milan, Italy; Buckwalter, J.G., IMSC, School of Gerontology, University of Southern California, Los Angeles, CA, United States; Davies, R.C., IMSC, School of Gerontology, University of Southern California, Los Angeles, CA, United States; Gamberini, L., IMSC, School of Gerontology, University of Southern California, Los Angeles, CA, United States; Johansson, G., Division of Ergonomics, Department of Design Sciences, Lund University, Sweden; Katz, N., Hadassah Hospital, Hebrew University, School of Occupational Therapy, Israel; Marchi, S., Lab. Sperim. di Ric. Psicologiche, Istituto Auxologico Italiano, Milan, Italy; Mendozzi, L., Scientific Institute, S. Maria Nascente, Don Gnocchi Foundation, Milan, Italy; Molinari, E., Dipartimento di Psicologia, Univ. Cattol. del Sacro Cuore, Milan, Italy, Lab. Sperim. di Ric. Psicologiche, Istituto Auxologico Italiano, Milan, Italy, Division of Ergonomics, Department of Design Sciences, Lund University, Sweden, Dipartimento di Psicologia Generale, Univ. degli Studi di Padova, Padova, Italy; Pugnetti, L., Scientific Institute, S. Maria Nascente, Don Gnocchi Foundation, Milan, Italy; Rose, F.D., Department of Psychology, University of East London, London, United Kingdom; Weiss, P.L., Hadassah Hospital, Hebrew University, School of Occupational Therapy, Israel","A group of worldwide virtual reality and health-care researchers have decided to combine their efforts in a multidisciplinary project titled VETERAN - virtual environments in the diagnosis, prevention and intervention of age-related diseases. The main goal of the VETERAN project is the tuning and testing of different virtual environments, designed to address the cognitive/functional impairments that may occur due to the aging process and age-related disorders. In particular the developed modules will address the problems commonly found in the following pathologies that have a strong impact on the elderly health care policy: Alzheimer's disease and other senile dementias; stroke and unilateral spatial neglect; mobility-related accidents within specific environments (e.g., falls, shocks). The project will focus on research into clinical aspects of age-related diseases and disorders of high morbidity and specifically target goals of prevention, treatment, or delay in onset. Another goal of the VETERAN project is to define and develop new protocols and tools to be used for general rehabilitation purposes. These tools will aim to provide systematic restorative training within the context of functionally relevant, ecologically valid simulated environments. This approach is hoped to optimise the degree of transfer of training and/or generalisation of learning to the person's real world environment.",,"article; clinical protocol; clinical research; computer assisted diagnosis; computer assisted therapy; computer simulation; degenerative disease; evaluation; health care planning; health program; human; preventive health service; validation process; virtual reality",Article,"Final","",Scopus,2-s2.0-0033393299
"Xiao C.-G., De Groat W.C., Godec C.J., Dai C., Xiao Q.","56233492000;35478567000;7004337277;7202309570;21136715400;","'Skin-CNS-bladder' reflex pathway for micturition after spinal cord injury and its underlying mechanisms",1999,"Journal of Urology","162","3 I",,"936","942",,70,"10.1097/00005392-199909010-00094","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032881192&doi=10.1097%2f00005392-199909010-00094&partnerID=40&md5=ed3bf8dcb36ce556c97bce3338848786","Department of Urology, Long Island College Hospital, Brooklyn, NY 11203, United States","Xiao, C.-G., Department of Urology, Long Island College Hospital, Brooklyn, NY 11203, United States; De Groat, W.C.; Godec, C.J.; Dai, C.; Xiao, Q.","Purpose: A 'skin-CNS-bladder' reflex pathway for inducing micturition after spinal cord injury has been established in cat. This reflex pathway which is basically a somatic reflex arc with a modified efferent limb that passes somatic motor impulses to the bladder, has been designed to allow spinal cord injured patients to initiate voiding by scratching the skin. Materials and Methods: The skin-CNS-bladder reflex was established in the cat by intradural microanastomosis of the left L7 ventral root (VR) to the S1 VR while leaving the L7 dorsal root (DR) intact to conduct cutaneous afferent signals that can trigger the new micturition reflex arc. After allowing 11 weeks for axonal regeneration, urodynamic, pharmacological and electrophysiological studies were conducted in pentobarbital or chloralose anesthetized animals. Results: A detrusor contraction was initiated at short latency by scratching the skin or by percutaneous electrical stimulation in the L7 dermatome. Maximal bladder pressures during this stimulation were similar to those activated by bladder distension in control animals. Electrophysiological recording revealed that single stimuli (0.3 to 3 mA, 0.02 to 0.2 msec duration) to the left L7 spinal nerve in which the efferent axons had degenerated evoked action potentials (0.5 to 1 mV) in the left S1 spinal nerve distal to the anastomosis. In addition, increases in bladder pressure were elicited by trains of the stimuli (5 to 20 Hz, 5 seconds) applied to the L7 spinal nerve. Urodynamic studies including external sphincter EMG recording demonstrated that the new reflex pathway could initiate voiding without detrusor-external urethral sphincter dyssynergia. Atropine (0.05 mg./kg., i.v.) or trimethaphan (5 mg./kg., i.v.), a ganglionic blocking agent, depressed the bladder contractions elicited by skin stimulation. The skin-CNS-bladder reflex could also be elicited after transecting the spinal cord at the L2-L3 or L7-S1 levels. Conclusion: The cross-wired somato-autonomic bladder reflex is effective in initiating bladder contractions and coordinated voiding in cats with an intact neuraxis and can also induce bladder contractions after acute transection of the lumbar spinal cord. The new pathway is mediated by cholinergic transmission involving both nicotinic and muscarinic receptors. It is concluded that somatic motor axons can innervate bladder parasympathetic ganglion cells and thereby transfer somatic reflex activity to the bladder smooth muscle.","Neurogenic bladder; Reflex pathway; Reinnervation; Spinal cord injury","atropine; muscarinic receptor; nicotinic receptor; trimetaphan; animal experiment; article; bladder; bladder pressure; cat; central nervous system; cholinergic transmission; controlled study; detrusor muscle; electromyography; electrostimulation; evoked response; male; micturition reflex; nonhuman; parasympathetic ganglion; priority journal; scratching; skin; spinal cord injury; spinal nerve",Article,"Final","",Scopus,2-s2.0-0032881192
"Clawson Deborah M., Miller Michael S., Knott Benjamin A., Sebrechts Marc M.","7005106974;57199377170;57197573025;6701858562;","Navigational training in virtual and real buildings",1998,"Proceedings of the Human Factors and Ergonomics Society","2",,,"1427","1431",,5,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032283823&partnerID=40&md5=ac1720dd62e84d8b62717a0b2795e470","Catholic Univ of America, Washington, United States","Clawson, Deborah M., Catholic Univ of America, Washington, United States; Miller, Michael S., Catholic Univ of America, Washington, United States; Knott, Benjamin A., Catholic Univ of America, Washington, United States; Sebrechts, Marc M., Catholic Univ of America, Washington, United States","Three experiments explored aspects of virtual reality (VR) that may influence its utility for training in navigating architectural spaces. Taken together, these experiments suggest that the utility of virtual reality depends on characteristics of the user-virtual environment interface. In experiments testing the importance of movement control, full participant control of rotational and forward movement in VR led to nearly optimal training on a medium-sized building, but limited control in VR was worse than no control. Transparent walls, a VR possibility that goes beyond real-world options, were beneficial during training and on a direct measure of learning spatial layouts. Finally, in an experiment examining both training and transfer, VR training was similar to real-world training, and was quicker and transferred better to navigating a real-world building than floor-plan training. However, this held only when the testing route was traveled in the trained direction.",,"Computer aided instruction; Personnel training; User interfaces; Virtual reality; Navigational training; Human engineering",Article,"Final","",Scopus,2-s2.0-0032283823
"Castano Diego, Rinaldi Mary Christine, Tracey Michael R., Lathan Corinna","57198313210;7202149772;7005401571;6701652016;","Investigation of Virtual Reality training transfer to the real world",1998,"Proceedings of the Human Factors and Ergonomics Society","2",,,"1648","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032283817&partnerID=40&md5=47e7928ac6b45c4f35f481bd38c344b0","Catholic Univ of America, Washington, United States","Castano, Diego, Catholic Univ of America, Washington, United States; Rinaldi, Mary Christine, Catholic Univ of America, Washington, United States; Tracey, Michael R., Catholic Univ of America, Washington, United States; Lathan, Corinna, Catholic Univ of America, Washington, United States","A simple computer simulation of a real world task was used to create a Virtual Reality (VR) task. The hypothesis tested was that a group trained using VR would perform a motor task in the real world as well as, or better than, a group trained in the real world. An object manipulation task was performed using a real robot arm and a virtual robot arm implemented in a computer simulation. Results indicate that the group trained in the real world performs significantly better than the group trained in the virtual world.",,"Computer simulation; Personnel training; Robotic arms; Virtual reality; Virtual reality training; Ergonomics",Article,"Final","",Scopus,2-s2.0-0032283817
"Purcell Kevin, Monaghan Mickey","35957875700;7006637267;","Contextual interference as a training paradigm for virtual reality",1998,"Proceedings of the Human Factors and Ergonomics Society","2",,,"1646","",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032265498&partnerID=40&md5=c271bca88095e92289df84281b8c0fae","San Jose State Univ, San Jose, United States","Purcell, Kevin, San Jose State Univ, San Jose, United States; Monaghan, Mickey, San Jose State Univ, San Jose, United States","A taxonomy of contextual interference effects is presented, and its transfer of training in virtual reality (VR) simulation is discussed. The contextual interference effect is a learning phenomenon that suggests increased contextual variety can produce more elaborate and distinctive processing that leads to better delayed retention, especially under changed contextual conditions at the time of retrieval. VR is an effective training medium because of the contextual interference effect.",,"Cognitive systems; Computer aided instruction; Personnel training; Simulators; Virtual reality; Contextual interference effect; Ergonomics",Article,"Final","",Scopus,2-s2.0-0032265498
"Burn-Thornton K.E., Thorpe S.I.","6603308226;36856584700;","Enabling an understanding of ATM networks using virtual reality",1998,"IEE Colloquium (Digest)",,"454",,"7/1","7/5",,,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032266146&partnerID=40&md5=abd60d262d264500b9601cc8134a7643","Plymouth Univ, Plymouth, United Kingdom","Burn-Thornton, K.E., Plymouth Univ, Plymouth, United Kingdom; Thorpe, S.I., Plymouth Univ, Plymouth, United Kingdom","The historical development of transmission networks, from frame based information transfer (Frame Relay) to cell based information transfer (packet switching), which led to the emergence of ATM (Asynchronous Transfer Mode), often proves to be difficult for undergraduate students (and even postgraduate students) to readily comprehend. Furthermore the rationale behind the transmission standards for such networks, in order to meet the demands of an ever-expanding multimedia society, also presents some of the students with additional problems. We have found that a Virtual Reality (VR) representation of an ATM network can prove to be an enabling vehicle from which students can readily learn about transmission networks and the concepts of ATM. The students' learning process is readily enforced by their enjoyment of learning - this includes the exploration of the many nooks, and crannies, in the various layers present in the VR representation of the ATM network. VR has also proved to be equally successful at enabling a further understanding of the concepts, and various topologies, of Local Area Networks (LANs) and Wide Area Networks (WANs). Increased learning re-enforcement has been achieved by the students' further immersion in VR during the creation of their own ATM, LAN and WAN worlds.",,"Asynchronous transfer mode; Local area networks; Wide area networks; Virtual reality representation; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-0032266146
"Weiss P.L., Jessel A.S.","55435137100;6603707376;","Virtual reality applications to work",1998,"Work","11","3",,"277","293",,65,"10.3233/wor-1998-11305","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031725605&doi=10.3233%2fwor-1998-11305&partnerID=40&md5=7398e200de73e0a20dbb3eb9258b845d","School of Occupational Therapy, Faculty of Medicine, Hadassah-Hebrew University, POB 24026, 91240 Mount Scopus, Jerusalem, Israel","Weiss, P.L., School of Occupational Therapy, Faculty of Medicine, Hadassah-Hebrew University, POB 24026, 91240 Mount Scopus, Jerusalem, Israel; Jessel, A.S., School of Occupational Therapy, Faculty of Medicine, Hadassah-Hebrew University, POB 24026, 91240 Mount Scopus, Jerusalem, Israel","Virtual reality (VR) entails the use of advanced technologies, including computers and various multimedia peripherals, to produce a simulated (i.e. virtual) environment that users perceive as comparable to real world objects and events. With the aid of specially designed transducers and sensors, users interact with displayed images, moving and manipulating virtual objects, and performing other actions in a way that engenders a feeling of actual presence (immersion) in the simulated environment. The unique features and flexibility of VR give it extraordinary potential for use in work-related applications. It permits users to experience and interact with a life-like model or environment, in safety and at convenient times, while providing a degree of control over the simulation that is usually not possible in the real-life situation. The work-related applications that appear to be most promising are those that employ virtual reality for visualization and representation, distance communication and education, hands-on training, and orientation and navigation. This article presents an overview to the concepts of VR focusing on its applications in a variety of work settings. Issues related to potential difficulties in using VR including side effects and the transfer of skills learned in the virtual environment to the real world are also reviewed.","Computer simulation; Immersion; Side effects; Transfer; Virtual environments; Virtual reality","article; computer simulation; education; interpersonal communication; orientation; sensor; skill; training; transducer; virtual reality; work environment",Article,"Final","",Scopus,2-s2.0-0031725605
"Sung M., Park C.","57203866185;56140934000;","The avatar navigation of distributed virtual environment by using multiview client",1998,"Proceedings - 3rd Asia Pacific Computer Human Interaction, APCHI 1998",,, 704167,"108","113",,1,"10.1109/APCHI.1998.704167","https://www.scopus.com/inward/record.uri?eid=2-s2.0-11244263368&doi=10.1109%2fAPCHI.1998.704167&partnerID=40&md5=f072ef51488bfbf79f58998ca6f1b77c","Human Comput. Interaction Dept, Syst. Eng. Res. Inst, Eoueun-dong Yusung-ku, Taejun, 305-666, South Korea","Sung, M., Human Comput. Interaction Dept, Syst. Eng. Res. Inst, Eoueun-dong Yusung-ku, Taejun, 305-666, South Korea; Park, C., Human Comput. Interaction Dept, Syst. Eng. Res. Inst, Eoueun-dong Yusung-ku, Taejun, 305-666, South Korea","The multi participant VR system can more enhance the sense of reality than existing single user VR systems. But, we should be careful when designing the system, since the current Internet using TCP/IP cannot afford to deliver such a massive amount of information required for the real time constraint of a VR system. We introduce distributed network structure and protocols for multiple user virtual space navigation and interaction through their avatars. This network structure is composed of heterogeneous multi servers, multiview clients and protocols. The multiview client can give proper information to the avatar when navigating the distributed virtual environment. And, for minimizing traffic on the network, we designed the VSTP-the Virtual Space Transfer Protocol to meet real time constraints. The avatars have nine behaviors and recognize the state of each other by using the pre-defined VSTP protocol. © 1998 IEEE.","Avatar; Avatar behavior; Virtual Reality","Distributed computer systems; Human computer interaction; Interactive computer systems; Real time systems; Virtual reality; Amount of information; Avatar; Avatar behavior; Distributed network structures; Distributed Virtual Environments; Network structures; Real time constraints; Transfer protocol; Internet protocols",Conference Paper,"Final","",Scopus,2-s2.0-11244263368
"Pausch R., Proffitt D., Williams G.","57204319989;7005887383;55469196100;","Quantifying immersion in virtual reality",1997,"Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1997",,,,"13","18",,38,"10.1145/258734.258744","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009782003&doi=10.1145%2f258734.258744&partnerID=40&md5=8abf9e12747b0103845b53e53bc673a6","Carnegie Mellon University and University of Virginia, United States; University of Virginia, United States; Fakespace, Mountain View, Inc. 241 Polaris AveCA, United States","Pausch, R., Carnegie Mellon University and University of Virginia, United States; Proffitt, D., University of Virginia, United States; Williams, G., Fakespace, Mountain View, Inc. 241 Polaris AveCA, United States","Virtual Reality (VR) has generated much excitement but little formal proof that it is useful. Because VR interfaces are difficult and expensive to build, the computer graphics community needs to be able to predict which applications will benefit from VR. In this paper, we show that users with a VR interface complete a search task faster than users with a stationary monitor and a hand-based input device. We placed users in the center of the virtual room shown in Figure 1 and told them to look for camouflaged targets. VR users did not do significantly better than desktop users. However, when asked to search the room and conclude if a target existed, VR users were substantially better at determining when they had searched the entire room. Desktop users took 41% more time, re-examining areas they had already searched. We also found a positive transfer of training from VR to stationary displays and a negative transfer of training from stationary displays to VR. Copyright © 1997 by the Association for Computing Machinery, Inc.",,"Computer graphics; Virtual reality; Formal proofs; Input devices; Search tasks; Transfer of trainings; Virtual rooms; Interactive computer graphics",Conference Paper,"Final","",Scopus,2-s2.0-85009782003
"Pausch Randy, Proffitt Dennis, Williams George","57204319989;7005887383;55469196100;","Quantifying immersion in virtual reality",1997,"Proceedings of the ACM SIGGRAPH Conference on Computer Graphics",,,,"13","18",,155,,"https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030684946&partnerID=40&md5=5a107a9475f718f238fe210450502fab","Univ of Virginia, Charlottesville, United States","Pausch, Randy, Univ of Virginia, Charlottesville, United States; Proffitt, Dennis, Univ of Virginia, Charlottesville, United States; Williams, George, Univ of Virginia, Charlottesville, United States","Virtual Reality (VR) has generated much excitement but little formal proof that it is useful. Because VR interfaces are difficult and expensive to build, the computer graphics community needs to be able to predict which applications will benefit from VR. In this paper, we show that users with a VR interface complete a search task faster than users with a stationary monitor and a hand-based input device. We placed users in the center of the virtual room shown in Figure 1 and told them to look for camouflaged targets. VR users did not do significantly better than desktop users. However, when asked to search the room and conclude if a target existed, VR users were substantially better at determining when they had searched the entire room. Desktop users took 41% more time, re-examining areas they had already searched. We also found a positive transfer of training from VR to stationary displays and a negative transfer of training from stationary displays to VR.",,"Display devices; Graphical user interfaces; Human computer interaction; Subjective testing; Three dimensional computer graphics; Head mounted display (HMD); Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-0030684946
"Glantz K., Durlach N.I., Barnett R.C., Aviles W.A.","6603248945;7006481672;55663045100;36954569800;","Virtual reality (VR) and psychotherapy: Opportunities and challenges",1997,"Presence: Teleoperators and Virtual Environments","6","1",,"87","105",,66,"10.1162/pres.1997.6.1.87","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031061711&doi=10.1162%2fpres.1997.6.1.87&partnerID=40&md5=61a9f440114db055c95803c2e80b428f","Virtual Reality Therapies, Inc., MIT (VETREC), Cambridge, MA 02139, United States","Glantz, K., Virtual Reality Therapies, Inc., MIT (VETREC), Cambridge, MA 02139, United States; Durlach, N.I., Virtual Reality Therapies, Inc., MIT (VETREC), Cambridge, MA 02139, United States; Barnett, R.C., Virtual Reality Therapies, Inc., MIT (VETREC), Cambridge, MA 02139, United States; Aviles, W.A., Virtual Reality Therapies, Inc., MIT (VETREC), Cambridge, MA 02139, United States","Virtual reality technology is now being used to provide exposure and desensitization for a number of phobic conditions. In this paper, we first review these current applications and discuss the work needed to refine and expand these applications to phobias. We then comment briefly on some preliminary applications of VR technology to mental-health problems outside the domain of phobias. Finally, we consider ways in which VR might be used to further enhance psychotherapy and assist in the treatment of a wide vanety of disorders. Various possible interventions are discussed, along with the technological developments needed to make them possible.",,"adaptive behavior; article; behavior therapy; classification; cognitive therapy; computer interface; computer simulation; human; imagination; instrumentation; memory; methodology; phobia; psychological aspect; psychotherapy; technology; Adaptation, Psychological; Behavior Therapy; Cognitive Therapy; Computer Simulation; Desensitization, Psychologic; Humans; Imagination; Memory; Phobic Disorders; Psychotherapy; Technology Transfer; User-Computer Interface",Article,"Final","",Scopus,2-s2.0-0031061711
"Johnston R., Weiss P.","57214378842;57209896407;","Analysis of virtual reality technology applied in education",1997,"Minimally Invasive Therapy and Allied Technologies","6","2",,"126","127",,8,"10.3109/13645709709152716","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030992792&doi=10.3109%2f13645709709152716&partnerID=40&md5=832311a431961d040b77332fc495a51c","Virtual Environ. Technol. Laboratory, University of Houston, NASA Johnson Space Center, Houston, TX, United States; Institute for Defense Analyses, Alexandria, VA, United States; Univ. of California San Francisco, Department of General Surgery, San Francisco, CA, United States; 4106 Drake Street, #1, Houston, TX 77005, United States","Johnston, R., Virtual Environ. Technol. Laboratory, University of Houston, NASA Johnson Space Center, Houston, TX, United States, Institute for Defense Analyses, Alexandria, VA, United States, Univ. of California San Francisco, Department of General Surgery, San Francisco, CA, United States, 4106 Drake Street, #1, Houston, TX 77005, United States; Weiss, P., Virtual Environ. Technol. Laboratory, University of Houston, NASA Johnson Space Center, Houston, TX, United States, Institute for Defense Analyses, Alexandria, VA, United States","The use of virtual reality (VR) technology in training and education is an extension of 50 years of flight simulation research. As virtual reality becomes integrated into medical practices, the same questions that confronted the developers of flight simulation also apply to those in the medical domain. Does this technology work for training and education? If so, how well does it work? How much does it cost? Is it less expensive than the alternative training methods? In order to answer these questions the authors have taken a look at the same problems in the history of military simulation. The four techniques used to assess the value of military simulation have been, and still are, task analyses (a detailed, timed description of the actual tasks), standard experimental designs (i.e. the pre-test, post-test control group design), transfer-of-training experiments (where the evaluation metric is the actual task) and various combinations of the three. At present the only evaluation technique being used for VR in medical education is the task analysis.","Standard experimental designs; Task analyses; Transfer effectiveness ratio; Transfer of training","article; computer simulation; human; medical education; medical practice; minimally invasive surgery; priority journal; surgical training; virtual reality",Article,"Final","",Scopus,2-s2.0-0030992792
"Taylor Valerie E., Chen Jian, Disz Terrence L., Papka Michael E., Stevens Rick","7103021424;57206950347;6602403487;6603782792;7403202225;","Interactive virtual reality in simulations: Exploring lag time",1996,"IEEE computational science & engineering","3","4",,"46","54",,9,"10.1109/99.556512","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030408292&doi=10.1109%2f99.556512&partnerID=40&md5=3a32d9f6580627f6943422219173d258","Northwestern Univ, Evanston, United States","Taylor, Valerie E., Northwestern Univ, Evanston, United States; Chen, Jian, Northwestern Univ, Evanston, United States; Disz, Terrence L., Northwestern Univ, Evanston, United States; Papka, Michael E., Northwestern Univ, Evanston, United States; Stevens, Rick, Northwestern Univ, Evanston, United States","Virtual reality (VR) is increasingly being used as an immersive simulation tool in a wide range of engineering processes, such as virtual prototyping and product testing. However, the reliability of VR systems is strongly influenced by end-to-end lag or the delay between a user action and then display of the result of that action. Too much lag prevents interactivity and makes it difficult for users to control system behavior. The different components of lag, namely: tracking lag, simulation lag, synchronization lag, rendering lag, frame-rate-induced lag and network lag, are discussed.",,"Computer networks; Computer simulation; Computer software; Data communication systems; Data transfer; Graphical user interfaces; Interactive computer systems; Rapid prototyping; Synchronization; Three dimensional computer graphics; End to end lag time; Interactive virtual reality; Virtual reality",Article,"Final","",Scopus,2-s2.0-0030408292
"Strickland D., Marcus L.M., Mesibov G.B., Hogan K.","7101782936;7005305244;7004265105;7102252301;","Brief report: Two case studies using virtual reality as a learning tool for autistic children",1996,"Journal of Autism and Developmental Disorders","26","6",,"651","659",,151,"10.1007/BF02172354","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030463162&doi=10.1007%2fBF02172354&partnerID=40&md5=f728cd14b4b6418246a642c78a72e62c","North Carolina State University, United States; University of North Carolina at Chapel Hill, School of Medicine, United States","Strickland, D., North Carolina State University, United States; Marcus, L.M., University of North Carolina at Chapel Hill, School of Medicine, United States; Mesibov, G.B., University of North Carolina at Chapel Hill, School of Medicine, United States; Hogan, K., University of North Carolina at Chapel Hill, School of Medicine, United States","The children complied with most requests. Some of our teaching goals were limited by technology or space while others were limited by the difficulty of presenting a task to the children in a way that was understandable within their environment. However, the opportunity to introduce this technology to children was an important first step in exploring the potential VR offers to understanding the perceptual processes involved in autism. Our results indicate that the children will accept a VR helmet and wear it, identify familiar objects and qualities of these objects in their environment while using the helmet, and locate and move toward objects in their environment while wearing the helmet. More research is necessary to verify the potential in this area, especially to discover if learning experiences through VR generalize to other environments, but it appears virtual reality may provide a useful tool for furthering our understanding of autism and guiding efforts at treatment and intervention.",,"article; autism; case report; computer interface; female; human; learning; male; priority journal; school child; sensory stimulation; virtual reality; visual illusion; Autistic Disorder; Child; Computers; Female; Humans; Learning; Male; Reality Therapy",Article,"Final","",Scopus,2-s2.0-0030463162
"Arai Fumihito, Tanimoto Mitsutaka, Fukuda Toshio, Shimojima Koji, Matsuura Hideo, Negoro Makoto","7102069340;7201913084;36037263500;8390074000;57194376373;7006675006;","Distributed virtual environment for intravascular tele-surgery using multimedia telecommunication",1996,"Proceedings - Virtual Reality Annual International Symposium",,,,"79","85",,24,"10.1109/vrais.1996.490514","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029754824&doi=10.1109%2fvrais.1996.490514&partnerID=40&md5=f7730df44dce72d754c386efcd70b300","Nagoya Univ, Nagoya, Japan","Arai, Fumihito, Nagoya Univ, Nagoya, Japan; Tanimoto, Mitsutaka, Nagoya Univ, Nagoya, Japan; Fukuda, Toshio, Nagoya Univ, Nagoya, Japan; Shimojima, Koji, Nagoya Univ, Nagoya, Japan; Matsuura, Hideo, Nagoya Univ, Nagoya, Japan; Negoro, Makoto, Nagoya Univ, Nagoya, Japan","The number of the specialized medical doctors is decreasing. It is important to assist doctors operating surgical tools. To solve this problem, we propose a distributed VR system using multimedia tele-communication for training, diagnosis, and assistance in surgery. To realize this system, it is important to exchange high quality moving pictures. Here we use high speed optical fiber network with ATM (Asynchronous Transfer Mode). ATM has excellent features such as bandwidth allocation, which is suitable for multimedia communication on computer networks. Based on this new information infrastructure, we built a prototype tele-surgery system for the intravascular neurosurgery. We made a virtual simulator for the operation of a catheter, that is designed for minimum invasive surgery inside complex and narrow brain blood vessels. Force display and visual assistance method are proposed to assist the doctor. We did teleoperation experiments between Nagoya and Tokyo, about 350 km away each other, using high speed optical fiber network, and evaluated effectiveness of the proposed system.",,"Asynchronous transfer mode; Distributed computer systems; Fiber optic networks; Medical applications; Neurosurgery; Remote control; Telecommunication systems; Distributed virtual environment; Intravascular telesurgery; Multimedia telecommunication; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-0029754824
"Paasch R., Van Dam A., Bryson S., Robinett W.","56895926900;7005933490;35744574400;8647587600;","Tutorial: Implementing virtual reality",1994,"Conference on Human Factors in Computing Systems - Proceedings","1994-April",,,"399","400",,,"10.1145/259963.260525","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943539346&doi=10.1145%2f259963.260525&partnerID=40&md5=72e40e3245d093103345b3d96eb90f5e","Computer Science Department, Thornton Hall, University of Virginia, Charlottesville, VA  22903-2442, United States; Brown University, United States; CSC/NASA Ames, United States","Paasch, R., Computer Science Department, Thornton Hall, University of Virginia, Charlottesville, VA  22903-2442, United States; Van Dam, A., Brown University, United States; Bryson, S., CSC/NASA Ames, United States; Robinett, W.","While virtual reality systems seem to hold great promise for facilitating the use of computers, actual virtual reality development is fraught with difficulties. These difficulties include limited hardware, uncertain interface paradigms and the integration of various components and concepts into a high-performance system. This course addresses these and other difficulties. We begin with an introduction to the virtual reality field, both in reference to computer graphics and in terms of the current state of the art. Interface hardware will be surveyed, emphasizing the performance limitations of current products. The human factors impact of the limited interface devices will be discussed on both a theoretical and phenomenological level. After setting this background, the external design of a virtual environment will be discussed from the point of view of how that environment is experienced by the user. The objects that populate a virtual environment will be discussed both in the abstract and through examples. The implications of the interactive user interface on system performance will be a primary focus. The actual implementation of the virtual environment will be addressed, discussing both the software platform and the overall system. The course will end with a discussion of virtual reality development on a budget and lessons learned about how to get a virtual reality project going from start to a useful application. By the end of the tutorial, attendees should be comfortable with the major issues involved in starting a VR lab and creating a complete, working VR system. These issues include limited hardware, uncertain interface paradigms and the integration of various components and concepts into a high-performance system. We begin with an introduction to the virtual reality field, both in reference to computer graphics and in terms of the current state of the art. Interface hardware will be surveyed, emphasizing the performance limitations of current products. The human factors impact of the limited interface devices will be discussed on both a theoretical and phenomenological level. After setting this background, the external design of a virtual environment will be discussed from the point of view of how that environment is experienced by the user. The objects that populate a virtual environment will be discussed both in the abstract and through examples. The implications of the interactive user interface on system performance will be a primary focus. The actual implementation of the virtual environment will be addressed, discussing both the software platform and the overall system. The course will end with a discussion of virtual reality development on a budget and lessons learned about how to get a virtual reality project going from start to a useful application. This course is intended for those who wish to know how to design and implement working high performance immersive interactive virtual environments. Moderate maturity in three-dimensional graphics programming is assumed, including transformation matrices, use of graphics libraries and basic cartesian geometry. No knowledge of virtual reality is required. After taking this course, the attendee will have a greater understanding of how to develop a fully immersive interactive virtual reality system. The attendee will know how to select the hardware for a particular virtual environment, outline the appropriate software structure, and implement that structure in a way which will give the greatest possible performance. © 1994 ACM.","Computer graphics; Human factors; Immersive environments; Software development environments; Virtual reality","Budget control; Computer graphics; Computer hardware; Computer software; Curricula; Hardware; Human engineering; Linear transformations; Software design; Surveys; Teaching; Technology transfer; User interfaces; High performance systems; Immersive environment; Interactive user interfaces; Interactive virtual environments; Interactive virtual reality; Software development environment; Three-dimensional graphics; Transformation matrices; Virtual reality",Conference Paper,"Final","",Scopus,2-s2.0-84943539346
"Gauvin D.V., Harland R.D., Criado J.R., Michaelis R.C., Holloway F.A.","7006585393;35552637600;57208856599;13204165800;7005319622;","The discriminative stimulus properties of ethanol and acute ethanol withdrawal states in rats",1989,"Drug and Alcohol Dependence","24","2",,"103","113",,23,"10.1016/0376-8716(89)90072-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0024452299&doi=10.1016%2f0376-8716%2889%2990072-0&partnerID=40&md5=337ee0417521479f98d44221dfb17787","University of Oklahoma Health Sciences Center, Department of Psychiatry and Behavioral Sciences, Oklahoma City, OK 73190-3000, United States","Gauvin, D.V., University of Oklahoma Health Sciences Center, Department of Psychiatry and Behavioral Sciences, Oklahoma City, OK 73190-3000, United States; Harland, R.D., University of Oklahoma Health Sciences Center, Department of Psychiatry and Behavioral Sciences, Oklahoma City, OK 73190-3000, United States; Criado, J.R., University of Oklahoma Health Sciences Center, Department of Psychiatry and Behavioral Sciences, Oklahoma City, OK 73190-3000, United States; Michaelis, R.C., University of Oklahoma Health Sciences Center, Department of Psychiatry and Behavioral Sciences, Oklahoma City, OK 73190-3000, United States; Holloway, F.A., University of Oklahoma Health Sciences Center, Department of Psychiatry and Behavioral Sciences, Oklahoma City, OK 73190-3000, United States","Twelve male Sprague-Dawley rats were trained in a standard two-choice Drug 1-Drug 2 discrimination task utilizing 3.0 mg/kg chlordiazepoxide (CDP, an anxiolytic drug) and 20 mg/kg pentylenetetrazol (PTZ, an anxiogenic drug) as discriminative stimuli under a VR 5-15 schedule of food reinforcement. Saline tests conducted at specific time points after acute high doses of ethanol (3.0 and 4.0 g/kg) indicated a delayed rebound effect, evidenced by a shift to PTZ-appropriate responding. Insofar as such a shift in lever selection indexes a delayed anxiety-like state, this acute 'withdrawal' reaction can be said to induce an affective state similar to that seen with chronic ethanol withdrawal states. Ethanol generalization tests:1 resulted in a dose-and time-dependent biphasic generalization to CDP, (2) failed to block the PTZ stimulus and (3) failed to block the time- and dose-dependent elicitation of an ethanol-rebound effect. These data suggest that ethanol's anxiolytic effects are tenuous. © 1989.","drug discrimination; ethanol; ethanol-rebound; homeostatic opponent-process; pentylenetetrazol","alcohol; chlordiazepoxide; pentetrazole; animal experiment; nonhuman; priority journal; rat; withdrawal syndrome; Affect; Alcohol Drinking; Alcohol Withdrawal Delirium; Alcoholic Intoxication; Animal; Arousal; Chlordiazepoxide; Choice Behavior; Comparative Study; Cues; Dose-Response Relationship, Drug; Generalization (Psychology); Male; Pentylenetetrazole; Psychoses, Alcoholic; Rats; Rats, Inbred Strains; Support, U.S. Gov't, P.H.S.",Article,"Final","",Scopus,2-s2.0-0024452299
"Haavik S.F., Spradlin J.E., Altman K.I.","6603602767;7003428942;7004662003;","Generalization and Maintenance of Language Responses: A Study Across Trainers, Schools, and Home Settings",1984,"Behavior Modification","8","3",,"331","359",,3,"10.1177/01454455840083003","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0021177018&doi=10.1177%2f01454455840083003&partnerID=40&md5=a0c9e4684a146224882bd886d7565a5d","University of Kansas, United States","Haavik, S.F., University of Kansas, United States; Spradlin, J.E., University of Kansas, United States; Altman, K.I., University of Kansas, United States","Manipulating the reinforcement contingencies in training and generalization settings facilitated school-to-home generalization of language responses. Four developmentally disabled preschool children were trained in a one-to-one school setting to point to two sets of pictures in multiple baseline fashion. Initial generalization in the presence of a second trainer in school and the mother at home was documented in both no-reinforcement and intermittent reinforcement probe conditions (in which correct responses to nonprobe items were reinforced on a VR-3 schedule). High levels of correct responding with the second trainer at school were maintained in both the no-reinforcement and intermittent reinforcement conditions, regardless of the sequence of conditions. The reversal design showed that for three of the four children, intermittent reinforcement was necessary to maintain high levels of correct responding at home. Deterioration, increased variability, and, in some instances, extinction occurred when the no-reinforcement condition was in effect in the home setting. © 1984, SAGE PUBLICATIONS, INC. All rights reserved.",,"behavior; case report; central nervous system; human; language; preschool child; reinforcement; therapy; Behavior Therapy; Child, Preschool; Education of Mentally Retarded; Female; Generalization (Psychology); Human; Language Development Disorders; Language Disorders; Male; Social Environment; Support, Non-U.S. Gov't",Article,"Final","",Scopus,2-s2.0-0021177018
"Wilcox B.L., Teghtsoonian M.","7101808809;6701839405;","The control of relative size by pictorial depth cues in children and adults",1971,"Journal of Experimental Child Psychology","11","3",,"413","429",,14,"10.1016/0022-0965(71)90046-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0015077659&doi=10.1016%2f0022-0965%2871%2990046-4&partnerID=40&md5=e1baf2c424af26484515e8b3b96687dd","Smith College, United States","Wilcox, B.L., Smith College, United States; Teghtsoonian, M., Smith College, United States","A developmental study of the relation between apparent size and pictorial depth demonstrated the usefulness of operant techniques in establishing equivalent differential responding and in testing stimulus equivalence in different age groups. A visual area discrimination was established by reinforcing, on a VR schedule, responses to the larger area in each pair of figures. Presenting pairs of figures of equal area on backgrounds with pictorial depth cues produced higher response rates to the pictorially further. This size ""illusion"" created by pictorial cues to depth proved very effective for adults, moderately effective for 9-year-olds, ineffective for 3-year-olds. © 1971.",,"adult; age; article; association; child; child development; depth perception; discrimination learning; female; human; illusion; learning; male; pattern recognition; perception; perceptive discrimination; preschool child; reinforcement; vision; Adult; Age Factors; Child; Child Development; Child, Preschool; Cues; Depth Perception; Discrimination (Psychology); Discrimination Learning; Female; Form Perception; Generalization (Psychology); Human; Illusions; Male; Reinforcement (Psychology); Size Perception; Transfer (Psychology); Visual Perception",Article,"Final","",Scopus,2-s2.0-0015077659
